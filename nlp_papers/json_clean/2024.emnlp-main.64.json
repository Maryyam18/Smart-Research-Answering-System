{
  "paperid": "2024.emnlp-main.64",
  "title": "A Survey on In-context Learning",
  "authors": [
    "Qingxiu Dong",
    "Lei Li",
    "Damai Dai",
    "Ce Zheng",
    "Jingyuan Ma",
    "Rui Li",
    "Heming Xia",
    "Jingjing Xu",
    "Zhiyong Wu",
    "Baobao Chang"
  ],
  "year": 2024,
  "abstract": "With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, prompt designing strategies, and related analysis. Additionally, we explore various ICL application scenarios, such as data engineering and knowledge updating. Finally, we address the challenges of ICL and suggest potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.",
  "sections": [
    {
      "heading": "Introduction",
      "text": "With the scaling of model size and data size (Brown et al., 2020;Chowdhery et al., 2023;OpenAI, 2023;Touvron et al., 2023a,b), large language models (LLMs) demonstrate the in-context learning (ICL) ability, that is, learning from a few examples in the context. Many studies have shown that LLMs can perform a series of complex tasks through ICL, such as solving mathematical reasoning problems (Wei et al., 2022c). These strong abilities have been widely verified as emerging abilities for large language models (Wei et al., 2022b). The key idea of in-context learning is to learn from analogy. Figure 1 gives an example that describes how language models make decisions via ICL. First, ICL requires a few demonstration examples to form a prompt context. These examples are usually written in natural language templates. Then, ICL concatenates a query question and the piece of prompt context together to form the input, which is then fed into the language model for prediction. Different from supervised learning, which requires a training stage that uses backward gradients to update model parameters, ICL does not perform parameter updates. The model is expected to learn the pattern hidden in the demonstration and accordingly make the right prediction. As a new paradigm, ICL has multiple attractive advantages. First, since the demonstration is written in natural language, it provides an interpretable interface to communicate with LLMs (Brown et al., 2020). This paradigm makes it much easier to incorporate human knowledge into LLMs by changing the demonstration and templates (Liu et al., 2022;Lu et al., 2022;Wei et al., 2022c;Wu et al., 2023b). Second, in-context learning is similar to the decision process of human beings by learning from analogy (Winston, 1980). Third, compared to supervised training, ICL is a training-free learning framework. This could not only greatly reduce the computational costs for adapting the model to new tasks, but also make language-model-as-aservice (Sun et al., 2022) possible and can be easily applied to large-scale real-world tasks. Despite being promising, there are also interesting questions and intriguing properties that require further investigation in ICL. Although a range of vanilla GPT models show excellent ICL capability, several studies have found that this capability can be significantly improved through adaptation during pretraining (Min et al., 2022b;Li et al., 2024c). Moreover, the performance of ICL is sensitive to specific settings, including the prompt template, the selection and order of demonstration examples, and other factors (Wang et al., 2023e;Liu et al., 2024b). Additionally, optimizing the conciseness of demonstration examples and improving the computational efficiency of ICL are critical areas of ongoing research (Liu et al., 2024a). Furthermore, despite preliminary explanations (Dai et al., 2023a;Jiang, 2023), the underlying working mechanism of ICL remains unclear and requires further investigation. With the rapid growth of studies in ICL, our survey aims to sensitize the community toward the current progress. In the following sections, we delve into an in-depth discussion of related studies, and we summarize the taxonomy in Figure 2 and the key findings in Appendix A. We highlight the challenges and potential directions and hope our work provide a useful roadmap for beginners interested in this area and shed light on future research."
    },
    {
      "heading": "Definition and Formulation",
      "text": "Following Brown et al. (2020), we here provide a formal definition of in-context learning: In-context learning is a paradigm that allows language models to learn tasks given only a few examples in the form of demonstration. Formally, given a query input text x and a set of candidate answers Y = {y 1 , . . . , y m }, a pretrained language model M takes the candidate an-swer with the maximum score as the prediction, 1 conditioned a demonstration set C. C contains an optional task instruction I and k demonstration examples, thus C = {I, s(x 1 , y 1 ), . . . , s(x k , y k )} or C = {s ′ (x 1 , y 1 , I), . . . , s ′ (x k , y k , I)}, where s ′ (x i , y i , I) is an example written in natural language according to the task. Depending on whether k and the demonstration examples belong to the same task, it can be categorized as task-specific ICL and cross-task ICL. In the latter, different examples have their own instructions. The likelihood of a candidate answer y j comes from a scoring function f on the whole input sequence: The final predicted label ŷ is the candidate answer with the highest probability: According to the definition, we can see that ICL differs from related concepts as follows: (1) Prompt Learning: prompts can be discrete templates or soft parameters that encourage the model to predict the desired output. ICL can be regarded as a subclass of prompt tuning where the demonstration examples are part of the prompt. Liu et al. (2023c) made a thorough survey on prompt learning, but ICL was not included in their study. (2) Few-shot Learning: few-shot learning is a general machine learning approach that involves adapting model parameters to perform a task with a limited number of supervised examples (Wang and Yao, 2019). In contrast, ICL does not require parameter updates and is directly performed on pretrained LLMs."
    },
    {
      "heading": "Model Training",
      "text": "Although LLMs have demonstrated promising ICL capability directly, many studies revealed that these ICL capabilities can be further enhanced through specialized training before inference (Chen et al., 2022;Gu et al., 2023;Shi et al., 2024)."
    },
    {
      "heading": "Pretraining",
      "text": "One straightforward direction to boost the ICL capability of LLMs is through pretraining or continual pretraining. For instance, Gu et al. (2023) and Shi et al. (2024) proposed to reorganize pretraining corpora by aggregating related contexts, 1 Y could be class labels or a set of free-text phrases. making models learn to reason across prior demonstrations. Differently, Li et al. (2024c) introduced a meta-distillation pretraining process, which allows LLMs to reason with distilled demonstration vectors, thereby enhancing ICL efficiency without compromising its effectiveness."
    },
    {
      "heading": "Warmup",
      "text": "Another way to enhance ICL ability is adding a continual training stage between pretraining and ICL inference, which we call model warmup for short. Warmup is an optional procedure for ICL, which adjusts LLMs before inference by modifying or adding parameters. As most pretraining data are not tailored for ICL (Chen et al., 2022), researchers have introduced various warmup strategies to bridge the gap between pretraining and ICL inference. Both Min et al. (2022b) and Wang et al. (2022b) proposed to continually finetune LLMs on a broad range of tasks with multiple demonstration examples, which boosts ICL abilities. To encourage the model to learn input-label mappings from the context, Wei et al. (2023a) proposed symbol tuning, which substitutes natural language labels (e.g., \"positive/negative sentiment\") with arbitrary symbols (e.g., \"foo/bar\"). Chen et al. (2022) proposed a self-supervised method to align raw text with ICL formats in downstream tasks. Besides, multiple studies have indicated the potential value of instructions (Mishra et al., 2021;Wei et al., 2022a). Tuning the 137B LaMDA-PT (Thoppilan et al., 2022) on over 60 datasets verbalized via natural language instruction templates, FLAN (Wei et al., 2022a) improves the ability of LLMs to follow instructions, boosting both the zero-shot and few-shot ICL performance. Chung et al. (2022) and Wang et al. (2022b) proposed to further scale up instruction tuning with more than 1000+ task instructions."
    },
    {
      "heading": "Prompt Designing",
      "text": "In this section, we focus on the principles of ICL during inference, including demonstration organization ( §4.1) and instruction formatting ( §4.2) ."
    },
    {
      "heading": "Demonstration Organization",
      "text": "Many studies have shown that the performance of ICL strongly relies on the demonstration surface, including the selection, formatting, and ordering of demonstration examples (Zhao et al., 2021;Lu et al., 2022). In this subsection, we survey demonstration organization strategies and classify them into three categories, as shown in Table 1."
    },
    {
      "heading": "Demonstration Selection",
      "text": "Demonstrations selection aims to answer a fundamental question: Which samples are good examples for ICL? We categorize the related studies into two approaches: unsupervised methods based on predefined metrics and supervised methods. Unsupervised Method A straightforward approach to selecting ICL examples is to choose the nearest neighbors of input instances based on their similarities (Liu et al., 2022;Tanwar et al., 2023;Qin et al., 2023). Distance metrics, such as L2 distance or cosine similarity based on sentence embeddings, are commonly used for this purpose. For example, Liu et al. (2022) proposed KATE, the first kNN-based unsupervised retriever for selecting in-context examples. Similarly, k-NN cross-lingual demonstrations can be retrieved for multi-lingual ICL to strengthen source-target language alignment (Tanwar et al., 2023). Su et al. (2023) proposed to combine graphs and confidence scores to select diverse and representative examples. In addition to distance metrics, mutual information (Sorensen et al., 2022) and perplexity (Gonen et al., 2023) have proven valuable for prompt selection without labeled examples or specific LLMs. Furthermore, using output scores of LLMs as unsupervised metrics has shown effectiveness in demonstration selection (Wu et al., 2023b;Nguyen and Wong, 2023;Li and Qiu, 2023). Particularly, Wu et al. (2023b) selected the best subset permutation of kNN examples based on the code length for data transmission to compress label y given x and C. Li and Qiu (2023) used infoscore, i.e., the average of P (y|x i , y i , x)P (y|x) for all (x, y) pairs in a validation set with a diversity regularization. Supervised Method Though off-the-shelf retrievers offer convenient services for extensive NLP tasks, they are heuristic and sub-optimal due to the lack of task-specific supervision. To address this issue, numerous supervised methods have been developed (Rubin et al., 2022;Ye et al., 2023;Wang et al., 2023e;Zhang et al., 2022a). EPR (Rubin et al., 2022) introduced a two-stage method to train a dense retriever for demonstration selection. For a specific input, it first utilized unsupervised methods (e.g., BM25) to recall similar examples as candidates and then used this data to build a supervised dense retriever. Following EPR, Li et al. (2023d) adopted a unified demonstration retriever to select demonstrations across different tasks. Unlike prior work that retrieves individual demonstrations, Ye et al. (2023) proposed retrieving entire demonstration sets to model inter-relationships between examples. Additionally, Mavromatis et al. (2023) introduced AdaICL, a model-adaptive method that employs LLM to predict the unlabeled data set, generating an uncertainty score for each instance. Based on prompt tuning, Wang et al. (2023e) viewed LLMs as topic models that can infer concepts θ from a few demonstrations and generate tokens based on these concepts. They represent latent concepts with task-related concept tokens, which are learned to maximize P (y|x, θ). Demonstrations are selected based on their likelihood to infer the concept variable using P (θ|x, y). Additionally, reinforcement learning was introduced by Zhang et al. (2022a) for example selection. They formulated demonstration selection as a Markov decision process (Bellman, 1957) and selected demonstrations via Q-learning. The action is choosing an example, and the reward is defined as the accuracy of a labeled validation set. In order to have a more intuitive comparison of the performance of several unsupervised methods, we select topk (Liu et al., 2022), votek (Su et al., 2023), mdl (Wu et al., 2023b) to conduct experiments. The result is shown in Table 2. The details of the experiment can be found in Appendix B."
    },
    {
      "heading": "Demonstration Reformatting",
      "text": "In addition to directly selecting examples from training data, another research trend involves utilizing LLMs to reformat the representation of existing demonstrations (Kim et al., 2022;Yang et al., 2023a;Hao et al., 2022b;Yang et al., 2023b;Liu et al., 2024a;Li et al., 2024a). For instance, Kim et al. (2022) proposed generating demonstrations directly from LLMs to reduce the reliance on external demonstration data. Structured Prompting (Hao"
    },
    {
      "heading": "Demonstration Acquisition LLMs Features",
      "text": "Demonstration Selection KATE (Liu et al., 2022) Human design GPT-3 KNN Selection MI (Sorensen et al., 2022) Human design GPT-3 Mutual Information EPR (Rubin et al., 2022) Human design GPT-{J, 3}/CodeX Score-based Retrieval IDS (Qin et al., 2023) Human design GPT-3.5 Iterative Selection AdaICL (Mavromatis et al., 2023) Human design GPT-{J, Neo} Selective Demonstration UDR (Li et al., 2023d) Human design GPT-Neo-2.7B Unified Retrieval Demonstration Reformatting SG-ICL (Kim et al., 2022) LM generated GPT-J Auto Demonstration Generation AutoICL (Yang et al., 2023a) LM generated GPT-3.5-Turbo-0301 Reasoning Path Generation MSP (Yang et al., 2023b) Human design GPT series Adjusting Demonstration Weight ICV (Liu et al., 2024a) Human Table 2: Fair comparison of demonstration selection methods. CQA and News are abbreviations of Commonsense QA and AG News, respectively. The best results are bolded. Our experiments on topk (Liu et al., 2022), votek (Su et al., 2023), mdl (Wu et al., 2023b) show that the effectiveness of ICL example selection methods are model-dependent. On GPT-2, the mdl method performs the best, while on the other three models, topk performs the best. et al., 2022b) proposed to encode demonstration examples separately with special positional embeddings, which are then provided to the test examples using a rescaled attention mechanism. Diverging from these methods, other approaches focus on modifying the latent representation of demonstrations (Liu et al., 2024a; Li et al., 2024a). Specifically, Liu et al. (2024a) developed In-Context Vectors (ICVs) derived from the latent embeddings of demonstration examples in LLMs. These ICVs are used during inference to adjust the latent states of the LLM, thereby enhancing the model's ability to follow the demonstrations more effectively. 4.1.3 Demonstration Ordering Ordering the selected demonstration examples is also an important aspect of demonstration organization. Lu et al. (2022) have proven that order sensitivity is a common problem and always exists for various models. To handle this problem, previous studies have proposed several training-free methods for sorting demonstration examples. Particularly, Liu et al. (2022) arranged examples based on their proximity to the input, positioning the closest example as the rightmost demonstration. Lu et al. ( 2022) introduced global and local entropy metrics, finding a positive correlation between these metrics and the ICL performance. Consequently, they utilized the entropy metric to determine the optimal demonstration ordering. Additionally, ICCL (Liu et al., 2024b) suggested ranking demonstrations from simple to complex, thereby gradually increasing the complexity of demonstration examples during the inference process."
    },
    {
      "heading": "Instruction Formatting",
      "text": "A common way to format demonstrations is concatenating examples (x 1 , y 1 ), . . . , (x k , y k ) with a template T directly. However, in some tasks that need complex reasoning (e.g., math word problems and commonsense reasoning), it is not easy to learn the mapping from x i to y i with only k demonstrations. Although template engineering has been studied in prompting (Liu et al., 2023c), some researchers aim to design a better format of demonstrations for ICL by describing tasks with the instruction I. Honovich et al. (2023) found that given several demonstration examples, LLMs can generate task instructions themselves. Considering the generation abilities of LLMs, Zhou et al. (2023c) proposed an Automatic Prompt Engineer for automatic instruction generation and selection. Method Target Efficiency Coverage Stability Direct M(y j | C, x) +++ + + PPL PPL(S j ) + +++ + Channel M(x | C, y j ) + + ++ Table 3: Summary of different scoring functions. Coverage refers to task coverage. The qualitative results for 'Efficiency' and 'Stability' metrics are elaborated in Table 4 and Table 5, respectively. To further improve the quality of the automatically generated instructions, several strategies have proposed using LLMs to bootstrap off its own generations (Wang et al., 2023f;Chen et al., 2024). Additionally, chain-of-thought (CoT) (Wei et al., 2022c) introduces intermediate reasoning steps between inputs and outputs to enhance problem-solving and comprehension. Recent advancements have also emphasized the process of enhancing step-by-step reasoning in models (Zhang et al., 2023c;Wang et al., 2022a;Zhou et al., 2023a)."
    },
    {
      "heading": "Scoring Function",
      "text": "The scoring function determines how to transform the predictions of a language model into an estimation of the likelihood of a specific answer. The Direct method uses the conditional probability of candidate answers represented by tokens in the model's vocabulary (Brown et al., 2020). The answer with the highest probability is selected as the final answer, but this method restricts template design by requiring answer tokens to be at the end of input sequences. Perplexity (PPL) is another commonly used metric that computes the sentence perplexity of the entire input sequence S j = {C, s(x, y j , I)}, which includes tokens from demonstration examples C, the input query x, and the candidate label y j . PPL evaluates the probability of the sentence, eliminating token position limitations but requiring additional computation time. Min et al. (2022a) proposed using channel models (Channel) to compute the conditional probability in reverse, estimating the likelihood of the input query given the label. This approach requires language models to generate every token in the input, potentially boosting performance under imbalanced training data. We summarize all three scoring functions in Table 3. Note that in Table 3, 'Efficiency' refers to the language model inference latency; 'Coverage' reflects whether the method utilizes the output probability of the local or all token positions in the input sequence; and 'Stability' indicates whether the in-context learning ability is easily affected by changes in the demonstration examples."
    },
    {
      "heading": "Analysis",
      "text": "To understand ICL, recent studies attempt to investigate what influence ICL performance (Shin et al., 2022;Yoo et al., 2022;Kossen et al., 2023) and why ICL works (Dai et al., 2023a;Irie et al., 2022). In this section, we present a detailed elaboration of influencing factors ( §5.1) and learning mechanisms ( §5.2) of ICL, as illustrated in Figure 4."
    },
    {
      "heading": "Influencing Factors",
      "text": "We discuss relevant research addressing what influences ICL performance, including factors both in the pretraining stage and in the inference stage."
    },
    {
      "heading": "Pretraining Stage",
      "text": "We first introduce factors that influence the pretraining stage. The diversity of pretraining corpora significantly impacts ICL performance (Shin et al., 2022;Yadlowsky et al., 2023;Raventós et al., 2023). In particular, Shin et al. (2022) found that the source domain is more important than the corpus size, suggesting that combining multiple corpora may lead to the emergence of ICL ability. Similarly, Raventós et al. (2023) empirically identified a task diversity threshold beyond which LLMs exhibit strong ICL capabilities in unseen tasks. Another line of research investigates the impact of data distribution on ICL (Chan et al., 2022;Wies et al., 2023). For instance, Chan et al. ( 2022) demonstrated that ICL capability emerges when the training data exhibits specific distributional properties, such as burstiness, wherein items appear in clusters rather than being uniformly distributed over time. Beyond these works, several studies have investigated the impact of model architecture and training process on ICL performance (Wei et al., 2022b;Brown et al., 2020;Ding et al., 2024). Wei et al. (2022b) investigated the emergent abilities of many large-scale models on multiple tasks. They suggested that a pretrained model acquires some emergent ICL abilities when it reaches a large scale of pretraining steps or model parameters. Ding et al. (2024) pointed out that the in-context samples should attend to each other during inference, indicating that current causal LLMs may lead to suboptimal ICL performance."
    },
    {
      "heading": "Inference Stage",
      "text": "During inference, there are also multiple properties of demonstration examples that influence ICL performance. Min et al. (2022c) proved that inputlabel settings such as the pairing format, the exposure of label space, and the input distribution contribute substantially to ICL performance. However, contrary to the conclusion in Min et al. (2022c) that input-label mapping matters little to ICL, latter studies showed that the accurate mapping influence ICL performance significantly (Yoo et al., 2022;Pan et al., 2023a;Tang et al., 2023a). Wei et al. (2023b) further pointed that flipped or semanticallyunrelated input-label mapping also can be learned. From the perspective of demonstration construction, recent literature focuses on the diversity and simplicity of demonstrations (An et al., 2023), the order of samples (Lu et al., 2022;Zhang et al., 2022b;Liu et al., 2023b), and the similarity between demonstrations and queries (Liu et al., 2022). For example, Liu et al. (2022) found that demonstration samples with embeddings closer to those of the query samples typically yield better performance than those with more distant embeddings. Notably, despite efforts to refine demonstrations to optimize the performance, there still remain clear feature biases during ICL inference (Si et al., 2023). Overcoming strong prior biases and ensuring the model gives equal weight to all contextual information remain challenges (Kossen et al., 2023)."
    },
    {
      "heading": "Learning Mechanism",
      "text": "From a learning mechanism perspective, we delve into the research addressing why ICL is effective."
    },
    {
      "heading": "Functional Modules",
      "text": "The ICL capability is intimately connected to specific functional modules within Transformers. As one of the core components, the attention module is a focal point in the study of ICL mechanism (Olsson et al., 2022;Bietti et al., 2023;Dai et al., 2023a;Irie et al., 2022;Li et al., 2023c;Gao et al., 2023;Zhang et al., 2023b). Particularly, Olsson et al. (2022) identified specific attention heads, referred to as \"induction heads\", that can replicate previous patterns for next-token prediction, thus progressively developing ICL capabilities. Additionally, Wang et al. (2023b) focused on the information flow in Transformers and found that during the ICL process, demonstration label words serve as anchors, which aggregate and distribute key information for the final prediction."
    },
    {
      "heading": "Theoretical Interpretation",
      "text": "In this subsection, we introduce the theoretical interpretations of ICL from different views. Bayesian View In the Bayesian framework, ICL is explained as implicit Bayesian inference, where models perform ICL by identifying a shared latent concept among examples (Xie et al., 2022;Wies et al., 2023;Ahuja et al., 2023;Jiang, 2023;Wang et al., 2023e). Additional perspectives suggest that LLMs encode the Bayesian Model Averaging algorithm via the attention mechanism (Zhang et al., 2023b). As the number of in-context examples increases, implicit Bayesian inference becomes analogous to kernel regression (Han et al., 2023a). Gradient Descent View Gradient descent offers another valuable lens for understanding ICL. Dai et al. (2023a) identified a dual form between Transformer attention and gradient descent, finding that GPT-based ICL behaves similarly to explicit finetuning from multiple perspectives. Other studies have attempted to establish connections between ICL and gradient descent in simplified regression settings (von Oswald et al., 2023;Ahn et al., 2023;Mahankali et al., 2023;Li et al., 2023c). For in-stance, von Oswald et al. (2023) showed that linear attention-only Transformers with manually constructed parameters are closely related to models learned by gradient descent. Li et al. (2023c) found that self-attention-only Transformers exhibit similarities with models trained via gradient descent. However, the simplified settings used in these studies have led to debates about the direct applicability of these connections in real-world contexts (Shen et al., 2024). Fu et al. (2023) argued that Transformers perform ICL on linear regression using higher-order optimization techniques rather than gradient descent. Other Views Beyond connecting ICL with a single algorithm, researchers have analyzed it from various perspectives, including ability decoupling, algorithmic learning, and information theory. Pan et al. (2023b) decoupled ICL capabilities into task recognition ability and task learning ability, each manifesting under different conditions. Another typical theory abstracts ICL as an algorithmic learning problem (Akyürek et al., 2023;Garg et al., 2022;Li et al., 2023e;Bai et al., 2023b), where Transformers dynamically select algorithms, such as gradient descent and ridge regression, tailored to different ICL instances. Moreover, Hahn and Goyal (2023) utilized information theory to show an error bound for ICL under linguistically motivated assumptions, explaining how next-token prediction can bring about the ICL ability. These analytical studies have taken an essential step to explain ICL. However, most of them focused on simple tasks and small models. Extending analysis on extensive tasks and large models may be the next step to be considered."
    },
    {
      "heading": "Application",
      "text": "Given its user-friendly interface and lightweight prompting method, ICL has broad applications on traditional NLP tasks (Kim et al., 2022;Min et al., 2022b;Zhu et al., 2023b). Particularly, by using demonstrations that explicitly guide the reasoning process, ICL manifests remarkable effects on tasks requiring complex reasoning (Wei et al., 2022c;Li et al., 2023b;Zhou et al., 2022) and compositional generalization (Zhou et al., 2023a). We explore several emerging and prevalent applications of ICL, including data engineering, model augmentation, and knowledge updating. 1) Data Engineering: Unlike traditional methods such as human annotation and noisy automatic annotation, ICL generates relatively high-quality data at a lower cost, leading to improved performance. (Wang et al., 2021;Khorashadizadeh et al., 2023;Ding et al., 2023). 2) Model Augmentation: The context-flexible nature of ICL shows promise in model augmentation. It can enhance retrievalaugmented methods by prepending grounding documents to the input (Ram et al., 2023). Additionally, ICL for retrieval demonstrates potential in steering models toward safer outputs (Panda et al., 2023;Meade et al., 2023). 3) Knowledge Updating: LLMs often contain outdated or incorrect knowledge (Dong et al., 2023). ICL has demonstrated efficacy in revising such knowledge through carefully crafted demonstrations, yielding higher success rates compared to gradient-based methods (De Cao et al., 2021). As mentioned above, ICL has yielded significant benefits on both traditional and emergent NLP applications. The tremendous success of ICL in NLP has inspired researchers to explore its potential in various modalities beyond text (elaborated in Appendix D), including vision (Bar et al., 2022;Wang et al., 2023c), vision-language (Tsimpoukelli et al., 2021;Alayrac et al., 2022), as well as speech applications (Wang et al., 2023a;Zhang et al., 2023d)."
    },
    {
      "heading": "Challenges and Future Directions",
      "text": "In this section, we review existing challenges and discuss future directions for ICL."
    },
    {
      "heading": "Efficiency and Scalability",
      "text": "The use of demonstrations in ICL introduces two challenges: (1) higher computational costs with an increasing number of demonstrations (efficiency), and (2) fewer learnable samples due to the maximum input length of LLMs (scalability). Prior research has attempted to mitigate these issues by distilling lengthy demonstrations into compact vectors (Li et al., 2024d,c) or expediting LLM inference times (Liu et al., 2023d). However, these methods often involve a trade-off in performance or necessitate access to model parameters, which is impractical for closed-source models like ChatGPT and Claude (Zhou et al., 2023b). Thus, enhancing the scalability and efficiency of ICL with more demonstrations remains a significant challenge. Generalization ICL heavily relies on highquality demonstrations selected from annotated examples, which are often scarce in low-resource languages and tasks. This scarcity poses a chal-lenge to the generalization ability of ICL (He et al., 2024). Given that there is a substantial discrepancy in the availability of annotated high-resource data and low-resource data, the potential to leverage high-resource data to address low-resource tasks is highly appealing (Chatterjee et al., 2024;Tanwar et al., 2023). Long-context ICL Recent advances in contextextended LLMs have spurred research into the impact of ICL when using an increasing number of demonstration examples (Agarwal et al., 2024;Bertsch et al., 2024). However, researchers have found that increasing the number of demonstrations does not necessarily enhance performance and may even be detrimental. These performance declines indicate a need for further investigation. Additionally, Li et al. (2024b) developed LongICLBench, which includes diverse extreme-label classification tasks, revealing further weaknesses of LLMs in comprehending extended demonstrations."
    },
    {
      "heading": "Conclusion",
      "text": "In this paper, we comprehensively review the existing literature on ICL, examining advanced techniques, conducting analytical studies, discussing relevant applications, and identifying critical challenges and potential directions for future research. To our knowledge, this is the first comprehensive survey dedicated to ICL. We aim to highlight the current state of research in ICL and provide insights to guide future work in this promising area."
    },
    {
      "heading": "Limitations",
      "text": "This paper offers a comprehensive examination and summary of current methodologies and analyses in the area of In-Context Learning (ICL). However, given the extensive body of related work, particularly in demonstration design and the principle analysis of ICL, we may have overlooked some equally valuable contributions. Additionally, we outline several future directions for research in ICL, including long-context ICL, efficiency and scalability in ICL, etc. We plan to leave these aspects for future work. Furthermore, many papers covered by this survey did not utilize the most up-to-date models while running experiments. We advocate for more thorough and up-to-date research to provide actionable insights for practitioners. Model Direct PPL Channel GPT2 44.13(1.00) 114.02(2.58) 157.70(3.57) GPT-J 611.04(1.00) 1766.82(2.89) 1793.27(2.93) Qwen2 745.89(1.00) 1886.63(2.53) 1957.97(2.63) Llama3 790.46(1.00) 1935.04(2.45) 1956.21(2.47) AVG 1.00 2.61 2.90  ing set for retrieval and the first 1000 data from the test set for testing. During the inference phase, a PPL-based approach is employed. The entire code framework is built upon OpenICL (Wu et al., 2023a), for which we extend our gratitude to the authors. Table 4 and Table 5 show the quantitative results on the efficiency and stability metrics for different scoring functions in Table 3."
    },
    {
      "heading": "C.1 Traditional Tasks",
      "text": "As a general learning paradigm, ICL can be examined on various traditional datasets and benchmarks, e.g., SuperGLUE (Wang et al., 2019), SQuAD (Rajpurkar et al., 2018). Implementing ICL with 32 randomly sampled examples on Su-perGLUE, Brown et al. (2020) found that GPT-"
    },
    {
      "heading": "C.2 New Challenging Tasks",
      "text": "In the era of large language models with in-context learning capabilities, researchers are more interested in evaluating the intrinsic capabilities of large language models without downstream task finetuning (Bommasani et al., 2021). To explore the capability limitations of LLM on various tasks, Srivastava et al. (2022) proposed the BIG-Bench (Srivastava et al., 2022), a large benchmark covering a large range of tasks, including linguistics, chemistry, biology, social behavior, and beyond. The best models have already outperformed the average reported human-rater results on 65% of the BIG-Bench tasks through ICL (Suzgun et al., 2023). To further explore tasks actually unsolvable by current language models, Suzgun et al. (2023) proposed a more challenging ICL benchmark, BIG-Bench Hard (BBH). BBH includes 23 unsolved tasks, constructed by selecting challenging tasks where the state-of-art model performances are far below the human performances. Besides, researchers are searching for inverse scaling tasks, 2 that is, tasks where model performance reduces when scaling up the model size. Such tasks also highlight potential issues with the cur-rent paradigm of ICL. To further probe the model generalization ability, Iyer et al. (2022) proposed OPT-IML Bench, consisting of 2000 NLP tasks from 8 existing benchmarks, especially benchmark for ICL on held-out categories. Specifically, a series of studies focus on exploring the reasoning ability of ICL. Saparov and He (2023) generated an example from a synthetic world model represented in first-order logic and parsed the ICL generations into symbolic proofs for formal analysis. They found that LLMs can make correct individual deduction steps via ICL. Shi et al. (2022) constructed the MGSM benchmark to evaluate the chain-of-thought reasoning abilities of LLMs in multilingual settings, finding that LLMs manifest complex reasoning across multiple languages. To further probe more sophisticated planning and reasoning abilities of LLMs, Valmeekam et al. (2022) provided multiple test cases for evaluating various reasoning abilities on actions and change, where existing ICL methods on LLMs show poor performance. In addition, Tang et al. (2023b) proposed a benchmark called SAMSum, which is a humanannotated dataset specifically designed for multiturn dialogue summarization, to evaluate the quality of dialogue summaries generated by LLMs via ICL."
    },
    {
      "heading": "C.3 Open-source Tools",
      "text": "Noticing that ICL methods are often implemented differently and evaluated using different LLMs and tasks, Wu et al. (2023a) developed OpenICL, an open-source toolkit enabling flexible and unified ICL assessment. With its adaptable architecture, OpenICL facilitates the combination of distinct components and offers state-of-the-art retrieval and inference techniques to accelerate the integration of ICL into advanced research. and multi-modal chain-of-thought prompting abilities (Huang et al., 2023b). METALM introduces a semi-causal language modeling objective to achieve strong ICL performance across visionlanguage tasks (Hao et al., 2022a). The ICL-D3IE approach employs a novel in-context learning framework that iteratively updates diverse demonstrations-including hard, layout-aware, and formatting demonstrations to train large language models (LLMs) for enhanced document information extraction (DIE) (He et al., 2023). Recent advancements include creating instruction tuning datasets from existing vision-language tasks or with advanced LLMs like GPT-4, connecting LLMs with powerful vision foundational models like BLIP-2 for multi-modal learning (Xu et al., 2023b;Li et al., 2023a;Liu et al., 2023a;Zhu et al., 2023a;Dai et al., 2023b)."
    },
    {
      "heading": "D.3 Speech In-Context Learning",
      "text": "In the speech area, Wang et al. (2023a) treated textto-speech synthesis as a language modeling task. They use audio codec codes as an intermediate representation and propose the first TTS framework with strong in-context learning capability. Subsequently, VALLE-X (Zhang et al., 2023d) extend the idea to multi-lingual scenarios, demonstrating superior performance in zero-shot cross-lingual textto-speech synthesis and zero-shot speech-to-speech translation tasks."
    },
    {
      "heading": "D.4 Comparison with other survey papers",
      "text": "Our survey was drafted and posted on the Arxiv at the end of 2022, which is, to the best of our knowledge, the very first to review in-context learning in the field. We also regularly update this survey in a timely manner, with four major revisions. Starting from 2023, we notice the emerge of several related survey in the field of in-context learning. Xu et al. (2024) made a comprehensive review on the choices for models, training procedures and inference algorithms to retrieve demonstrative examples of in-context learning. Li (2023) provided practical suggestions on prompt engineering for incontext learning. Zhou et al. (2023d) and Highmore (2024) focused on the theoretical interpretation and analysis of ICL, which corresponds to Section 5 in this survey. All the above-mentioned survey papers differ with ours in terms of scope and topics. This survey focused on the general development of ICL, including the formal definition of ICL, training strategies, prompt designing analysis and applications."
    }
  ],
  "figures": [],
  "equations": []
}