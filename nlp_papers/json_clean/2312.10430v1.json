{
  "paperid": "2312.10430v1",
  "title": "A Survey on Post-Quantum Cryptography: State-of-the-Art and Challenges",
  "authors": [
    "Marel Alvarado",
    "Luke Gayler",
    "Alex Seals",
    "Tao Wang",
    "Tao Hou",
    "Evgeny Milanov",
    "Daniel Bernstein",
    "Tanja Lange",
    "Ron Rivest",
    "Peter Shor"
  ],
  "year": 2024,
  "abstract": "The paper explains that post quantum cryptography is necessary due to the introduction of quantum computing causing certain algorithms to be broken. We analyze the different types of post-quantum cryptography, quantum cryptography and quantum-resistant cryptography, to provide a thorough understanding of the current solutions to the problems and their limitations. We explain the current state of quantum computing and how it has changed over time while discussing possible attacks on both types of post-quantum cryptography. Next, current post-quantum algorithms are discussed, and implementations are demonstrated. Lastly, we conclude that due to quantum cryptography's present limitations it is not a viable solution like it is often presented to be and that it is currently better to use quantum-resistant cryptography.",
  "sections": [
    {
      "heading": "Introduction",
      "text": "The importance of studying and developing post-quantum cryptography can be understood by first understanding what traditional cryptography is, why we use it, how it works, and its weaknesses. Traditional cryptography has been used for thousands of years [32] to ensure the security of information so that malicious parties cannot tamper with important data. The idea behind traditional cryptography is to scramble or encrypt plaintext messages/information into a cipher-text by using a certain algorithm so that a third party cannot decrypt the message/information. Computers rely on these traditional algorithms so that our information can be secure. A prominent example of our reliance on these algorithms is our use of Transport Layer Security (TLS) to encrypt our network traffic and ensure no third party can violate the confidentiality, integrity, or authenticity of this traffic. TLS uses a certain algorithm called Rivest-Shamir-Adleman (RSA) encryption which is a type of public-key cryptography. RSA was originally developed in 1978 by Ron Rivest, Adi Shamir, and Leonard Adleman to replace the National Bureau of Standards algorithm [1]. RSA works through using two systems, Public-key encryption and by adding digital signatures to the messages/information. RSA can be explained with the help of the commonly used Alice and Bob example. Let us say Alice wants to send a private message to Bob using the RSA algorithm. The RSA algorithm uses two different keys. The public key, available to everybody and used to encrypt the message, and the private key, only available to the owner (Bob) and used to decrypt the message. To generate the public key, we multiply two large prime numbers p and q together to create n, which is the modulus and choose a value, e, that is relatively prime to (p-1) * (q-1). The modulus n and exponent e together gives us the public key, the public key pair would look like (n,e). Now, to generate the private key, d, we use the formula: The private key pair would look like (n,d). For RSA to work, the message must be converted to a series of numbers. From here, Alice would generate the cipher-text, c, using: where S is the plaintext. Then, Bob would use the RSA decryption formula: ùëê = ùëÜ ùëí ùëöùëúùëë ùëõ to retrieve the plaintext [3]. An additional layer of protection can be added to ensure the message sender is who they say they are. This is achieved in RSA by adding a signature, or unique string of digits generated through a hash function, to the original data, and using same encryption and decryption formulas as before. While RSA is extremely effective for current computers, its effectiveness relies on the assumption of the difficulty of computing n [3] with our current technology. This reliance on mathematical uncertainties is prevalent within many algorithms used in today's world. However, it turns out that some of these assumptions are only applicable to the current capabilities of computers and are theoretically broken by the creation of quantum computing. RSA specifically will not be secure anymore because of a quantum algorithm known as Shor's algorithm, developed in theory in 1994 by Peter Shor. Shor's algorithm with Beauregard's improvements reduces the complexity of finding a prime number to ùëÇ(ùëõ 3 log ùëõ)and uses 2n + 3 qubits [5], which makes solving the problem take a significantly shorter amount of time. The fact that our data will be compromised by algorithms like Shor's is a leading motivator for research into quantumsafe cryptographic measures."
    },
    {
      "heading": "Post-Quantum Cryptography Preliminaries",
      "text": "Post-quantum cryptography contains two different approaches, quantum cryptography and quantumresistant traditional cryptography. The first approach, quantum cryptography was first theorized in 1970 by Stephen Wiesner but was only published by him in 1983 in \"Conjugate Coding\", where he theorized a quantum communication channel, and a type of quantum money. The first difference between quantum cryptography and traditional cryptography is that quantum uses a unit called qubits instead of bits. A qubit has two distinct states of \"0\" and \"1\" much like a bit, but a qubit can also exist in superposition states. These superposition states allow the qubit to exist in both a pure form and a mixed state, which allows many more states to be represented in a smaller amount. By pure form and a mixed state, it means that a qubit can be represented as \"1\" in different ways. For example, a qubit could be \"1\" in a ground state or it could be \"1\" in an excited state. These superpositions provide the qubit with a lot more representation per unit than bits. A single qubit can be denoted as the matrices: Another fundamental difference between the two cryptographies is that quantum cryptography relies on quantum mechanics, a type of theory behind atoms and particle physics, so the properties behind quantum are concrete whereas traditional cryptography relies on mathematical uncertainties. The properties that are currently most important to quantum cryptography are the Heisenberg Uncertainty Principle, Quantum Entanglement, and the No-Cloning Theorem. The Heisenberg Uncertainty principle establishes that due to how some pairs of physical properties relate to one another, it is impossible to measure any object without disturbing it [8]. The Heisenberg Uncertainty can be utilized in cryptographic encryption to detect eavesdropping as any observance of data will cause it to be disturbed. Quantum Entanglement is a feature of qubits in which no matter the distance between two entangled qubits, the measurements will show a high correlation but will not be able to tell what value the qubit has. The use of quantum entanglement is essential for long-distance quantum key distribution [9]. The no-cloning theorem states that you cannot create an identical copy of a quantum state. These three properties are utilized for quantum key distribution (QKD) which is a widely researched type of cryptographic protocol that uses quantum mechanics to produce keys for encrypting and decrypting messages. On top of the quantum-based cryptography measures there are four main types of traditional quantum-resistant cryptography: lattice-based, code-based, hash-based, and multivariate polynomial. While these four types do not rely on quantum mechanics, they are safe from the current quantum algorithms because they do not rely on the hardness of factoring and discrete logarithm problems which have been solved with Shor's algorithm. These traditional post-quantum cryptographic measures are necessary because widespread QKD is not yet feasible due to the inability to transmit qubits across the entire world. Also, the reliability of qubits is not at an adequate level to support main-stream usage. Next, we will discuss the current state of quantum."
    },
    {
      "heading": "Current Status of Quantum as It Pertains to QKD",
      "text": "In the past 25 years there has been much improvement and development in many parts of quantum computers. First, is the number of qubits available, which has increased from 3-qubits in 1998 [12] to 433qubits with IBM's Osprey Chip in 2022 [13] with an estimated 1,121-qubit processor estimated to be achieved in 2023. As more qubits are available, researchers are more accurately able to assess the impact of quantum algorithms because certain quantum algorithms require a lot of qubits. Second, is the distance at which we can reliably transmit quantum entangled particles across Earth's surface, which has been demonstrated at 1,120 kilometers (about 695.94 mi) by researchers in China using ground stations that transmit to a satellite and the satellite transmits to the other ground station [9]. This distance is significant progress as the transmission loss across distances has been a barrier to large-scale quantum networks [17]. When long distance transmission of quantum entangled particles is possible, then QKD will become more feasible because systems can be distributed across the world instead of needing to be close in proximity. Lastly, the overall reliability of a quantum computer's qubits is still an issue, but IBM has recently developed error mitigating strategies that reduce the amount of noise by running a quantum computer's circuit multiple times, so the error rate is lower, but this is at the cost of performance [15]. Reliability of a qubit is important in obtaining correct results from quantum algorithms, so with accurate qubits researchers will be able to test theoretical quantum algorithms and ensure the result is accurate. Overall, quantum computing is making slow but steady improvements but again, it is not sufficient for practical use yet. IBM researchers estimate that quantum computing will not be able to solve substantial engineering problems until about 2033 [16]. Next, we will discuss some modern quantum-resistant algorithms, their strengths and weaknesses, and explain and discuss a recent implementation of one of the most recent QKD algorithms developed, Twin fields quantum key distribution (TFQKD)."
    },
    {
      "heading": "Recent Cryptographic Methods",
      "text": "4.1 CRYSTALS-Kyber: Chosen by NIST (National Institute for Standards and Technology) in 2022 for general encryption, this public-key encryption method utilizes complicated path-building within lattices to drastically increase computational time for quantum processors (10). To introduce the implementation, for background, the NTT (Number Theoretic Transform) will mathematically transform an input vector into a different vector by using the input vector's values. The XOF (Extendable output function) will generate hashes of desired length; versions of XOF include SHAKE-128 and SHAKE-256. The CBD function will generate noise from an input by using the centered binomial distribution. Additionally, the environment for Kyber will use constant integers k, q, du, and dv. To generate the keys, first, two values a and b are made from an SHA3 512 hash of a randomized byte array of length 32. Then, in a k * k sized two-dimensional matrix A, for every position in the matrix (i,j), the value at that position becomes an NTT representation of an XOF SHAKE-128 hash generated with parameters a, i, and j. In a one-dimensional matrix of length k, named S, each value becomes a CBD of an XOF SHAKE-256 hash generated with parameters b and the values' literal indexes (for example, if setting the third value in the matrix, the parameters for the hash would be 'b' and 3). Set S to an NTT representation of itself. Another one-dimensional matrix of length k, named E, will be generated the same way as S was generated, but instead of using the values' literal positions as a parameter, the sum of the position and 'k' will be used (for example, if 'k' is 5, and the fourth value of the matrix is being set, then the parameters used would be 'b' and 5 + 4 = 9). Similarly, set E to an NTT representation of itself. Now, a new matrix T will become the sum of E with the matrix product of A and S. The public key will be generated by encoding the concatenation of 'T mod q' with 'a' whilst the private key will be generated by encoding S mod q. In this environment, we will define another constant integer 'n', which is the product of the length of the private key with ' 96 ùëò '. To encrypt a message 'm', given the receiver's public key 'pk' and a randomized byte array of length 32 'c', first, 'a' is set to \"ùëùùëò + 12 ‚ãÖ ùëò ‚ãÖ ùëõ 8 \". In a k * k sized two-dimensional matrix A, for every position in the matrix (i,j), the value at that position becomes an NTT representation of an XOF SHAKE-128 hash generated with parameters a, i, and j. In a one-dimensional matrix of length k, named 'r', each value becomes a CBD of a SHAKE-256 hash generated with parameters 'c' and the values' literal positions. Another one-dimensional matrix of length k, named 'e1', will be generated the same way as 'r' was generated, but instead of using the values' literal positions as parameters, the sum of the position and 'k' will be used. 'R' will become an NTT representation of 'r', and 'u' will become the sum of 'e1' with the inverse NTT of the matrix product of A and R. Then, 'v' will become the sum of the following: the inverse NTT of the matrix product of 'R' with the public key decoded, 'e2', and 'm' decoded and decompressed. Finally, the encrypted message will be the concatenation of 'u' compressed with parameter du and encoded along with 'v' compressed with parameter dv and encoded. For a receiver with private key 'sk', given a ciphertext 'c', 'u' will become 'c' decoded with parameter 'du' and decompressed, and 'v' will become 'ùëê + ùëëùë¢ ‚ãÖ ùëò ‚ãÖ ùëõ 8 ' decoded with parameter 'dv' and decompressed. Finally, the message is the private key decoded, matrix multiplied with the NTT representation of 'u', which becomes the parameter of inverse NTT, which is then subtracted from 'v', and finally, compressed and encoded to retrieve message 'm'. Kyber, in addition to its difficult nature, is incredibly compact in size. Kyber comes in three flavors of increasing difficulty: Kyber-512, Kyber-768, and Kyber-1024. For NIST's level of highest security, level 5, the proposed solution is Kyber-1024, which when benchmarked, used only 4,376 bytes to store the keys, allowing continued security even for lower-end devices (11).  [27,28]. The KEM allows two parties to generate a session key which is used for secure communication. Party A generates the session key and party B generates a public and private key. Party A will encrypt the session key with party B's public key and send the encrypted session key to party B. Party B will decrypt the session key using their private key to retrieve the session key. Now both parties have a session key which can be used to \"encapsulate\" and \"decapsulate\" messages in a similar fashion to public-key encryption [29]. In Classic McEliece, for the public and private key, a finite field 'F' of order 2·µê for natural number m, a random monic irreducible polynomial function 'g(z)' of degree 't' which is an element of 'F', a uniformly random subset of F of distinct elements 'A' "
    },
    {
      "heading": "SPHINCS+:",
      "text": "Chosen by NIST in 2022 for digital signing, SPHINCS+ is a stateless hash-based signature scheme reliant on the use of hash functions to allow authentication for a limited number of messages [27]. For background, SPHINCS+ requires use of W-OTS+ (Winternitz One-Time Signature) and XMSS (exTended Merkle Signature Scheme) to build a hypertree, and FORS (Forest of Random Subsets) to build the FORS-hypertree combination. W-OTS+: Given a SPHINCS+ signing key 'sk', 'w' number of bits in a window at a time, 'W = 2 ∑', we generate a public-private vector key pair. A private vector key 'SK' contains values generated by the PRF (pseudo-random function), which generates random sequences of values given a seed key. Here, each value in 'SK' is the PRF of 'sk'. Additionally, the corresponding public vector key 'PK' of the same length as 'SK' consists of values generated by a chaining pseudo-random function on each corresponding value within 'SK' (the chaining pseudo-random function repeatedly applies any hash function such as SHA2-256 a specified number of times on a value). Now with 'SK', a signature for a message can be generated. A given message 'msg' is split into window chunks of 'w' number of bits. Consider the sum '‚àë (ùëä -1 -ùë§ ùëñ ) ùëñ ' for every window bit chunks w·µ¢, and again split this sum into 'w' number of bits. In a new vector 'œÉ' of the size of the number of window bit chunks, for every value in 'œÉ', the i'th value in 'œÉ' is the result of the chaining pseudo-random function on the i'th value in 'sk', parameterized by the i'th window bit chunk. Now 'œÉ' becomes the signature for 'msg'. Now with 'œÉ' and 'msg', the same public key 'PK' can be extracted. Similarly, 'msg' is split into window chunks of 'w' number of bits. Consider the sum '‚àë (ùëä -1 -ùë§ ùëñ ) ùëñ ' for every window bit chunks w·µ¢, and again split this sum into 'w' number of bits. In a new vector 'pk' of the size of the number of window bit chunks, for every value in 'pk', the i'th value in 'pk' is the result of the chaining pseudo-random function on the i'th value in 'œÉ', parameterized by 'W -1 -w·µ¢', where w·µ¢ is the i'th window bit chunk. Now 'pk' should be the same public vector key 'PK'. XMSS: Given 'h' tree height and SPHINCS+ signing key 'sk', 2 ∞ number of W-OTS+ public-private vector key pairs are generated. A vector containing the private vector keys from all the pairs becomes the XMSS signing key 'SK'. Additionally, each corresponding public vector key is applied to any given hash function, such as SHA2-256, in the same ordering as the corresponding private vector keys in 'SK'. A binary hash tree is created from these hashed public vector keys, where two keys are hashed together to a separate key for all keys to form a binary tree-like structure. For example, if 'h = 3', then 2¬≥ = 8 nodes are created. The first layer will contain four nodes. Two of them are hashed to another node and the other two hashed to a separate node. The two nodes that were hashed to are now hashed to a different node. Now that this different node remains without enough other nodes to continue building the binary hash tree, this node becomes the root of the tree. Now with the binary hash tree of vector keys, this becomes the public key 'PK'. Now an \"authentication path\" within the binary hash tree can be signed using 'SK'. For a public vector key node within 'PK', use its corresponding private vector key within 'SK' to produce 'œÉ', the W-OTS+ signature for the message. Additionally, compute 'auth', the authentication path for the index of this public vector key node within 'PK'. The signature for the message becomes '(œÉ, auth)'. Like W-OTS+, given the signature and the known message 'msg', the XMSS public key can be extracted. Using W-OTS+ the corresponding W-OTS+ public vector key 'pk' is extracted using 'œÉ' and 'msg'. Using XMSS, with 'pk' hashed by the same hash function used to generate the original XMSS public key, along with 'auth', the original XMSS public key 'PK' is extracted. Hypertree: Like XMSS, the hypertree for SPHINCS+ will be a tree composed of XMSS key pairs where nodes are \"stacked\" and the XMSS node above signs the node below. The tree is parameterized by height 'H', total hypertree heigh 'h', and 'd' layers from 0 to 'd -1', where the 0'th node is the bottommost node and the node at 'd -1' is the top-most node. Given the SPHINCS+ signing key 'sk', the hyptertree signing key 'SK' becomes 'sk', and the hypertree public key 'PK' becomes the public of the XMSS public key at layer 'd -1'. In addition to the keys, note that due to the nature of the hypertree, given the tree index T·µ¢ of a node in the hypertree where 0 ‚â§ i < d -1, the tree index of the next node T·µ¢‚Çä‚ÇÅ and the index of the W-OTS+ public vector key Œª·µ¢‚Çä‚ÇÅ within that next node (recall it is a binary hash tree) can be found. From T·µ¢, T·µ¢‚Çä‚ÇÅ is the '‚Ñé -ùêª(ùëñ + 1)' number of most significant bits of T·µ¢, and Œª·µ¢‚Çä‚ÇÅ is the 'H' number of least significant bits of T·µ¢. With a way to access every node in the hypertree, t"
    },
    {
      "heading": "Twin fields quantum key distribution:",
      "text": "Twin fields quantum key distribution (TFQKD) was first proposed in 2018 by Marco Lucamarini et al. [16] and has quickly risen to become a very popular and promising solution to quantum key distribution across long distances. The authors' goal behind their paper was to propose a type of QKD that does not rely on the use of quantum repeaters to transmit across long distances. The motivation to bypass quantum repeaters is that quantum repeaters are not yet a feasible piece of technology despite the recent advancements, as we need something that can be implemented feasibly today [16]. To explain the TFQKD protocol, we will use an Alice and Bob example. First, Alice and Bob will both have a light source and an interferometer while a third-party Charlie will have a beam splitter and detectors. Next, these light sources will be used to create two random phases between [0,2ùúã) and will then be encoded with two sets of secret bits and bases, which are essentially encoding phrases. These are sent as pulses to a third-party station Charlie, who could even be a malicious individual. Charlie will then utilize a beam splitter to overlap the pulses to measure them. Charlie will then tell Alice and Bob which of the detectors lit up, one lights up if the bits are equal while the other lights up if they are different. Due to having the detectors, Charlie will also be able to tell whether the bits were equal or not but not what their values are, thus keeping the protection against eavesdropping intact. After Alice and Bob know which detector lights up, they will publicly announce the random phase and the encoding phrase. If their phases are equal, they will be considered \"twins\", and these \"twins\" will be saved while the phases that are not equal will be discarded. Additionally, to protect against eavesdropping, decoy states are employed, which are fake or decoy quantum states that are purely used to detect eavesdropping. The phase \"randomization\" mentioned earlier and decoy states are necessary to support long-distance TFQKD's security. It is important to note that there are performance impacts to adding decoy states, so to reduce this the devices utilizing TFQKD must alternate between code and decoy modes. A recent implementation of TFQKD was demonstrated in 2022 by a group of researchers across an 830km fiber cable. To achieve this feat, the researchers used a laser with a central wavelength of 1,550.12 nm and a linewidth of 0.1 kHz, which was then split in two and sent to both ends (Alice and Bob for example), Lastly, the modified light beams were sent through a quantum channel made of G.654.E ULL optical fiber to a third party's (Charlie for example) beam splitter, then two detectors comprised of NbN thin films checked the lights truth values [19]."
    },
    {
      "heading": "Quantum Attacks on Modern Cryptography",
      "text": "Only a decade after quantum computers were first proposed, scientists and mathematicians were already developing algorithms to break common cryptography methods. In 1994, Daniel Simon developed Simon's algorithm. Then, in the same year, mathematician Peter Shor developed an algorithm based on modular arithmetic that would be able to break RSA and Diffie-Hellman key encryption. Two years later in 1996, computer scientist Lov Grover devised an algorithm that highlights the speed-up that could be achieved with quantum computers. When it comes to breaking the encryption standards we use today, Shor's algorithm is seen as the biggest threat. The security of RSA encryption comes from the difficulty of finding the prime factors of very large numbers. This task is the very thing Shor's algorithm was designed to do. It works by performing calculations that bring it closer to a solution with each step. If we have a number, N, that fits the parameters of RSA encryption, we first choose some guess, a, such that 1 < a < N. Then, we can perform a series of calculations of ùëé ùëü ùëöùëúùëë ùëÅ, where r is increased by 1 for each iteration. Eventually, the results of this equation will begin repeating. The number of values in one repetition is called the order, denoted by r. This step is the order finding sub-routine and it is the quantum portion of the algorithm. It involves modular exponentiation and an inverse quantum Fourier-transform. Once r is found, it can be plugged into the equation gcd(ùëé ùëüfoot_0 ¬± 1, ùëÅ). The results of this will be the prime factors of N. Shor's algorithm is quite intensive when it comes to the required resources. As the value of N increases, the number qubits and gates needed quickly exceeds what we have available. As of now, quantum computing technology has not been able to perform these demonstrations without using some predetermined parameters to reduce the resource requirements of the system [24]. In 2001, a group of researchers at IBM successfully used Shor's algorithm to find the prime factors of 15. This was done using a process called nuclear magnetic resonance [20]. In 2019, the numbers 15, 21, and 35 were factored using a version of Shor's algorithm on a 6-bit IBM quantum processor [22]. This demonstration used one qubit in what is called the control register. This meant the qubit had to be recycled for each measurement. Two years later in 2021, an IBM quantum processor was used again to find the prime factors of 21. The number of qubits in this demonstration was reduced to 5. The circuit contained 2 qubits in the work register and 3 qubits in the control register. A sub-processor configuration of IBM's 7 qubit, ibmq-casablanca, and 21 qubit, ibmq-toronto were used. Because of the high resource of Shor's algorithm, the researchers needed to implement a pentagonal circuit mapping that was not available with any single quantum processor. The pentagonal circuit arrangement allowed for more connections between qubits which helped to reduce the number of gates needed to perform the algorithm. In the demonstration, the initial guess was chosen to be 4. For the quantum part of the algorithm, measurements showed probability peaks at 3 and 5. Then using a classical algorithm to perform further calculations, the order was found to be 3. Plugging this into the final step, gcd(4"
    },
    {
      "heading": "Proposed Attacks on Quantum Key Distribution",
      "text": "As discussed previously, quantum computers will not only be a powerful tool for breaking encryption. Some of the same principles that make quantum computers so dangerous also allow them to implement powerful security measures as with Quantum Key Distribution. Theoretically, QKD methods should be unbreakable. However, there are imperfections in the generation and measurement of photons, leaving space for an attack to be carried out [18]. One such attack was proposed in 2018 against BB84 QKD protocols [18]. It is known as the photon number splitting attack. A basic requirement of BB84 is sending a photon between two parties, Alice and Bob. Typically, if this photon was intercepted and measured by a third eavesdropping party, their presence would be easily recognizable due to the no-cloning theory. However, generating a single photon can be difficult. In many cases, when Bob generates a photon, multiple identical photons are generated and sent to Alice. This would allow someone to capture and measure one of the \"extra\" photons without giving any sign that they are present. In 2015, four attacks against QKD protocols were proposed [19]. The first, a Man in the Middle Attack (MITM), relies on Eve setting up her own equipment for measurement and generation in the communication channel. She would also need to have access to quantum memory. This MITM attack requires Eve to impersonate both Alice and Bob. In one QKD protocol, an initial set of messages is sent back and forth between Alice and Bob to form a key. The first message is generated by Alice using a particular basis state. Once Bob receives this message, he will need to choose a basis state for measurement. If he chooses the same state as Alice, the message is kept and used as part of the key. If the state does not match, the message is discarded. This is repeated until Alice and Bob have enough matching messages to form a key. If Eve is able to intercept these messages, she could effectively impersonate Alice and Bob. She would intercept Alice's first message and store it in her quantum memory. She could then use the next message sent by Alice to compare with her memory and find collisions in the hashing. This would lead to Eve obtaining an identical copy of Alice's raw key. Eventually, if Eve uses the same protocol as Alice and Bob, all three parties will end up generating the same \"private\" key. If this key is then used as part of the generation of subsequent keys, then it will be even easier for Eve to obtain these keys."
    },
    {
      "heading": "Conclusion",
      "text": "Based on our research, quantum cryptography is an emerging field of study with great potential. However, it is not currently an effective countermeasure to quantum computing's nullification of some traditional cryptography algorithms. Namely, there needs to be more research and development into long-distance quantum transmission because currently these systems cannot work across far distances on terrestrial Earth. It is likely that quantum cryptography will be the superior method of resisting attacks in the future, but it is currently quantum-resistant traditional cryptography that is the best method to use. This was concluded because quantum cryptography is in its infancy and has many fundamental issues that likely not be solved for a long time, and with quantum computing approaching at a rapid pace, we need to be able to protect our data in the meantime, which quantum-resistant traditional cryptography is capable of. On top of the fundamental issues, quantum cryptography requires highly specialized equipment to operate while quantum-resistant traditional cryptography operates on current computers, so there is not a high cost associated with shifting to quantum-resistant as the standard. Even though quantum-resistant traditional cryptography is already functional, further research needs to be done to optimize and develop new algorithms. By developing attacks against them, researchers can modify the algorithms to ensure maximum security."
    }
  ],
  "figures": [],
  "equations": []
}