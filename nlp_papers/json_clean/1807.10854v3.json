{
  "paperid": "1807.10854v3",
  "title": "A Survey of the Usages of Deep Learning for Natural Language Processing",
  "authors": [
    "Daniel Otter",
    "Julian Medina",
    "Jugal Kalita",
    "K Jones",
    "E Liddy",
    "A Coates",
    "B Huval",
    "T Wang",
    "D Wu",
    "B Catanzaro"
  ],
  "year": 2024,
  "abstract": "Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This survey provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to a number of applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.",
  "sections": [
    {
      "heading": "I. INTRODUCTION",
      "text": "T HE field of natural language processing (NLP) encom- passes a variety of topics which involve the computational processing and understanding of human languages. Since the 1980s, the field has increasingly relied on datadriven computation involving statistics, probability, and machine learning [1], [2]. Recent increases in computational power and parallelization, harnessed by Graphical Processing Units (GPUs) [3], [4], now allow for \"deep learning\", which utilizes artificial neural networks (ANNs), sometimes with billions of trainable parameters [5]. Additionally, the contemporary availability of large datasets, facilitated by sophisticated data collection processes, enables the training of such deep architectures [6], [7], [8]. In recent years, researchers and practitioners in NLP have leveraged the power of modern ANNs with many propitious results, beginning in large part with the pioneering work of Collobert et al. [9]. In the very recent past, the use of deep learning has upsurged considerably [10], [11]. This has led to significant advances both in core areas of NLP and in areas in which it is directly applied to achieve practical and useful objectives. This survey provides a brief introduction to both natural language processing and deep neural networks, and then presents an extensive discussion on how deep learning is being used to solve current problems in NLP. While several other papers and books on the topic have been published [12], [10], none have extensively covered the state-of-theart in as many areas within it. Furthermore, no other survey has examined not only the applications of deep learning to computational linguistics, but also the underlying theory and traditional NLP tasks. In addition to the discussion of recent revolutionary developments in the field, this survey will be useful to readers who want to familiarize themselves quickly with the current state of the art before embarking upon further advanced research and practice. The topics of NLP and AI, including deep learning, are introduced in Section II. The ways in which deep learning has been used to solve problems in core areas of NLP are presented in Section III. The section is broken down into several subsections, namely natural language modeling (III-A), morphology (III-B), parsing (III-C), and semantics (III-D). Applications of deep learning to more practical areas are discussed in Section IV. Specifically discussed are information retrieval (IV-A), information extraction (IV-B), text classification (IV-C), text generation (IV-D), summarization (IV-E), question answering (IV-F), and machine translation (IV-G). Conclusions are then drawn in Section V with a brief summary of the state of the art as well as predictions, suggestions, and other thoughts on the future of this dynamically evolving area."
    },
    {
      "heading": "II. OVERVIEW OF NATURAL LANGUAGE PROCESSING AND DEEP LEARNING",
      "text": "In this section, significant issues that draw attention of researchers and practitioners are introduced, followed by a brisk explanation of the deep learning architectures commonly used in the field."
    },
    {
      "heading": "A. Natural Language Processing",
      "text": "The field of natural language processing, also known as computational linguistics, involves the engineering of computational models and processes to solve practical problems in understanding human languages. These solutions are used to build useful software. Work in NLP can be divided into two broad sub-areas: core areas and applications, although it is sometimes difficult to distinguish clearly to which areas issues belong. The core areas address fundamental problems such as language modeling, which underscores quantifying associations among naturally occurring words; morphological processing, dealing with segmentation of meaningful components of words and identifying the true parts of speech of words as used; syntactic processing, or parsing, which builds sentence diagrams as possible precursors to semantic processing; and semantic processing, which attempts to distill meaning of words, phrases, and higher level components in text. The application areas involve topics such as extraction of useful information (e.g. named entities and relations), translation of text between and among languages, summarization of written works, automatic answering of questions by inferring answers, and classification and clustering of documents. Often one needs to handle one or more of the core issues successfully and apply those ideas and procedures to solve practical problems. Currently, NLP is primarily a data-driven field using statistical and probabilistic computations along with machine learning. In the past, machine learning approaches such as naïve Bayes, k-nearest neighbors, hidden Markov models, conditional random fields, decision trees, random forests, and support vector machines were widely used. However, during the past several years, there has been a wholesale transformation, and these approaches have been entirely replaced, or at least enhanced, by neural models, discussed next."
    },
    {
      "heading": "B. Neural Networks and Deep Learning",
      "text": "Neural networks are composed of interconnected nodes, or neurons, each receiving some number of inputs and supplying an output. Each of the nodes in the output layers perform weighted sum computation on the values they receive from the input nodes and then generate outputs using simple nonlinear transformation functions on these summations. Corrections to the weights are made in response to individual errors or losses the networks exhibit at the output nodes. Such corrections are usually made in modern networks using stochastic gradient descent, considering the derivatives of errors at the nodes, an approach called back-propagation [13]. The main factors that distinguish different types of networks from each other are how the nodes are connected and the number of layers. Basic networks in which all nodes can be organized into sequential layers, with every node receiving inputs only from nodes in earlier layers, are known as feedforward neural networks (FFNNs). While there is no clear consensus on exactly what defines a deep neural network (DNN), generally networks with multiple hidden layers are considered deep and those with many layers are considered very deep [7]. 1) Convolutional Neural Networks: Convolutional neural networks (CNNs) [14], [15], built upon Fukashima's neocognitron [16], [17], derive the name from the convolution operation in mathematics and signal processing. CNNs use functions, known as filters, allowing for simultaneous analysis of different features in the data [18], [19]. CNNs are used extensively in image and video processing, as well as speech and NLP [20], [21], [22], [23]. Often, it is not important precisely where certain features occur, but rather whether or not they appear in particular localities. Therefore, pooling operations, can be used to minimize the size of feature maps (the outputs of the convolutional filters). The sizes of such pools are generally small in order to prevent the loss of too much precision. 2) Recursive Neural Networks: Much like CNNs, recursive networks [24], [25] use a form of weight sharing to minimize training. However, whereas CNNs share weights horizontally (within a layer), recursive nets share weights vertically (between layers). This is particularly appealing, as it allows for easy modeling of structures such as parse trees. In recursive networks, a single tensor (or a generalized matrix) of weights can be used at a low level in the tree, and then used recursively at successively higher levels [26]. 3) Recurrent Neural Networks and Long Short-Term Memory Networks: A type of recursive neural network that has been used heavily is the recurrent neural network (RNN) [27], [28]. Since much of NLP is dependent on the order of words or other elements such as phonemes or sentences, it is useful to have memory of the previous elements when processing new ones [29], [30], [31]. Sometimes, backwards dependencies exist, i.e., correct processing of some words may depend on words that follow. Thus, it is beneficial to look at sentences in both directions, forwards and backwards, using two RNN layers, and combine their outputs. This arrangement of RNNs is called a bidirectional RNN. It may also lead to a better final representation if there is a sequence of RNN layers. This may allow the effect of an input to linger longer than a single RNN layer, allowing for longer-term effects. This setup of sequential RNN cells is called an RNN stack [32], [33]. One highly engineered RNN is the long short-term memory (LSTM) network [34], [35]. In LSTMs, the recursive nodes are composed of several individual neurons connected in a manner designed to retain, forget, or expose specific information. Whereas generic RNNs with single neurons feeding back to themselves technically have some memory of long passed results, these results are diluted with each successive iteration. Oftentimes, it is important to remember information from the distant past, while at the same time, other very recent information may not be important. By using LSTM blocks, this important information can be retained much longer while irrelevant information can be forgotten. A slightly simpler variant of the LSTM, called the Gated Recurrent Unit (GRU), has been shown to perform as well as or better than standard LSTMs in many tasks [36], [37]. 4) Attention Mechanisms and Transformer: For tasks such as machine translation, text summarization, or captioning, the output is in textual form. Typically, this is done through the use of encoder-decoder pairs. An encoding ANN is used to (a) shows a transformer with four \"encoders\" followed by four \"decoders\", all following a \"positional encoder\". (b) shows the inner workings of each \"encoder\", which contains a self-attention layer followed by a feed forward layer. (c) shows the inner workings of each \"decoder\", which contains a self-attention layer followed by an attentional encoderdecoder layer and then a feed forward layer. produce a vector of a particular length"
    },
    {
      "heading": "III. DEEP LEARNING IN CORE AREAS OF NATURAL LANGUAGE PROCESSING",
      "text": "The core issues are those that are inherently present in any computational linguistic system. To perform translation, text summarization, image captioning, or any other linguistic task, there must be some understanding of the underlying language. This understanding can be broken down into at least four main areas: language modeling, morphology, parsing, and semantics. The number of scholarly works in each area over the last decade is shown in Figure 3. Language modeling can be viewed in two ways. First, it determines which words follow which. By extension, however, this can be viewed as determining what words mean, as individual words are only weakly meaningful, deriving their full value only from their interactions with other words. Morphology is the study of how words themselves are formed. It considers the roots of words and the use of prefixes and suffixes, compounds, and other intraword devices, to display tense, gender, plurality, and a other linguistic constructs. Parsing considers which words modify others, forming constituents, leading to a sentential structure. The area of semantics is the study of what words mean. It takes into account the meanings of the individual words and how they relate to and modify others, as well as the context these words appear in and some degree of world knowledge, i.e., \"common sense\". There is a significant amount of overlap between each of these areas. Therefore, many models analyzed can be classified as belonging in multiple sections. As such, they are discussed in the most relevant sections with logical connections to those other places where they also interact."
    },
    {
      "heading": "A. Language Modeling and Word Embeddings",
      "text": "Arguably, the most important task in NLP is that of language modeling. Language modeling (LM) is an essential piece of almost any application of NLP. Language modeling is the process of creating a model to predict words or simple linguistic components given previous words or components [48]. This is useful for applications in which a user types input, to provide predictive ability for fast text entry. However, its power and versatility emanate from the fact that it can implicitly capture syntactic and semantic relationships among words or components in a linear neighborhood, making it useful for tasks such as machine translation or text summarization. Using prediction, such programs are able to generate more relevant, human-sounding sentences. 1) Neural Language Modeling: A problem with statistical language models was the inability to deal well with synonyms or out-of-vocabulary (OOV) words that were not present in the training corpus. Progress was made in solving the problems with the introduction of the neural language model [49]. While much of NLP took another decade to begin to use ANNs heavily, the LM community immediately took advantage of them, and continued to develop sophisticated models, many of which were summarized by DeMulder et al. [50]. 2) Evaluation of Language Models: While neural networks have made breakthroughs in the LM field, it is hard to quantify improvements. It is desirable to evaluate language models independently of the applications in which they appear. A number of metrics have been proposed, but no perfect solution has yet been found. [51], [52], [53] The most commonly used metric is perplexity, which is the inverse probability of a test set normalized by the number of words. Perplexity is a reasonable measurement for LMs trained on the same datasets, but when they are trained on different vocabularies, the metric becomes less meaningful. Luckily, there are several benchmark datasets that are used in the field, allowing for comparison. Two such datasets are the Penn Treebank (PTB) [54], and the Billion Word Benchmark [55]. 3) Memory Networks and Attention Mechanisms in Language Modeling: Daniluk et al. [56] tested several networks using variations of attention mechanisms. The first network had a simple attention mechanism, which was not fully connected, having a window length of five. They hypothesized that using a single value to predict the next token, to encode information for the attentional unit, and to decode the information in the attentional unit hinders a network, as it is difficult to train a single parameter to perform three distinct tasks simultaneously. Therefore, in the second network, they designed each node to have two outputs: one to encode and decode the information in the attentional unit, and another to predict the next tokens explicitly. In the third network, they further separated the outputs, using separate values to encode the information entering the attentional unit and decode the information being retrieved from it. Tests on a Wikipedia corpus showed that the attention mechanism improved perplexity compared to the baseline, and that successively adding the second and third parameters led to further increases. It was also noted that only the previous five or so tokens carried much value (hence the selection of the window size of five). Therefore, they tested a fourth network which simply used residual connections from each of the previous five units. It was found that this network also provided results comparable to many larger RNNs and LSTMs, suggesting that reasonable results can be achieved using simpler networks. Another recent study was done on the usage of residual memory networks (RMNs) for LM [57]. The authors found that residual connections skipping two layers were most effective, followed closely by those skipping a single layer. In particular, a residual connection was present between the first layer and the fourth, as was between the fifth layer and the eighth, and between the ninth and the twelfth. It was found that increasing network depth improved results, but that when using large batch sizes, memory constraints were encountered. Network width was not found to be of particular importance for performance, however, wide networks were found to be harder to train. It was found that RMNs are capable of outperforming LSTMs of similar size."
    },
    {
      "heading": "4) Convolutional Neural Networks in Language Modeling:",
      "text": "A CNN used recently in LM replaced the pooling layers with fully-connected layers [58]. These layers allowed the feature maps to be reduced to lower dimensional spaces just like the pooling layers. However, whereas any references to location of such features are lost in pooling layers, fully-connected layers somewhat retain this information. Three different architectures were implemented: a multilayer perceptron CNN (MLPConv) in which the filters were not simply linear, but instead small MLPs [59]; a multilayer CNN (ML-CNN) in which multiple convolutional layers were stacked on top of each other; and a combination of these networks called COM, in which kernel sizes for filters varied (in this case they were three and five). The results showed that stacking convolutional layers was detrimental in LM, but that both MLPConv and COM reduced perplexity. Combining MLPConv with the varying kernel sizes of COM provided even better results. Analysis showed that the networks learned specific patterns of words, such as, \"as . . . as\". Lastly, this study showed that CNNs can be used to capture long term dependencies in sentences. Closer words were found to be of greatest importance, but words located farther away were of some significance as well. 5) Character Aware Neural Language Models: While most CNNs used in NLP receive word embeddings (Section III-A6) as input, recent networks have analyzed character level input instead. For example, Kim et al. [60], unlike previous networks [61], accepted only character level input, rather than combining it with word embeddings. A CNN was used to process the character level input to provide representations of the words. In a similar manner as word embeddings usually are, these representations were then fed into an encoderdecoder pair composed of a highway network (a gated network resembling an LSTM) [46] and an LSTM. They trained the network on the English Penn Treebank, as well as on datasets for Czech, German, Spanish, French, Russian, and Arabic. For every non-English language except Russian, the network outperformed previously published results [61] in both the large and small datasets. On the Penn Treebank, results were produced on par with the existing state of the art [62]. However, the network had only 19 million trainable parameters, which is considerably lower than others. Since the network focused on morphological similarities produced by character level analysis, it was more capable than previous models of handling rare words. Analysis showed that without the use of highway layers, many words had nearest neighbors that were orthographically similar, but not necessarily semantically similar. Additionally, the network was capable of recognizing misspelled words or words not spelled in the standard way (e.g. looooook instead of look) and of recognizing out of vocabulary words. The analysis also showed that the network was capable of identifying prefixes, roots, and suffixes, as well as understanding hyphenated words, making it a robust model. Jozefowicz et al. [63] tested a number of architectures producing character level outputs [64], [55], [65], [66]. Whereas many of these models had only been tested on small scale language modeling, this study tested them on a large scale, testing them with the Billion Word Benchmark. The most effective model, achieving a state-of-the-art (for single models) perplexity of 30.0 with 1.04 billion trainable parameters (compared to a previous best by a single model of 51.3 with 20 billion parameters [55]), was a large LSTM using a character level CNN as an input network. The best performance, however, was achieved using an ensemble of ten LSTMs. This ensemble, with a perplexity of 23.7, far surpassed the previous state-of-the-art ensemble [65], which had a perplexity of 41.0. 6) Development of Word Embeddings: Not only do neural language models allow for the prediction of unseen synonymous words, they also allow for modeling the relationships between words [67], [68]. Vectors with numeric components, representing individual words, obtained by LM techniques are called embeddings. This is usually done either by use of Principle Component Analysis or by capturing internal states in a neural language model. (Note that these are not standard LMs, but rather are LMs constructed specifically for this purpose.) Typically, word embeddings have between 50 and 300 dimensions. An overused example is that of the distributed representations of the words king, queen, man, and woman. If one takes the embedding vectors for each of these words, computation can be performed to obtain highly sensible results. If the vectors representing these words are respectively represented as k, q, m, and w, it can be observed that k -q ≈ m -w, which is extremely intuitive to human reasoning. In recent years, word embeddings have been the standard form of input to NLP systems. 7) Recent Advances and Challenges: Language modeling has been evolving on a weekly basis, beg"
    },
    {
      "heading": "B. Morphology",
      "text": "Morphology is concerned with finding segments within single words, including roots and stems, prefixes, suffixes, and-in some languages-infixes. Affixes (prefixes, suffixes, or infixes) are used to overtly modify stems for gender, number, person, et cetera. Luong et al. [76] constructed a morphologically aware LM. An RvNN was used to model the morphological structure. A neural language model was then placed on top of the RvNN. The model was trained on the WordSim-353 dataset [77] and segmentation was performed using Morfessor [78]. Two models were constructed-one using context and one not. It was found that the model that was insensitive to context overaccounted for certain morphological structures. In particular, words with the same stem were clustered together, even if they were antonyms. The context-sensitive model performed better, noting the relationships between the stems, but also accounting for other features such as the prefix \"un\". The model was also tested on several other popular datasets [79], [80], [81], significantly outperforming previous embedding models on all. A good morphological analyzer is often important for many NLP tasks. As such, one recent study by Belinkov et al. [82] examined the extent to which morphology was learned and used by a variety of neural machine translation models. A number of translation models were constructed, all translating from English to French, German, Czech, Arabic, or Hebrew. Encoders and decoders were LSTM-based models (some with attention mechanisms) or character aware CNNs, and the models were trained on the WIT 3 corpus [83], [84]. The decoders were then replaced with part-of-speech (POS) taggers and morphological taggers, fixing the weights of the encoders to preserve the internal representations. The effects of the encoders were examined as were the effects of the decoders attached during training. The study concluded that the use of attention mechanisms decreases the performance of encoders, but increases the performance of decoders. Furthermore, it was found that character-aware models are superior to others for learning morphology and that the output language affects the performance of the encoders. Specifically, the more morphologically rich the output language, the worse the representations created by the encoders. Morita et al. [85] analyzed a new morphological language model for unsegmented languages such as Japanese. They constructed an RNN-based model with a beam search decoder and trained it on an automatically labeled [86] corpus and on a manually labeled corpus. The model performed a number of tasks jointly, including morphological analysis, POS tagging, and lemmatization. The model was then tested on the Kyoto Text Corpus [87] and the Kyoto University Web Document Leads Corpus [88], outperforming all baselines on all tasks. A recent line of work in morphology is universal morphology. This task considers the relationships between the morphologies of different languages and how they relate to each other, aiming towards the ultimate goal of a single morphological analyzer. However, to the authors' knowledge, there has been only a single study applying deep learning to this area [89], and even then, only as a supporting task to universal parsing (Section III-C4). For those wishing to apply deep learning to this task, several datasets are already available, including one from a CoNLL shared task [90]. In addition to universal morphology, the development of morphological embeddings, that take into account the structures of words, could aid in multi-language processing. They could possibly be used across cognate languages, which would be valuable when some languages are more resourced than others. In addition, morphological structures may be important in handling specialized languages such as those used in the biomedical literature. Since deep learning has become quite entrenched in NLP, better handling of morphological compo-nents is likely to improve performance of overall models."
    },
    {
      "heading": "C. Parsing",
      "text": "Parsing examines how different words and phrases relate to each other within a sentence. There are at least two distinct forms of parsing: constituency parsing and dependency parsing [48]. In constituency parsing, phrasal constituents are extracted from a sentence in a hierarchical fashion. Dependency parsing looks at the relationships between pairs of individual words. Most recent uses of deep learning in parsing have been in dependency parsing, within which there exists another major divide in types of solutions. Graph-based parsing constructs a number of parse trees that are then searched to find the correct one. Most graph-based approaches are generative models, in which a formal grammar, based on the natural language, is used to construct the trees [48]. More popular in recent years than graph-based approaches have been transition-based approaches that usually construct only one parse tree. While a number of modifications have been proposed, the standard method of transition-based dependency parsing is to create a buffer containing all of the words in the sentence and stack containing only the ROOT label. Words are then pushed onto the stack, where connections, known as arcs, are made between the top two items. Once dependencies have been determined, words are popped off the stack. The process continues until the buffer is empty and only the ROOT label remains on the stack. Three major approaches are used to regulate the conditions in which each of the previously described actions takes place. In the arc-standard approach [91], [92], all dependents are connected to a word before the word is connected to its parent. In the arc-eager approach [91], [92], words are connected to their parents as soon as possible, regardless of whether or not their children are all connected to them. Finally, in the swaplazy approach [93], the arc-standard approach is modified to allow swapping of positions on the stack. This makes the graphing of non-projective edges possible. 1) Early Neural Parsing: One early application of deep learning to NLP, that of Socher et al. [94], [95], included the use of RNNs with probabilistic context-free grammars (PCFGs) [96], [97]. As far as the authors are aware, the first neural model to achieve state-of-the-art performance in parsing was that of Le and Zuidema [98]. Such performance was achieved on the Penn Treebank for both labeled attachment score (LAS) and unlabeled attachment score (UAS) by using an Inside-Out Recursive Neural Network, which used two vector representations (an inner and an outer) to allow both top-down and bottom-up flows of data. Vinyals et al. [99] created an LSTM with an attention mechanism in a syntactic constituency parser, which they tested on data from domains different from those of the test data (the English Web Treebank [100] and the Question Treebank [101] as opposed to the Wall Street Journal portion of the Penn Treebank [54]), showing that neural models can generalize between domains. Embeddings were first used in dependency parsing by Stenetorp [102]. This approach used an RNN to create a directed acyclic graph. While this model did produce results within 2% of the state of the art (on the Wall Street Journal portion of the CoNLL 2008 Shared Task dataset [103]), by the time it reached the end of a sentence, it seemed to have difficulty remembering phrases from early in the sentence. 2) Transition-Based Dependency Parsing: Chen and Manning [104] pushed the state of the art in both UAS and LAS on both English and Chinese datasets on the English Penn Treebank. They accomplished this by using a simple feedforward neural network as the decision maker in a transition-based parser. By doing so they were able to subvert the problem of sparsity persistent in the statistical models. Chen and Manning used a simple greedy search, which was replaced by Zhou et al. [105] with a beam search, achieving a significant improvement. Weiss et al. [106] improved upon Chen and Manning's work by using a deeper neural network with residual connections and a perceptron layer placed after the softmax layer. They were able to train on significantly more examples than typical by using tri-training [107], a process in which potential data samples are fed to two other parsers, and those samples upon which both of the parsers agree are used for training the primary parser. Another model was produced using an LSTM instead of a feedforward network [108]. Unlike previous models, this model was given knowledge of the entire buffer and the entire stack and had knowledge of the entire history of transition decisions. This allowed for better predictions, generating stateof-the-art on the Stanford Dependency Treebank [109], as well as state-of-the-art results on the CTB5 Chinese dataset [110]. Lastly, Andor et al. [111] used a feedforward network with global normalization on a number of tasks including part-of-speech tagging, sentence compression, and dependency parsing. State-of-the-art res"
    },
    {
      "heading": "D. Semantics",
      "text": "Semantic processing involves understanding the meaning of words, phrases, sentences, or documents at some level. Word embeddings, such as Word2Vec [67], [68] and GloVe [131], claim to capture meanings of words, following the Distributional Hypothesis of Meaning [132]. As a corollary, when vectors corresponding to phrases, sentences, or other components of text are processed using a neural network, a representation that can be loosely thought to be semantically representative is computed compositionally. In this section, neural semantic processing research is separated into two distinct areas: Work on comparing the semantic similarity of two portions of text, and work on capturing and transferring meaning in high level constituents, particularly sentences. 1) Semantic Comparison: One way to test the efficacy of an approach to computing semantics is to see if two similar phrases, sentences or documents, judged by humans to have similar meaning also are judged similarly by a program. Hu et al. [133] proposed two CNNs to perform a semantic comparison task. The first model, ARC-I, inspired by Bordes et al. [134], used a Siamese network, in which two CNNs sharing weights evaluated two sentences in parallel. In the second network, connections were placed between the two, allowing for sharing before the final states of the CNNs. The approach outperformed a number of existing models in tasks in English and Chinese. Building on prior work [26], [21], [133], Yin and Schütze [135] proposed a Bi-CNN-MI (MI for multigranular interaction features), consisting of a pretrained CNN sentence model, a CNN interaction model, and a logistic regressor. They modifiied a Siamese network using Dynamic CNNs [21] (Section III-D2). Additionally, the feature maps from each level were used in the comparison, rather than simply the toplevel feature maps. They achieved state-of-the-art results on the Microsoft Research Paraphrase Corpus (MSRP) [136]. He et al. [137] constructed feature maps, which were then compared using a \"similarity measurement layer\" followed by a fully-connected layer and then a log-softmax output layer within a CNN. The windows used in the convolutional layers ranged in length from one to four. The network was trained and evaluated on three datasets: MSRP, the Sentences Involving Compositional Knowledge (SICK) dataset [138], and the Microsoft Video Paraphrase Corpus (MSRVID) [139]. State-of-the-art results were achieved on the first and the third. Tai et al. concocted a model using an RvNN with LSTMlike nodes [114] called a Tree-LSTM. Two variations were examined (constituency-and dependency-based) and tested on both the SICK dataset and Stanford Sentiment Treebank [94]. The constituency-based model achieved state-of-the-art results on the Stanford Sentiment Treebank and the dependency-based one achieved state-of-the-art results on SICK. He et al. presented another model [140], which outperformed that of Tai et al. on SICK. The model formed a matrix of the two sentences before applying a \"similarity focus layer\" and then a nineteen-layer CNN followed by dense layers with a softmax output. The similarity focus layer matched semantically similar pairs of words from the input sentences and applied weights to the matrix locations representing the relations between the words in each pair. They also obtained state-of-the-art resuults on MSRVID, SemEval 2014 Task 10 [141], WikiQA [142], and TreeQA [143] datasets. 2) Sentence Modeling: Extending from neural language modeling, sentence modeling attempts to capture the meaning of sentences in vectors. Taking this a step further are models, such as that of Le and Mikolov [144], which attempt to model paragraphs or larger bodies of text in this way. Kalchbrenner et al. [21] generated representations of sentences using a dynamic convolutional neural network (DCNN), which used a number of filters and dynamic k-max pooling layers. Due to dynamic pooling, features of different types and lengths could be identified in sentences with varying structures without padding of the input. This allowed not only shortrange dependencies, but also long-range dependencies to be identified. The DCNN was tested in applied tasks that require semantic understanding. It outperformed all comparison models in predicting sentiment of movie reviews in the Stanford Sentiment Treebank [95] and in identification of sentiment in tweets [145]. It was also one of the top performers in classifying types of questions using the TREC database [146]. Between their requirement for such understanding and their ease of examination due to the typical encoder-decoder structure they use, neural machine translation (NMT) systems (Section IV-G) are splendid testbeds for researching internal semantic representations. Poliak et al. [147] trained encoders on four different language pairs: English and Arabic, English and Spanish, English and Chinese, and English and German. The decoding classifiers were trained on four distinct"
    },
    {
      "heading": "E. Summary of Core Issues",
      "text": "Deep learning has generally performed very well, surpassing existing states of the art in many individual core NLP tasks, and has thus created the foundation on which useful natural language applications can and are being built. However, it is clear from examining the research reviewed here that natural language is an enigmatically complex topic, with myriad core or basic tasks, of which deep learning has only grazed the surface. It is also not clear how architectures for ably executing individual core tasks can be synthesized to build a common edifice, possibly a much more complex distributed neural architecture, to show competence in multiple or \"all\" core tasks. More fundamentally, it is also not clear, how mastering of basic tasks, may lead to superior performance in applied tasks, which are the ultimate engineering goals, especially in the context of building effective and efficient deep learning models. Many, if not most, successful deep learning architectures for applied tasks, discussed in the next section, seem to forgo explicit architectural components for core tasks, and learn such tasks implicitly. Thus, some researchers argue that the relevance of the large amount of work on core issues is not fully justified, while others argue that further extensive research in such areas is necessary to better understand and develop systems which more perfectly perform these tasks, whether explicitly or implicitly."
    },
    {
      "heading": "IV. APPLICATIONS OF NATURAL LANGUAGE PROCESSING USING DEEP LEARNING",
      "text": "While the study of core areas of NLP is important to understanding how neural models work, it is meaningless in and of itself from an engineering perspective, which values applications that benefit humanity, not pure philosophical and scientific inquiry. Current approaches to solving several immediately useful NLP tasks are summarized here. Note that the issues included here are only those involving the processing of text, not the processing of verbal speech. Because speech processing [162], [163] requires expertise on several other topics including acoustic processing, it is generally considered another field of its own, sharing many commonalities with the field of NLP. The number of studies in each discussed area over the last decade is shown in Figure 4 A. Information Retrieval The purpose of Information Retrieval (IR) systems is to help people find the right (most useful) information in the right (most convenient) format at the right time (when they need it) [164]. Among many issues in IR, a primary problem that needs addressing pertains to ranking documents with respect to a query string in terms of relevance scores for ad-hoc retrieval tasks, similar to what happens in a search engine. Deep learning models for ad-hoc retrieval match texts of queries to texts of documents to obtain relevance scores. Thus, such models have to focus on producing representations of the interactions among individual words in the query and the documents. Some representation-focused approaches build deep learning models to produce good representations for the texts and then match the representations straightforwardly [165], [133], [166], whereas interaction-focused approaches first build local interactions directly, and then use deep neural networks to learn how the two pieces of text match based on word interactions [133], [167], [168]. When matching a long document to a short query, the relevant portion can potentially occur anywhere in the long document and may also be distributed, thus, finding how each word in the query relates to portions of the document is helpful. Mindful of the specific needs for IR, Guo et al. [169] built a neural architecture called DRMM, enhancing an interactionfocused model that feeds quantized histograms of the local interaction intensities to an MLP for matching. In parallel, the query terms go through a small sub-network on their own to establish term importance and term dependencies. The outputs of the two parallel networks are mixed at the top so that the Fig. 4: Publication Volume for Applied Areas of NLP. All areas of applied natural language processing discussed have witnessed growth in recent years, with the largest growth occurring in the last two to three years. relevance of the document to the query can be better learned. DRMM achieved state-of-the-art performance for its time. Most current neural IR models are not end-to-end relevance rankers, but are re-rankers for documents a first-stage efficient traditional ranker has deemed relevant to a query. The representations the neural re-rankers learn are dense for both documents and queries, i.e., most documents in a collection seem to be relevant to a query, making it impossible to use such ANNs for ranking an entire collection of documents. In contrast, Zamani et al. [170] presented a standalone neural ranking model called SNRM PRF, that learned sparse representations for both queries and documents, mimicking what traditional approaches do. Since queries are much shorter than documents and queries contain much less information than documents, it makes sense for query representations to be denser. This was achieved by using, during training, a sparsity objective combined with hinge loss. In particular, an n-gram representation for queries and documents was used. It passed the embedding of each word separately through an individual MLP and performed average pooling on top. During training, the approach used pseudo-relevant documents obtained by retrieving documents using existing models like TF-IDF and BM25, because of the lack of enough correctly labeled documents to train large ANN models. The approach created a 20,000 bit long inverted index for each document using the trained network, just like a traditional end-to-end approach. For retrieval, a dot product was computed between query and document representations to obtain the retrieval relevance score. The SNRM PRF system obtained the best metrics (measured by MAP, P@20, nDCG@20, and Recall) across the board for two large datasets, Robust and ClueWeb. MacAveney et al. [171] extracted query term representations from two pre-trained contextualized language models, ELMo [70] and BERT [71], and used the representations to augment three existing competitive neural ranking architectures for ad-hoc document ranking, one of them being DRMM [169]. They also presented a joint model that combined BERT's classification vector with these architectures to get benefits from both approaches. MacAve"
    },
    {
      "heading": "B. Information Extraction",
      "text": "Information extraction extracts explicit or implicit information from text. The outputs of systems vary, but often the extracted data and the relationships within it are saved in relational databases [172]. Commonly extracted information includes named entities and relations, events and their participants, temporal information, and tuples of facts. 1) Named Entity Recognition: Named entity recognition (NER) refers to the identification of proper nouns as well as information such as dates, times, prices, and product IDs. The multi-task approach of Collobert et al. [9] included the task, although no results were reported. In their approach, a simple feedforward network was used, having a context with a fixed sized window around each word. Presumably, this made it difficult to capture long-distance relations between words. LSTMs were first used for NER by Hammerton [173]. The model, which was ahead of its time, had a small network due to the lack of available computing power at the time. Additionally, sophisticated numeric vector models for words were not yet available. Results were slightly better than the baseline for English and much better than the baseline for German. Dos Santos et al. [174] used a deep neural network architecture, known as CharWNN, which jointly used wordlevel and character-level inputs to perform sequential classification. In this study, a number of experiments were performed using the HAREM I annotated Portuguese corpus [175], and the SPA CoNLL2002 annotated Spanish corpus [176]. For the Portuguese corpus, CharWNN outperformed the previous state-of-the-art system across ten named entity classes. It also achieved state-of-the-art performance in Spanish. The authors noted that when used alone, neither word embeddings nor character level embeddings worked. This revalidated a fact long-known: Joint use of word-level and character-level features is important to effective NER performance. Chiu and Nichols [177] used a bidirectional LSTM with a character-level CNN resembling those used by dos Santos et al. [174]. Without using any private lexicons, detailed information about linked entities, or produce state-of-the-art results on the CoNLL-2003 [178] and OntoNotes [179], [180] datasets. Lample et al. [181] developed an architecture based on bidirectional LSTMs and conditional random fields (CRFs). The model used both character-level inputs and word embeddings. The inputs were combined and then fed to a bidirectional LSTM, whose outputs were in turn fed to a layer that performed CRF computations [182]. The model, when trained using dropout, obtained state-of-the-art performance in both German and Spanish. The LSTM-CRF model was also very close in both English and Dutch. The claim of this study was that state-of-the-art results were achieved without the use of any hand-engineered features or gazetteers. Akbik et al. [183] achieved state-of-the-art performance in German and English NER using a pre-trained bidirectional character language model. They retrieved for each word a contextual embedding that they passed into a BiLSTM-CRF sequence labeler to perform NER. 2) Event Extraction: Event extraction is concerned with identifying words or phrases that refer to the occurrence of events, along with participants such as agents, objects, recipients, and times of occurrence. Event extraction usually deals with four sub-tasks: identifying event mentions, or phrases that describe events; identifying event triggers, which are the main words-usually verbs or gerunds-that specify the occurrence of the events; identifying arguments of the events; and identifying arguments' roles in the events. Chen et al. [184] argued that CNNs that use max-pooling are likely to capture only the most important information in a sentence, and as a result, might miss valuable facts when considering sentences that refer to several events. To address this drawback, they divided the feature map into three parts, and instead of using one maximum value, kept the maximum value of each part. In the first stage, they classified each word as either being a trigger word or non-trigger word. If triggers were found, the second stage aligned the roles of arguments. Results showed that this approach significantly outperformed other state-of-the-art methods of the time. The following year, Nguyen et al. [185] used an RNN-based encoder-decoder pair to identify event triggers and roles, exceeding earlier results. Liu et al. [186] presented a latent variable neural model to induce event schemas and extract open domain events, achieving best results on a dataset they created and released. 3) Relationship Extraction: Another important type of information extracted from text is that of relationships. These may be possessive, antonymous or synonymous relationships, or more natural, familial or geographic, relationships. The first deep learning approach was that of Zeng et al. [23], who used a simple CNN to classify a number of relationships between"
    },
    {
      "heading": "C. Text Classification",
      "text": "Another classic application for NLP is text classification, or the assignment of free-text documents to predefined classes. Document classification has numerous applications. Kim [20] was the first to use pretrained word vectors in a CNN for sentence-level classification. Kim's work was moti-vating, and showed that simple CNNs, with one convolutional layer followed by a dense layer with dropout and softmax output, could achieve excellent results on multiple benchmarks using little hyperparameter tuning. The CNN models proposed were able to improve upon the state of the art on 4 out of 7 different tasks cast as sentence classification, including sentiment analysis and question classification. Conneau et al. [191] later showed that networks that employ a large number of convolutional layers work well for document classification. Jiang [192] used a hybrid architecture combining a deep belief network [193] and softmax regression [194]. (A deep belief network is a feedforward network where pairs of hidden layers are designed to resemble restricted Boltzmann machines [195], which are trained using unsupervised learning and are designed to increase or decrease dimensionality of data.) This was achieved by making passes over the data using forward and backward propagation many times until a minimum engery-based loss was found. This process was independent of the labeled or classification portion of the task, and was therefore initially trained without the softmax regression output layer. Once both sections of the architecture were pretrained, they were combined and trained like a regular deep neural net with backpropagation and quasi-Newton methods [196]. Adhikari et al. [197] used BERT [71] to obtain state-of-theart classification results on four document datasets. While deep learning is promising for many areas of NLP, including text classification, it is not necessarily the end-all-beall, and many hurdles are still present. Worsham and Kalita [198] found that for the task of classifying long full-length books by genre, gradient boosting trees are superior to neural networks, including both CNNs and LSTMs."
    },
    {
      "heading": "D. Text Generation",
      "text": "Many NLP tasks require the generation of human-like language. Summarization and machine translation convert one text to another in a sequence-to-sequence (seq2seq) fashion. Other tasks, such as image and video captioning and automatic weather and sports reporting, convert non-textual data to text. Some tasks, however, produce text without any input data to convert (or with only small amounts used as a topic or guide). These tasks include poetry generation, joke generation, and story generation. 1) Poetry Generation: Poetry generation is arguably the hardest of the generation subtasks, as in addition to producing creative content, the content must be delivered in an aesthetic manner, usually following a specific structure. As with most tasks requiring textual output, recurrent models are the standard. However, while recurrent networks are great at learning internal language models, they do a poor job of producing structured output or adhering to any single style. Wei et al. [199] addressed the style issue by training using particular poets and controlling for style in Chinese poetry. They found that with enough training data, adequate results could be achieved. The structure problem was addressed by Hopkins and Kiela [200], who generated rhythmic poetry by training the network on only a single type of poem to ensure produced poems adhered to a single rhythmic structure. Human evalu-ators judged poems produced to be of lower quality than, but indistinguishable from, human produced poems. Another approach to poetry generation, beginning this year, has been to use pretrained language models. Specifically, Radford et al.'s GPT-2 model [201], the successor of the GPT model (Section III-A7) has been used. Radford et al. hypothesised that alongside sequence-to-sequence learning and attention, language models can inherently start to learn text generation while training over a vast dataset. As of late 2019, these pre-trained GPT-2 models are arguably the most effective and prolific neural natural language generators. Bena and Kalita [202] used the 774 million parameter GPT-2 model to generate high-quality poems in English, demonstrating and eliciting emotional response in readers. (Two other models are available: 355 million parameters, and as of Novemeber 2019, 1.5 billion parameters.) Tucker and Kalita [203] generated poems in several languages-English, Spanish, Ukrainian, Hindi, Bengali, and Assamese-using the 774 M model as well. This study provided astonishing results in the fact that GPT-2 was pre-trained on a large English corpus, yet with further training on only a few hundred poems in another language, it turns into a believable generator in that language, even for poetry. 2) Joke and Pun Generation: Another area which has received little attention is the use of deep learning for joke and pun generation. Yu et al. [204] generated homographic puns (puns which use multiple meanings of the same written word) using a small LSTM. The network produced sentences in which ambiguities were introduced by words with multiple meanings, although it did a poor job of making the puns humorous. The generated puns were classified by human evaluators as machine generated a majority of the time. The authors noted that training on pun data alone is not sufficient for generating good puns. Ren and Yang [205] used an LSTM to generate jokes, training on two datasets, one of which was a collection of short jokes from Conan O'Brien. Since many of these jokes pertain to current events, the network was also trained on a set of news articles. This gave context to the example jokes. Chippada and Saha [206] generated jokes, quotes, and tweets using the same neural network, using an additional input to specify which should be produced. It was found that providing more general knowledge of other types of language, and examples of non-jokes, increased the quality of the jokes produced. 3) Story Generation: While poetry and especially humor generation have not gained much traction, story generation has seen a recent rise in interest. Jain et al. [207] used RNN variants with attention to produce short stories from \"oneliner\" story descriptions. Another recent study of interest is that by Peng et al. [208], who used LSTMs to generate stories, providing an input to specify whether the story should have a happy or sad ending. Their model successfully did so while at the same time providing better coherence than non-controlled stories. More recent attempts at the task have used special mechanisms focusing on the \"events\" (or actions) in the stories [209] or on the entities (characters and important objects) [210]. Even with such constraints, generated stories generally become incoherent or lose direction rather shortly. Xu et al. [211] addressed this by using a \"skeleton\" based model to build general sentences and fill in important information. This did a great job of capturing only the most important information, but still provided only modest e"
    },
    {
      "heading": "E. Summarization",
      "text": "Summarization finds elements of interest in documents in order to produce an encapsulation of the most important content. There are two primary types of summarization: extractive and abstractive. The first focuses on sentence extraction, simplification, reordering, and concatenation to relay the important information in documents using text taken directly from the documents. Abstractive summaries rely on expressing documents' contents through generation-style abstraction, possibly using words never seen in the documents [48]. Rush et al. [39] introduced deep learning to summarization, using a feedforward neural networrk. The language model used an encoder and a generative beam search decoder. The initial input was given directly to both the language model and the convolutional attention-based encoder, which determined contextual importance surrounding the summary sentences and phrases. The performance of the model was comparable to other state-of-the-art models of the time. As in other areas, attention mechanisms have improved performance of encoder-decoder models. Krantz and Kalita [232] compared various attention models for abstractive summarization. A state-of-the-art approach developed by Paulus et al. [40] used a multiple intra-temporal attention encoder mechanism that considered not only the input text tokens, but also the output tokens used by the decoder for previously generated words. They also used similar hybrid cross-entropy loss functions to those proposed by Ranzato et al. [233], which led to decreases in training and execution by orders of magnitude. Finally, they recommended using strategies seen in reinforcement learning to modify gradients and reduce exposure bias, which has been noted in models trained exclusively via supervised learning. The use of attention also boosted accuracy in the fully convolutional model proposed by Gehring et al. [234], who implemented an attention mechanism for each layer. Zhang et al. [235] proposed an encoder-decoder framework, which generated an output sequence based on an input sequence in a two-stage manner. They encoded the input sequence using BERT [71]. The decoder had two stages. In the first stage, a Transformer-based decoder generated a draft output sequence. In the second stage, they masked each word of the draft sequence and fed it to BERT, and then by combining the input sequence and the draft representation generated by BERT, they used a Transformer-based decoder to predict the refined word for each masked position. Their model achieved state-of-the-art performance on the CNN/Daily Mail and New York Times datasets."
    },
    {
      "heading": "F. Question Answering",
      "text": "Similar to summarization and information extraction, question answering (QA) gathers relevant words, phrases, or sentences from a document. QA returns this information in a coherent fashion in response to a request. Current methods resemble those of summarization. Wang et al. [41] used a gated attention-based recurrent network to match the question with an answer-containing passage. A self-matching attention mechanism was used to refine the machine representation by mapping the entire passage. Pointer networks were used to predict the location and boundary of an answer. These networks used attention-pooling vector representations of passages, as well as the words being analyzed, to model the critical tokens or phrases necessary. Multicolumn CNNs were used by Dong et al. [236] to automatically analyze questions from multiple viewpoints. Parallel networks were used to extract pertinent information from input questions. Separate networks were used to find context information and relationships and to determine which forms of answers should be returned. The output of these networks was combined and used to rank possible answers. Santoro et al. [237] used relational networks (RNs) for summarization. First proposed by Raposo et al. [238], RNs are built upon an MLP architecture, with focus on relational reasoning, i.e. defining relationships among entities in the data. These feedforward networks implement a similar function among all pairs of objects in order to aggregate correlations among them. For input, the RNs took final LSTM representations of document sentences. These inputs were further paired with a representation of the information request given [237]. BERT [71] achieved state of theart in QA experiments on SQuAD 1.1 and SQuAD 2.0 datasets. Yang et al. [239] demonstrate an end-to-end question answering system that integrates BERT with the open-source Anserini information retrieval toolkit. This system is able to identify answers from a large corpus of Wikipedia articles in an end-to-end fashion, obtaining best results on a standard benchmark test collection."
    },
    {
      "heading": "G. Machine Translation",
      "text": "Machine translation (MT) is the quintessential application of NLP. It involves the use of mathematical and algorithmic techniques to translate documents in one language to another. Performing effective translation is intrinsically onerous even for humans, requiring proficiency in areas such as morphology, syntax, and semantics, as well as an adept understanding and discernment of cultural sensitivities, for both of the languages (and associated societies) under consideration [48]. The first attempt at neural machine translation (NMT) was that by Schwenk [240], although neural models had previously been used for the similar task of transliteration, converting certain parts of text, such as proper nouns, into different languages [241]. Schwenk used a feed-forward network with seven-word inputs and outputs, padding and trimming when necessary. The ability to translate from a sentence of one length to a sentence of another length came about with the introduction of encoder-decoder models. The first use of such a model, by Kalchbrenner and Blumson [242], stemmed from the success of continuous recurrent representations in capturing syntax, semantics, and morphology [243] in addition to the ability of RNNs to build robust language models [29]. This original NMT encoder-decoder model used a combination of generative convolutional and recurrent layers to encode and optimize a source language model and cast this into a target language. The model was quickly reworked and further studied by Cho et al. [244] and numerous novel and effective advances to this model have since been made [38], [245]. Encoder-decoder models have continuously defined the state of the art, being expanded to contain dozens of layers, with residual connections, attention mechanisms, and even residual attention mechanisms allowing the final decoding layer to attend to the first encoding layer [246]. Stateof-the-art results have also been achieved by using numerous convolutional layers in both the encoder and decoder, allowing information to be viewed in several hierarchical layers rather than a multitude of recurrent steps [234]. Such derived models are continually improving, finding answers to the shortcomings of their predecessors and overcoming any need for hand engineering [247]. Recent progress includes effective initialization of decoder hidden states, use of conditional gated attentional cells, removal of bias in embedding layers, use of alternative decoding phases, factorization of embeddings, and test time use of the beam search algorithm [248], [249]. The standard initialization for the decoder state is that proposed by Bahdanau et al. [38], using the last backward encoder state. However, as noted by Britz et al. [247], using the average of the embedding or annotation layer seems to lead to the best translations. Gated recurrent cells have been the gold standard for sequence-to-sequence tasks, a variation of which is a conditional GRU (cGRU) [248], most effectively utilized with an attention mechanism. A cGRU cell consists of three key components: two GRU transition blocks and an attention mechanism between them. These three blocks combine the previous hidden state, along with the attention context window to generate the next hidden state. Altering the decoding process [38] from Look at input, Generate output token, Update hidden representation to a process of Look, Update, Generate can simplify the final decoding. Adding further source attributes such as morphological segmentation labels, POS tags, and syntactic dependency labels improves models, and concatenating or factorizing these with embeddings increases robustness further [250], [248]. For remembering long-term dependencies, vertically stacked recurrent units have been the standard, with the optimum number of layers having been determined to be roughly between two and sixteen [247], depending on the desired input length as well as the presence and density of residual connections. At test time, a beam search algorithm can be used beside the final softmax layer for considering multiple target predictions in a greedy fashion, allowing the best predictions to be found without looking through the entire hypothesis space [249]. In a direction diverging from previous work, Vaswani et al. [42], [251] proposed discarding the large number of recurrent and convolutional layers and instead focusing exclusively on attention mechanisms to encode a language globally from input to output. Preferring such \"self-attention\" mechanisms over traditional layers is motivated by the following three principles: reducing the complexity of computations required per layer, minimizing sequential training steps, and lastly, abating the path length from input to output and its handicap on the learning of the long-range dependencies which are necessary in many sequencing tasks [252]. Apart from increased accuracy across translation tasks, self-attention models allow more parallelization throughout architecture"
    },
    {
      "heading": "H. Summary of Deep Learning NLP Applications",
      "text": "Numerous other applications of natural language processing exist including grammar correction, as seen in word processors, and author mimicking, which, given sufficient data, generates text replicating the style of a particular writer. Many of these applications are infrequently used, understudied, or not yet exposed to deep learning. However, the area of sentiment analysis should be noted, as it is becoming increasingly popular and utilizing deep learning. In large part a semantic task, it is the extraction of a writer's sentiment-their positive, negative, or neutral inclination towards some subject or idea [268]. Applications are varied, including product research, futures prediction, social media analysis, and classification of spam [269], [270]. The current state of the art uses an ensemble including both LSTMs and CNNs [271]. This section has provided a number of select examples of the applied usages of deep learning in natural language processing. Countless studies have been conducted in these and similar areas, chronicling the ways in which deep learning has facilitated the successful use of natural language in a wide variety of applications. Only a minuscule fraction of such work has been referred to in this survey. While more specific recommendations for practitioners have been discussed in some individual subsections, the current trend in state-of-the-art models in all application areas is to use pre-trained stacks of Transformer units in some configuration, whether in encoder-decoder configurations or just as encoders. Thus, self-attention which is the mainstay of Transformer has become the norm, along with cross-attention between encoder and decoder units, if decoders are present. In fact, in many recent papers, if not most, Transformers have begun to replace LSTM units that were preponderant just a few months ago. Pre-training of these large Transformer models has also become the accepted way to endow a model with generalized knowledge of language. Models such as BERT, which have been trained on corpora of billions of words, are available for download, thus providing a practitioner with a model that possesses a great amount of general knowledge of language already. A practitioner can further train it with one's own general corpora, if desired, but such training is not always necessary, considering the enormous sizes of the pre-training that downloaded models have received. To train a model to perform a certain task well, the last step a practitioner must go through is to use available downloadable task-specific corpora, or build one's own task-specific corpus. This last training step is usually supervised. It is also recommended that if several tasks are to be performed, multi-task training be used wherever possible."
    },
    {
      "heading": "V. CONCLUSIONS",
      "text": "Early applications of natural language processing included a well-acclaimed but simpleminded algebra word problem solver program called STUDENT [272], as well as interesting but severely constrained conversational systems such as Eliza, which acted as a \"psycho-therapist\" [273]), and another that conversed about manipulating blocks in a microworld [274]. Nowadays, highly advanced applications of NLP are ubiquitous. These include Google's and Microsoft's machine translators, which translate more or less competently from a language to scores of other languages, as well as a number of devices which process voice commands and respond in like. The emergence of these sophisticated applications, particularly in deployed settings, acts as a testament to the impressive accomplishments that have been made in this domain over the last sixty or so years. Without a doubt, incredible progress has taken place, particularly in the last several years. As has been shown, this recent progress has a clear causal relationship with the remarkable advances in Artificial Neural Networks. Considered an \"old\" technology just a decade ago, these machine learning constructs have ushered in progress at an unprecedented rate, breaking performance records in myriad tasks in miscellaneous fields. In particular, deep neural architectures, have instilled models with higher performance in natural language tasks, in terms of \"imperfect\" metrics. Consolidating the analysis of all the models surveyed, a few general trends can be surmised. Both convolutional and recurrent specimen had contributed to the state of the art in the recent past, however, of very late, stacks of attention-powered Transformer units as encoders and often decoders, have consistently produced superior results across the rich and varying terrain of the NLP field. These models are generally heavily pre-trained on general language knowledge in an unsupervised or supervised manner, and somewhat lightly trained on specific tasks in a supervised fashion. Second, attention mechanisms alone, without recurrences or convolutions, seem to provide the best connections between encoders and decoders. Third, forcing networks to examine different features (by performing multiple tasks) usually improves results. Finally, while highly engineering networks usually optimizes results, there is no substitute for cultivating networks with large quantities of high quality data, although pre-training on large generic corpora seems to help immensely. Following from this final observation, it may be useful to direct more research effort toward pre-training methodologies, rather than developing highly-specialized components to squeeze the last drops of performance from complex models. While the numerous stellar architectures being proposed each month are highly competitive, muddling the process of identifying a winning architecture, the methods of evaluation used add just as much complexity to the problem. Datasets used to evaluate new models are often generated specifically for those models and are then used only several more times, if at all, although consolidated datasets encompassing several tasks such as GLUE [275] have started to emerge. As the features and sizes of these datasets are highly variable, this makes comparison difficult. Most subfields of NLP, as well as the field as a whole, would benefit from extensive, large-scale discussions regarding the necessary contents of such datasets, followed by the compilation of such sets. In addition to high variability in evaluation data, there are numerous metrics used to evaluate performance on each task. Oftentimes, comparing similar models is difficult due to the fact that different metrics are reported for each. Agreement on particular sets of metrics would go a long way toward ensuring clear comparisons in the field. Furthermore, metrics are usually only reported for the best case, with few mentions of average cases and variability, or of worst cases. While it is important to understand the possible performance of new models, it is just as important to understand the standard performance. If models produce highly variable results, they may take many attempts to train to the cutting-edge levels reported. In most cases, this is undesirable, and models that can be consistently trained to relatively high levels of performance are preferable. While increasingly large numbers of randomized parameters do reduce variation in performance, some variance will always exist, necessitating the reporting of more than just best-case metrics. One final recommendation for future work is that it be directed toward a wider variety of languages than it is at present. Currently, the vast majority of research in NLP is conducted on the English language, with another sizeable portion using Mandarin Chinese. In translation tasks, English is almost always either the input or output language, with the other end usually being one of a dozen major European or Eastern Asia"
    }
  ],
  "figures": [],
  "equations": []
}