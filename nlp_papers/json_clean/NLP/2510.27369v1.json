{
  "paperid": "2510.27369v1",
  "title": "From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle",
  "authors": [
    "Adewumi",
    "Karlsson",
    "Liwicki",
    "Sjödahl",
    "Alkhaled",
    "Gargouri",
    "Habib",
    "Hennies",
    "Abdel-Nabi",
    "Awajan",
    "Ali",
    "Adelani",
    "Abbott",
    "Neubig",
    "Kreutzer",
    "Lignos",
    "Palen-Michel",
    "Buzaaba",
    "Rijhwani",
    "Ruder",
    "Adewumi",
    "Alkhaled",
    "Gurung",
    "Van Boven",
    "Pagliai",
    "Adewumi",
    "Alkhaled",
    "Imbert",
    "Han",
    "Habib",
    "Löwenmark",
    "Adewumi",
    "Habib",
    "Alkhaled",
    "Barney",
    "Adewumi",
    "Habib",
    "Alkhaled",
    "Barney",
    "Adewumi",
    "Liwicki",
    "Liwicki",
    "Adewumi",
    "Liwicki",
    "Fs",
    "Liwicki",
    "Gardelli",
    "Alkhaled",
    "Mokayed",
    "Adewumi",
    "Vadoodi",
    "Tripathy",
    "Nikolaido",
    "Liwicki",
    "Liwicki",
    "Calzolari",
    "Béchet",
    "Blache",
    "Choukri",
    "Cieri",
    "Declerck",
    "Goggi",
    "Isahara",
    "Maegaard",
    "Mariani",
    "Mazo",
    "Odijk",
    "Attia",
    "Moch",
    "Herring",
    "Bai",
    "Yao",
    "Lin",
    "Wu",
    "Li",
    "Wang",
    "Ma",
    "Mu",
    "Hu",
    "Yang",
    "Bender",
    "Friedman",
    "Benzeghiba",
    "Mori",
    "Deroo",
    "Dupont",
    "Erbes",
    "Jouvet",
    "Fissore",
    "Laface",
    "Mertins",
    "Ris",
    "Berger",
    "Schöggl",
    "Baumgartner",
    "Bian",
    "Duan",
    "Hao",
    "Yang",
    "Feng",
    "Bojar",
    "Buck",
    "Federmann",
    "Haddow",
    "Koehn",
    "Leveling",
    "Monz",
    "Pecina",
    "Post",
    "Saint-Amand",
    "Brown",
    "Mann",
    "Ryder",
    "Subbiah",
    "Kaplan",
    "Jd",
    "Dhariwal",
    "Neelakantan",
    "Shyam",
    "Sastry",
    "Askell",
    "Brundage",
    "Sexton",
    "Hodkiewicz",
    "Dima",
    "Lukens",
    "Cheung",
    "Zhuang",
    "Li",
    "Shetty",
    "Zhao",
    "Grampurohit",
    "Ramprasad",
    "Zhang",
    "Choi",
    "Lee",
    "Choudhary",
    "Kelley",
    "Clark",
    "Bleken",
    "Fl",
    "Stier",
    "Flores",
    "Andersen",
    "Marcinek",
    "Szczesna-Chrzan",
    "Gaberscek",
    "Palacin",
    "Mr",
    "Uhrin",
    "Cohan",
    "Dernoncourt",
    "Kim",
    "Bui",
    "Kim",
    "Chang",
    "& Goharian",
    "Degen",
    "Winter",
    "Bendig",
    "Tübke",
    "Derczynski",
    "Nichols",
    "Van Erp",
    "Limsopatham",
    "Devlin",
    "Chang",
    "Lee",
    "Toutanova",
    "Dima",
    "Lukens",
    "Hodkiewicz",
    "Sexton",
    "Brundage",
    "Dione",
    "Adelani",
    "Di",
    "Nabende",
    "Alabi",
    "Sindane",
    "Buzaaba",
    "Muhammad",
    "Sh",
    "Emezue",
    "Cc",
    "Ogayo",
    "Aremu",
    "Gitau",
    "Mbaye",
    "Mukiibi",
    "Sibanda",
    "Dossou",
    "Bfp",
    "Bukula",
    "Mabuya",
    "Tapo",
    "Munkoh-Buabeng",
    "Koagne",
    "Kabore",
    "Taylor",
    "Kalipe",
    "Macucwa",
    "Marivate",
    "Gwadabe",
    "Elvis",
    "Mt",
    "Onyenwe",
    "Atindogbe",
    "Adelani",
    "Akinade",
    "Samuel",
    "Nahimana",
    "Musabeyezu",
    "Niyomutabazi",
    "Chimhenga",
    "Gotosa",
    "Mizha",
    "Agbolo",
    "Traore",
    "Uchechukwu",
    "Yusuf",
    "Abdullahi",
    "Klakow",
    "Eisenstein",
    "El-Bousiydy",
    "Lombardo",
    "Primo",
    "En",
    "Duquesnoy",
    "Morcrette",
    "Johansson",
    "Simon",
    "Grimaud",
    "Franco",
    "El-Kassas",
    "Ws",
    "Salama",
    "Cr",
    "Rafea",
    "Mohamed",
    "Hk",
    "Gasparetto",
    "Marcuzzo",
    "Zangari",
    "Albarelli",
    "Gehrmann",
    "Adewumi",
    "Aggarwal",
    "Ammanamanchi",
    "Ps",
    "Aremu",
    "Bosselut",
    "Chandu",
    "Kr",
    "Clinciu",
    "Das",
    "Dhole",
    "Du",
    "Durmus",
    "Dušek",
    "Emezue",
    "Cc",
    "Gangal",
    "Garbacea",
    "Hashimoto",
    "Hou",
    "Jernite",
    "Jhamtani",
    "Ji",
    "Jolly",
    "Kale",
    "Kumar",
    "Ladhak",
    "Madaan",
    "Maddela",
    "Mahajan",
    "Mahamood",
    "Majumder",
    "Bp",
    "Martins",
    "Mcmillan-Major",
    "Mille",
    "Van Miltenburg",
    "Nadeem",
    "Narayan",
    "Nikolaev",
    "Rubungo",
    "Osei",
    "Parikh",
    "Perez-Beltrachini",
    "Rao",
    "Raunak",
    "Rodriguez",
    "Santhanam",
    "Sedoc",
    "Sellam",
    "Shaikh",
    "Shimorina",
    "Cabezudo",
    "Ma",
    "Strobelt",
    "Subramani",
    "Xu",
    "Yang",
    "Yerukola",
    "Zhou",
    "Gou",
    "Zhang",
    "Zhu",
    "Shu",
    "Graves",
    "Fernández",
    "Schmidhuber",
    "Grishman",
    "Guzmán",
    "Chen",
    "Ott",
    "Pino",
    "Lample",
    "Koehn",
    "Chaudhary",
    "Ranzato",
    "Habib",
    "Adewumi",
    "Liwicki",
    "Barney",
    "He",
    "Zhang",
    "He",
    "Gao",
    "Chen",
    "Hu",
    "Hou",
    "Liu",
    "Huang",
    "Cole",
    "Huang",
    "Cole",
    "Huang",
    "Cole",
    "Jiang",
    "Lu",
    "Jiang",
    "Wang",
    "Tian",
    "Wang",
    "Lookman",
    "Su",
    "Kheddar",
    "Hemis",
    "Himeur",
    "Kim",
    "Kim",
    "Moon",
    "Kryscinski",
    "Rajani",
    "Agarwal",
    "Xiong",
    "Radev",
    "Lane",
    "Dyshel",
    "Lee",
    "Choi",
    "Mizuseki",
    "Lee",
    "Lee",
    "Mizuseki",
    "Choi",
    "Lee",
    "Lee",
    "Min",
    "Lee",
    "Shin",
    "Hwang",
    "Liang",
    "Wang",
    "Li",
    "Wang",
    "Liddy",
    "Lin",
    "Lin",
    "Chou",
    "Liu",
    "Hu",
    "Zhou",
    "Tong",
    "Widanage",
    "Marco",
    "Liu",
    "He",
    "Bian",
    "Guo",
    "Zhang",
    "Liu",
    "Ott",
    "Goyal",
    "Du",
    "Joshi",
    "Chen",
    "Levy",
    "Lewis",
    "Zettlemoyer",
    "Stoyanov",
    "Löwenmark",
    "Taal",
    "Vurgaft",
    "Nivre",
    "Liwicki",
    "Sandin",
    "Lyonnard",
    "Biscari",
    "Bozzini",
    "Casas-Cabanas",
    "Calisto",
    "Bm",
    "Fransson",
    "Graceffa",
    "Hennies",
    "Hinrichsen",
    "Karlsson",
    "Maas",
    "Daly",
    "Pham",
    "Huang",
    "Ng",
    "Potts",
    "Maghsoudi",
    "Mohammadi",
    "Bakhtiari",
    "Mahbub",
    "Huang",
    "Jensen",
    "Hood",
    "Zd",
    "Rupp",
    "Olivetti",
    "Manning",
    "Marcus",
    "Santorini",
    "Marcinkiewicz",
    "Mikolov",
    "Chen",
    "Corrado",
    "Dean",
    "Minaee",
    "Kalchbrenner",
    "Cambria",
    "Nikzad",
    "Chenaghlu",
    "Gao",
    "Mitali",
    "Dhinakaran",
    "Mohamad",
    "Mitchell",
    "Wu",
    "Zaldivar",
    "Barnes",
    "Vasserman",
    "Hutchinson",
    "Spitzer",
    "Raji",
    "Id & Gebru",
    "Munjal",
    "Prein",
    "Venugopal",
    "Huang",
    "Olivetti",
    "Na",
    "Long",
    "Chen",
    "Wang",
    "Yang",
    "Sun",
    "Huang",
    "Nekahi",
    "Dorri",
    "Rezaei",
    "Bouguern",
    "Reddy",
    "Li",
    "Deng",
    "Zaghib",
    "Nekahi",
    "Feyzi",
    "Srivastava",
    "Yeganehdoust",
    "Reddy",
    "Zaghib",
    "Nie",
    "Zheng",
    "Liu",
    "Chen",
    "Li",
    "Lei",
    "Pan",
    "Openai",
    "Hurst",
    "Lerer",
    "Goucher",
    "Ap",
    "Perelman",
    "Ramesh",
    "Clark",
    "Ostrow",
    "Welihinda",
    "Hayes",
    "Radford",
    "Mądry",
    "Baker-Whitcomb",
    "Beutel",
    "Borzunov",
    "Carney",
    "More",
    "Oprea",
    "Bâra",
    "Aydin",
    "Zajonz",
    "Günther",
    "Dermenci",
    "Kb",
    "Berecibar",
    "Urrutia",
    "Osaro",
    "Karpinski",
    "Alornyo",
    "Ighalo",
    "O'gorman",
    "Jensen",
    "Mysore",
    "Huang",
    "Mahbub",
    "Olivetti",
    "Mccallum",
    "Page",
    "Mckenzie",
    "Bossuyt",
    "Boutron",
    "Hoffmann",
    "Mulrow",
    "Cd",
    "Shamseer",
    "Tetzlaff",
    "Akl",
    "Ea",
    "Brennan",
    "Se",
    "Park",
    "Onwuli",
    "Walsh",
    "Pei",
    "Yin",
    "Zhang",
    "Pettersson",
    "Hult",
    "Eriksson",
    "Adewumi",
    "Pievaste",
    "Belouettar",
    "Mercuri",
    "Fantuzzi",
    "Dehghani",
    "Izadi",
    "Ibrahim",
    "Lengiewicz",
    "Belouettar-Mathis",
    "Bendine",
    "Popowicz",
    "Pohlmann",
    "Schöggl",
    "Baumgartner",
    "Pushkarna",
    "Zaldivar",
    "Kjartansson",
    "Ren",
    "Wu",
    "Zhuang",
    "Sun",
    "Guo",
    "Wu",
    "Chen",
    "Liu",
    "Rizos",
    "Urban",
    "Schomburg",
    "Heidrich",
    "Wennemar",
    "Drees",
    "Roth",
    "Kurrat",
    "Heimes",
    "Jossen",
    "Winter",
    "Cheong",
    "Sebastiani",
    "Shen",
    "Gao",
    "Shon",
    "Min",
    "Singh",
    "Mittal",
    "Chouhan",
    "Srinivasa-Desikan",
    "Kim",
    "Meulder",
    "Toutanova",
    "Klein",
    "Manning",
    "Singer",
    "Vaswani",
    "Shazeer",
    "Parmar",
    "Uszkoreit",
    "Jones",
    "Gomez",
    "Kaiser",
    "Polosukhin",
    "Wang",
    "Wu",
    "He",
    "Huang",
    "Church",
    "Wankhade",
    "Rao",
    "Kulkarni",
    "Wen",
    "Jain",
    "Kirchenbauer",
    "Goldblum",
    "Geiping",
    "Goldstein",
    "Weng",
    "Olide",
    "Kovalchuk",
    "Siegel",
    "Stefanopoulou",
    "Weston",
    "Tshitoyan",
    "Dagdelen",
    "Kononova",
    "Trewartha",
    "Persson",
    "Ceder",
    "Jain",
    "Wilkinson",
    "Dumontier",
    "Aalbersberg",
    "Ij",
    "Appleton",
    "Axton",
    "Baak",
    "Blomberg",
    "Boiten",
    "Da",
    "Santos",
    "Bourne",
    "Winter",
    "Brodd",
    "Wu",
    "Nguyen",
    "Luu",
    "Xiao",
    "Cao",
    "Gridley",
    "Golden",
    "Ji",
    "Johnson",
    "Lu",
    "Lin",
    "Liu",
    "Liu",
    "Xu",
    "Zhang",
    "Xu",
    "Xu",
    "Wu",
    "Tang",
    "Gui",
    "Yatskar",
    "Ye",
    "Ren",
    "Wang",
    "Wan",
    "Razzak",
    "Hoex",
    "Wang",
    "Xie",
    "Zhang",
    "Zhang",
    "Kishore",
    "Wu",
    "Weinberger",
    "Artzi",
    "Zhao",
    "Chen",
    "Zhou",
    "Li",
    "Tang",
    "Harris",
    "Sj",
    "Liu",
    "Li",
    "Zheng",
    "Li",
    "Liu",
    "Wang",
    "Guo",
    "Wang",
    "Han",
    "Ouyang",
    "Zuo",
    "Zheng",
    "He",
    "Vishwanath",
    "Chan",
    "Stevens",
    "Amine",
    "Xu"
  ],
  "year": 2025,
  "abstract": "We present a comprehensive systematic survey of the application of natural language processing (NLP) along the entire battery life cycle, instead of one stage or method, and introduce a novel technical language processing (TLP) framework for the EU's proposed digital battery passport (DBP) and other general battery predictions. We follow the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable databases or search engines, including Google Scholar, Institute of Electrical and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we assessed 274 scientific papers before the critical review of the final 66 relevant papers. We publicly provide artifacts of the review for validation and reproducibility. The findings show that new NLP tasks are emerging in the battery domain, which facilitate materials discovery and other stages of the life cycle. Notwithstanding, challenges remain, such as the lack of standard benchmarks. Our proposed TLP framework, which incorporates agentic AI and optimized prompts, will be apt for tackling some of the challenges.",
  "sections": [
    {
      "heading": "Introduction",
      "text": "In the fast-advancing field of natural language processing (NLP) and its many growing application areas, including battery production, new tasks are evolving. A battery is an energy storage system (ESS) that is capable of supplying electrical energy and is usually made of electrochemical substances (Mitali et al., 2022;Winter & Brodd, 2004). Meanwhile, NLP is a field with methods and tools for machines to analyze, understand and, possibly, generate natural human language (Eisenstein, 2019;Liddy, 2001). The battery production life cycle, as in many other fields, involves humans who communicate in natural language and store records of some of the communication about the entire complex value chain. Both successful and unsuccessful attempts along the value chain are usually documented in structured or unstructured reports. Indeed, the increasing storage demand because of sustainability is leading to Short title ongoing challenges and introduce our novel TLP framework for battery predictions. Finally, in Section 6, we conclude with the main insights from the study and possible future work."
    },
    {
      "heading": "Background",
      "text": "This section is intended to provide background information on related work that have surveyed NLP applications in the battery domain and the gaps they have. It provides the basics of NLP for battery engineers, who may be new to the field, and 11 of its traditional tasks in relation to the battery domain. The section also discusses the battery life cycle stages, which involve about 17 stages, from material sourcing to recycling or repurposing."
    },
    {
      "heading": "Related Work",
      "text": "There have been several attempts at surveying NLP in the battery domain. They are, however, limited to specific parts of the battery life cycle. For example, the work by Jiang et al. (2025) reviewed NLP application in materials science, with a focus on information extraction (IE) and materials discovery. They observed that within materials science, NLP is still in the early stages but the trend towards the development of material-specific pretrained language models is growing. Zuo et al. (2025) surveyed the applications of LLMs, addressing two questions of what LLMs offer to support battery-related tasks and how more effective LLMs may be developed? In contrast, our work offers a more comprehensive survey by including discriminative models. In the review by Pievaste et al. (2025), they highlighted macro-scale property prediction for the properties and performance of bulk materials in real-world applications, including multi-physics performance of a battery, as an example. The survey centered on machine learning (ML) methods for materials science, including traditional algorithms and deep learning architectures. Pei et al. (2025) reviewed the literature, examining how NLP facilitates the understanding and design of novel materials in materials science. The focus of their review was on the limitations of LLMs, the creation of a materials discovery pipeline, and the potential of generative pretrained transformer (GPT) models to synthesize existing knowledge for sustainable materials. Osaro et al. (2025) surveyed materials discovery and chemical synthesis, observing that AI-driven frameworks use existing compounds to predict new battery electrode materials with optimized properties for conductivity and stability. Kim et al. (2025) reviewed R-based energy forecasting for different energy sources instead of the more common Python language, including a brief mention of batteries. Lin & Chou (2025) conducted a systematic review of AI in patent analysis, discussing works that used principal component analysis (PCA) and random forest (RF). Earlier works, such as Singh et al. (2022), surveyed deep learning approaches in NLP for battery materials. They identified classification, IE, summarization and materials discovery as some of the tasks or applications of NLP in the battery domain. In their perspective paper, Zhao et al. (2024) discussed the potential for insights on battery research from LLMs, with particular attention on fast charging and ChatGPT. Clark et al. (2022) focused on the state of ontology development, emphasizing the need for such in battery research and production. Lee et al. (2023) conducted a short review on NLP for materials discovery. They observed that the number of scientific papers from different databases that are used vary significantly across different research studies, lacking standardization, and sometimes involved the use of optical character recognition (OCR) for older documents. A review of LiB state-of-charge (SoC) estimation using deep learning was carried out by Liu et al. (2022), where they classified the methods into two: structured adjustment and unstructured improvement. They observed that LiB is currently the dominant battery type and identified the usual data acquisition process for training and verification datasets during a hypothetical driving cycle. Their review was limited to the SoC and some deep neural networks, especially recurrent neural networks (RNNs). A comprehensive survey along the entire value chain, such as our work, can draw lessons from one stage to benefit other stages of the value chain."
    },
    {
      "heading": "NLP Basics",
      "text": "NLP has advanced considerably over the decades from simple rule-based methods for machine translation (MT) tasks to deep neural network (NN) and LLMs for general tasks. The general NLP pipeline for solving a task involves the iterative steps of (1) data acquisition, (2) preprocessing (e.g. removal of unwanted characters), (3) tokenization (e.g. splitting into words), (4) model selection, (5) model training, (6) validation and hyper-parameter tuning, (7) testing, and ( 8) deployment (Lane & Dyshel, 2025;Srinivasa-Desikan, 2018). The process of model training with NNs involves an important step of embedding creation, where the tokenized data is transformed into numerical representation (or embeddings) of a lookup table in relatively small dimension (Lane & Dyshel, 2025). The NN model training is based on minimizing a loss function (e.g. cross-entropy loss) to maximize a given utility function by comparing the model predictions to ground truth labels, in supervised learning, and backpropagating to iterate the procedure until a convenient validation loss is obtained so that the model can generalize to unseen data at test time. This pipeline is based on splitting the data into 3 parts -training, validation and test splits. The procedure is called unsupervised learning when there are no labels to compare predictions with and it must only learn patterns within the data. These two paradigms form the ends of the learning spectrum with variants in between, including reinforcement learning (RL). LLMs undergo self-supervised learning as pretraining before undergoing different types of post-training and deployment for inference. Models have become more complex and deep from the shallow, non-contextual networks of the past, such as Word2Vec (Mikolov et al., 2013). Important concepts from past models can be found in recent models (e.g. embeddings in the early layers of deep models). Recent state-of-the-art (SotA) models, like LLMs, are based on the SotA Transformer architecture, which has both an encoder and decoder (Vaswani et al., 2017). For efficiency, researchers decouple the encoder for discriminative language understanding tasks (e.g. text classification (TC)) while the decoder is used for language generation (or generative) tasks (e.g. summarization) though it is also suitable for discriminative tasks. Examples of discriminative models include bidirectional encoder representations from transformers (BERT) and its many variants (Devlin et al., 2019;Liu et al., 2019;He et al., 2021) while examples of generative models include the GPT series (Brown et al., 2020;OpenAI et al., 2024). Some of these models are used in battery-related research and predictions, as will be discussed later. For example, GPT4 has been used in chemical named entity recognition (NER) and other tasks by Lee et al. (2024a). Qwen2.5-7B and Gemma2-9B are LLMs used in Zheng et al. (2025). Below, we identify some traditional tasks of NLP, i.e. those before the advent of LLMs, where the first 6 are categorized as natural language understanding (NLU) tasks and the remaining as natural language generation (NLG) tasks, except the last one, which is an unsupervised learning task. NLU tasks are usually evaluated with metrics like accuracy or F1 score and NLG tasks with n-gram-based metrics like ROUGE (Lin, 2004;Gehrmann et al., 2021) or semantic-based models like BERTScore (Zhang et al., 2020). Noteworthy that despite the improvements in NLP, challenges, such as hallucinations and biases, still exist in the field (Adewumi et al., 2025a;Pettersson et al., 2024). Some Traditional NLP Tasks 1. TC: It is the general activity of automatically labeling natural language texts with thematic categories from a predefined set (Sebastiani, 2002). A variety of standard definitions of TC tasks exists in NLP. Some examples are sentiment analysis (SA), author attribution, news classification, and NER (Gasparetto et al., 2022;Habib et al., 2025). Each of these sub-tasks have many datasets available and they are widely used in research. In battery research, TC is used to automatically select battery related documents from a large collection, making literature screening and dataset building faster. For example, BatteryBERT was fine-tuned on labeled abstracts to classify whether a paper is battery-related, enabling more focused materials data mining (Huang & Cole, 2022a). 2. NER: It seeks to identify and classify mentions of specific entities often referred to as rigid designators into predefined semantic categories such as chemical compounds, persons, locations, organizations, and others (Adelani et al., 2021). NER enables structured extraction of key information from unstructured text, supporting tasks like search, summarization, and knowledge graph construction. Commonly used datasets include CoNLL-2003, OntoNotes 5.0, and W-NUT (Hu et al., 2024;Tjong Kim Sang & De Meulder, 2003;Derczynski et al., 2017). NER can be used to extract chemical and material names from battery literature to support the automatic generation of structured datasets or to identify materials, synthesis descriptions, and phase labels that are relevant to battery research from large collections of scientific abstracts (Huang & Cole, 2022b;Weston et al., 2019). 3. Part-of-Speech (PoS) tagging: It is the process of automatically assigning each word in a sentence a grammatical category such as noun, verb, adjective, or adverb, based on its definition and context within the sentence (Toutanova et al., 2003). It is a core NLP task that helps models to understand sentence structure, supporting downstream applications like parsing, NER, and IE. Some of the datasets include part of the Penn Treebank and AfricaPOS (Dione et al., 2023;Marcus et al., 1993). While PoS tagging improves contextual understanding, it can struggle with word ambiguity, domain-specific terms, and noisy technical text (Manning, 2011). 4. IE: It refers to the automatic identification and organization of specific types of information, like entities, relationships, and events from unstructured or semi-structured text, transforming natural language into structured, machine-readable data (Grishman, 1997). IE can help battery research and production by extracting key data, like capacity, voltage, and efficiency, from text and turning them into structured formats. This makes it easier to build battery databases, compare performances, and spot useful trends for material and design choices (Huang & Cole, 2022b). An example dataset includes POLYIE (Cheung et al., 2024). 5. SA: It is a TC task of automatically detecting and classifying emotions or opinions in text. This is typically positive and negative or may contain neutral (Maas et al., 2011). It plays a key role in applications such as customer feedback analysis, social media monitoring, and product review mining. It enables users to extract information from textual data automatically to support fast decisions about customer satisfaction or product improvement, even within the battery value chain (Wankhade et al., 2022). Example datasets include Yelp, internet movie database (IMDb), and movie review datasets (Minaee et al., 2021;Maas et al., 2011). 6. Question Answering (QA): It is a task involving systems that can understand a natural language question and automatically return an accurate and relevant answer, either from a given context (Extractive QA) or based on previously learned knowledge (Abdel-Nabi et al., 2023). This task is particularly useful in education (Adewumi et al., 2025b;Pettersson et al., 2024). QA systems allow users to retrieve precise information quickly without reading full documents, even in the battery domain, making them highly useful for time-sensitive tasks and large-scale knowledge access. Examples of datasets include Stanford Question Answering Dataset (SQuAD) 2.0 and Conversational Question Answering Challenge (CoQA) (Yatskar, 2019). 7. Summarization: It aims to produce a concise and coherent summary of a document or documents that captures the main ideas of the source text while reducing its length (El-Kassas et al., 2021). Text summaries of battery documents can lead to more efficient workflows. Like with many generative tasks that have different objective metrics to evaluate the tasks, human evaluation is usually the gold standard, though subjective. Datasets include BOOKSUM, ArXiv, and PubMed (Kryscinski et al., 2022;Cohan et al., 2018). 8. MT: It is a process of automatic conversion of text from one natural language to another (Jiang & Lu, 2020). Since this helps in allowing people to access content in different languages without human intervention, even in cross-border partnerships in the battery domain, it is useful in communication and multilingual applications. While MT can speed up information access, it's challenging when it concerns complex languages, idioms, and other linguistic issues (Wang et al., 2022;Adewumi et al., 2022b). Datasets include those from the Workshop on St"
    },
    {
      "heading": "2018, 99 1-25",
      "text": "First Author and Second Author 9. Automatic speech recognition (ASR): This is also known as speech-to-text (STT) and is the process of converting spoken language into written text using computational models (Kheddar et al., 2024). ASR is useful in applications like voice assistants and transcription services as it helps users interact with machines more naturally. Challenges include dealing with background noise, accents, and overlapping speech (Benzeghiba et al., 2007). Datasets include LibriSpeech and Google-Sc, among others (Kheddar et al., 2024). 10. Dialog Generation: It is the single or multi-turn conversations generated by models communicating with humans or another model (Adewumi et al., 2022a). The task can be divided into task-oriented or open-domain dialog generation. LLMs are used in open-domain dialog generation, including materials dialog, and are being adapted in task-oriented dialog systems also (e.g. flight bookings) (Lee et al., 2024b). Phenomenal improvements in dialog coherence and other features have been witnessed in the past few years in open-domain dialog generation. However, some limitations like hallucinations still exist (Adewumi et al., 2024c). A dataset example includes the Ubuntu dialog dataset (Adewumi et al., 2022a). 11. Topic modeling (TM): It learns patterns in the data in an unsupervised manner to discover latent topics and infer topic proportions of documents (Wu et al., 2024). It can be used to support other tasks for better results. Two common challenges with topic modeling are trivial topics, which are based on uninformative words, and repetitive topics, where synonyms exist. An example of a dataset for the task is 20newsgroup (Wu et al., 2024)."
    },
    {
      "heading": "Battery Life Cycle",
      "text": "The increase in RESs and electric vehicles (EVs) has made the battery production industry one of the fastest-growing industries (Nekahi et al., 2024). The LiB has attracted particular interest because of its high energy, high power density, long cycle life, and potential across electronic mobility and stationary storage. Battery production is a complex process that involves many steps, from material sourcing, mining and refining raw materials to assembling cells together into finished battery packs (Xiao et al., 2025;Örüm Aydin et al., 2023;Nekahi et al., 2025). During every step of the production process, specific physical and chemical processes must be followed, supported by quality assurance and environmental controls. These processes generate large volumes of textual data throughout the entire life cycle, which can be leveraged through NLP for process analysis, compliance, and optimization (Lee et al., 2025;Jiang et al., 2025). Figure 1 depicts the stages of the battery life cycle. We categorize and discuss each of the stages briefly below."
    },
    {
      "heading": "Material sourcing & Mixing",
      "text": "Material sourcing is the foundation of the entire production chain. Cobalt, nickel, manganese, graphite, and lithium are key raw materials, each with unique electrochemical properties. Mining and refining operations are required to achieve the purity levels needed for batteries (Xiao et al., 2025). For example, lithium comes from hard rock mineral deposits (e.g. spodumene, LiAl(SiO 3 ) 2 ) and brines pools (e.g. in South America). The refining process, such as acid roasting and precipitation, then follows to produce lithium carbonate or hydroxide. Material sourcing significantly impacts both environmental outcomes and production costs (Degen et al., 2023). It also generates extensive documentation, such as mining reports, safety sheets, and procurement contracts. These sources of documentation coupled with the wealth of information on the internet make NLP tasks like materials discovery, question answering (QA), and information retrieval (IR) through deep analysis of the available information an important component of this stage, and possibly the first, to guide informed decisions before material mixing, where conductive additives and polymer binders are homogenously dispersed in a solvent (usually water or N-methyl-2-pyrrolidone) to create a homogenous slurry (Lee et al., 2025)."
    },
    {
      "heading": "Electrode preparation (front stage process)",
      "text": "Electrode preparation, which converts refined powder into active electrodes, is the most costly and time-consuming stage of the manufacturing process (Nekahi et al., 2024;Örüm Aydin et al., 2023). Two main approaches exist to process the electrode fabrication step: solvent-based wet processing (which currently dominates) and solvent-free dry processing. Dry processing is gaining attention due to its lower energy use and environmentally friendly process. The main sub-steps are: coating, in which the slurry is applied onto a metallic foil (aluminum or copper) while maintaining precise control of the thickness, drying, which removes solvent and forms a solid film, representing one of the most energy intensive steps in the process, calendering, where the electrodes are compressed between hard rollers to improve contact and mechanical integrity, slitting, where wide rolls are cut into narrow electrode strips, electrode making and die-cutting, where electrode making is for producing both cathode and anode sheets and die-cutting is for trimming the coated foils into specific geometries, such as cylindrical, prismatic, or pouch shapes (Degen et al., 2023). Each sub-step requires optimization to balance electrochemical performance with mechanical robustness. The process documentations, including mixing ratios, coating logs, temperature and humidity records, and inspection reports, serve as rich textual sources for NLP-driven process optimization and predictive quality control (Liu et al., 2021). At the laboratory scale, various coating methods are available, including spray coating, spin coating, dip coating, comma-bar First Author and Second Author coating, ink-jet printing, electrophoretic deposition, doctor blading, and slot-die coating (Degen et al., 2023)."
    },
    {
      "heading": "Battery Assembly",
      "text": "In the assembly stage, electrodes and separators are combined into complete cells (Attia et al., 2025). During winding and stacking, depending on the type, electrodes can be wound (for cylindrical cells) or stacked (for prismatic or pouch cells). The anode, separator, and cathode layers are rolled into a tight 'jelly roll' to ensure uniform ion transport. Stacking arranges sheets in alternating layers, enabling high packing density and consistent performance (Degen et al., 2023). Assembly line ensures electrode tabs are welded to terminal leads, and the assembled cell goes through the drying oven to remove residual moisture, that is, the solvent and water from the cathodes and anodes, respectively. Finally, electrolyte filling introduces a lithium salt solution into the porous structure in a controlled atmosphere. Each step produces operational and safety logs that can be analyzed using NLP to detect anomalies or optimize production sequences."
    },
    {
      "heading": "Battery tester",
      "text": "This stage initiates the cell's electrochemical activity through controlled charge and discharge cycles, which generate the solid electrolyte interphase (SEI) and cathode electrolyte interphase (CEI). These layers are critical for cell stability and safety (Schomburg et al., 2024;Weng et al., 2023). Formation generally occurs over several days under constant current, constant voltage (CCCV) conditions. After formation, cells undergo a series of test, including impedance measurement, self-discharge assessment, and safety evaluations, to verify performance consistency and compliance with quality standards (Liu et al., 2021). Generally, at the charge stage, the charging method determines battery capacity (Huang & Cole, 2020). Methods include CCCV and the cutoff voltages. The tester is used to qualify and verify the performance of the battery components to ensure they meet electrical and safety standards. Logs generated during the formation and testing stages are often stored in digital manufacturing systems, which again can serve NLP application purposes to improve yield and enable predictive maintenance."
    },
    {
      "heading": "Assembly, Usage & Repurposing",
      "text": "Validated cells are combined into modules in a module assembly. A typical battery module consists of several cells connected in series or parallel. Multiple modules are then combined in the pack assembly, which, like the module assembly, is equipped with thermal management and electronic control systems (Liu et al., 2021). In addition, the pack contains a battery management system (BMS), cooling components, and safety devices. Once assembled, the pack undergoes conditioning cycles to verify the functionality of sensors, wiring, and control electronics prior to deployment for usage. The safe use of LiBs relies on the BMS, which manages several parameters, including SoC of the batteries, for efficient function during the life of the batteries (Bian et al., 2024). The BMS also continuously monitors voltage and temperature to ensure safety and efficiency. The SoC indicates the capacity left in a LiB, thereby providing information against overcharging or undue discharging. Methods of estimating SoC may be divided into 4 categories: look-up table, Ampere-hour counting, model-based, and data-driven. The data-driven method has been gaining attention in recent times (Bian et al., 2024). Recycling and repurposing forms the final stage of the battery life cycle. Valuable materials such as lithium, nickel, cobalt, and copper are recovered through recycling and reintroduced into the supply chain to support a circular battery economy. Recycling processes and life cycle assessments produce a wide range of textual data, from dismantling instructions and recovery reports to environmental impact studies and compliance records (Lee et al., 2025). Batteries that cannot be recycled come to their end of life and must be disposed off properly or repurposed."
    },
    {
      "heading": "Methodology",
      "text": "We followed the PRISMA method (Page et al., 2021) for systematic reviews for a thorough and balanced survey to achieve the stated objective of this work. Figure 2 presents the PRISMA flow diagram for the review. It follows the rigorous and auditable general guidelines recommended for conducting a systematic literature review (Page et al., 2021;Adewumi et al., 2024a). We searched 3 reputable databases or search engines with relevant (inclusion) terms and focused on search results in English."
    },
    {
      "heading": "The Databases",
      "text": "The databases (or search engines) are Google Scholar, IEEE Xplore, and Scopus. They are suitable because they index the major publishers or databases. Each database complements the other. For example, IEEE Xplore and Scopus serve as additional validation for Google Scholar, which sometimes includes archived (or non-pair-reviewed) papers while Scholar has a wider coverage of results compared to the other two."
    },
    {
      "heading": "Search Criteria",
      "text": "The search terms (or keywords) we settled for are 3: 'text', 'language processing', and 'battery'. These are based on the inclusion criterion of the objective of the study. This is because NLP commonly involves written text, 'language processing' applies to natural language processing, technical language processing, and materials language processing, and battery applies to any stage of the battery life cycle. The search terms were combined using the AND operator on all the 3 databases as \"text AND 'language processing' AND battery\". We also attempted 4 combined terms: 'text', 'language', 'processing', and 'battery' but realized this gave a lot more non-relevant results than our earlier terms. Also, we chose not to include many other terms to avoid losing relevant articles since the objective was to cover the entire life cycle. Hence, we settled for our initial 3 search terms."
    },
    {
      "heading": "The PRISMA method",
      "text": "As depicted in Figure 2, the number of search results at every stage of the screening, including the year filter, are provided. Our choice of year filter (or cut off) from 2025 back to 2017 was because 2017 marked a pivotal period in NLP with the introduction of the Transformer architecture (Vaswani et al., 2017;Huang & Cole, 2022b). To decide the number of papers to review, we used sampling as a heuristic, though we're not randomly sampling from a population since the most relevant papers appear at the top or foremost pages. Given a 95% confidence level, 9% margin of error, and the biggest population of 17,100 from Google Scholar, we arrive at 118 as the sample size. Hence we used this value for Scopus also and reviewed all the 38 papers from IEEE Xplore since it returned a much smaller number in results. For the same reason we did not filter IEEE Xplore by year. Screening the titles and abstracts revealed papers that were not relevant. In situations where it was not immediately clear if a paper was relevant, we performed a quick automatic search for our keywords (especially 'battery') in the body of the paper. Furthermore, we observed that for some non-relevant papers, especially health-inclined ones, the term \"battery of ...\" or similar appears, where battery is used to mean something different, e.g. a series of things. For validation and reproducibility of our work, the search result links 1 , downloadable Scholar list, 2 and the list of non-relevant papers are in the appendix."
    },
    {
      "heading": "Findings: NLP in the Battery Life Cycle",
      "text": "After the careful review of all the relevant papers from the search results, we categorized each paper (identified as DatabasePaperNumber) based on the NLP tasks they address, resulting in Table 1 while we synthesized some of the SotA results, where applicable, into Table 2. In Table 1, there are 16 tasks and about 8 are new or different from the 11 identified in Section 2.2. Some of the papers address multiple tasks. In Table 2, SotA results and models are compared for different datasets per task, where applicable. Different metrics are reported, depending on the task, and the category of each model is also identified. Some of the tasks identified in Table 1 have no results reported in Table 2 because the relevant paper in the earlier table is either a review paper or does not report a relevant SotA result. Hence, 11 main tasks are reported in Table 2 and the category of models are deep learning, classical, LLM, and knowledge graph (KG). In the following subsections, we discuss some details of the relevant papers based on their contributions.  extraction from the scientific literature. Recipes contain both materials and instructions about the materials. A major challenge in materials discovery is the lack of a representative metric or evaluation framework for evaluating successful discoveries without the need for expensive experimentation for validation. In addition, IE is a challenging task in the domain because it requires multiple critical variables for materials selection. To address this challenge, Nie et al. (2022) proposed a semantic knowledge graph (KG) dedicated to Li-ion battery (LiB) cathodes and featuring a dual-attention component that refines word embeddings. Their implementation is based on the bidirectional long short-term memory (BiLSTM). This is, however, known for limitations like less capacity for long-time dependencies 2018, 99 1-25 Short title and reliance on serial processing Graves et al. (2005), especially compared to the SotA Transformer architecture. The material sodium is gaining attention because it is abundant and cheap, leading to Sodium-ion battery (SiB), which has similar working principles to LiB. Gou et al. (2024) performed IE for cathode materials of SiB. Their approach combined a number of other related tasks (e.g. chemical NER and TC) to improve performance on IE. Also, in the chemical NER contribution by O'Gorman et al. ( 2021) they annotated labels over a new corpus of 595 synthesis procedures and made the data (MS-Mentions) publicly available. Bai et al. (2025) also used NLP to guide the screening catalysts for the Na-S batteries. In the work by Zheng et al. (2025), they introduced cognition-enhanced instruction framework (CEIF), where a teacher model provided feedback, prompt refinement, and optimized training data to guide the learning process of student models. Park et al. (2025) introduced Chemeleon, which was designed to generate chemical compositions and crystal structures from both textual descriptions and 3-dimensional structural data. However, the vastness of the possible combinations of chemical composition makes comprehensive exploration time-consuming and computationally demanding. Regarding explainability, an important transparency concept, Xu et al. (2025a) used Shapley additive explanations (SHAP) as explainable AI while employing biterm topic modelling for the analysis of patents related to LiB research. SHAP, however, like other posthoc explainability methods does not provide intuitive explanations for humans like textual explanations chain-of-thought (CoT) reasoning from LLMs."
    },
    {
      "heading": "Battery Production, Maintenance & Sustainability",
      "text": "Interestingly, several deep learning methods have been explored in the diagnostics of batteries, including SoC estimation (Bian et al., 2024). Adequate monitoring, diagnosis and maintenance ensure the prevention of battery overcharge, undue discharge, and explosion, thereby extending battery life (Liu et al., 2022). Bian et al. (2024) explored SoC estimation for LiB using LLMs. The task can be challenging due to harsh temperatures and dynamic operations, which are just a couple of factors out of several others that challenge reliable estimates within a module. In their work, they proposed hard prompt generator to translate LiB data into instruction and answer text while a soft prompt encodes task-specific information of various LiBs into a set of independent vectors. Since datasets are important for data-driven battery property predictions and estimates, some work focused on this. Huang & Cole (2020) introduced an automatically-generated materials dataset from the literature by extracting battery materials and 5 functional properties using ChemDataExtractor, which is a toolkit with NLP techniques for materials science. The extracted functional properties are capacity, conductivity, Coulombic efficiency, energy density, and voltage. Shon & Min (2023) extracted the ionic conductivities of SSE from scientific literature to create a materials database. Meanwhile, El-Bousiydy et al. (2021) noted that the lack of standard benchmark and how electrode and cell properties are reported in the domain are some of the challenges in LiB research giving rise to issues of lack of reproducibility among others. Furthermore, Oprea & Bâra (2025) rightly identified that there are environmental concerns over the production of batteries, their use and disposal while Ren et al. (2025) addressed the disassembly of retired electric vehicle battery packs in their work by proposing disassembly-oriented knowledge graph. Deep learning methods face challenges such as poor generalization and robustness, especially when moving from LiB to LiB (Bian et al., 2024). This is complicated at harsh sub-zero ambient temperatures when SoC drops drastically with fluctuations due to chemical reactions in the LiBs. Besides, to use language modeling for SoC estimation, there is the need for models to learn measurements in numerical format, though this is a typical challenge (Jiang et al., 2025)."
    },
    {
      "heading": "Discussion",
      "text": "The application of NLP in the battery domain is growing. However, challenges exist, as already highlighted. Below, we further highlight some of the key challenges and subsequently discuss details of our proposed novel TLP framework 2018, 99 1-25 First Author and Second Author that is capable of addressing some of the challenges."
    },
    {
      "heading": "Challenges",
      "text": "Missing in Table 2 is agentic AI for any of the tasks. This is clearly a limitation in existing attempts, which our framework addresses. Also missing is any task related to the new EU DBP or digital product passport (DPP). These are in addition to some of the earlier identified gaps and limitations. Among some of the challenges in battery research are the lack of standard battery benchmark data, proprietary data, vocabulary standards, and interoperability of tools (Clark et al., 2022). Different authors used different self-created datasets. As a result, the SotA comparison made by Choi & Lee (2024) in their work may be considered unfair because their results were compared with other works which evaluated different datasets. Also, it would have been helpful if many of the authors gave unique names to their datasets for easy identification. Many of these shortcomings have negatively affected transparency in the field."
    },
    {
      "heading": "TLP framework for DBP and battery predictions",
      "text": "AI transparency provides an avenue for responsible human oversight (Adewumi et al., 2025a). The new EU DBP, which is an electronic record that may be stored in the cloud and is part of the DPP, provides the required transparency along the entire battery life cycle and promotes a circular economy (Popowicz et al., 2025;Rizos & Urban, 2024). The passport contains battery-specific texts, numeric values and dates. The initiative is similar to the concepts of data card, data statement, or model card in NLP (Pushkarna et al., 2022;Bender & Friedman, 2018;Mitchell et al., 2019). Data cards or statements provide summaries of ML data in a structured way with explanations of the processes and rationale behind the data. The DBP also aligns with the Findability, Accessibility, Interoperability, and Reusability (FAIR) guiding principles for scientific data management, which formulates a guideline for those who want to enhance the reusability of their data, and provides machines with the ability to automatically find and use such data (Wilkinson et al., 2016). It does not include personal data of the stakeholders, who include end-users, manufacturers, recyclers, and regulatory bodies, among others (Berger et al., 2022). Just as it is beneficial for LLMs to have detailed prompts or instructions for improved performance (Adewumi et al., 2024b), it is beneficial to provide as much detail as necessary in the digital passport for the benefit of AI systems, besides the stakeholders. Consequently, the information, including those at relevant points in the value chain, can be transformed for TLP for BMS modeling and predictions since a BMS is responsible for monitoring and managing a battery pack for safe and optimal performance (Shen & Gao, 2019). The DBP will provide information on material origin, composition, chemical substances, carbon footprint, capacity, hazardous substances, state-of-health (SoH), battery status (e.g. reused), number of charging and discharging cycles, performance, recycling and disposal aspects, among others. BMSs typically provide information on the SoH and the expected battery lifetime (Berger et al., 2022). Accurately estimating battery state in extreme temperatures is one of the challenges in the field and the TLP framework aims to address that. We propose a comprehensive but simple TLP framework for battery predictions, including various tasks identified in Table 2. Figure 3 depicts the framework. The information provided by the DBP or BMS will be useful within the framework. It involves a battery-agnostic model context protocol (MCP) AI agent that can connect to external tools that have information of the DBP or BMS and provides soft prompts (continuous feature vectors learned by prompt-tuning), which will be combined with optimized hard prompts (plain text inputs enhanced with gradient-based optimization) (Wen et al., 2023). The combination will then be supplied as input to a capable multimodal LLM for relevant TLP task predictions, e.g. SoC estimation or IR. In addition, the framework has a component capable of being a standalone part (indicated in the purple box of Fig. 3), which can perform tasks related to traditional datasets. The strategy of combining both hard and soft prompts (or prompt parameters) can be beneficial by providing complementary perspectives as detailed and precise input to the LLM. The benefit of using LLMs for the tasks (instead of traditional methods) is that they have emergent properties and the capability to perform coding and other ML tasks that can support predictions. One disadvantage with dense LLMs is their size but using a mixture of experts (MoE) can be useful for mitigating this because not all the parameters need to be activated during inference."
    },
    {
      "heading": "Conclusion",
      "text": "The application of NLP along the entire battery life cycle is growing, with increasing research, reports, logs and other types of documents, as observed from the papers reviewed in this systematic survey. This work presented a comprehensive survey in the field, describing some traditional NLP tasks and emerging ones, as they relate to the battery domain. We showed, with the battery life cycle, that NLP can play important parts at different stages, from materials sourcing to recycling and repurposing. Our findings revealed that challenges still exist, especially with standardizing the benchmarks, creating the right evaluation framework or metric for materials discovery, and employing even more modern NLP methods, such as agentic AI. The EU DBP is another innovation not addressed in any of the papers surveyed. Hence, we introduced a novel TLP framework for battery predictions to address some of the challenges. With the planned DBP in the near future, the TLP framework will have even more data for driving better predictions. The inclusion of multimodal AI (featuring text, image, and sensor data) will also provide improved performance along the battery value chain. First Author and Second Author &hl=en&as_sdt=0%2C5&as_ylo=2017&as_yhi=2025 IEEE Xplore: https://ieeexplore.ieee.org/search/searchresult.jsp?action=search&newsearch=true&matchBoolean=true&queryText= (%22All%20Metadata%22:text)%20AND%20(%22All%20Metadata%22:%22language%20processing%22) %20AND%20(%22All%20Metadata%22:battery)&highlight=true&returnFacets=ALL&returnType=SEARCH &matchPubs=true&rowsPerPage=50&pageNumber=1 Scopus: https://www.scopus.com/results/results.uri?sort=plf-f&src=s&sid=87cba225c81851a1f3193513dccf661b&sot =a&sdt=a&sl=80&s=text+AND+%22language+processing%22+AND+battery+AND+PUBYEAR+%3E+2016+AND+ PUBYEAR+%3C+2026&origin=savedSearchNewOnly&txGid=f0e09e9bcf4ff3781509c6543c2c2898&sessionSearchId= 87cba225c81851a1f3193513dccf661b&limit=10"
    },
    {
      "heading": "List of non-relevant papers",
      "text": "Below, we identify the non-relevant papers in the search results by listing DatabasePaperNumber (and the focus of the paper). Google scholar G14 (about electrical equipment malfunction not battery), G16 (about consumer sentiments), G20 (neurocognitive assessment batteries -a set of clinical equipment), G21 (materials of inorganic glasses), G24 (Encryption in Mobile Ad Hoc Network), G26 (Quaternion algebra), G27 (Skateboard Monitoring Device), G29 (technology lexical database), G30 (requirement management in engineering), G32 (vehicle diagnostics using free-text customer service reports), G33 (Crowdfunding Videos), G34 (Android-Based Text Extraction), G35 (Materials Applications), G36 (in-text citation analysis), G39 (Analysis of Software Industry), G41 (neural databases), G42 (L2 Listening Proficiency), G43 (ensemble learning), G44 (Video summarization), G45 (Corporate Sustainability Reports ), G46 (systems to detect significant future business changes), G48 (Unstructured Data from Medical Reports), G50 (Detection of Cognitive Decline), G51 (sentiment analysis (SA) for movie reviews), G52 (Digital shop floor management), G53 (Plastic Waste Recycling), G54 (Aviation Safety Reports), G55 (ADVANCES IN Computer Science), G58 (proceedings document), G59 (corrosion-resistant alloy), G60 (Monitoring Alzheimer's Disease), G61 (Fault Diagnosis of Signal Equipment), G62 (Language impairment in adults), G63 (clinical neuropsychology), G64 (properties of alloys), G65 (design research), G66 (therapist facilitative interpersonal skills), G67 (Loneliness in Older Adults), G68 (exploring GPT-3), G69=G71 (mild cognitive impairment), G70=G72 (Semantic Web), G73 (fMRI Dataset), G74 (sarcasm), G76 (product reviews), G77 (Personality and Psychological Distress), G78 (general language processing), G79 (Customer Satisfaction), G80 (Cognitive Functions), G81 (Clinical Data Generation), G82 (Psycholinguistic Assessments), G83 (opportunity discovery), G84 (IoT for aquaculture), G85 (Human-Machine Interaction), G86 (Arabic Sentiment Analysis), G87 (Symptom Documentation), G88 (Software Test Case Generation), G90 (extractive text summarization), G91 (cognitive plausibility), G92 (extraction from polymer literature), G93 (morphemic boundaries), G94 (Arabic NLP), G95 (Arabic Text Categorization), G96 (personnel selection), G97 (Generative AI), G98 (organisational culture), G99 (Energy Districts), G101 (Complex Engineered Systems), G102 (Legal Informatics), G103 (Customers' Sentiment Analysis), G104 (Measurement Extraction), G105 (IoT Based Voice Assistant), G106 (deep learning for NLP), G107 (Geolocation Context), G108 (Eye movements), G109 (Grid Monitoring), G110 (neuroimaging), G111 (psychological constructs), G112 (Examination System), G113 (Depression Disorder), G114 (Sentiment Classification), G115 (RAMS Information for Metro Vehicles), G116 (Neurodevelopmental Disorders:), G117 (Readers with Autism), G118 (Aspect Sentiment Analysis)."
    }
  ]
}