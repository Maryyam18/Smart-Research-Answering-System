{
  "paperid": "2510.01283v1",
  "title": "Evaluation Sheet for Deep Research: A Use Case for Academic Survey Writing",
  "authors": [
    "Azime",
    "Destaw Belay",
    "Lambebo Tonja",
    "Nacional",
    "Mbzuai",
    "Jayne Amol",
    "Asiko Chimoto",
    "Delilah Gesicho",
    "Gitau",
    "Etori",
    "Kinyanjui",
    "Ndung'u",
    "Moruye",
    "Otieno Ooko",
    "Kitonga",
    "Muhia",
    "Gitau",
    "Ndolo",
    "Wanzare",
    "Kahira",
    "Tombe",
    "Bousetouane",
    "Huang",
    "Yu",
    "Ma",
    "Zhong",
    "Feng",
    "Wang",
    "Chen",
    "Peng",
    "Feng",
    "Qin",
    "Joshi",
    "Kale",
    "Chandel",
    "Kumar",
    "Naveed",
    "Ullah Khan",
    "Qiu",
    "Saqib",
    "Anwar",
    "Usman",
    "Akhtar",
    "Barnes",
    "Mian",
    "Openai",
    "Lambebo",
    "Destaw Belay",
    "Abebe Azime",
    "Ali Ayele",
    "Ahmed Mehamed",
    "Kolesnikova",
    "Muhie",
    "Wu",
    "Zhu",
    "Liu",
    "Xiong",
    "Bian",
    "Li",
    "Li",
    "Du",
    "Wang",
    "Yin",
    "Helal"
  ],
  "year": 2025,
  "abstract": "Large Language Models (LLMs) powered with argentic capabilities are able to do knowledgeintensive tasks without human involvement. A prime example of this tool is Deep research with the capability to browse the web, extract information and generate multi-page reports. In this work, we introduce an evaluation sheet that can be used for assessing the capability of Deep Research tools. In addition, we selected academic survey writing as a use case task and evaluated output reports based on the evaluation sheet we introduced. Our findings show the need to have carefully crafted evaluation standards. The evaluation done on OpenAI's Deep Search and Google's Deep Search in generating an academic survey showed the huge gap between search engines and standalone Deep Research tools, the shortcoming in representing the targeted area.* Equal Contribution. and accurate answers through iterative searching and reasoning, \"Deep Research\" leverages reasoning to search, interpret, and analyze information, producing comprehensive long-form reports that explore complex topics in depth (OpenAI, 2025). In this paper, we focus mainly on Deep Research tools.Deep Research tools are designed to create comprehensive, long-form reports that dive deep into complex topics (Wu et al., 2025). Their defining characteristics include unassisted web browsing, compilation of several sources, long waiting time, and results that resemble reports, not chat responses (OpenAI, 2025). Deep Research improves traditional search capabilities from keyword-based searching to more exhaustive search incorporating reasoning, inference synthesis, and response generation. This profound research feature transcends basic question-answering; it enables LLMs to navigate the internet, process extensive datasets, synthesize insights, and create structured reports with appropriate citations (Xiong et al., 2024). Unlike traditional search engines, which primarily provide direct answers, it employs an iterative search process that deconstructs complex inquiries and engages in reasoning before generating responses (Wu et al., 2025). This method operates several search cycles, such as an iterative reading, searching, and reasoning cycle, until the most accurate response is achieved. The entire operation can be segmented into three main distinct phases (search, read and reason), as illustrated in Figure 1.LLM providers such as Google 1 , OpenAI 2 , Perplexity 3 , XAI 4 and others are making available their Deep Research agent-based application,",
  "sections": [
    {
      "heading": "Introduction",
      "text": "Large Language Models (LLMs) present a transformative evolution in artificial intelligence, particularly their capacity for advanced text generation, reasoning, and analytical tasks (Naveed et al., 2024). A notable enhancement in LLM functionalities is the incorporation of the vertical AI agents (Bousetouane, 2025). Vertical AI agents are specialized intelligent systems tailored to specific industries, combining domain expertise with realtime adaptability to enhance workflows, perform unassisted tasks and decision-making. One of the notable examples of well integrated AI agents is Deep Research. Deep Research empowers LLMs to perform in-depth examinations of intricate subjects autonomously by accessing web using search engines (OpenAI, 2025). While the term \"Deep Search\" emphasizes tool delivering quick, concise, a list of \"Deep Research\" tools with their details is shown in Table 1. One of the main real-world application areas of Deep Research is to use them as helpers for academic research, such as conducting a comprehensive literature review in a specific field of study. Academics can get a draft literature summary in minutes instead of days, and analysts can quickly pull together data from hundreds of webpages. However, these tools still require oversight, and the effectiveness of these Deep Research tools requires rigorous evaluation and study. They might sometimes \"hallucinate\" (produce incorrect information), cite less credible sources or give priority for outdated contents. Even though, Deep Research tools are powerful for scaling up our research capabilities, users must understand their strengths and limitations to choose the right tool. In this work: • We introduce Evaluation Sheet as a road-map for evaluating the performance of Deep Research tools. The main categories of this evaluation sheet (also known as Pillars) are discussed in Section 3. • As a use case, we selected three recent NLP survey papers focused on African countries and languages: an Ethiopian language survey (Tonja et al., 2023), a Nigerian language survey (Inuwa-Dutse, 2025), and a Kenyan language survey (Amol et al., 2024) to assess the applicability of the introduced evaluation sheet in order to evaluate the generated Deep Research report. We generated Deep Research reports that resemble these papers from the two selected Deep Research tools (ChatGPT and Gemini) and evaluated their effectiveness, assuming that these survey papers were created using Google-like search engines combined with human involvement."
    },
    {
      "heading": "Motivation",
      "text": "Deep Research tools allow users to extract, summarize, and gather information on research areas with which they may not be familiar. As the reliability of these tools continues to improve, ensuring their accuracy and dependability is crucial to trusting and using the outputs from these models. LLMs are becoming the new search engines, and if they are not thoroughly tested, research findings may be lost unnoticed, and only selected knowledge will be propagated. Although Deep Research tools can generate wellstructured content, they generate hallucinated references, biased arguments, or incorrect stories. We believe that evaluation sheets are essential to assess AI-generated content to ensure that it meets the required standards, has logical coherence, and has relevant and appropriate sources. This evaluation sheet helps the users to determine whether AI-generated content has accurate data, unbiased output, and diverse perspectives. It also provides ways to verify the source's credibility and the generated text's reliability. The users can effectively leverage Deep Research tools using the evaluation sheet while maintaining the required standards. We also hope that researchers will use this evaluation sheet as a starting point and add more pillars along with questions to create a standard way of testing Deep Research tools. for different use cases. Here, we discuss the six pillars of the proposed evaluation sheet: (1) LLMs & Deep Research for [Surveying NLP Papers and Datasets for Low-Resource African Languages]foot_0 . Surveying existing NLP papers in research areas such as low-resource languages presents unique challenges. A crucial task is determining whether these tools can effectively identify the most important and impactful research, even when such research papers do not appear in the top search results. The primary issue we aim to address is how the growing popularity of these tools and their increasing role in replacing traditional searche engines affects the visibility and accessibility of significant research. To access the usage of LLMs & Deep Research in survey report writing in low-resource languages, we crafted the following question: • Does the Deep Research reports effectively identifies and consolidate NLP papers on lowresource [African]foot_1 languages? • Does the selection of datasets for lowresource [African] languages is comprehensive and representative? • Does the Deep Research method provide sufficient depth in its analysis of linguistic challenges in [African] NLP? • Does the LLM-generated survey highlights the most impactful research in [African] NLP? • Does the coverage of low-resource [African] languages in the survey align with the actual research landscape? (2) Hallucination Hallucination refers to information that appears true to someone without prior knowledge of the subject but cannot be verified by a reliable source (Huang et al., 2025). In contrast, errors are categorized as mistakes that are easily noticeable. Hallucination is a huge treat in practical LLM usage, specifically while automating knowledge extraction from contents like research works. This set of guidelines and questions helps us determine the focus we must place on the reliability of the output. The following questions are crafted to evaluate whether the Deep Research generated report contains hallucination. • Does the Deep Research generated survey contains minimal factual errors or hallucinations? • Does the hallucinated content, if present, is easy to identify and correct? • Does the Deep Research tool properly distinguishes between verified academic sources and speculative content? • Does a lower risk of hallucination improve the reliability of the survey's insights? (3) Correctness of sources Sources can range from reliable, peer-reviewed papers to blogs and social media pages that present personal opinions. While extracting information from both types of sources is optional, web agents should be able to distinguish between reliable and unreliable sources. Below, we pose a set of questions to assess whether the source impacts the reliability of the information and whether certain sources are preferable. This approach ensures that the extracted information is accurate and verified. • Does the sources suggested in the report are based on verifiable and authoritative sources? • Does the Deep Research tool appropriately prioritize papers on credibility and impact? • Does the mechanism used by Deep Research to extract information from sources adequately account for domain-specific knowledge in [NLP]? (4) Information Validity The validity of the references provided can be assessed based on their accessibility, verification through independent sources, and whether they demonstrate why they are superior to other potential alternatives. Below are the questions created to assess the validity of information generated by Deep Research. • Does the cited links and references in the survey are valid and accessible? • Does the Deep Research tool effectively differentiates between credible and non-credible sources? • Does the report content remains valid and relevant when cross-checked with independent sources? • Does the Deep Research tool provide sufficient transparency regarding how sources are selected and ranked? • Does the Deep Research generated report appropriately handles broken or outdated links in its output? (5) Information Latestness Recent information is more valid compared to older information that may have a high search volume but could have been corrected or improved by more recent works. Research papers with higher citation counts and those that appear at the top of search results are not always the latest studies, which can pose a challenge for LLM agents searching the web for information. The following question will help to assess whether the information generated in the report has been extracted from the latest sources. • Does the report prioritize the most recent sources? • Does the Deep Research tool effectively identify the latest trends in NLP for low-resource African languages? • Does the Deep Research method ensure that outdated references are minimized in the survey? • Does the system effectively highlight emerging resources that are not widely recognized? • Does the report output remain relevant given the fast-paced evolution of AI and [NLP] research? (6) Quantifying Actual Google Search Results"
    },
    {
      "heading": "vs. Deep Research Answers",
      "text": "Finally, we added questions below to explore how the shift from using search engines like Google for information retrieval compares to using automated search agents like Deep Research tools. • Does the report findings align well with actual Google search results on the same topics? • Does Deep Research generated answers provided by Deep Research are insightful than Google search results? • Does the Deep Research tool accurately quantify differences in retrieval efficiency between LLMs and traditional search engines? • Does the Deep Research tool effectively reduce misinformation compared to open-web search engines? • Does the Deep Research approach provide added value beyond standard keyword-based search queries?"
    },
    {
      "heading": "Rating Procedure",
      "text": "For the above questions (listed in Section 3), we recommend that users use the Likert scale (Joshi et al., 2015) rating system when answering. The rating scale consists of six levels to express agreement or disagreement with a question. These are: Strongly Disagree (0)indicates complete opposition with no support for the statement. Disagree (1)reflects mostly disagreement, though some merit is acknowledged. Somewhat Disagree (2)suggests a leaning toward disagreement while recognizing certain validity. Neutral (3)signifies neither agreement nor disagreement or an undecided stance. Somewhat Agree (4)represents general agreement but with some reservations. Finally, Strongly Agree (5)-expresses full endorsement and support without any doubt. 4 Case study: Ethiopia, Nigeria, Kenya 4.1 Methodology Creating evaluation sheet We selected three regional survey papers that focus on capturing valuable research progress within their respective countries: the Ethiopian language survey (Tonja et al., 2023), the Nigerian language survey (Inuwa-Dutse, 2025), and the Kenyan language survey (Amol et al., 2024). We analyzed these papers in detail, extracted the key questions they addressed, and then combined them to formulate prompts (see A)incorporating these questions. To create the evaluation sheet, we carefully identified scenarios the Deep Research tools fail at and must be tested with and created a list of questions under each important evaluation topic. Questions were edited, filtered and removed based on discussion among the authors. Generating representative outputs We evaluated the prompts for validity and selected the one capable of generating detailed reports. Using a selected prompt, we generated three distinct Deep Research outputs by modifying only the countryspecific information while utilizing OpenAI Deep Research and Google Deep Research. Three reviewers selected from the authors of this study reviewed the outputs of the tools and rated the generated report based on the rating criteria for each question in the pillars. They used the actual research paper from each of the countries as a reference while answering the questions accordingly."
    },
    {
      "heading": "Comparative analysis",
      "text": "In this section, we discuss our observations while evaluating reports generated by Google's Deep Research and OpenAI's Deep Research tools. Due to the limited number of reports considered in this study and the frequent updates made to these tools, we focus only on the broader conclusions from the results. We recommend scaling this work with a larger number of reports and evaluators to derive more detailed findings. Hallucination The inclusion of social media links alongside verified academic peer review catalogs as sources makes Deep Research tools particularly susceptible to hallucinations and erroneous outputs. Additionally, the absence of source information in reports or the citation of incorrect sources complicates the process of identifying and verifying hallucinations. However, based on our analysis, we found that the rate of misinformation and hallucination is not significantly high."
    },
    {
      "heading": "LLMs",
      "text": "Correctness of Sources When examining the detailed process these tools follow while \"researching\", they tend to review a large number of relevant resources. Google's tool heavily summarizes information and often does not mention many of the sources it picks up during the process. Additionally, both tools tend to include social media links, such as Facebook and Reddit, as information sources. Information/Link Validity We observe that the tools use sources multiple times during their execution. Apart from that, the tools have a problem of identifying the correct source from which the information is obtained and mostly rely on survey papers and summarized contents rather than extracting information from the original source. Actual Google Search Results vs. LLM Answers Although the system does not produce significant misinformation, its outputs are not fully aligned with Google search results. We find better choices, more recent works, and broader domain coverage when using Google Search."
    },
    {
      "heading": "Lesson learned -Takeaway",
      "text": "The need for evaluation standard With the rapid introduction of tools that improve or entirely replace search engines, it is crucial to establish evaluation guidelines that foster consistency and common characteristics across benchmarks. The careful design and assessment of these tools are essential, as they shape the knowledge and research considered important, as well as how different approaches and solutions are presented for comparison, ultimately influencing decision-making. If these tools are not designed to provide as much relevant information as possible to users, the real decision-making process-including the selection of problems and solutions-risks being controlled by autonomous agents developed by big tech companies. Are Deep Research tools reliable for extracting information and generating user-ready reports for low resource research summarization? The use cases in this study, focused on generating scientific summary reports on underrepresented groups, highlight the challenges of finding, sorting, and presenting hard-to-access research. We found that Deep Research tools are not fully reliable, as their selection of research works lacks transparency, and their summaries-drawn from multiple sources-fail to comprehensively represent the research landscape of the targeted area. Despite the limitations discussed above, Deep Research tools have a potential in presenting summarized information and making it more accessible."
    },
    {
      "heading": "Conclusion",
      "text": "LLMs equipped with web search capabilities can delve deeper and spend more time answering questions, making them valuable for knowledgeintensive tasks by comparing multiple sources and improving reasoning. The introduction of Deep Research tools exemplifies this capability, enabling LLMs to search for sources, filter numerous links, and generate detailed reports. In this work, we developed an Evaluation Sheet to help researchers identify the most critical evaluation criteria for assessing Deep Research tools for different use cases. This evaluation sheet seeks to standardize benchmarking datasets by highlighting key focus areas. To demonstrate its applicability, we conducted a proof-of-concept study on \"Deep Research for Survey Paper Generation\" and used it to evaluate two well-known Deep Research tools. We hope researchers will adopt this Evaluation Sheet to create benchmarking datasets in their respective domains, ultimately improving the effectiveness of agentic tools that require minimal human interaction. By ensuring these tools generate reliable and informative outputs-comparable to what users would find through independent searches-we aim to improve their practical utility and trustworthiness."
    },
    {
      "heading": "Limitation",
      "text": "Deep Research tools are relatively new, and we selected OpenAI and Google as use cases due to their availability and popularity. Future research will expand the scope by incorporating a broader range of tools, generating a larger number of reports and a larger number of evaluators to better assess their capabilities on a wider scale."
    }
  ]
}