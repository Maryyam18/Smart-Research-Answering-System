{
  "paperid": "2202.07138v2",
  "title": "Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge",
  "authors": [
    "Kebing",
    "Zhuo",
    "Alshaina",
    "John",
    "Nath",
    "Ammanabrolu",
    "Cheung",
    "Broniec",
    "Riedl",
    "Kim Amplayo",
    "Angelidis",
    "Lapata",
    "Nasr Azadani",
    "Ghadiri",
    "Davoodijam",
    "Azaria",
    "Krishnamurthy",
    "Mitchell",
    "Azaria",
    "Srivastava",
    "Krishnamurthy",
    "Labutov",
    "Mitchell",
    "Bahdanau",
    "Brakel",
    "Xu",
    "Goyal",
    "Lowe",
    "Pineau",
    "Courville",
    "Bengio",
    "Banerjee",
    "Mitra",
    "Sugiyama",
    "Baud",
    "Lovis",
    "Alpay",
    "Rassinoux",
    "Scherrer",
    "Nowlan",
    "Rector",
    "Bisk",
    "Shih",
    "Choi",
    "Marcu",
    "Blindheim",
    "Gros",
    "Johansen",
    "Blukis",
    "Misra",
    "Knepper",
    "Artzi",
    "Branavan",
    "Chen",
    "Zettlemoyer",
    "Barzilay",
    "Branavan",
    "Kushman",
    "Lei",
    "Barzilay",
    "Brawer",
    "Mangin",
    "Roncone",
    "Widder",
    "Scassellati",
    "Buzhinsky",
    "Cambria",
    "White",
    "Camilleri",
    "Cantrell",
    "Schermerhorn",
    "Scheutz",
    "Cantrell",
    "Talamadupula",
    "Schermerhorn",
    "Benton",
    "Kambhampati",
    "Scheutz",
    "Cercone",
    "Mccalla",
    "Chen",
    "Mooney",
    "Chen",
    "Liu",
    "Yin",
    "Tang",
    "Chen",
    "Suhr",
    "Misra",
    "Snavely",
    "Artzi",
    "Chen",
    "Tan",
    "Kuntz",
    "Bansal",
    "Alterovitz",
    "Chi",
    "Shen",
    "Eric",
    "Kim",
    "Hakkani-TÃ¼r",
    "Chu",
    "Carberry",
    "Philip R Cohen",
    "Daniel G Costa",
    "Paulo",
    "Peixoto",
    "Thiago",
    "Jesus",
    "Portugal",
    "Vasques",
    "Dong",
    "Li",
    "Gong",
    "Chen",
    "Li",
    "Shen",
    "Yang",
    "Fan",
    "Lewis",
    "Dauphin",
    "Feng",
    "Hankui Zhuo",
    "Kambhampati",
    "Fogli",
    "Guida",
    "Fox",
    "Long",
    "Tyler",
    "Frasca",
    "Oosterveld",
    "Chita-Tegmark",
    "Scheutz",
    "Garoufi",
    "Gatt",
    "Krahmer",
    "Geib",
    "Steedman",
    "Gerevini",
    "Long",
    "Guan",
    "Verma",
    "Guo",
    "Zhang",
    "Kambhampati",
    "GÃ¼lÃ§ehre",
    "Dutil",
    "Trischler",
    "Bengio",
    "Hayton",
    "Porteous",
    "Fernando Ferreira",
    "Lindsay",
    "HlÃ¡dek",
    "StaÅ¡",
    "Pleva",
    "Hua",
    "Sreevatsa",
    "Wang",
    "Huang",
    "Wang",
    "Fan",
    "Zhuo",
    "Sun",
    "Li",
    "Huang",
    "Abbeel",
    "Pathak",
    "Mordatch",
    "Huang",
    "Xia",
    "Xiao",
    "Chan",
    "Liang",
    "Florence",
    "Zeng",
    "Tompson",
    "Mordatch",
    "Chebotar",
    "Sermanet",
    "Brown",
    "Jackson",
    "Luu",
    "Levine",
    "Hausman",
    "Ichter",
    "Pham",
    "Yoshimi",
    "Iqbal",
    "Qureshi",
    "Peter",
    "Jansen",
    "Hanqi",
    "Cao",
    "Wang",
    "Kambhampati",
    "Kambhampati",
    "Sreedharan",
    "Verma",
    "Zha",
    "Guan",
    "Khurana",
    "Koli",
    "Khatter",
    "Singh",
    "Kim",
    "Mooney",
    "Koller",
    "Hoffmann",
    "Kong",
    "Huang",
    "Tung",
    "Guan",
    "Huang",
    "Litton",
    "Kurisinkel",
    "Zhang",
    "Varma",
    "KÃ¼stenmacher",
    "PlÃ¶ger",
    "Li",
    "Lee-Urban",
    "Johnston",
    "Riedl",
    "Li",
    "Puig",
    "Paxton",
    "Du",
    "Wang",
    "Fan",
    "Chen",
    "Huang",
    "AkyÃ¼rek",
    "Anandkumar",
    "Andreas",
    "Mordatch",
    "Torralba",
    "Zhu",
    "Li",
    "Zhuang",
    "Guo",
    "Zhuo",
    "Zhang",
    "Lieven",
    "LÃ¼ders",
    "Kulus",
    "Thoneick",
    "Lindsay",
    "Read",
    "Ferreira",
    "Hayton",
    "Porteous",
    "Gregory",
    "Lopez",
    "Stephanie",
    "Lukin",
    "Walker",
    "Ma",
    "Li",
    "Zhang",
    "Li",
    "Liu",
    "Macmahon",
    "Stankiewicz",
    "Kuipers",
    "Marfurt",
    "Henderson",
    "Matuszek",
    "Fox",
    "Koscher",
    "Mcdermott",
    "Ghallab",
    "Howe",
    "Knoblock",
    "Ram",
    "Veloso",
    "Weld",
    "Wilkins",
    "Mei",
    "Bansal",
    "Walter",
    "Shah Jahan Miah",
    "Vu",
    "Alahakoon",
    "Jishma Mohan",
    "Sunitha",
    "Ganesh",
    "Jaya",
    "Mohan",
    "Laird",
    "Muise",
    "Chakraborti",
    "Agarwal",
    "Bajgar",
    "Chaudhary",
    "Lastras-Montano",
    "Ondrej",
    "Vodolan",
    "Wiecha",
    "Narayan",
    "Zhao",
    "Maynez",
    "SimÃµes",
    "Nikolaev",
    "Mcdonald",
    "Narayanan",
    "Shoeybi",
    "Casper",
    "Legresley",
    "Patwary",
    "Korthikanti",
    "Vainbrand",
    "Kashinkunti",
    "Bernauer",
    "Catanzaro",
    "Nyga",
    "Beetz",
    "Md Okpor",
    "Daniel W Otter",
    "Medina",
    "Kalita",
    "Pallagani",
    "Srivastava",
    "Perrault",
    "Allen",
    "Ronald",
    "Petrick",
    "Foster",
    "Ngoc",
    "Pham",
    "Yoshimi",
    "Porteous",
    "Cavazza",
    "Porteous",
    "JoÃ£o",
    "Ferreira",
    "Lindsay",
    "Cavazza",
    "Porteous",
    "JoÃ£o",
    "Ferreira",
    "Lindsay",
    "Cavazza",
    "Resch",
    "Summa",
    "Zeile",
    "Strube",
    "Riedl",
    "Michael",
    "Rose",
    "Engel",
    "Cramer",
    "Cowley",
    "Sanner",
    "Santos",
    "Dragoni",
    "Say",
    "Scheutz",
    "Krause",
    "Oosterveld",
    "Frasca",
    "Platt",
    "Sha",
    "Mou",
    "Liu",
    "Poupart",
    "Li",
    "Chang",
    "Sui",
    "Shaalan",
    "Sharma",
    "Torralba",
    "Andreas",
    "She",
    "Chai",
    "She",
    "Cheng",
    "Chai",
    "Jia",
    "Yang",
    "Xi",
    "She",
    "Yang",
    "Cheng",
    "Jia",
    "Chai",
    "Xi",
    "Shu",
    "Nakayama",
    "Sil",
    "Yates",
    "Simon",
    "Muise",
    "Sreedharan",
    "Chakraborti",
    "Muise",
    "Khazaeni",
    "Kambhampati",
    "Stahlberg",
    "Storks",
    "Gao",
    "Chai",
    "Suddrey",
    "Talbot",
    "Maire",
    "Tambwekar",
    "Dhuliawala",
    "Martin",
    "Mehta",
    "Harrison",
    "Riedl",
    "Tellex",
    "Kollar",
    "Dickerson",
    "Walter",
    "Banerjee",
    "Teller",
    "Roy",
    "Tenorth",
    "Nyga",
    "Beetz",
    "Thomason",
    "Murray",
    "Cakmak",
    "Zettlemoyer",
    "Thomason",
    "Zhang",
    "Mooney",
    "Stone",
    "Torfi",
    "Rouzbeh",
    "Shirvani",
    "Keneshloo",
    "Tavaf",
    "Fox",
    "Ware",
    "Michael",
    "Wilensky",
    "Xiang",
    "Jiang",
    "Chang",
    "Sui",
    "Xu",
    "Ren",
    "Zhang",
    "Zeng",
    "Cai",
    "Sun",
    "Yao",
    "Peng",
    "Weischedel",
    "Knight",
    "Zhao",
    "Yan",
    "Ye",
    "Xu",
    "Liu",
    "Hong",
    "Sun",
    "Chi",
    "Sun",
    "Yordanova",
    "Kirste",
    "Michael",
    "Ware",
    "Cassell",
    "Robertson",
    "Yu",
    "Li",
    "Chan",
    "Yan",
    "Zhao",
    "Yu",
    "Zhu",
    "Li",
    "Hu",
    "Wang",
    "Heng",
    "Jiang",
    "Zha",
    "Guan",
    "Kambhampati",
    "Zhang",
    "Gu",
    "Han",
    "Chen",
    "Xiao",
    "Sun",
    "Yao",
    "Qi",
    "Guan",
    "Ke",
    "Zhao",
    "Yang",
    "Li",
    "Guo",
    "Li",
    "Hankui",
    "Kambhampati",
    "Hankui",
    "Kambhampati",
    "Hankui Zhuo",
    "MuÃ±oz-Avila",
    "Yang",
    "Hankui",
    "Yang",
    "Hankui Zhuo",
    "Zha",
    "Kambhampati",
    "Tian"
  ],
  "year": 2023,
  "abstract": "Natural language processing (NLP) aims at investigating the interactions between agents and humans, processing and analyzing large amounts of natural language data. Large-scale language models play an important role in current natural language processing. However, the challenges of explainability and complexity come along with the developments of language models. One way is to introduce logical relations and rules into natural language processing models, such as making use of Automated Planning. Automated planning (AI planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. Recently, there have been plenty of works related to these two fields, which have the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from tacit knowledge, e.g., neural models, respectively. Integrating AI planning and natural language processing effectively improves the communication between human and intelligent agents. This paper outlines the commons and relations between AI planning and natural language processing, argues that each of them can effectively impact on the other one by five areas: (1) planning-based text understanding, (2) planning-based natural language processing, (3) planning-based explainability, (4) text-based human-robot interaction, and (5) applications. We also explore some potential future issues between AI planning and natural language processing. To the best of our knowledge, this survey is the first work that addresses the deep connections between AI planning and Natural language processing.",
  "sections": [
    {
      "heading": "INTRODUCTION",
      "text": "Natural language processing (NLP) aims at investigating the interactions between agents and humans, processing and analyzing large amounts of natural language data. In recent years, for attaining better performance and handling large corpora, building large-scale language models is an inevitable trend in real applications [62,78,126]. Despite the success of language models in various domains, the explainability and complexity of language models have drawn intense research interests recently. In order to make models explainable and lightweight, integrating models with symbolic planning has been demonstrated effective in various NLP tasks. Symbolic planning (AI planning) is a branch of artificial intelligence that focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. The plans are typically for execution by intelligent agents, autonomous robots, and unmanned vehicles. Different from classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space. Generally, those approaches are mostly based on structured data, which has a well-defined structure and logically explainable to humans. Compared with structured data used in AI planning, natural language descriptions are often complicated by omissions, inverted order, etc., resulting in difficulties in reasoning about language descriptions. It is thus often hard to directly train neural models to generate available and correct solutions, although deep learning has been widely used to handle unstructured data. Deep learning methods do well in acquiring knowledge from data, capturing implied rules, and expressing them by mathematical and neural models, which are tacit and unable to be directly shared with other humans and agents. Different from deep learning methods that aim to learn tacit knowledge, planning-based methods are better at capturing changes, formalizing them by rules, and generating valid plans when handling structured data. Rules are already codified, namely explicit knowledge, which can be clearly expressed and easily shared with others. Therefore, AI planning is one of the considerable steps to understand implied rules and build domain models from large amount of texts in natural language processing [32,72]. On the other hand, unstructured data in real world is not disorderly but often a sequence based on rules. As for a natural language description, there is a theme running through it, along with a series of relevant events and a coherent text unfolds. Each sentence relates to the preceding texts and influences following sentences, just like preconditions and effects of actions in AI planning. For example, in a recipe about making a meatloaf shown in Figure 1(a), humans can easily understand it and capture the main information including verbs, e.g., \"Heat\", and objects, e.g., \"butter\" and \"skillet\". However, as for agents, when given a mass of data in the form of sentences, it is hard to directly build models to reason about the implied rules and predict next moves. If we extract these information and formalize them structurally, as shown in Figure 1(b), it is easier to construct models based on planning methods for guiding future unseen tasks. Besides using AI planning to help reason about implied rules in texts, the power of AI planning about capturing implied relations and computing valid solutions is another effective way to improve natural language processing, such as text summarization and machine translation. For example, there have been planning-based text generation methods [57,119] extending a clear storyline ordered in advance. Those methods first compute sequences composed of keywords, key phrases, or contents as storylines, then use natural language processing techniques to extend storylines to coherent texts. In the above-mentioned example, generating an available recipe in a correct order shown in Figure 1(a) is hard. However, given some rules, such as domain models about the operations of cooking, agents can compute plans toward achieving specified goals like a theme about making a meatloaf, as shown in Figure 1(b). Agents can easily extend the plan and gain a valid recipe. The integration of AI planning and natural language processing combines the best of tacit knowledge learning from sentences and explicit knowledge in the form of rules. As discussed in [52], it would be more effective to combine explicit and tacit knowledge rather than giving up explicit knowledge and learning everything from tacit knowledge, which is the current trend. Integrating AI planning and natural language processing allows human to communicate with agents in a more comfortable way, and enables intelligent agents to explain themselves to human in a human-understandable way. Natural language, as the most comfortable way to communicate with humans, establishes a relationship between humans and intelligent agents. In recent years, researchers have made efforts to connect with natural language and robots, such as by dialogue  systems [82,105] and natural language commands understanding [59,108]. On the other hand, planning-based natural language models are based on structured data or implied rules, such as predicted storylines, which allows human to partly understand the principles of models. In this paper, we first introduce some background knowledge in AI planning and natural language processing as well as their relations. Then we give a comprehensive overview of integrating AI planning and natural language processing by four aspects and their challenges: planning-based text understanding, planning-based natural language processing, planning-based explainability, and text-based human-robot interaction. Their relations are shown in Figure 2. Firstly, planning-based natural language understanding includes extracting actions from texts and learning domain models from texts. Secondly, we introduce planning-based natural language processing by three tasks integrated with AI planning, i.e., text generation, text summarization, and machine translation. Then we discuss planning-based explainability. Next, we introduce text-based human-robot interaction by extracting actions from natural language instructions, natural language command understanding, and dialogue generation. Finally, we present current applications, several future directions and conclude this paper. To the best of our knowledge, this survey is the first work that addresses the deep connections between AI planning and NLP."
    },
    {
      "heading": "PLANNING DOMAIN DESCRIPTION LANGUAGE AND NLP",
      "text": "In this section, we introduce modeling knowledge in AI planning, backgrounds in natural language processing (NLP), and relations between AI planning and NLP, including similarities, differences, and language model-based planning."
    },
    {
      "heading": "Planning-based Natural Language Understanding",
      "text": "Extract information, capture rules, and build domain models. Learn implied rules, organize skeletons, and predict key information."
    },
    {
      "heading": "Planning domain description language",
      "text": "A planning problem is composed of a planning domain D and an instance ð‘, defined by planning domain description language. With the development of AI planning, more and more extended planning domain description languages [34,39,92] have been proposed. Taking PDDL (Planning Domain Definition Language) [71] as an example, a planning domain D is made up by several action models. An action model is defined by a tuple of ð´ = âŸ¨ð‘Ž, pre(ð‘Ž), eff(ð‘Ž)âŸ©, where ð‘Ž is an action name with zero or more types of parameters. An action is a grounding of an action model, each of whose parameters is an object. pre(ð‘Ž) is a set of preconditions requiring to be satisfied when executing ð‘Ž, each of which is a proposition or a numeric constraint. Similarly, eff(ð‘Ž) is a set of effects, an effect can be a topical proposition, added into or deleted from the state after executing ð‘Ž, or a numeric updating, increasing or decreasing the value of variables according to specified functions. An instance is defined by ð‘ = âŸ¨ð‘  0 , ð‘”, ðœ‰âŸ©, where ð‘  0 is a set of initial assignments by propositions and variables, and ð‘” is a set of goals requiring to be achieved. ðœ‰ is an objective function guiding planner to compute for a minimum cost or maximum reward. A planning problem is to compute an available action sequence, which can transfer ð‘  0 to a state containing desired goals ð‘”. For example, parts of action models in the Rover domain are shown in Figure 3(a), where \"(equipped_for _imaging ?r)\" is a proposition asking that a rover \"?r\" should equip with a camera for taking image when executing action \"Calibrate\". \"(>= (energy ?r) 1)\" is a numeric precondition requiring the energy of rover \"?r\" should be larger than 1. Figure 3(b) and (c) show an initial state and goals, respectively. An example valid plan, updating the initial state to a state achieving the goals, is shown in Figure 3(d), where each action is a grounding action model with parameters. (:action Calibrate :parameters (?r -rover ?i -camera ?t -objective ?w -waypoint) :precondition (and (equipped_for_imaging ?r) (>= (energy ?r) 2) (calibration_target ?i ?t) (at ?r ?w) (visible_from ?t ?w) (on_board ?i ?r)) :effect (and (decrease (energy ?r) 2)(calibrated ?i ?r) )) (:action Take_image :parameters (?r -rover ?p -waypoint ?o -objective ?i -camera ?m -mode) :precondition (and (calibrated ?i ?r) (on_board ?i ?r) (equipped_for_imaging ?r) (supports ?i ?m) (visible_from ?o ?p) (at ?r ?p) (>= (energy ?r) 1)) :effect (and (have_image ?r ?o ?m)(not (calibrated ?i ?r))(decrease (energy ?r) 1))) ... Calibrate (rover0 camera0 objective1 waypoint3) â†’ Take_image (rover0 waypoint3 objective1 camera0 high_res) â†’ Communicate_image_data (rover0 camera objective1 high_res waypoint3 waypoint0) â†’ Sample_rock (rover0 rover0store waypoint3) â†’ Drop (rover0 rover0store) â†’ Communicate_rock_data (rover0 camera waypoint3 waypoint3 waypoint0) â†’ Navigate (rover0 waypoint3 waypoint1) â†’ Navigate (rover0 waypoint1 waypoint2) â†’ Sample_soil (rover0 rover0store waypoint2) â†’ Communicate_soil_data (rover0 camera waypoint2 waypoint2 waypoint0) (:init (equipped_for_imaging rover0) (calibration_target camera0 objective1) (at rover0 waypoint3) (on_board camera0 rover0) (available rover0) (calibration_target camera0 objective1) (supports camera0 colour) (supports camera0 high_res) (in_sun waypoint0) (= (energy rover0) 50) .... ) (:goal (and (communicated_soil_data waypoint2) (communicated_rock_data waypoint3) (communicated_image_data objective1 high_res))) Fig. 3. An example in the Rover domain, including action models, initial state, goals, and an available plan."
    },
    {
      "heading": "Natural language processing",
      "text": "Recently, natural language processing (NLP) [17,54,114] has attracted lots of attention, and it builds a bridge between human and agents. Natural language processing is grand, including various fields, such as natural language understanding (NLU) [81,107], natural language generation (NLG), [30,37] machine translation [80], and spelling correction [43]. NLP has undergone several stages of rule-based models, statistic-based models, and neural network models. Rule-based NLP [97] is led by hand-crafted rule sets, whose main task is to understand natural language. It is, however, difficult and time-consuming to build all hand-crafted rules, lacking of scalability. Statistic-based NLP [65] makes use of probability distributions to generate proper words and sentences, promoting the application of statistical machine learning methods based on large-scale corpora in natural language processing. Nevertheless, statistic-based models is barely to capture long-term relations and use information included in contexts. Recently, deep learning has been widely used in NLP tasks [106], it is able to capture tacit knowledge implied in texts. However, deep learning is to fit neural networks and predict based on statistics, it can not \"understand\" the real meaning in natural language. In this paper, we focus on those NLP tasks related to AI planning. Compared with NLP approaches totally based on deep learning, planning-based NLP methods are more curious about implied logic and reasons of the solutions."
    },
    {
      "heading": "Relations between AI planning and natural language processing",
      "text": "In this section, we will sketch the relations between AI planning and natural language processing, which is mentioned by [38,116,122]. We will first introduce the similarities between AI planning and natural language processing, and then talk about their differences and deep relations. We discuss the similarities between AI planning and natural language processing by two aspects. First of all, AI planning and natural language processing both revolve around observations and knowledge [38]. Planning tasks aim at either solving problems based on a current observation and goals along with priori knowledge like action models, or constructing knowledge such as transition functions based on sequential observations. Similarly, in natural language processing tasks, a text can be regarded as a sequence of observations, each observation is a sentence describing a partially observed state, where observations changes following implied rules. Secondly, they share two major common problems in planning tasks and natural language processing tasks: consistency and diversity. Both of plan traces and texts are cohesive descriptions and stringed by some rules and goals. As for planning, the rules are action models and transition functions, which update current states to next ones. The goals are sets of goal states or objective functions, guiding planners to attain optimal solutions. As for natural language processing, the rules are implied in the organization of texts, such as transition connections or consequences. Their goals can be titles, themes, or topics. On the other hand, in natural language processing, given goals, we can generate lots of coherent texts composed of different events, similar to different plan traces computed for the same goal states. Moreover, a sequence of events can be written as various stylized texts. As shown in Table 1, we enumerate some concepts in AI planning and natural language processing, which can have some similarities. For example, objects, such as \"rover0\" and \"objective1\" in Figure 3, in planning problems are similar to entities in texts, e.g., \"skillet\" and \"onions\" in Figure 1. Although AI planning and natural language processing have those commons, the difference between them is that AI planning is good at generating explicit knowledge, such as domain models [128][129][130][131], while natural language processing often learns tacit knowledge, such as training models from natural language data. [52] argues that AI systems should be able to know when to take advice and when to learn, to find a balance between explicit and tacit knowledge. Taking planning-based text generation as an example, although texts are required to be coherent and with correct logic, natural language processing is weak in computing available and valid events, which AI planning is good at. And the integration of both allows agents to generate coherent texts by first using AI planning to generate storylines and then learning text generator by natural language processing techniques. In a word, there are close ties between AI planning and natural language processing, due to their different advantages of explicit and tacit knowledge. The combination allows each of them to effectively impact on the other one."
    },
    {
      "heading": "Language Model-based Planning",
      "text": "Although AI planning can effectively capture rules from action sequences, it is hard for humans without expert knowledge to construct structured plans. A natural and intuitive way is to use human natural language to describe plans, asking language model-based planners to be able to handle text sequences and predict the next moves [94,132]. Prior works mostly make use of pre-trained language models (LMs) to understand abstract, high-level textual actions and learn actionable knowledge for guiding planning [47,50,61]. Specifically, Huang et al. [46] use large language models (LLMs) to generate natural language actions, they investigated actionable knowledge already contained pre-trained LLMs. On the other hand, some works map natural language instructions and high-level goals to actions and goals, and learn policy to make decisions [98]. For example, LID [61] uses policies initialized with pre-trained LMs and fine-tunes policies for predicting actions, validating that LMs are able to contain rich actionable knowledge. Language model-based planners are mostly based on templated textual actions datasets, rather than complex natural language instructions with various styles of descriptions. In the following sections, we introduce deep connections between AI planning and natural language processing, to rise to the dual challenges from rules and natural language."
    },
    {
      "heading": "PLANNING-BASED NATURAL LANGUAGE UNDERSTANDING",
      "text": "In this section, we introduce a comprehension overview of natural language understanding based on AI planning. Natural language understanding aims at comprehending human language, including sentiments, relations in contexts, topics, etc. Compared with learning relations from structured state traces, learning relations between extracted events from texts are even more challenging. It asks agents to reason about contexts, capture themes of sentences by selecting words to represent them, compute causal relationships between the selected words. There are two major areas introduced in the following section, which are both based on AI planning, to understand the texts and learn causal relationships from texts. The first one is to extract action sequences from texts, which requires agents to understand complex contexts from action descriptions. Moreover, it requires agents to be capable of reasoning about connotations in texts, such as exclusion relations and optional relations between actions. The other one is to first select words to represent the main ideas of sentences, and then learn the rules implied in sentences and formalize them by readable domain models for guiding agents to solve future unseen tasks and helping agents and people understand logical relations between events."
    },
    {
      "heading": "Extracting actions from texts",
      "text": "There have been works on extracting action sequences from action descriptions [127]. The inputs of the task mostly include some texts describing some actions and procedures, the outputs are action sequences from the texts, each action is composed of a verb as action name and some objects. Figure 4 shows an example in [32], where an input text is in left part of Figure 4, extracting action traces are shown in the right part of Figure 4, the relations between actions are shown in the middle of Figure 4. This task does not only need extract a word standing for an action of the sentence, but also reason about contexts for completing omissions caused by pronouns. Early approaches [55,70] mostly make use of specialized resources, such as semantic parsers and learned lexicons, to reason about natural language route instructions. For example, MARCO [68] was proposed to Cook the rice the day before, or use leftover rice in the refrigerator. The important thing to remember is not to heat up the rice, but keep it cold. In a bowl, add 1 tablespoon of oil to rice. Use a spoon or your hands to work the oil into the rice, evenly coating the rice. Transfer the rice to a colander and drain. Combine eggs and salt in a small bowl and gently whisk until blended. Heat 1 tablespoon oil in a wok. Add whisked eggs and cumin seeds to wok. Stir frequently, working the eggs to a scramble. Heat the remaining oil in the wok. If desired, you can recycle some of the oil that drained from the rice. Add the garlic and onion to the wok. Stir-fry together over high heat for about 5 minutes or until the onion looks transparent, but is not soft. Add the rice, eggs, soy sauce, chili sauce, vinegar, and celery. Mix together, continuing to stir-fry over high heat for 1-2 minutes while stirring frequently. Spoon onto a plate and serve. Input Training Text Mission Start Cook Use Keep Heat Add Recycle Work Serve EX EX ES ES ES ES ES OP Extracting Action Names and Action Arguments Some Possible Outputs ES: essential OP: optional EX: exclusive Make Egg Fried Rice Mission End Cook rice Use leftover rice Keep rice, cold Add oil spoon Use hands Action Names Action Arguments ES ES ES ES EX EX Cook (rice) Keep (rice, cold) Add (oil) Use (spoon) Work (oil, rice) â€¦ Work (eggs) Heat (oil) â€¦ Serve () Use (leftover rice) Keep (rice, cold) Add (oil) Use (spoon) Work (oil, rice) â€¦ Work (eggs) Heat (oil) â€¦ Serve () Use (leftover rice) Keep (rice, cold) Add (oil) Use (hands) Work (oil, rice) â€¦ Work (eggs) Heat (oil) â€¦ Serve () Use (leftover rice) Keep (rice, cold) Add (oil) Use (hands) Work (oil, rice) â€¦ Work (eggs) Recycle (oil) Heat (oil) â€¦ Serve () ... is unknown. We propose an approach called EASDRL, which stands for Extracting Action Sequences from texts based on Deep Reinforcement Learning. In EASDRL, we view texts associated with actions as \"states\", and associating words in texts with labels as \"actions\", and then build deep Q-networks to extract action sequences from texts. We capture complex tation actions [Pomarlan et al., 2017] from texts. [Sil et al., 2010; Sil and Yates, 2011] learn sentence patterns and lexicons or use off-the-shelf toolkits, i.e., OpenNLP 1 and Stanford CoreNLP 2 . [Lindsay et al., 2017] also build action models with the help of LOCM [Cresswell et al., 2009] after extracting action sequences by using NLP tools. These tools are Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18) Fig. 4. An illustration of action sequence extraction problem in [32] ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022. map free-form natural language route instructions to action sequences, arising great interest in natural language processing community. MARCO is able to model a sentence by an instruction, e.g., \"Turn to face the green hallway\" can be modeled by \"Turn(until=(object=Path, appear=Green, side=Front, dist=0:))\". [22] presented a system along with a plan refinement algorithm to transform natural language navigation instructions into executable formal plans. Generally, methods with semantics parsers require high simplicity of the texts. Therefore, mostly approaches are based on instructional texts or similar texts following some templates. In recent years, learning methods, such as reinforcement learning and LSTM, have been widely used in natural language processing, as well as extracting action sequences from natural language texts, with the rapid development of artificial intelligence. For example, [13] proposed a reinforcement learning approach for mapping natural language instructions in two domains, Windows troubleshooting guides and game tutorials, to sequences of executable actions. It uses a reward function to define the quality of the executed actions, and a policy gradient algorithm to estimate the parameters of a log-linear model for action selection. The learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward. To handle free natural language without restricted templates, EASDRL [32] was presented to extract action sequences from texts, making use of deep reinforcement learning. It builds Q-networks to learn policies of extracting actions and extract plans from the labeled texts. EASDRL regards texts associated with actions as \"states\", and associating words in texts with labels as \"actions\". During capturing relations, EASDRL considers previously extracted actions as parts of states for deciding the choice of next operations. Therefore, EASDRL is able to reason about connotations in texts, such as exclusion relations and optional relations between actions. Except for reinforcement learning, there are more techniques used in extracting actions from texts. With the help of with long short-term memory (LSTM) recurrent neural networks, Mei at al. [72] proposed a neural sequenceto-sequence model to translate single-sentence natural language instructions to action sequences based upon a representation of the observable world state. LSTMs are applicable to a number of sequence learning problems, due to their ability to learn long-term dependencies, and they have been shown to be effective in tasks existing sequences. The LSTM framework allows agents to bidirectionally encode the navigational instruction sequence and decode the representation to an action sequence, based on a representation of the current state."
    },
    {
      "heading": "Learning domain models from texts",
      "text": "Besides extracting action sequences from texts, another way to understand text is to learn the implied relations from sentences. The input of the learning task is a set of texts, and the output is a planning domain model composed of action models describing the relations by propositional preconditions and effects following the syntax of planning domain description language, such as PDDL [71]. Preconditions and effects make use of propositions to describe conditions that must be satisfied when executing actions and results after executing them, respectively. Learning domain models from instructional texts is a little different from narrative stories. Instructional texts are simpler than narrative stories, and the words are domain-dependent. Narrative stories are mostly third person synopses and they are always along with omission, which results in complexity when parsing sentences. A general way to construct a domain model is first to extract words and objects by parsing sentences for annotations (e.g., OpenNLPfoot_1 and Stanford CoreNLPfoot_2 ), and then learn causal relationships between them and formalize the relations by action models. To learn domain models from instructional texts, Sil and Yates [103] used text mining via a search method to identify documents that contain words that represent target verbs or events. Then they used inductive learning techniques to identify appropriate action preconditions and effects. The method relies on handcrafted Pointwise Mutual Information to learn a SVM-based classifier that scores preconditions for a given action. Branavan et al. [14] presented a reinforcement learning framework to extract precondition and effects relations implied by the text, and used these relations to compute action sequences for completing given tasks in the environment. Single argument predicates are extracted from the text as states, and regarded as sub-goals to construct hierarchical planning problems. Yordanova and Kirste [121] extracted verbs and objects from text instructions based on part of speech (POS) tagging module, and discovered causal relations on the basis of the order of appearance to build PDDL models. However, due to lacking of connections between texts and world states and analyses between variable texts with the same meaning, it is hard to directly construct domain models as learning action models from structured data. In this paper, domain models are constructed according to some templates after parsing sentences. For example, \"If the apple is ripe, put the apple on the table. \" indicates that \"ripe\", a state of an apple, is a precondition of action \"put\". Therefore, a precondition of action \"put\" is \"(state-ripe)\". Although the model is readable for human, it is kind of redundant and not easy to understand for agents because of synonyms and polysemous words. Similarly, Lindsay et al. [64] assumed texts are in restricted templates when describing actions. They generated sequences of actions by constructing representations of sentences and cluster operators by computing similarity, and built PDDL domain models with the help of a domain model acquisition tool. Considering the power of AI planning about offering correct causality and flexible narrative generation possibilities, constructing domain models has been used in narrative systems recently. Hayton et al. [42] proposed an approach taking natural language sentences which summarise the main elements of stories as inputs and generating action representations following PDDL, a narrative planning domain model. To overcome difficulties in parsing narrative stories, they presented two sets of rules to handle pronouns in stories. Then they used a template similar to [121] to construct planning domains. Another specific difficulty for planning-based narrative systems is that hand-crafted domain models require more narrative actions and types of narrative objects compared to generated planning domains. The plentiful actions and objects let generated plan traces and storyline be more interesting and they can be extended to enjoyable stories. To achieve it, Porteous et al. [87] tried to anticipate the consequences of plan failure and the remedial actions or objects needed, or described several potential alternatives. They extended narrative planning domains by two types of principled mechanisms to operationalize narrative action and object substitution during narrative plan authoring. An original domain model can be extended with the addition generated by two mechanisms alternately."
    },
    {
      "heading": "Challenges and future prospects",
      "text": "In AI planning, rules implied in states and actions are enforcedly constrained by preconditions and effects. Compared with AI planning, rules between events, such as concurrence, causality, and progression, in natural language processing are more flexible, which often intricately correlate with others. Moreover, the preconditions and effects are implied in natural language, which are abstract and hard to be modeled by propositions. In the other hand, in natural language text, a event can be written in different words, and a word owns various meanings. It therefore is difficult to directly distinguish them by only parsers. Those challenges make it hard to extract detailed logical relations implied in natural language, let along model implied relations by constructing structural domain models. It might be interesting to dig out clear logical relations implied in natural language text, which can lay a foundation for natural language processing tasks, such as explainability and controllable text generation."
    },
    {
      "heading": "PLANNING-BASED NATURAL LANGUAGE PROCESSING",
      "text": "In this section, we introduce three natural language tasks integrated with AI planning, including text generation, text summarization, and machine translation. Planning-based natural language processing tasks concern about reasonability and coherence, making use of the power of AI planning about reasoning about rules and relations."
    },
    {
      "heading": "Planning-based text generation",
      "text": "One important field combined with AI planning is text generation, in which there have been significant advances, recently. Text generation asks models to generate coherent and interesting text based on preceding parts of the text, topics, titles, or themes, requiring agents to be capable of generating valid and clear logical frameworks. AI planning is one of crucial steps to guide models to generate well-organized long texts, owing to its power in learning domain models and computing solutions for goal-driven tasks. In this section, we introduce planning-based text generation methods with respect to the following two features: â€¢ Symbolic planning text generation combines text generation with a classical planning framework, taking prior knowledge, e.g., domain models formalized by planning domain description language, as extra inputs. â€¢ Neural planning text generation are neural generators combined learning with a skeleton planning, to make up for the difficulties in building hand-crafted domain models."
    },
    {
      "heading": "Symbolic planning text generation.",
      "text": "In order to generate coherent text with correct logic, it is natural to give agents some prior knowledge about basic rules between events. On the other hand, early rule-based researches [9,21,83] about natural language processing explore constructing representations of texts and combine with hand-crafted rules. It, however, is hard and tedious to enumerate all rules. Therefore, making use of AI planning to capture implied rules in the form of domain models with symbolic representations and compute proper skeletons is a natural way, which can overcome the difficulties of manually constructing rules [36,56,66]. For example, Porteous et al. [86] proposed an approach injecting narrative control into plan generation through the use of PDDL [71] state trajectory constraints, to express narrative control information within the planning representation. They constructed constraint trees according to input domain models, and injected control into automatically generated narratives system. With the help of constraints, the approach decomposes problems into sets of smaller subproblems using the temporal orderings described by the constraints, and solves subproblems incrementally by a planner. Intentional Partial Order Causal Link (IPOCL) planning framework [90] is an extension of classical planning, it aims at finding a sound and believable sequence of character actions that transforms an initial state into a state arriving goals. IPOCL does not only create causally sound plot progression, but also reasons about character intentionality by identifying possible character goals that explain their actions and creating plans that explain why those characters commit to their goals. Compared to IPOCL, CPOCL [115] preserves the conflicting subplans without damaging the causal soundness of the overall story to generate interesting stories. CPOCL is an extension of IPOCL that explicitly captures how characters can thwart one another in pursuit of their goals, which is the essence of narrative conflicts. Making use of hand-crafted, well-defined domain models, symbolic planning text generation methods have the ability to produce impressive results in limited domains."
    },
    {
      "heading": "4.1.2",
      "text": "Neural planning text generation. However, it is often tedious or difficult to build domain models by hand due to the high requirements of manual efforts and domain knowledge. Automatically learning domains and constructing storylines have significantly attracted researchers' attention recently [88,104]. To automatically learn domain models for helping generate coherent and valid stories, Li et al. [60] used a crowd-sourced corpus of stories to learn plot graphs that can then be used as constrained search spaces for sequences of story events, instead of relying on priori domain models. Specifically, the approach crowdsources a corpus of narrative examples of a new domain, automatically constructs domain models capturing different possible, non-contradictory story trajectories, and samples from the space of stories allowed by the domain model according to some story quality criteria. During the plot graph learning, learning mutual exclusion relations and optional events lets the generated story be coherent. C2PO [2] learns a branching story graph structure that can be searched, and introduces soft causal relations as causal relations inferred from commonsense reasoning. It creates a branching space of possible story continuations that bridge between plot points that are automatically extracted from existing natural language plot summaries. Another way for constructing valid line of text is to construct storylines in advance, which can be skeletons, or sequences of keywords, key phrases, or contents. Xu et al. [118] generated skeletons composed of phrases learned by a reinforcement learning method, and then expanded skeletons to complete and fluent sentences. Fan et al. [31] proposed a novel approach which first generates plans in the form of predicate-argument structures, then generates stories with placeholder tokens to indicate entities, and finally replaces tokens by entities based on the global story contexts. The inputs of the task are short descriptions of scenes or events, and the approach outputs relevant narrative stories following the inputs. Instead of generating skeletons with detailed prompts, some approaches first plan out storylines, which enable them to generate controllable stories with goals. [119] proposed a hierarchical generation framework that first planned a controllable storyline composed of keywords towards a goal (i.e., a title), and then generated a story based on the storyline. The RAKE algorithm [91] takes each sentence as an input and combines several word frequency based and graph-based metrics to weight the importance of the words. The approach regards the most important word as the keyword. The storyline is planned out based on the title, previously generated sentences, and the previous keywords in the storyline. In the experiments, they explore two strategies, dynamic schema and static schema. Results show the static schema performs better than the other one because it plans the storyline holistically, thus tends to generate more coherent and relevant stories. Similarly, [57] made use of a related framework, which first plans out storyline composed of a sequence of keywords and then generates the whole story, to handle stylized story generation. Stylized story generation is to generate stories with specified style given a leading context. Keywords are selected following some emotion-driven style, such as \"fear\", \"anger\", and \"surprsie\". According to the stylized keywords, the approach can generate generates the whole stylized story with the guidance of the keywords. Yu et al. [123] followed Yao et al. [119] and used the RAKE algorithm to extract keywords to train a generation model for conducting keyword planning given story titles as inputs. Then the approach combines the story titles and the corresponding keywords of each story as the inputs of the graph module to automatically generate a graph for each story. According to the keywords, titles, story graphs, the approach encodes them into latent variables and further decodes them to generate the corresponding stories. Except for generating stories according to prompts or goals, DYPLOC [44], a dynamic planning generation framework, takes a set of content items as inputs, each content item consists of a title, a set of entities, and a set of core concepts. To organize unordered content items, DYPLOC introduces a plan scoring network, which learns to dynamically select and order contents based on what has been produced previously while generating the outputs."
    },
    {
      "heading": "Challenges and future prospects.",
      "text": "Recently, text generation [49,51,124] has gained lots of attraction, aiming at letting intelligent agents express like humans. Numbers of methods to generate coherent texts have been proposed in recent years. Generating logical and controllable texts, however, is still a challenging task. AI planning is one of critical ways to enable agents to generate logical and controllable texts. Compared with symbolic planning text generation methods and neural planning text generation methods, the former is more capable of generating logical storylines with goals, and the texts generated by the latter are more diverse and coherent. Specially, symbolic planning methods can generate more explainable storylines, which is still challenging for deep learning methods. In general, it would be interesting to combine both for generating logical, controllable, and coherent text with diversity. Although there have been some approaches [31,96,109] proposed, based on the syntax of plans or representation of structure in AI planning, they use neural networks to predict unseen events instead of speculating based on logical relations implied. We hold the opinion that, compared with only learning blackbox neural models with implicit rules, appropriately combined with explicit logical relations would be a new attempt, which maybe contribute to natural language processing tasks."
    },
    {
      "heading": "Planning-based Text Summarization",
      "text": "Text summarization is to extract important information from texts and generate new texts based on those information in the form of summarizes. It requires agents to understand texts, filter information from abundant descriptions and organize them to form summarizes, which is one of the most researched areas among the NLP community. Text summarization can be categorized into extractive and abstractive techniques. Extractive summarization aims at selecting subsets of words or sentences from input articles to summarize them. Abstractive summarization takes articles as inputs, tries to understand the texts and generate summarizes. In recent years, some researchers try to integrate text summarization models with AI planning. The combination of AI planning and text summarization is mostly based on deep learning abstractive summarization, making use of content planning which describes or predicts skeletons of articles. Planning-based text summarization methods first plan out skeletons of summarizies or compute probability distributions, and then generate the whole sentences based on the skeletons or predictions. For example, Narayan et al. [77] first computed plans in the form of entity chains, which are ordered sequences of entities, and then generated summaries conditioned on the plans. Marfurt et al. [69] proposed an abstractive summarization model implemented with a planning step, done by a hierarchical decoder, which first plans out an outline for the next sentence in the form of sentence representations and generates words according to the representations. Amplayo et al. [3] incorporated content planning in unsupervised summarization and datasets creation. They predicted aspect and sentiment probability distributions as content plans and generated sentences according to the predictions. During creating datasets, they made use of the distributions parametrized by the content planner to control the structures of created datasets. In current planning-based text summarization approaches, content planning is based on deep learning which learns models and probability distributions to predict. However, only fitting deep learning models based on representations of sentences and words is hard to capture the relations implied. We believe that it would be interesting and challenging to let content planning modules understand relations implied in texts, which will allow content plans to be more coherent and controllable. On the other hand, although some mainstream text summarization methods are not based on AI planning, there are some commonalities between them. For example, tree-based and ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date: April 2022. graph-based text summarization approaches [4,8,58] first find the most important information from the text and then use trees and graphs to create summaries. Those structures aim at representing the relations between sentences, which is similar to the relations between actions in AI planning but at a more abstract level. Secondly, some text summarization methods try to obtain important words from sentences, such as verbs, objects, and subjects, to represent sentences semantically [1]. These forms have similarities with the structured representations in AI planning such as propositions and first-order predicates. Thirdly, ontology-based text summarization methods [74,117] collect entities and their relationships, which reminds us of domain models in AI planning. We believe that there is a vast scope for researchers to combine AI planning and text summarization."
    },
    {
      "heading": "Planning-based Machine Translation",
      "text": "Machine translation aims at automatically translating content from source language to another target language, having a long history. One way to understand source texts and generate target texts is to combine neural language models with planning phases, i.e., first generating skeletons, and extending them by target languages. For example, GÃ¼lÃ§ehre et al. [41] integrated an autoencoder with a planning mechanism, the auto-encoder first encodes texts by sequences of vector representations and decodes representations by generating target translation character-by-character. Specifically, they first created plans ahead in the form of action matrices, which are sequences of probability distributions, and made use of commitment plan vectors to govern whether to recompute plans or use them. Then they computed soft alignments based on the plan and generated texts in target language at each time-step. Shu and Nakayama [102] combined neural machine translation with a planning phase, which first generates planner codes to disambiguate uncertain information about the sentence structure and control the structure of output sentences. Bahdanau et al. [7] used actor-critic methods from reinforcement learning (RL) to generate sequences. They showed that sequences can be used in machine translation tasks, gaining better translation performance. Those approaches first produce big pictures of output texts by planning, then generate complete sentences conditioned on plans. They take advantages of capturing implied rules to generate more accurate and coherent target texts. In natural language texts, the transitions between sentences imply relations and rules. Machine translation tasks do not only need to understand word-level structures of sentences, but also need to capture sentence-level relationships. Only relying on word-by-word text generation is hard and challenging to generate coherent and logical texts, especially when generating accurate transitions between sentences. Current approaches to capture implied rules and generate plans are mostly based on neural black-box models, lacking the explainability of making decisions. Previous researches about rule-based translation are explainable, they are based on hand-crafted rules. Although those rules are explicit and accurate, it is hard to manually write rules and the rules are not scalable. Producing rules are time-consuming and tedious. However, it would be interesting if we regard it as action models learning in planning community, which structurally formalize rules by preconditions and effects. We believe that combining rule-based machine translation with planning and neural machine translation may spark new ideas."
    },
    {
      "heading": "PLANNING-BASED EXPLAINABILITY",
      "text": "Nowadays, although deep learning approaches have been widely used in AI fields, human cannot understand practical meaning inside black-box neural models. Differently, AI planning is able to offer explicit knowledge, in the form of first-order logic, domain models, etc, implied in natural language. Therefore, the combination of natural language and AI planning may enable AI systems to be able to explain their reasoning to humans, which meets the needs for AI systems to work synergistically with humans. Those systems require agents to be aware of the intentions, capabilities and mental model of the human in the loop during its decision process. As shown in Figure 5, besides extracting action sequences [32,68] and building domain models [14,64] mentioned above, another way for making AI system explainable is to construct human-understandable symbolic interfaces (cf. [53]). A human-understandable symbolic interface is not only developed for its own computational efficiency, but also beneficial to humans. EXPAND system [40] and SERLfD framework [125], respectively. EXPAND system accelerates Human-in-the-Loop deep reinforcement learning by using human evaluative feedback and visual explanation. SERLfD uses self-explanation to recognize valuable high-level relational features as an interpretation of why a successful trajectory is successful, allowing SERLfD to guide itself and improve the efficiency."
    },
    {
      "heading": "TEXT-BASED HUMAN-ROBOT INTERACTION",
      "text": "The rapid developments of artificial intelligence let robots move out from industrial environments, and enter the daily life of humans, such as homes and hospitals. It requires robots to be able to respond quickly and effectively to rapidly-changing conditions and expectations. Language-based communication is the most natural method for humans to communicate with others, so natural language is a good candidate to be robot instruction for human-robot interaction. In this section, we will introduce text-based human-robot interaction from three aspects: extracting actions from natural language commands, natural language command understanding, and dialogue generation, as shown in the Figure 6."
    },
    {
      "heading": "Extracting actions from natural language command",
      "text": "One of important tasks in text-based human-robot interaction is to extract actions from natural language commands [48,79,85,111]. Extracting actions from natural language commands is similar to action extraction in Section 3.1. Differently, extracting actions from natural language commands is not only to capture important words to indicate sentences, but also to understand implied rules and generate action sequences to guide robots to achieve tasks. Some approaches make use of with language descriptions, then build models that map language commands to action sequences. Tellex et al. [110] introduced a system, Generalized Grounding Graphs (G 3 ), taking a natural language command as input and outputting a plan for the robot. G 3 instantiates a probabilistic graphical model for a particular natural language command according to hierarchical and compositional semantic structure of the command. Cantrell et al. [20] presented a robotic architecture equipping with a planner that uses newly discovered information to produce new and updated plans, specifically information originating in spoken input produced by human operators. The robot can learn action sequences with defined preconditions and effects from natural language descriptions, and immediately apply this knowledge to improve planning. On the other hand, some approaches [16,120] focus on temporal logic between natural language commands, aiming at handling semantic disambiguation of natural language."
    },
    {
      "heading": "Natural Language Command Understanding",
      "text": "Another important task is to enable agents to understand natural language commands given by humans, which requires agents to understand natural language commands and capture implied rules [10,10,12,25,25,99], or learn new actions based on natural language commands and dialogues [35,75,95,101]. To understand natural language commands, Thomason et al. [113] introduced a dialog agent to understand human natural language commands through semantic parsing, actively resolve ambiguities using a dialog manager, and incrementally learn from human-robot conversations. The agent employs incremental learning of a semantic parser from conversations on a mobile robot. It is implemented and tested both on a web interface with hundreds of users and on a mobile robot over several days, tasked with understanding navigation and delivery requests through natural language in an office environment. Brawer et al. [15] presented a framework for effectively grounding situated and natural language to action selection during human-robot interaction. It integrates verbal commands from a human partner with contextual information in the form of a task model. The approach is capable of acquiring and deploying new task representations from limited and natural language data sets, and without any prior domain knowledge of language or the task itself. Moreover, understanding action models and predicting next actions are widely researched for robotic tasks and navigation tasks with natural language commands [24,26,112]. On the other hand, another challenge in natural language command understanding tasks is to learn new actions when facing unknown natural language commands [6,100]. Cantrell et al. [19] introduced an algorithm, to learn meanings of action verbs through dialogue-based natural language descriptions and integrated it in the robot's natural language subsystem. The algorithm allows robots to perform the actions associated with the learned verb meanings right away without any additional help or learning trials. Moreover, it allows human to interact with a robot to explain new action words in natural language, and lets the robot be able to perform the new action and store the procedural knowledge for future usage. Learning by Instruction Agent (LIA) [5] was proposed to learn new commands by natural language interaction with human. When facing a new natural language command that LIA does not understand, it prompts users to explain how to achieve the command through a sequence of natural language steps. LIA interprets commands using a semantic parser that maps each command to a logical form, which contains one or more of functions and predicates. Undoubtedly, letting agents understand natural language commands and infer about next actions is an important but challenging task. An agent does not only need to capture rules implied in utterances, but also need to distinguish sentences described in different ways. We believe that the combination of planning-based natural language processing and human-robot interaction would create something interesting for natural language commands understanding tasks."
    },
    {
      "heading": "Dialogue Systems",
      "text": "Dialogue systems [23,67] have been a bridge between human and robots, which interacts with human in natural language. AI planning is one of crucial mechanisms used in dialogue systems to recognize the intentions conveyed in dialogues [18,76]. Planning-based dialogue systems take advantage of the power of capturing and expressing rules and use it to manage utterances or guide the generation. Rules, plans and intentions offer proper logical forms which derive appropriate communication acts in dialogue systems [28]. Plan-based model [27,93] were proposed to manage the intentions and information implied in dialogues. Those models describe the common activities and relations between utterances, and can be used in the following generation processes. However, planning-based dialogue systems are still in early stages [28,84], which facing the challenges of complex representations in open-domain, difficulties of manually constructing models and limitations of scalability of dialogue models. Nevertheless, we believe that planning could be a strong suit for dialogue systems by integrating with automatically domain models learning and searching strategies, especially for controlled dialogue generation. Moreover, we are interested in the explainability of planning-based dialogue systems, it would be interesting to know the reason for intentions generation."
    },
    {
      "heading": "APPLICATIONS",
      "text": "In this section, we introduce some reality applications based on combinations of AI planning and natural language processing. AI planning is widely used in reality management systems, such as logistics management, workshop schedule, and reservoir operation. Moreover, natural language processing (NLP) helps human communicate with agents, the combination of AI planning and NLP enables applications to be found in many fields, such as emergency managements [11,29,29,33] and urban planning [63,63,89]. For example, the Urban Redevelopment Authority (URA) Centre in Singapore 3 deployed Robotic Process Automation and NLP to help conduct operations for resource optimization. The combination allows routine tasks to make use of AI planning and NLP, such as chatbots for public queries, which capture information from large datasets, analyze textual feedback, make planning decisions, and respond intelligently. On the other hand, the navigation systems in daily use, such as Baidu Maps 4 and Google Mapsfoot_5 , combine making decisions and NLP techniques, which plan out routes with different objectives according to goals, and generate natural language suggestions to guide human. Moreover, agents learn from human commands and navigation datasets, helping agents understand human behaviors [45,73]."
    },
    {
      "heading": "CONCLUSION",
      "text": "In this paper, we consider that AI planning and natural language processing have strong ties, and we introduce recent works about four related tasks, i.e., planning-based text understanding, planningbased natural language processing, planning-based explainability, and text-based human-robot interaction. We first introduce backgrounds about AI planning and natural language processing and discuss commons between them, as well as their abilities to generate explicit knowledge, e.g., domain models, and learning from tacit knowledge, e.g., neural models. We then introduce methods of planning-based text understanding by extracting action sequences from texts and learning domain models from texts. Next, we give an overview of planning-based natural language processing about text generation, text summarization, and machine translation. Then, we introduce recent works in planning-based explainability and text-based human-robot interaction. With this paper, we aim to provide a high-level view of AI planning and natural language processing for further studies, about integrating them for a combination of explicit and tacit knowledge. Combining learning from tacit knowledge and using explicit knowledge in a fully principled way is an open problem, although there are non-negligible relations between AI planning and natural language processing, allowing each of them can effectively impact the other one. However, there is not enough communication between these two fields. While many advances have been made in natural language processing by using AI planning algorithms, a significant amount of research is still required to understand the implied knowledge hidden in texts. Meanwhile, improving the ability to describe environments by domain models and solve large-scale planning problems is also beneficial to understanding texts and generating coherent and interesting texts. We believe that integrating AI planning and natural language processing, a complex combination of explicit and tacit knowledge, is a promising research area, which can improve the communication between human and intelligent agents."
    }
  ]
}