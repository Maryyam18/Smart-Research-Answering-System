{
  "paperid": "2401.05632v4",
  "title": "Natural Language Processing for Dialects of a Language: A Survey",
  "authors": [
    "Joshi",
    "Dippold",
    "Abdul-Mageed",
    "Alhuzali",
    "Elaraby",
    "Abdul",
    "Diab",
    "Abdul-Mageed",
    "Elmadany",
    "Zhang",
    "Abdul-Mageed",
    "Zhang",
    "Bouamor",
    "Habash",
    "Abdul-Mageed",
    "Zhang",
    "Elmadany",
    "Bouamor",
    "Habash",
    "Abdul-Mageed",
    "Zhang",
    "Elmadany",
    "Bouamor",
    "Habash",
    "Abdulrahim",
    "Inoue",
    "Shamsan",
    "Khalifa",
    "Habash",
    "Abe",
    "Matsubayashi",
    "Okazaki",
    "Inui",
    "Acm",
    "Abe",
    "Suzuki",
    "Liang",
    "Utsuro",
    "Yamamoto",
    "Matsuyoshi",
    "Kawada",
    "Aepli",
    "Anastasopoulos",
    "Chifu",
    "Domingues",
    "Faisal",
    "Gaman",
    "Aepli",
    "Çöltekin",
    "Van Der",
    "Goot",
    "Jauhiainen",
    "Kazzaz",
    "Ljubešić",
    "North",
    "Plank",
    "Scherrer",
    "Zampieri",
    "Aepli",
    "Sennrich",
    "Ahia",
    "Aremu",
    "Abagyan",
    "Gonen",
    "Ifeoluwa Adelani",
    "Abolade",
    "Smith",
    "Tsvetkov",
    "Ahia",
    "Kumar",
    "Gonen",
    "Kasai",
    "David R Mortensen",
    "Smith",
    "Tsvetkov",
    "Karim",
    "Ali",
    "Fikri Aji",
    "Indra Winata",
    "Koto",
    "Cahyawijaya",
    "Romadhony",
    "Mahendra",
    "Kurniawan",
    "Moeljadi",
    "Prasojo",
    "Baldwin",
    "Han Lau",
    "Ruder",
    "Al-Ghadhban",
    "Al-Twairesh",
    "Al-Mannai",
    "Sajjad",
    "Khader",
    "Al Obaidli",
    "Nakov",
    "Vogel",
    "Mahfuz",
    "Alam",
    "Ahmadi",
    "Anastasopoulos",
    "Abu",
    "Habash",
    "Hasan Alkheder",
    "Bouamor",
    "Habash",
    "Zengin",
    "Ebtesam",
    "Almansor",
    "Al-Ani",
    "Alshareef",
    "Muazzam",
    "Siddiqui",
    "Alshutayri",
    "Atwell",
    "Artemova",
    "Blaschke",
    "Plank",
    "Artemova",
    "Plank",
    "Assiri",
    "Emam",
    "Al-Dossari",
    "Azouaou",
    "Guellil",
    "Bafna",
    "España-Bonet",
    "Van Genabith",
    "Sagot",
    "Bawden",
    "Baimukan",
    "Bouamor",
    "Habash",
    "Ball-Burack",
    "Seng",
    "Lee",
    "Cobbe",
    "Singh",
    "Baly",
    "Khaddaj",
    "Hajj",
    "El-Hajj",
    "Bashir Shaban",
    "Barnes",
    "Maehlum",
    "Touileb",
    "Ben",
    "Mabrouk",
    "Ben Haj",
    "Hmida",
    "Fourati",
    "Haddad",
    "Messaoudi",
    "Bird",
    "Blaschke",
    "Purschke",
    "Blaschke",
    "Schütze",
    "Plank",
    "Su",
    "Blodgett",
    "Barocas",
    "Daumé",
    "Wallach",
    "Su",
    "Blodgett",
    "Green",
    "Connor",
    "Su",
    "Blodgett",
    "Wei",
    "Connor",
    "Bouamor",
    "Habash",
    "Oflazer",
    "Bouamor",
    "Habash",
    "Salameh",
    "Zaghouani",
    "Rambow",
    "Abdulrahim",
    "Obeid",
    "Khalifa",
    "Eryani",
    "Erdmann",
    "Boujelbane",
    "Ellouze Khemekhem",
    "Benayed",
    "Hadrich",
    "Boujou",
    "Chataoui",
    "Mekki",
    "Benjelloun",
    "Chairi",
    "Berrada",
    "Bowers",
    "Arppe",
    "Lachler",
    "Moshagen",
    "Trosterud",
    "Burghardt",
    "Granvogl",
    "Wolff",
    "Chakrabarty",
    "Dabre",
    "Ding",
    "Tanaka",
    "Utiyama",
    "Sumita",
    "Chakrabarty",
    "Dabre",
    "Ding",
    "Utiyama",
    "Sumita",
    "Chaves",
    "Egbert",
    "Hocking",
    "Doerry",
    "Aurelio",
    "Chiang",
    "Diab",
    "Habash",
    "Rambow",
    "Shareef",
    "Chifu",
    "Glavaš",
    "Radu",
    "Ionescu",
    "Ljubešić",
    "Miletić",
    "Miletić",
    "Scherrer",
    "Vulić",
    "Chitturi",
    "Hansen",
    "Siew",
    "Chow",
    "Bond",
    "Coats",
    "Coats",
    "Contarino",
    "Acm",
    "Cotterell",
    "Callison-Burch",
    "Cox",
    "Cox",
    "Palethorpe",
    "Criscuolo",
    "Aluisio",
    "Dabre",
    "Dabre",
    "Pereira",
    "Dacon",
    "Liu",
    "Tang",
    "Darwish",
    "Habash",
    "Abbas",
    "Al-Khalifa",
    "Huseein",
    "Al-Natsheh",
    "Bouamor",
    "Bouzoubaa",
    "Cavalli-Sforza",
    "Samhaa",
    "El-Beltagy",
    "El-Hajj",
    "Darwish",
    "Mubarak",
    "Eldesouki",
    "Abdelali",
    "Samih",
    "Alharbi",
    "Attia",
    "Magdy",
    "Kallmeyer",
    "Darwish",
    "Sajjad",
    "Mubarak",
    "De Camillis",
    "Egon",
    "Stemle",
    "Chiocchetti",
    "Fernicola",
    "Demszky",
    "Sharma",
    "Clark",
    "Prabhakaran",
    "Eisenstein",
    "Demszky",
    "Sharma",
    "Clark",
    "Prabhakaran",
    "Eisenstein",
    "Diab",
    "Habash",
    "Rambow",
    "Altantawy",
    "Benajiba",
    "Dibas",
    "Khairallah",
    "Habash",
    "Sadi",
    "Sairafy",
    "Sarabta",
    "Ardah",
    "Van Dinh",
    "Dang",
    "Nguyen",
    "Van Nguyen",
    "Doğruöz",
    "Nakov",
    "Dou",
    "Gao",
    "Pan",
    "Wang",
    "Che",
    "Zhan",
    "Lou",
    "Ducel",
    "Fort",
    "Lejeune",
    "Lepage",
    "Dunn",
    "Dunn",
    "Adams",
    "Eggleston",
    "Connor",
    "Eisenstein",
    "Vinodkumar Prabhakaran",
    "Rivera",
    "Demszky",
    "Sharma",
    "Mekki",
    "Mahdaouy",
    "Berrada",
    "Khoumsi",
    "Elfardy",
    "Diab",
    "Elmadany",
    "Abdou",
    "Gheith",
    "Elmadany",
    "Mubarak",
    "Magdy",
    "Ashraf Elnagar",
    "Sane",
    "Yagi",
    "Bou Nassif",
    "Shahin",
    "Salloum",
    "Elsaid",
    "Mohammed",
    "Fattouh",
    "Sakre",
    "Erdmann",
    "Habash",
    "Taji",
    "Bouamor",
    "Erdmann",
    "Zalmout",
    "Habash",
    "Eskander",
    "Habash",
    "Rambow",
    "Pasha",
    "Estival",
    "Cassidy",
    "Cox",
    "Burnham",
    "Fadhil",
    "Faisal",
    "Ahia",
    "Srivastava",
    "Ahuja",
    "Chiang",
    "Fleisig",
    "Smith",
    "Bossi",
    "Rustagi",
    "Yin",
    "Klein",
    "Følstad",
    "Bae",
    "Fuad",
    "Al-Yahya",
    "Gaman",
    "Hovy",
    "Radu",
    "Ionescu",
    "Jauhiainen",
    "Jauhiainen",
    "Lindén",
    "Ljubešić",
    "Partanen",
    "Purschke",
    "Scherrer",
    "Zampieri",
    "Goebl",
    "Goswami",
    "Sarkar",
    "Bharathi",
    "Chakravarthi",
    "Fransen",
    "Philip",
    "Goutte",
    "Léger",
    "Malmasi",
    "Zampieri",
    "Guellil",
    "Azouaou",
    "Benali",
    "Ala-Eddine",
    "John",
    "Gumperz",
    "Habash",
    "Rambow",
    "Hamed",
    "Habash",
    "Abdennadher",
    "Vu",
    "Hanani",
    "Naser",
    "Harrat",
    "Meftouh",
    "Smaïli",
    "Acm",
    "Harris",
    "Halevy",
    "Howard",
    "Bruckman",
    "Yang",
    "Harris",
    "Mgbahurike",
    "Kumar",
    "Yang",
    "Hassan",
    "Elaraby",
    "Tawfik",
    "Hassani",
    "Haugen",
    "Haugh",
    "Schneider",
    "Held",
    "Ziems",
    "Yang",
    "Hofmann",
    "Pratyusha",
    "Kalluri",
    "Jurafsky",
    "King",
    "Honnet",
    "Popescu-Belis",
    "Musat",
    "Baeriswyl",
    "Hou",
    "Huang",
    "Hovy",
    "Purschke",
    "Hovy",
    "Yang",
    "Husain",
    "Al-Ostad",
    "Omar",
    "Igarashi",
    "Miyagawa",
    "Inoue",
    "Alhafni",
    "Baimukan",
    "Bouamor",
    "Habash",
    "Inoue",
    "Khalifa",
    "Habash",
    "Jarrar",
    "Habash",
    "Alrimawi",
    "Akra",
    "Zalmout",
    "Jauhiainen",
    "Lui",
    "Zampieri",
    "Baldwin",
    "Lindén",
    "Jeblee",
    "Feely",
    "Bouamor",
    "Lavie",
    "Habash",
    "Oflazer",
    "Jenkins",
    "Deborah",
    "Johnson",
    "Verdicchio",
    "Jørgensen",
    "Hovy",
    "Søgaard",
    "Joukhadar",
    "Saghergy",
    "Kweider",
    "Ghneim",
    "Jurgens",
    "Tsvetkov",
    "Jurafsky",
    "Braj",
    "Kachru",
    "Kanjirangat",
    "Samardzic",
    "Rinaldi",
    "Dolamic",
    "Kantharuban",
    "Vulić",
    "Korhonen",
    "Kaseb",
    "Farouk",
    "Kåsen",
    "Hagen",
    "Nøklestad",
    "Priestly",
    "Keleg",
    "Goldwater",
    "Magdy",
    "Keswani",
    "Celis",
    "Salam Khalifa",
    "Habash",
    "Abdulrahim",
    "Hassan",
    "Salam Khalifa",
    "Zalmout",
    "Habash",
    "Anthony",
    "Kroch",
    "Kumar",
    "Anastasopoulos",
    "Wintner",
    "Tsvetkov",
    "Kuparinen",
    "Olli Kuparinen",
    "Miletić",
    "Scherrer",
    "Lameli",
    "Schönberg",
    "Le",
    "Luu",
    "Lent",
    "Tatariya",
    "Dabre",
    "Chen",
    "Fekete",
    "Ploeger",
    "Zhou",
    "Armstrong",
    "Eijansantos",
    "Malau",
    "Hans",
    "Heje",
    "Lavrinovics",
    "Kanojia",
    "Belony",
    "Bollmann",
    "Grobol",
    "De Lhoneux",
    "Hershcovich",
    "Degraff",
    "Søgaard",
    "Bjerva",
    "Li",
    "Mao",
    "Liu",
    "Held",
    "Yang",
    "Liu",
    "Ni",
    "Ti Aw",
    "Chen",
    "Lu",
    "Lu",
    "Lu",
    "Tsai",
    "Lui",
    "Baldwin",
    "Lui",
    "Cook",
    "Maamouri",
    "Bies",
    "Kulick",
    "Ciul",
    "Habash",
    "Eskander",
    "Malmasi",
    "Zampieri",
    "Ljubešić",
    "Nakov",
    "Ali",
    "Tiedemann",
    "Kumar Maurya",
    "Kejriwal",
    "Mdhaffar",
    "Bougares",
    "Esteve",
    "Hadrich-Belguith",
    "Meftouh",
    "Harrat",
    "Jamoussi",
    "Abbas",
    "Smaili",
    "John Merrison",
    "Wilson",
    "Davies",
    "Haugh",
    "Acm",
    "Meyer",
    "Moghimifar",
    "Qu",
    "Wu",
    "Li",
    "Haffari",
    "Moore",
    "Morin",
    "Coats",
    "Mozafari",
    "Farahbakhsh",
    "Crespi",
    "Mulki",
    "Haddad",
    "Gridach",
    "Babaoğlu",
    "Nagata",
    "Nerbonne",
    "Heeringa",
    "Nerbonne",
    "Heeringa",
    "Nerbonne",
    "Heeringa",
    "Hailu Nigatu",
    "Lambebo Tonja",
    "Rosman",
    "Solorio",
    "Choudhury",
    "Obeid",
    "Khalifa",
    "Habash",
    "Bouamor",
    "Zaghouani",
    "Oflazer",
    "Obeid",
    "Salameh",
    "Bouamor",
    "Habash",
    "Obeid",
    "Zalmout",
    "Khalifa",
    "Taji",
    "Oudah",
    "Alhafni",
    "Inoue",
    "Eryani",
    "Erdmann",
    "Habash",
    "Okpala",
    "Cheng",
    "Mbwambo",
    "Luo",
    "Olabisi",
    "Hudson",
    "Jetter",
    "Agrawal",
    "Oussous",
    "Benjelloun",
    "Paul",
    "Finch",
    "Dixon",
    "Sumita",
    "Plüss",
    "Deriu",
    "Schraner",
    "Paonessa",
    "Hartmann",
    "Schmidt",
    "Scheller",
    "Hürlimann",
    "Samardžić",
    "Vogel",
    "Cieliebak",
    "Qian",
    "Sindhujan",
    "Kabra",
    "Kanojia",
    "Orasan",
    "Ranasinghe",
    "Blain",
    "Rajai",
    "Ennasser",
    "Ramponi",
    "Ramponi",
    "Casula",
    "Ramponi",
    "Casula",
    "Riabi",
    "Mahamdi",
    "Seddah",
    "Riley",
    "Dozat",
    "Botha",
    "Garcia",
    "Garrette",
    "Riesa",
    "Firat",
    "Constant",
    "Roberts",
    "Roy",
    "Sukhada",
    "Singh",
    "Saadany",
    "Orăsan",
    "Mohamed",
    "Tantawy",
    "Sajjad",
    "Abdelali",
    "Durrani",
    "Dalvi",
    "Salameh",
    "Bouamor",
    "Habash",
    "Salloum",
    "Habash",
    "Todd",
    "Sandel",
    "Sap",
    "Card",
    "Gabriel",
    "Choi",
    "Smith",
    "Scannell",
    "Schneider",
    "Seddah",
    "Essaidi",
    "Fethi",
    "Futeral",
    "Muller",
    "Suárez",
    "Sagot",
    "Srivastava",
    "Shapiro",
    "Duh",
    "Shoufan",
    "Alameri",
    "Simaki",
    "Simakis",
    "Paradis",
    "Kerren",
    "Sun",
    "Sellam",
    "Clark",
    "Vu",
    "Dozat",
    "Garrette",
    "Siddhant",
    "Eisenstein",
    "Gehrmann",
    "Tahssin",
    "Kishk",
    "Torki",
    "Talafha",
    "Kadaoui",
    "Samar",
    "Magdy",
    "Habiboullah",
    "Chafei",
    "Chafei",
    "Oumar El-Shangiti",
    "Zayed",
    "Tan",
    "Joty",
    "Varshney",
    "Kan",
    "Vaillant",
    "Van Der Goot",
    "Sharaf",
    "Imankulova",
    "Üstün",
    "Stepanović",
    "Ramponi",
    "Oryza Khairunnisa",
    "Komachi",
    "Plank",
    "Vidal-Gorène",
    "Tomeh",
    "Khurshudyan",
    "Wang",
    "Zhang",
    "Leonard Chan",
    "Yang",
    "Chieu",
    "Wang",
    "Rikke",
    "Bundgaard-Nielsen",
    "Baker",
    "Maxwell",
    "Xiao",
    "Held",
    "Liu",
    "Yang",
    "Xie",
    "Ahia",
    "Tsvetkov",
    "Anastasopoulos",
    "Xu",
    "Xu",
    "Wang",
    "Li",
    "Rs Yadav",
    "Younes",
    "Souissi",
    "Achour",
    "Ferchichi",
    "Zampieri",
    "Malmasi",
    "Scherrer",
    "Samardžić",
    "Tyers",
    "Silfverberg",
    "Klyueva",
    "Pan",
    "Huang",
    "Ionescu",
    "Butnaru",
    "Jauhiainen",
    "Zampieri",
    "Nakov",
    "Zampieri",
    "Nakov",
    "Scherrer",
    "Zampieri",
    "Tan",
    "Ljubešić",
    "Tiedemann",
    "Zampieri",
    "Tan",
    "Ljubešić",
    "Tiedemann",
    "Nakov",
    "Zbib",
    "Malchiodi",
    "Devlin",
    "Stallard",
    "Matsoukas",
    "Schwartz",
    "Makhoul",
    "Zaidan",
    "Callison-Burch",
    "Zerva",
    "Blain",
    "José",
    "De Souza",
    "Kanojia",
    "Deoghare",
    "Nuno",
    "Guerreiro",
    "Attanasio",
    "Rei",
    "Orasan",
    "Negri",
    "Turchi",
    "Chatterjee",
    "Bhattacharyya",
    "Freitag",
    "Martins",
    "Zhan",
    "Li",
    "Kang",
    "Feng",
    "Hua",
    "Qu",
    "Ying",
    "Chandra",
    "Rosalin",
    "Jureynolds",
    "Zhan",
    "Li",
    "Wang",
    "Luo",
    "Feng",
    "Kang",
    "Hua",
    "Qu",
    "Soon",
    "Sharma",
    "Zhang",
    "Van De Meent",
    "Wallace",
    "Wayne Xin Zhao",
    "Zhou",
    "Li",
    "Tang",
    "Wang",
    "Hou",
    "Min",
    "Zhang",
    "Zhang",
    "Dong",
    "Zhao",
    "Sun",
    "Cao",
    "Wan",
    "Ziems",
    "Chen",
    "Harris",
    "Anderson",
    "Yang",
    "Ziems",
    "Held",
    "Yang",
    "Dhamala",
    "Gupta",
    "Yang"
  ],
  "year": 2024,
  "abstract": "State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectal datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German, among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and extends to several NLU and NLG tasks. For these tasks, we describe classical machine learning using statistical models, along with the recent deep learning-based approaches based on pre-trained language models. We expect that this survey will be useful to NLP researchers interested in building equitable language technologies by rethinking LLM benchmarks and model architectures.CCS Concepts: • Computing methodologies → Natural language processing.",
  "sections": [
    {
      "heading": "INTRODUCTION",
      "text": "Natural language processing (NLP) is an area of artificial intelligence that deals with processing of human language in its textual form. NLP tasks are broadly viewed as two categories: natural language understanding (NLU) and natural language generation (NLG). The former broadly covers language understanding tasks such as dialect identification or sentiment classification, as well as tasks such as morphosyntactic analysis. The latter includes tasks where both the input and the output are textual sequences (for example, summarisation). The state-of-the-art NLP, for both NLU and NLG, is based on Transformer-based models [Naveed et al. 2023;Zhao et al. 2023]. Large language models (LLMs) that use decoders in the Transformer architecture have significantly increased attention toward NLP leading to LLM-based applications in several domains such as medicine, business or law. LLMs released by commercial organisations report an increasingly higher number of parameters and, as a result, improved performances on several NLP tasks. NLP approaches using LLMs are largely viewed as black-box models trained on massive corpora whose composition is not accurately known. This survey dissects one of many attributes in which variations may exist in the training and test corpora: dialects of a language. Traditionally, a dialect is defined as the regionally or locally based variety of a language [Haugen 1966]. Wikipedia defines a dialect as \"a variety of a language that is a characteristic of a particular group of the language's speakers. \" Zampieri and Nakov [2021] state that dialects are language varieties characterised by systematic patterns of variation. The current notion of dialect has extended to language varieties arising due to factors such as political reasons, country of origin, migration histories, historical factors, register shifts and so on. In fact, there is an association between perceived social hierarchies and dialects of a language, leading to a term 'sociolect ' [Kroch 1986]. For the sake of brevity, we use 'dialects' as an umbrella term to refer to 'dialects/national varieties/cultural variants/sociolects' of a language while acknowledging that the distinction between dialects and language is nuanced [Sandel 2015]. An example of a dialect is the national variety, Australian English, whose phonemes are predominantly derived from Southern British English and other Englishes [Cox 2006;Cox and Palethorpe 2007], but has also developed its own unique vocabulary [Moore 1999]. Overlapping with dialects are Creole languages that develop from the process of different languages simplifying and mixing into a new form (often, a pidgin), and then that form expanding and elaborating into a full-fledged language with native speakers, all within a fairly brief period. Lent et al. [2024] highlight the social and scholarly stigmatisation of Creole languages that has resulted in limited advances in NLP for these languages. In general, our survey is catalysed by the recent efforts in extending LLMs on NLP tasks for dialects of different languages. As researchers continue to look 'under the hood' of LLMs, dialectal differences in training and testing datasets are being increasingly scrutinised, and adaptation techniques to improve their performance on different dialects are being devised. As a result, we hope that this survey will help readers and researchers understand past work in NLP techniques for dialects of a language, and contribute to ideas about fair and equitable NLP in the future. There have been related surveys in the past. Zampieri et al. [2020] describes the available corpora, and past approaches to fundamental NLP problems such as POS tagging and parsing, along with applications to NLP. Our survey builds upon theirs in three ways. Firstly, we cover a wider range of downstream tasks such as summarisation and sentiment analysis. Also, this survey contains recent papers, which highlight increasingly growing attention towards NLP for dialects. Finally, the exposition of our survey adopts a deep learning-centric view, by covering deep learning-based approaches, in particular, the recent LLM-based approaches. Another survey by Blodgett et al. [2020] describes biases of different kinds in an analysis of language technologies, including dialectal bias. We derive from their survey to formulate the motivation and trends in NLP for dialects. Similarly, Jauhiainen et al. [2019] present a survey of automatic language identification, which does not differentiate between dialect or language identification, and mention that dialect identification may be a more challenging task. Finally, extensive surveys focusing on languages from the Middle East have been reported [Darwish et al. 2021;Shoufan and Alameri 2015]. These are surveys of Natural Language Processing for Dialects of a Language: A Survey 1:3 Fig. 1. An example sentence highlighting the differences between Marathi and its Samvedi dialect. NLP for standard and dialectal Arabic, primarily focusing on dialect identification and synthesis in the form of machine translation. Our survey unifies the efforts in dialects of languages belonging to multiple language families. The contribution of our survey is: • We present past work in terms of NLU and NLG tasks, and include both pre-deep learning and deep learning techniques. • We highlight trends and future directions, and provide summary tables that will help researchers interested in dialectal NLP research. • The survey covers a broad range of languages from around the world. The rest of the paper is organised as follows. We motivate the need for a discussion on dialects in Section 2. We define the scope of the paper and highlight key trends in Section 3. We then cover dialect-specific resources in Section 4. Following that, Section 5 covers several NLU tasks: dialect identification, sentiment analysis, parsing, and NLU benchmarks. Section 6 presents relevant approaches in NLG for machine translation, summarisation and so on. Finally, we conclude the survey and discuss future work in the context of NLP research as well as social/ethical implications in Section 7. The survey contains several summary tables that will be useful for future research."
    },
    {
      "heading": "Linguistic Challenges Posed by Dialects",
      "text": "Dialectal differences primarily occur in terms of orthography, syntax and vocabulary. Some examples of dialectal differences in English are: 'I might could help you with that' observed in Southern US, Australian and New Zealand English [Coats 2022;Morin and Coats 2023] as well as British and Irish English [Coats 2023], 'Inside tent can not see leh !' in Singaporean English [Wang et al. 2017] or the uncommon placement of adverbs in native speakers of Asian languages as in 'Already, I have done it. ' [Nagata 2014]. Also, consider the case of the Samvedi dialect of Marathi, one of 42, where we give an example of the Samvedi and Marathi sentences in Table 1. Samvedi does not exhibit word order differences compared to standard Marathi, but it involves heavy pronunciation relaxation (ahe -> hay, and maza -> maa) and the usage of older words. Another challenge in handling dialects is that two dialects of the same language can be mutually unintelligible. A classic example of this is the case of the Aomori and Okinawan dialects of Japanese, which has a total of 47 known dialects. Therefore, it is not enough to collect data for one dialect and assume that it will help in NLP for another dialect, which indicates that special attention will need to be paid to each dialect to ensure that it will be well-represented. Dialects assume further importance when people from different cultural backgrounds interact with one another. Wang et al. [2022] show that monophthongal vowels spoken by Australian English speakers may be difficult to be understood by Mandarin English listeners. Dialects are also associated with pragmatics, with influences derived from macro-social factors such as region, social class, ethnicity, gender, age [Haugh and Schneider 2012]. For example, Schneider [2012] observes differences in small talk across inner circle varieties of English, i.e., varieties from countries where it is the primary language [Kachru 1992]. They also observed differences between speakers of different ages and genders. This suggests that the notion of 'dialect' can be linked to factors beyond geographical distribution. Merrison et al. [2012] showed that, in student requests to university staff, there were differences in the way obligation was expressed, and that these differences were linked to different ways of claiming social standing. Meyer [2014] compares interactions of Australians with people from other cultures in terms of (a) building trust with colleagues, (b) leading teams of a culturally dissimilar background etc. An example in the book states that an Australian may invest in shorter small talk than a Mexican with a colleague. Noting the differences in the pragmatic strategies of different dialect speakers provide an important social perspective on dialectal variation. However, these are currently not sufficiently accounted for in NLP."
    },
    {
      "heading": "Rethinking LLM benchmarks",
      "text": "There are more English language speakers in countries such as India than the United States, Australia and England [Dunn 2019]. In addition, an even larger number of speakers have acquired English in a classroom context (e.g., in countries such as China, Germany or Russia) and use it mainly as a contact language for specific transactional purposes, e.g., business or education. This latter perspective has been described through the notion of English as a lingua franca as \"the common language of choice [. . . ] among speakers who come from different lingua-cultural backgrounds\" [Jenkins 2009]. Despite that, the corpora used to train language models and more importantly, the datasets used to evaluate them do not necessarily reflect dialectal variations within a language. Inoue et al. [2021] examine the performance of BERT-based models for varieties/dialects of Arabic, and show that dialect proximity of pre-training and fine-tuning data bears impact on the performance of the downstream task. In the case of GPT-4, the evaluation dataset consists of questions from the MMLU benchmark written in Standard American English. Standard benchmarks used to claim performance of a language model for English primarily contain Standard American English. It has been found that the performance does not extend to NLU tasks for dialects of English [Ziems et al. 2022]. Further, a recent work by Fleisig et al. [2024] analyses the output of ChatGPT for varieties of English, and shows that the generated output may be of poorer quality and be prone to stereotyping for non-standard dialects of English. These findings holds for most foundation models that are trained on large amounts of data. The distribution of languages in the training corpora is either not known or difficult to determine."
    },
    {
      "heading": "Fair and equitable technologies",
      "text": "NLP systems that are deployed to serve multicultural communities must be mindful of the variations between different dialects. Evaluation and mitigation of disparity between dialects become an overgrowing need in times when language models claim excellent language performance using datasets from a specific dialect alone. Some examples showing the impact of dialects on the performance of NLP tasks are presented in Table 1. We note that these papers are from the past few years, which have otherwise witnessed a great development in the reported performance of NLP models. Some implications of dialects in terms of sociological factors are: (1) Performance of NLP models and per-capita GDP: A recent work by Kantharuban et al. [2023] show the dialectal gap in performance of LLM-based solutions for machine translation and automatic speech recognition for several dialects, similar to Ahia et al. [2023] who show the same for topologically diverse languages. They show a positive correlation between gross domestic product per capita and the efficacy of dialectal machine translation. (2) Healthcare monitoring: Jurgens et al. [2017] show that there exists a disparity between popular dialect speakers and others in the case of healthcare monitoringfoot_1 ."
    },
    {
      "heading": "NLP Task Paper Impact",
      "text": "Language classification [Blodgett et al. 2016] Language detection shows lower performance for African-American English. Sentiment classification [Okpala et al. 2022] Text in African-American English may be predicted more commonly as hate speech. Natural Language Understanding [Ziems et al. 2022] Popular models perform worse on GLUE tasks for African-American English text."
    },
    {
      "heading": "Summarisation [Keswani and Celis 2021]",
      "text": "Generated multi-document summaries may be biased towards majority dialect. Machine translation [Kantharuban et al. 2023] Significant drop in MT from and to dialects of Portuguese/Bengali/etc. to and from English. Parsing [Scannell 2020] Lower performance of parsers on Manx Gaelic as compared to Irish/Scottish Gaelic. Table 1. Examples of adverse impact on NLP task performance due to dialectal variations. (3) Racial biases in hate speech detection: Okpala et al. [2022] show that hate speech classifiers may lean towards predicting a text as true if it uses African-American English. (4) Prejudice in the prediction of employability and criminality: Hofmann et al. [2024] show that dialects may introduce bias in the output of language models. As a result, a person's output with respect to their employability or criminality may be affected based on the dialects they use. NLP may not perform as well for dialects of a language, particularly spoken by historically marginalized communities such as the African-American community. This has been shown for language identification where dialects are not predicted as the language since they differ from the standard version of the language [Blodgett et al. 2016]. An idea closely related to the survey is the 'Bender rule' in NLP research. The Bender rule states that the language of datasets used for evaluation must be stated explicitly without assuming English to be the implicit default [Ducel et al. 2022]. We similarly believe that languages are not monoliths and dialectal differences must be clearly stated. Similarly, Hovy and Yang [2021] show that incorporating dialectal aspects is closely related to social factors of language. As a result, incorporating an understanding of dialects of a dataset is pivoting for fairer NLP tools."
    },
    {
      "heading": "Recent work",
      "text": "One observes a renewed interest in using dialects to inform NLP tasks, as shown in Figure 2. The figure was generated using the ACL anthologyfoot_2 . For \"dialects\", we use 'dialect', 'national variety' (subword for inflections of 'variety'), 'national variation', and 'Creole'. For \"socio-cultural\", we use the words \"cultural\", and \"socio-cultural\". We restrict to the year range 2000-2023. Dialect awareness has been shown to improve the performance of NLP tasks such as machine translation [Sun et al. 2023], speech recognition [Plüss et al. 2023]. Recent works have also focused on dialect-aware NLP tasks as in the case of machine translation of dialect to standard language translation as in the case of Chinese [Lu et al. 2022] (for Hokkien, a dialect of Chinese)."
    },
    {
      "heading": "SCOPE & TRENDS",
      "text": "The focus of this survey is on NLP approaches that are aware of dialects: either in the form of the choice of the dataset, incorporation in the model or evaluation along dimensions involving dialect. The survey provides a broad introduction to past NLP research on dialects spoken in different parts of the world. In the forthcoming subsections, we clarify the scope of this paper (Section 3.1) and highlight key trends (Section 3.2) that are described in detail in the following sections."
    },
    {
      "heading": "Scope",
      "text": "We select papers that mention the dialect as an attribute of interest. The focus on dialects is either based on the evaluation datasets or the model innovations to improve performance on dialect-specific datasets. We keep the following out of scope, primarily to effectively manage the scope of the paper: (1) Code-mixing: Code-mixing involves the use of words from two or more languages, often to reduce cognitive load. This survey does not focus on code-mixing. (2) Implicit selection biases: We also acknowledge that selection biases in datasets may introduce dialectal variations. For example, a dataset of tweets downloaded from a specific country is likely to have predominant dialects spoken in the country. However, we cannot locate these papers in particular, or, for social implications, claim that they are based on dialectal variations of a language without the authors mentioning so. (3) Accent variations: Finally, we focus on 'text'-based research while acknowledging that the speech processing community has a rich history of using acoustic data centered around accent. To this end, we briefly touch upon speech since dialects and speech are intertwined to a certain degree. However, our primary focus is on text since the text aspect has received a lot more attention than the speech aspect. This also sets up a situation where a future survey can expand on the speech aspect of dialectal processing. The focus on the textual form is the typical purview of NLP. (4) Systematic review: This survey is not a systematic review in the sense that we do not exhaustively cover all works on dialects due to limited time and paper space. Instead, we select key representative papers based on our interpretation of the innovation, which, according to us, cover key progress and innovation in NLP for dialects. We acknowledge that we may have missed out on some important papers in the field. We will incorporate these papers as communicated by readers/reviewers. However, we cover a broad range of approaches in the survey. Natural Language Processing for Dialects of a Language: A Survey 1:7 (5) Linguistic studies: While we acknowledge similar rich linguistic work in terms of understanding dialects, we focus on NLP tasksfoot_3 . For example, dialectometry is a research area that studies variations in dialects of a language [Goebl 1993] but is not included in the survey."
    },
    {
      "heading": "Trends",
      "text": "Table 2 summarises the papers covered in this survey. We identify three trends in the past work: (1) Tasks in focus: Older research dealt with dialectal datasets primarily for dialect classification. Past work shows performance degradation when the text contains dialects of a language as compared to the predominant (i.e., standard) form. (2) Languages in focus: The papers reporting work on dialects of Arabic are significantly more than those for dialects of other languages. This has also been accelerated by research forums focusing on Arabic NLP. While the work in English is predominantly for the African-American dialect of English, recent papers examine other dialects such as Indian English, Singaporean English and so on. (3) Mitigation is more than perturbation: Modifying a sentence or its representation to or from its dialectal variations has been achieved by perturbation techniques of varying complexity. However, recent papers show that dialect mitigation can be integrated into the model architecture itself using adversarial networks [Ball-Burack et al. 2021], hypernetworks [Xiao et al. 2023], etc. It may seem that NLP for dialects of a language only pertains to datasets, i.e., it does not need any specialised handling beyond the introduction of a new dataset. However, we observe that the adaptation of NLP techniques for dialects operates at several points in a typical NLP pipeline: (1) Training resources: Labeled datasets (including treebanks) and lexicons in dialects of a language have been reported in the past. This includes datasets with dialect labels along with additional task-specific labels, where the task is an NLP research problem. (2) Models: Models have been enhanced with several techniques, as may be typical of the time of the research. The fact that dialect-aware NLP can benefit from model adaptations and not dataset replacement alone is a key point of the survey. (3) Evaluation datasets: NLP techniques evaluated on datasets in dialects have peculiar observations. Language identification classifiers produce lower performance when the text is in a dialect of a language. The performance of LLMs on dialectal datasets is positively correlated with socio-economic factors. Figure 3 shows an overview of the approaches in terms of NLP for dialects. There have been different approaches to create labeled datasets, tree-banks and lexicons. In terms of models, past work varies in terms of NLP tasks and the way dialectal adaptation is handled: dialect transformation (where data is translated between dialects for the purpose of processing), dialect invariance (where models are made invariant to dialects) and dialect awareness (where models include dialect-specific components). Finally, we also describe dialectal datasets and resultant evaluations on downstream tasks including applications such as health monitoring."
    },
    {
      "heading": "RESOURCES",
      "text": "Being a data-driven field, NLP techniques rely on resources such as lexicons and textual datasets. In this section, we describe ways in which dialectal datasets have been created. Languages Innovation Problem/Area English Chinese Arabic German Indic Languages Other Dataset Method/Model Evaluation/Metric Benchmark Dialect Classification Sentiment Analysis Machine Translation Morphology/Parsing Conversational AI Summarisation Speech/Visual [Nerbonne and Heeringa 1997] ✓ ✓ ✓ [Nerbonne and Heeringa 2001] ✓ ✓ ✓ [Chiang et al. 2006] ✓ ✓ ✓ [Habash and Rambow 2006] ✓ ✓ ✓ [Chitturi and Hansen 2008] ✓ ✓ ✓ [Paul et al. 2011] ✓ ✓ ✓ ✓ ✓ ✓ [Lui and Cook 2013] ✓ ✓ ✓ [Abdul-Mageed and Diab 2014] ✓ ✓ ✓ [Cotterell and Callison-Burch 2014] ✓ ✓ ✓ [Darwish et al. 2014] ✓ ✓ ✓ [Doğruöz and Nakov 2014] and Hussein 2020] ✓ ✓ ✓ [Al-Ghadhban and Al-Twairesh 2020] ✓ ✓ ✓ [Alshareef and Siddiqui 2020] ✓ ✓ ✓ [Demszky et al. 2020] ✓ ✓ ✓ ✓ [Dunn and Adams 2020] ✓ ✓ ✓ ✓ ✓ [Hanani and Naser 2020] ✓ ✓ ✓ [Hou and Huang 2020] Table 2. State of NLP research on Dialects."
    },
    {
      "heading": "Dialectal Lexicons",
      "text": "Dialectal lexicons correspond to word lists or word mappings about a dialect. Although lexicons were popular in early approaches of NLP, a recent paper by Artemova and Plank [2023] highlights the potential of dialectal lexicons and describes an approach to create such lexicons using large language models. Prior to this, research in the creation of dialectal lexicons lies in three categories: the use of online dictionaries, and the use of textual corpora."
    },
    {
      "heading": "Dialectal Datasets",
      "text": "Datasets based on different data sources (such as social media, and conversation transcripts) and dialects have been reported. In terms of procuring and labeling these datasets, the following methods have been used: 4.2.1 Recruit native speakers of specific language varieties. Estival et al. [2014] create a dataset of audio-visual recordings of 1000 speakers of Australian English. The dataset is accompanied by a transcript, which was manually created for 100 speakers. Bouamor et al. [2018] present MADAR: a manually curated parallel corpus of sentences in Arabic dialects along with English, French and Modern Standard Arabic. 4 Similarly, Riley et al. [2023] create a parallel corpus of English sentences and two dialects each of Portuguese and Chinese with the help of native speakers of these dialects. Eisenstein et al. [2023] introduce MD-3 a dataset of conversations between speakers playing the game of taboo. The dataset consists of speech recordings as well as text transcripts. Seddah et al. [2020] focus on treebank creation for Algerian supplemented with monolingual data obtained from CommonCrawl. They highlight the inherent difficulty of finding annotators and the cost of the same indicating the challenges for dialectal data generation. Riabi et al. [2023] further extend this with additonal layers of morpho-syntactic knowledge and correct errors in the same. 4.2.2 Perturbation. Ziems et al. [2022] evaluate natural language understanding for African-American English. They design rules to perturb the dataset from Standard American English to African-American English. They then get them validated by native speakers. Ziems et al. [2023] present Multi-VALUE, a suite of resources to evaluate fairness of LLMs by creating dialectal variations of a dataset. The suite provides mechanisms to generate 50 dialects of English by applying a set of perturbations. Messner and Lippincott [2024] present a dataset of 19th century American literary orthovariant tokens with a novel layer of human-annotated dialect group tags, to examine language modelling assumptions, and find evidence that choice of tokenization scheme meaningfully impact the type of orthographic information in a language model. 4.2.3 Keywords. Wang et al. [2017] create a dataset of Singaporean English sentences by searching for typical Singaporean English terms in online forums. Ramponi and Casula [2023a] take a complementary approach to create a dataset of tweets in dialects of Italian along with other languages spoken in Italy (which are not necessarily derived from Italian). They use location-based search to obtain the set of tweets from different regions of interest from within Italy. Following this, they use out-of-vocabulary words to identify words that are indicative of geographical regions and, as a result, dialects. A related dataset is GeoLingIt [Ramponi and Casula 2023b]. In the case of social media, hashtags can be used to obtain datasets in certain dialects. Kuparinen [2023] take advantage of dialect awareness week in Finland. They use a hashtag indicating usage of dialects in order to collect tweets in different dialects of Finnish. In the context of Arabic dialect tweets, Boujou et al. [2021] benchmark is a novel dataset of 50,000 tweets for five dialects of Arabic-Algerian, Lebanon, Morocco, Tunisian, and Egyptian. 4.2.4 Location. Data from particular geographics can be extracted using filters (where the location is known) or inference (where it is not known). Jurgens et al. [2017] use location-based filters available on Twitter at the time. They use language identification classifiers to predict the language and identify dialectal users. Husain et al. [2022] obtain tweets from Kuwait to create a dataset of tweets in the Kuwaiti dialect of Arabic. Coats [2022] create an unlabeled dataset of Youtube comments. They start with a list of councils in Australia, extract official Youtube channels and retrieve comments. They manually validate the correctness of the channels. When working with geographically dispersed dialects, sampling may also be used. Hovy and Purschke [2018] use Doc2Vec on a large corpus of anonymous online posts to learn document representation of cities, and recover dialect areas using geographic information via retrofitting and agglomerative clustering. Dunn and Adams [2020] create a Web-based corpus in different dialects by sampling sentences from different countries. The goal is to build a Web-based corpus where the number of instances is reflective of the population of speakers in a country. The paper states that such a geography-aware corpus can lead to geography-aware representations when language models are trained on them. A criticism to the location-based filtering mechanism is by Goutte et al. [2016]. 4.2.5 Dialect-aware annotation. One such example is by Sap et al. [2019]. They examine racial bias towards African-American English in the case of hate speech detection. They propose race and dialect priming in order to improve the quality of annotation. In order to prime the annotators, they propose to ask two questions: (a) is the tweet offensive to them?, and (b) is the tweet offensive to anyone? The dialect and race of the speaker are shown to the annotators. Shared Task Dialects/Languages [Zampieri et al. 2014] Brazilian Portuguese and European Portuguese; American and British English; and Argentinian Spanish and Castilian Spanish [Zampieri et al. 2015] American and British English; and Argentinian Spanish and Castilian Spanish [Malmasi et al. 2016] Dialects of English, Spanish, French and Arabic [Zampieri et al. 2019] Dialects of German, Chinese, Romanian [Gaman et al. 2020] Dialects of Romanian, Geolocation-based Varieties [Aepli et al. 2022] Dialects of French and Italian [Aepli et al. 2023] Dialects of Indo-European and Ural languages (and other tasks) [Abdul-Mageed et al. 2023] Dialects of Arabic Table 3. Shared tasks related to dialect identification. Several datasets exist for varieties of Arabic [Diab et al. 2010], including Palestinian Arabic [Dibas et al. 2022;Jarrar et al. 2017], Gulf Arabic [Khalifa et al. 2016], Egyptian Arabic [Maamouri et al. 2014], and Bahraini Arabic [Abdulrahim et al. 2022]. This is in stark contrast with the lack of availability of datasets for dialects of English or several other languages of the world."
    },
    {
      "heading": "NATURAL LANGUAGE UNDERSTANDING (NLU)",
      "text": "This section covers NLU approaches centered around dialects. This includes approaches for NLP tasks such as dialect identification, sentiment analysis, morphosyntactic analysis and parsing. We also describe approaches reported on NLU benchmarks, which cover multiple tasks."
    },
    {
      "heading": "Dialect Identification",
      "text": "The most commonly researched task in the scope of this paper is dialect identification. Dialect identification deals with the prediction of the dialect of an input text. Early approaches to dialect identification employed distance-based metrics, namely, Levenshtein, Manhattan, and Euclidean distance with different clustering techniques [Nerbonne andHeeringa 1997, 2002]. They indicate that feature representations are more sensitive, and that Manhattan distance and Euclidean distance are good measures of phonetic overlap. Elnagar et al. [2021] is a systematic review of identification of dialects of Arabic. For dialects of Arabic, lexical resources such as lexicons and treebanks, and models using SVM or sequential neural layers like BiLSTM have been reported. Jauhiainen et al. [2019] is a survey of automatic language identification. They describe that dialect detection may be more difficult than language detection since dialects may have lexical or syntactic overlap. In doing so, the survey does not make a distinction between languages and dialects -and treats different dialects as different class labels, while still maintaining a classification approach. However, one sees challenges in this regard. Boujou et al. [2021] present a baseline approach, which utilises classical machine learning. While the majority of past work defines dialect identification as a Boolean/multi-class classification, Baimukan et al. [2022] use a hierarchy of dialect labels based on geographical and linguistic proximity. We now describe details of past work in dialect identification in terms of shared tasks, datasets, and pre-deep learning and deep learning-based approaches. 5.1.1 Shared tasks. Shared tasks have accelerated past work in dialect identification. These have been primarily led by Workshop on NLP for Similar Languages, Varieties and Dialects, also known as VarDial. The shared tasks are listed in Table 3. Goutte et al. [2016] summarise the findings from the past versions of the shared task from 2014-2016. Similarly, the Nuanced Arabic Dialect identification (NADI) shared task is held annually. In the 2024 edition of NADI, a new task has been introduced to estimate the Arabic level of dialectness within Arabic sentences. 5.1.2 Datasets. Aji et al. [2022] report a dataset for several languages and dialects spoken in Indonesia. They observe that language identification works well for certain dialects (Ngoko-Central dialect of Javanese, for example). The paper also discusses code-mixing and orthography variations in these languages. Dunn [2019] reports dialect identification on 14 national varieties of English. He shows that cross-domain classification (CommonCrawl versus Twitter) also performs poorly. Cotterell and Callison-Burch [2014] present a multi-dialect, multi-genre corpus of news comments and tweets written in dialects of Arabic. The tweets are manually annotated for dialect identification on MTurk. Ramponi and Casula [2023a] present a benchmark dataset for dialects of Italian. The benchmark is named as DIATOPIT. There has been recent work on creating a corpus of Norwegian dialect [Barnes et al. 2021]. Also, Alshutayri and Atwell [2018] present a large (200K+ instances) corpus for Arabic dialects and Standard Arabic. The data is sourced largely from tweets but also includes comments from newspapers, and Facebook. The data is also being annotated for dialect identification and contains 24K annotated documents. Recently, Talafha et al. [2024] introduced CASABLANCA, a large scale community-driven effort to collect and transcribe a multi-dialectal Arabic dataset, covering eight dialects for Arabic releasing 48 hours of manually transcribed speech data including annotations for transcription, gender, dialect, and code-switching. Le and Luu [2023] present a parallel corpus for dialects of Vietnamese. Further, Dinh et al. [2024] propose a dialect identification, and speech recognition dataset, and fine-tuned models for for 63 provincial dialects of Vietnamese with 102.5 hours of audio, and 19000 spoken utterances."
    },
    {
      "heading": "5.1.3",
      "text": "Feature-based approaches. We now highlight features used for dialect identification. (1) Phonological features: Phonological features are based on markers in the written scripts. Darwish et al. [2014] use lexical along with a lexicon of dialectal Egyptian words, morphological and phonological features in a random forest classifier to detect dialects of Arabic spoken in a geographical region. (2) Linguistic features: Doğruöz and Nakov [2014] present a method to predict dialects of Turkish by using light verb constructions. They use a statistical classifier based on verb-based features (base word, verb order, affixes, etc.) for the task. Xie et al. [2024] discuss an approach to extract distinguishing lexical features of dialects by utilising interpretable dialect classifiers. With focus on varieties of Mandarin, Italian, and Low Saxon, this approach shows promising results on all varieties. The combinations of the above set of features have also been reported. While Hanani and Naser [2020] work on the detection of dialects from speech, they also use word-level n-gram features. Salameh et al. [2018] perform fine-grained dialect identification for 25 dialects of Arabic, using Naïve Bayes classifier and word and character n-grams as features. While dialect detection of Arabic has been explored in detail, the pre-deep learning work in the context of dialects of English is comparatively limited, although English is the predominant language for NLP research. Lui and Cook [2013] is an early work in the detection of dialects of English. Specifically, the paper focuses on Australian, British and Canadian English. Their baseline is the LangID classifier [Lui and Baldwin 2012] where dialects are treated as individual languages. They experiment with classifiers using features such as n-grams and POS-n-grams. This includes a distribution over function words and those in a vocabulary, akin to a clustering algorithm. Simaki et al. [2017] use linguistic, POS-tag-based and lexicon-based features."
    },
    {
      "heading": "Deep learning-based Approaches.",
      "text": "Deep learning-based approaches for dialect classification span three alternatives: train embeddings to reflect dialectal variations, use end-to-end LLMs, or predict dialect as a result of inference over dialect features. Embeddings in focus: Abdul-Mageed et al. [2018] label tweets with 10 dialects of Arabic. The city is considered the dialectal granularity. The analysis compares dialectal variants by looking at word embeddings of words across different dialects. They use word2vec representations to show how dialectal words are captured. Goswami et al. [2020] build character-to-sentence embeddings to represent words of different dialects. Unsupervised loss is computed in order to generate clusters of representations. While they also test on language identification, the dialect identification part is done on Swiss German dialect. Jurgens et al. [2017] use a character-based seq2seq model to map dialects. The models used for language identification are RNNs with GRU. Criscuolo and Aluisio [2017] use character n-grams to identify language groups. This is followed by convolutional neural network-based dialect classifiers for each language group. Fine-tuning LLMs: Ramponi and Casula [2023a] experiment with multiple models including statistical and neural. The fine-tuned AlBERTo model performs the best among umBERTo, mBERT and XLM-R. Obeid et al. [2020] present CAMeL: a python toolkit for Arabic language processing. It contains a dialect identifier that gives a distribution over multiple dialects. They use dialectal guidelines provided in Elfardy and Diab [2012]. Detecting dialect features: ? introduce an approach for dialect classification using a novel multitask approach that employs dialect feature detection. They train two multi-task learning-based approaches using a small number of minimal pairs. They evaluate the output based on 22 dialectal features based on Indian English and demonstrate that such models show the capability of learning to identify features with high accuracy. They show the efficacy of this task by applying it to dialect identification, and by providing a measure of dialect density."
    },
    {
      "heading": "Sentiment Analysis",
      "text": "Sentiment analysis is the NLU task of prediction of sentiment polarity of a text. Sentiment analysis encompasses several related tasks, such as sarcasm classification and target-specific sentiment analysis. We discuss past work in sentiment analysis along four directions: experiences from annotation (which highlights the challenge of dialects for sentiment analysis), dialect-aware models, dialect-invariant models, and, finally, de-biasing of sentiment analysis models as a post-processing step. Table 4 summarises approaches for sentiment analysis. Early guessing for dialects: A recent advancement in dialect identification is early guessing [Kanjirangat et al. 2022]. The approach detects a dialect for an incremental input. Salloum and Habash [2022] also break the input down into its components. Specifically, they present an unsupervised approach that uses unsupervised dialect segmentation for machine translation."
    },
    {
      "heading": "Datasets & Annotation.",
      "text": "Several datasets in Arabic sentiment analysis for dialects have been reported such as Moroccan [Oussous et al. 2020] and Levantine [Baly et al. 2019]. Dialects can have an impact on annotation itself. Farha and Magdy [2022] show that dialect familiarity helps sarcasm annotation. Mdhaffar et al. [2017] create a dataset of 17000 Facebook comments labeled with sentiment in Tunisian dialect of Arabic. Assiri et al. [2018] present a sentiment-labeled lexicon of words in the Saudi dialect of Arabic, and use simple counting-based sentiment analysis. Husain et al. [2022] use weakly supervised labels for sentiment analysis of tweets in the Kuwaiti dialect of Arabic. The labels are then manually validated and updated. 5.2.2 Dialect-aware representations. Given the high degree of similarity between dialects, there is a high likelihood for models to make inferences in the same way for different dialects and thus explicitly modeling dialect awareness into models is important. However, this same degree of similarity makes this dialect aware modeling challenging. Farha and Magdy [2022] train BERT-based models for sarcasm detection on data annotated by either of the two groups: those familiar with the dialect and those not. They show that familiarity of dialect improves the quality of the models trained on such a dataset. As a result, representations that capture dialects have been used for sentiment analysis. Mdhaffar et al. [2017] present models based on SVM and multi-layer perceptron (MLP). Mulki et al. [2019] use a syntax-ignorant n-gram composition to create embeddings. The classifier model is a dense neural network that works on the addition of word embeddings, with a softmax at the end. Guellil et al. [2021] propose 'one' model for sentiment classification in different dialects of Arabic. They use transliteration to map dialects to Standard Arabic. The sentiment analysis model itself uses word2vec features with statistical classifier. Finally, Husain et al. [2022] present statistical models based on SVM along with Transformers-based models like BERT. 5.2.3 Incorporating dialect information in sentiment prediction. El Mekki et al. [2021] use domain adaptation for sentiment analysis of dialects. Using representations from a BERT encoder, they use two classifiers: sentiment classifier and dialect classifier. The output of the two is later combined for the overall prediction. While this is a two-channel approach, the representation used for the task has also been used to predict dialect of the language. One such example is Okpala et al. [2022] who present an approach for hate speech detection using African-American English. In order to do so, they re-train BERT with AAE tweets. Finally, adversarial training is needed to regulate the debiasing of the hate speech classifier. Specifically, the adversary takes the final representation learned by the hate-speech classifier, and learns to predict the dialect from it. Kaseb and Farouk [2022] present a dialect-aware approach for sarcasm detection called the SAIDS model. SAIDS uses MARBERT to detect dialect and sarcasm. Following that, MARBERT, along with sarcasm and dialect output, are used to detect sentiment. Evaluated on Arabic dialects, SAIDS uses backpropagation only for prediction with respect to the BERT base model. It does not flow through sentiment<->sarcasm or sentiment<->dialect."
    },
    {
      "heading": "5.2.4",
      "text": "De-biasing sentiment analysis models. Making sentiment analysis agnostic to dialects involves removing dialectal biases in the resultant models. A work of this nature is by Ball-Burack et al. [2021] who apply adversarial debiasing to resampled data for harmful tweet detection of tweets written in African-American English. Resampling of the data uses a metric for margin of confidence which selects the set of tweets that are most likely to be mis-classified. Adversarial debiasing involves training an adversary network to debias the classifier by including the adversary network's loss. Similarly, Mozafari et al. [2020] report results on hate speech detection from African-American and Standard American tweets. They re-weight instances based on the presence of phrases that may highlight racial bias. They fine-tune BERT for the task. Finally, Zhang et al. [2021] present an approach to reduce spurious correlation between two attributes: toxicity and African-American Vernacular English. They construct triplets of sentences where the first two have the same toxicity label, and the first and the third have the same dialect label. The objective function of the model consists of a triplet loss over these triplets, and a disentanglement loss that ensures the masks for the true attributes are well-separated. Similarly, graphical models have been used to infer sociocultural norms since they are closely associated with dialectal variations based on the language and cultural background of the speaker. Moghimifar et al. [2023] present a Markov model to discover socio-cultural norms in emotion classification. Harris et al. [2024] evaluate the zero-shot performance of speech recognition systems across different genders and across four US-based English dialects: SAE, AAVE, Chicano English, and Spanglish, release a labeled dataset of 13 hours of podcast audio, transcribed by speakers of the represented dialects.While past research has only dealt with African-American English, there may indeed be other dialects, which are considered aggressive and may result in sentiment analyzers producing biased output. This is significantly Table 5. Approaches for Morphological Analysis Focusing on Dialects. Highlight-> Approach or Key Finding. underexplored for dialects of other languages such as the Khariboli (Haryanvi group) dialect of Hindi [Yadav 1974]."
    },
    {
      "heading": "Morphosyntactic analysis",
      "text": "Morphosyntactic analysis deals with linguistic tasks such as POS tagging and morphological analysis, and has been found to be useful for sense disambiguation, particularly in low-resource settings [Khalifa et al. 2020]. We now describe past work that deals with dialectal variations, as summarised in Table 5. 5.3.1 Classical approaches. Habash and Rambow [2006] is a seminal morphological analyser for dialects of Arabic called MAGEAD. Using morphological rewrite rules, they show how a morphological analyser can be adapted for dialects of a language. Jørgensen et al. [2015] evaluate on a dataset of African-American Vernacular English and show that the then-prevalent POS taggers perform significantly worse. Darwish et al. [2018] present a CRF-based POS tagger for dialects of Arabic. The POS tagger is trained on a small set of tweets using features derived from the dialects of interest. These features are progressive and negation particles. Eskander et al. [2016] adapt existing morphological analyzers to unseen dialects of Arabic by simulating the low-resource dialects. 5.3.2 Deep learning-based approaches. Inoue et al. [2022] use CamelBERT trained on Modern Standard Arabic fine-tuned on dialect-specific datasets for morphosyntactic analysis. They observe that training using high-resource dialects helps low-resource dialects as well. In the context of Indic languages, Bafna et al. [2023] explore POS tagging for 5 Indic dialects by focusing on Hindiaware LLM adaptation via small dialectal monolingual corpora. Aepli and Sennrich [2022] propose improving cross-lingual transfer between closely related language varieties from the Finnic, West and North Germanic, and Western Romance language branches using character-level noise injection, and go on to show consistent improvements for POS tagging. Their approach is further applied to seven languages from three families and a total of eighteen dialects [Blaschke et al. 2023] with results showing improvements by varying the level of noise injected during the cross-lingual transfer."
    },
    {
      "heading": "Parsing",
      "text": "Parsing involves the creation of syntactic parse trees from text. Past work in parsing texts written in dialects of a language lies in three categories. The first category uses an existing parser on a dataset in a dialect of interest. The focus of such work is to create a baseline performance of popular parsers. The second category provides approaches to adapt existing parsers towards texts in the dialect of a language. The third category creates a new parser for the dialect. 5.4.1 Use of existing parsers. Eggleston and O'Connor [2022] parse tweets in Standard American English and African-American English and use it to analyse social attributes of an entity, as per sentiment expressed in the tweets. Kåsen et al. [2022] create a tree bank of sentences in the Bokmål variety of Norwegian dialects. They present their results on the UUParser, an existing parser for Norwegian. Roy et al. [2020] present an analysis using Stanford parser and Allen NLP parser on parsing of news headlines in Indian English. Scannell [2020] create a treebank for Manx Gaelic and compare the performance of existing classifiers with Irish Gaelic and Scottish Gaelic. 5.4.2 Adaptation of an existing parser. Chiang et al. [2006] show how parsing of Arabic dialects can be done by a sentence transduction approach. This approach parses the standardised version of a dialectal sentence, and then links it to the original sentence. The standardisation is achieved using transduction, akin to n-gram decoding. However, Blodgett et al. [2018] use neural networks and present an approach to dependency parsing for African-American English. This approach uses two neural parsers, which are modified with the word embeddings used for initialisation. The word embeddings are trained on the standard and the dialect-specific datasets. Further, Wang et al. [2017] create a dependency parser for Singaporean English. This approach uses a base parser for standard English and stacks it with a series of BiLSTM layers known as the 'feature stack' to extract relevant features, and an MLP with an output layer to help produce dependency-parsed output. Zhao et al. [2020] use a treebank of learner English sentences labeled with POS tags and dependency information. They propose a factorisation-based parser that first predicts nodes followed by edges in a dependency parse. Dou et al. [2023] evaluates various parsers designed for converting text to SQL, focusing on a multilingual benchmark that covers dialects from seven different languages. This research is significant for its emphasis on semantic parsing, differing from the aforementioned dependency parsing works."
    },
    {
      "heading": "Paper",
      "text": "Dialects Approach [Ziems et al. 2022] African-American English Perturbation to create variants [Dacon et al. 2022] African-American English Adversarial learning [Held et al. 2023] Dialects of English Contrastive loss, Morphosyntactic loss [Xiao et al. 2023] Dialects of English Hypernetworks as LoRA adapters Table 6. Dialect-aware approaches evaluated on NLU benchmarks."
    },
    {
      "heading": "Development of a new parser.",
      "text": ": Vaillant [2008] propose a rule-based approach to construct a common syntactic description for a group of Creoles from Haiti, Guadeloupe, Martinique and French Guiana. Bowers et al. [2017] present a finite-state machine-based parser for the endangered Odawa dialect of Ojibwe spoken in Canada and northeastern United States. This approach uses a phonological module composed of a morphological module where morphological strings are modified by the phonology until they match surface forms of the language."
    },
    {
      "heading": "NLU Benchmarks",
      "text": "Finally, benchmarks such as GLUE, which provide datasets for NLP tasks like semantic textual similarity prediction (STS-B), sentiment classification (using the Stanford sentiment treebank (SST-2)), natural language inference (NLI), textual entailment and so on, are an important part of language model evaluation pipeline. Ziems et al. [2022] show a drop in performance on 7 GLUE tasks including SST-2, STS-B, when tested on dialectal English variations of the original Standard American English version. For example, for SST-2, there is a 1.5-2% drop using fine-tuned RoBERTa. Dacon et al. [2022] work with African-American English. They first propose CodeSwitch, a rulebased method of perturbing a sentence from Standard American English (SAE) to African-American English (AAE). They create perturbed versions of the dataset using CodeSwitch and manually evaluate it. They finally evaluate their method on NLI. In order to do so, they use adversarial learning that ensures that the predicted label is the same if either the SAE or AAE sentences are provided as the input. They refer to this as a disentanglement of language style. Tan et al. [2020] present base-inflection encoding: a mechanism to inject dialectal information into the encoder. They show that their encoding algorithm improves the performance of Vernacular African-American English for SQUAD and MNLI tasks. Held et al. [2023] model natural language understanding for dialects as a dialect adaptation task. Using Multi-VALUE, they create African-American English variations of the GLUE benchmark (which is primarily written in Standard American English). Following that, they adapt a model pre-trained on Standard American English. To do so, they use: (a) a contrastive loss to ensure the representation of a standard sentence and its dialectal version is as close as possible; (b) a morphosyntactic loss based on word-level alignment between the standard and dialectal sentences. Their results show improved robustness on 4 dialects based on the GLUE benchmark. Vidal-Gorène et al. [2024] provide a benchmark on lemmatization, POS-tagging, and morphological analysis for four Armenian varieties-Classical, Modern Eastern, Modern Western, and the under-documented Getashen dialect. They compare traditional RNN models, multilingual encoders, and large language models using supervised, transfer learning, and zero/few-shot learning approaches, and show how RNNs are strong at POS tagging, but LLMs handle unseen dialectal variations. A recent work by Xiao et al. [2023] shows how low-rank adapters Low-Rank Adapters (LoRA) (a parameter-efficient fine-tuning or PEFT technique that allows fine-tuning LLMs faster by storing weight updates instead of updating all weights) can use linguistic knowledge of dialects to improve zero-shot performance on NLU tasks. They integrate hypernetworks with LoRA adapters for dialect adaptation. Experts encode linguistic information in the form of feature vectors. A hypernetwork then learns to generate adapter weights for LoRA from the feature vectors. They demonstrate the impact of their fine-tuning approach on several GLUE tasks such as MNLI, RTE and so on. The dataset consists of variants of the GLUE benchmark for five dialects: African American Vernacular English (AAVE), Indian English (IndE), Nigerian English (NgE), Colloquial Singaporean English (CollSgE), and Chicano English (ChcE). Similarly, Liu et al. [2023] use dynamic aggregation of linguistic rules to adapt LLMs to multiple dialects. They first create a synthetic dataset of linguistic transformations using LLM probing. Following that, they train a set of feature adapters to generalise across multiple dialects of interest. They present their evaluation of multiple dialects of English. DIALECTBENCH [Faisal et al. 2024] is a large-scale benchmark covering 10 NLP tasks focusing on 281 language varieties. Their evaluation shows substantial disparities in performance between the standard and non-standard language varieties, while also identifying language clusters with large performance divergence across tasks. Most recently, the VarDial 2024 evaluation campaign [Chifu et al. 2024] released dataset on the choice of plausible alternatives (COPA) task focusing on three micro-dialects namely, Cerkno dialect of Slovenian, Chakavian dialect of Croatian, and the Torlak dialect which is spoken across Serbia, Macedonia, and Bulgaria. This task requires a computational model to select one of two candidate statements which is more likely to be the cause or effect of a given premise statement. Collectively, training and test datasets from VarDial evaluation campaigns (2014 -2024) organised over the years should act as a good benchmark for LLM evaluation of dialects."
    },
    {
      "heading": "Others",
      "text": "Erdmann et al. [2018] investigate how word embeddings trained on dialect-specific or mixed-dialect corpora perform. In their experiments for text in dialects of Arabic, they show how dialect-specific embeddings can be helpful for dictionary induction. Dictionary induction here refers to alignment tables between dialects of a language. Demszky et al. [2021] report models that predict dialect features using minimal pairs that represent linguistic properties of dialects. They do so for Indian English."
    },
    {
      "heading": "NATURAL LANGUAGE GENERATION (NLG)",
      "text": "The previous section showed that NLU for dialects has primarily focused on tasks like identification of dialects and sentiment analysis. We now present approaches in NLG. NLG deals with sequence-tosequence (seq2seq) tasks in NLP, which take a sequence as input and produce a sequence. Challenges in the presence of dialects in a generation task can differ significantly given the task. The data and evaluation methods can be different for tasks, especially where dialectal text is being generated. Some examples of such problems are summarisation, question answering and machine translation, and are described in Table 7. While the situation in the case of NLU was already dire, our survey indicates that for NLG, it is even worse. We will now discuss NLP approaches that deal with dialects of a language in the context of seq2seq problems. Two works reflect advances in the context of seq2seq problems: (1) Making evaluation metrics dialect-aware: Sun et al. [2023] state that metrics used to measure text generation may penalise outputs in certain dialects. They propose a metric named NANO, which allows perturbations in the generated output. They show that models pretrained with NANO as the metric can be helpful for dialect-robustness. (2) Creating dialectal variants of datasets for benchmarking: Ziems et al. [2023]  created rules. They create variants of benchmark datasets, and evaluate the variants for several seq2seq tasks including machine translation, question answering and so on. The models for evaluation are based on modern LLMs such as BERT, ROBERTA, BART and T5. The library provides a useful resource as well as insights for dialect-aware benchmarking in the future."
    },
    {
      "heading": "Summarisation",
      "text": "Past work in summarisation, although limited, states that dialect labels may not be explicitly necessary. However, a review of Arabic text summarisation by Elsaid et al. [2022] state the use of \"dialect period frameworks\" to incorporate semantic information about dialects. In the case of multi-document summarisation, clustering of sentences in the input set is a predominant paradigm. Two such works are noteworthy: (1) Olabisi et al. [2022] analyse the diversity of dialects in multi-document summarisation of social media posts. They present a dataset that contains summaries of a collection of tweets written in three dialects: African-American English, Hispanic English, and White English. They use extractive summarisation using LONGFORMER-EXT and abstractive summarisation using BART and T5. In order to bring diversity-awareness in summarisation, they create automatic clusters of input documents based on semantic attributes. They follow a 2-stage approach where the summarisers are separately applied, and the resultant outputs are combined again using a summariser. (2) Keswani and Celis [2021] examine the role of dialect diversity on multi-tweet summarisation. They use a variety of summarisers: typical traditional summarisers like TF-IDF, TextRank and LexRank, and SummaRunner (a neural summariser that treats summarisation as a sequence classifiation task). They create a control set: a subset of sentences that represent different dialects in the set of sentences. They introduce a bias mitigation procedure that introduces dialect-awareness in summaries using a parameter that is weighted to increase the score of dialect-diverse sentences in the dialect set."
    },
    {
      "heading": "Machine Translation",
      "text": "Compared to summarisation, machine translation has been studied a bit more. Recent work is broadly divided into two categories: (i) translation between dialects of the same language, and (ii) translation between the dialect of a language and another language. In the rest of this section, we cover the approaches in these categories. 6.2.1 MT between dialects of the same language. The primary goal of inter-dialect translation is the dissemination of information available between a standard dialect and a non-standard one. In this context, the following works are relevant. Mapping from less used dialects to their most common versions is called dialect normalisation. One such work by Kuparinen et al. [2023] provides a dialect normalisation dataset in Swiss German, Slovene, Finnish, and Norwegian. Bouamor et al. [2014] present a multi-dialectal dataset for various dialects of Arabic. Harnessing pre-trained models: Le and Luu [2023] show that models based on 𝐵𝐴𝑅𝑇 𝑝ℎ𝑜 perform well for dialect normalisation in dialects of Vietnamese. This indicates that denoising-based pretrained models can be a good source for dialect data generation owing to their infilling capabilities. Character level modeling: Abe et al. [2018] conduct Japanese dialect translation where they use NMT to translate from dialect to standard Japanese using character RNN trained on small datasets collected as a part of their work. Honnet et al. [2018] additionally suggest that normalisation is an important aspect for translating between Swiss German dialects, which is achievable via character-level models. Kuparinen et al. [2023] further show that sliding-window-based approaches are useful since dialect translation does not need the entire sentence-level context. Perturbation-based regularisation: Liu et al. [2022] present a seq2seq approach for machine translation of Singaporean English to standard English. They use word perturbation and sentence perturbation to prevent overfitting of lexical features. Maurya et al. [2023] used a similar approach for Indian dialects. Harnessing Linguistic Features: Erdmann et al. [2017] focus on translation among Arabic dialects in a low-resource setting where they supplement small parallel corpora with morphosyntactic information injected into the model for machine translation. In general, incorporating linguistic features into the MT framework is known to significantly boost translation quality in lowresource settings [Chakrabarty et al. [n. d.], 2020]. Especially, pre-training by leveraging linguistic features, as done by Chakrabarty et al. [[n. d.]], should be beneficial for dialectal translation, which is typically a low-resource problem. Code-mixed training: Lu et al. [2022] use XLM for Translation between Hokkien-Mandarin code-mixed text. They observe that continuous training with code-mixed data enables monolingual language models to provide better performance when applied to code-mixed tasks. Data Creation for MT between dialects: Zbib et al. [2012] and Meftouh et al. [2015] also focus on multi-dialect MT data collection for Arabic, which is, once again, to be noted as one of the most studied languages for dialects. Xu et al. [2015] use a Hidden Markov-based model to create word alignment between dialects of Chinese: Mainland Chinese, Hong Kong Chinese, and Taiwan Chinese. The outcome is a monolingual corpus that contains corresponding words used in the User-generated content: User-generated content (UGC) is often mistranslated on social media, especially, for low-resource languages like dialectal Arabic. Saadany et al. [2022] train a Transformer to translate from dialectal Arabic to English where they focus on challenges in translation of UGC, and propose a sentiment-aware evaluation metric for translation. They discuss results on multiple test sets, including a hand-crafted test set, and analyse the performance for a semi-supervised approach compared to a baseline NMT system, a pivoting-based system, and Google Translate. Use of multiple translation models: Translation models that translate between the standard version and a dialect can assist machine translation. Kumar et al. [2021] show an approach for MT from English to Ukrainian, Belarusian, Nynorsk, and Arabic dialects. They use two models: a dialect-to-standard translation model, and a standard source-to-target language translation model. Data creation for MT of dialect to another language: Hassan et al. [2017] explore synthetic data creation using word pairs between dialects based on embeddings. They take seed data, transform it into its dialectal variant and now have a dialectal parallel corpus. Similarly, Almansor and Al-Ani [2017] focus on using monolingual data and tiny parallel corpora in conjunction with cross-dialectal embeddings to improve MT between dialects. Sajjad et al. [2020] take dialect MT evaluation further and focus on multi-domain coarse-grained analysis of dialects of Arabic via their AraBench benchmark. Hamed et al. [2022] propose an Arabic-English code-switched speech translation dataset, which represents a practical use case since a vast majority of dialects are often spoken. There is a significant dearth of code-mixed datasets and recommend researchers to focus on the same. Alkheder et al. [2023], recognising the increasing usage of Arabic in several regions of Turkey, expand the MADAR corpus [Obeid et al. 2018] to enable benchmarking of translation between Arabic and Turkish. Contarino [2021] curates LEXB, a parallel corpus between South Tyrolean German and Italian containing nearly 175, 000 parallel segments from the legal domain. To curate parallel data, they use the LexBrowser database 5 and 20 national laws and codes (Civil Code, Criminal Code) translated into German. Igarashi and Miyagawa [2024] curate parallel corpus for Ainu⇐⇒Japanese where text for Ainu was curated from after post-processing OCR ouput for books, and other online resources. Ainu is a critically endangered family of dialects from from Northern Japan without any native writing script. 6.2.3 Dialect MT in Shared Tasks. Given that most dialects are spoken and not written, the IWSLT workshop, which focuses on spoken language translation, has been conducting shared tasks on dialects under the banner of low-resource MT. The 2022 6 and 2023 7 workshops featured dialectal speech translation, with resources for text-text as well as speech-text translation. The focus, as is typically the case, is on dialects of Arabic like Tunisian, Egyptian and Moroccan. The shared tasks are an excellent source of datasets and benchmarks for dialectal MT. Most recently, the ArabicNLP 2023 8 conference offered a shared task 9 on translation from 4 Arabic dialect to modern standard Arabic. Over the years, NADI has reported progress on country and province-level dialect identification, dialectal sentiment analysis, and dialect to MSA machine translation [Abdul-Mageed et al. 2023, 2020, 2021, 2022]. We should also note that the Workshop on Machine Translation (WMT 10 ) and the Workshop on Asian Translation (WAT 11 ) often feature shared tasks on closely related languages. The 2024 12 edition of IWSLT is expected to focus on North Levantine Arabic. 5 http://lexbrowser.provinz.bz.it/; Accessed on 20th November, 2024. 6 https://iwslt.org/2022/dialect; Accessed on 9th January, 2024. 7 https://iwslt.org/2023/low-resource; Accessed on 9th January, 2024. 8 https://arabicnlp2023.sigarab.org/; Accessed on 20th November, 2024. 9 https://nadi.dlnlp.ai/; Accessed on 20th November, 2024. 10 https://www2.statmt.org/wmt24; Accessed on 20th November, 2024. 11 https://lotus.kuee.kyoto-u.ac.jp/WAT/WAT2024/index.html 12 https://iwslt.org/2024/low-resource; Accessed on 9th January, 2024. Natural Language Processing for Dialects of a Language: A Survey 1:23"
    },
    {
      "heading": "Dialogue Systems",
      "text": "Dialogue systems, crucial in facilitating human-computer interaction, are categorised into taskoriented, chit-chat, and hybrid systems. These systems, especially when dialect-aware, face the added challenge of understanding and adapting to linguistic variations. Task-oriented dialogue system: Task-oriented systems are designed to accomplish specific tasks. They integrate NLU, a dialogue manager, and NLG components. The effectiveness of these systems in handling dialects is pivotal. For instance, Elmadany et al. [2018a]; Joukhadar et al. [2019] study the classification of dialogue acts in Arabic dialect utterances, demonstrating the system's capacity to adapt to dialectal variations. Al-Ghadhban and Al-Twairesh use the Artificial Intelligence Markup Language (AIML) to build a chatbot that assists students with academic enquiries in the Saudi Arabian dialect. The VarDial 2023 campaign [Aepli et al. 2023] reports progress on slot and intent detection for low-resource language varieties such as Swiss German, Neapolitan, South Tyrolean. Artemova et al. [2024] investigate the robustness of task-oriented dialogue systems, specifically their intent classification and slot detection components, to German dialects by applying perturbations that transform standard German sentences into colloquial variants. Chit-chat dialogue system: Chit-chat dialogue systems, also known as open-domain systems, primarily focus on daily chat and handle broader interactions. Ali and Habash [2016] employ AIML and rule-based systems to manage dialectal variation in Egyptian Arabic, incorporating features like short vowels and consonantal doubling. Ahmed and Hussein [2020] also use AIML for Kurdish dialogues. Additionally, Alshareef and Siddiqui [2020] train a Seq2Seq model on a tweet corpus to respond to open-domain Arabic questions. A specialised subset of chit-chat systems are socially-aware dialogue systems, which pay close attention to the influence of social norms and factors. These systems are designed to adhere to the cultural and social norms prevalent in different societies [Hovy and Yang 2021]. In different cultures, social norms will no doubt incorporate sociolect, including whatever discourse force it may carry. Ziems et al. [2023] propose a framework to evaluate dialect differences in cross-dialectal English. In addition, Zhan et al. [2024Zhan et al. [ , 2023] ] propose the socially-aware dialogue corpus based on Chinese culture and relevant dialectal norms. Sociolect in a dialogue will dramatically affect human's understanding and behaviours towards speakers. Rajai and Ennasser [2022] summarise existing problems and strategies towards dealing with sociolect in dialogues. Hybrid system: Hybrid systems combine features of both task-oriented and open-domain systems. An example is the system developed by Ben Elhaj Mabrouk et al. [2021], which answers user queries in various Arabic dialects like Tunisian, Igbo, Yoruba, and Hausa. This chatbot addresses both official FAQs, especially related to COVID-19, and informal chit-chat, responding to questions in the local dialect. Awareness of social and societal norms of behaviour is particularly important in dialogue systems that serve specific transactional goals, be it to book a doctor's appointment, to ask questions about income tax or to make a customer service complaint. Research in interactional sociolinguistics [Gumperz 1982] has, in a rich body of research in different social contexts such as employment interviews [Roberts 2021], shown that people interpret communicative intent against their own background expectations of what is 'normal' or 'expected behaviour'. This has the potential to exacerbate inequality (for example, by restricting access to employment), in particular, for underrepresented groups such as migrants. In the case of dialogue systems, a lack of representation of different dialects (e.g., due to the lack of diverse training data) has the potential to cause similar effects: If dialogue systems are not aware of social norms inherent to different dialects, and if what is communicated does not match users' expectations, communicative intent can be misinterpreted, and underrepresented user groups might become disengaged from the system. The xSID dataset [Van Der Goot et al. 2021] is a multilingual dataset for spoken language understanding, and includes a low-resource Austro-Bavarian German dialect and other dialects. Indeed, previous research on dialogue systems has confirmed the importance of alignment of system-style choices with user needs and preferences [Chaves et al. 2022;Følstad and Brandtzaeg 2020;Li and Mao 2015]."
    },
    {
      "heading": "CONCLUSION & FUTURE DIRECTIONS",
      "text": "Dialects are syntactic and lexical variations of a language, often associated with socially or geographically cohesive groups. This paper summarises NLP approaches for dialects of several languages. The need for NLP approaches focusing on dialects of a language rest on four motivations: dialects pose linguistic challenges, benchmarks may not have sufficient dialectal representation, dialectawareness is important for fair NLP technology, and there has been growing recent work in this direction. The survey identified trends in terms of tasks (which shows shifting focus from dialect classification), languages (with more work in Arabic as compared to other languages), and a shifting trend towards mitigation (by either making models dialect-invariant or dialect-aware). Following that, we described different methods to create dialectal lexicons and datasets, ranging from location/keyword-based filtering (of which location-based filtering has been found to be ineffective by Goutte et al. [2016]) to manual (via recruitment of native speakers) and automatic (via automatic perturbation). We then viewed past work in the context of NLU and NLG. For NLU, we covered dialect identification, sentiment analysis, morphosyntactic analysis, parsing and more recent work in NLU benchmarks. We described how the availability of datasets in multiple languages has fuelled research in dialect identification, which continues to date. Sentiment analysis techniques for dialects included peculiar de-biasing approaches, in addition to dialect invariance and dialect awareness. Approaches to parse dialectal datasets used or adapted existing parsers or developed dialect-specific parsers. Finally, we described how recent work on NLU benchmarks highlight how adversarial learning and LoRA can be used to reduce the degradation in the performance of dialectal datasets as compared to the standard ones. In the case of NLG, we described work in summarisation, machine translation and dialogue systems. We described the limited, recent work in multi-document summarisation of dialectal documents. Following that, we discussed approaches for machine translation in the context of dialect normalisation and dialect pivoting depending on whether the translation is between dialects of a language or between dialects and another language. Finally, we described dialogue systems in the context of task-oriented, chit-chat and hybrid systems. Based on our survey, we now identify future directions and social/ethical implications. We hope that the former will be helpful for NLP research for dialects, while the latter will get more researchers interested in this richly investigated yet emergent area of NLP. We believe that NLP researchers should adopt a socio-technical perspective [Johnson and Verdicchio 2017] on their role and consider not only their own possible biases influencing the selection of training data, the design of algorithms etc. but also other social arrangements (e.g., users and their behaviours) relevant to specific systems. In their survey of speakers of German dialects, Blaschke et al. [2024] also discuss in detail their needs as users of language technologies."
    },
    {
      "heading": "Implications to NLP research",
      "text": "In addition to the trends reported earlier in the paper, the following would be potential future directions in the context of NLP. 7.1.1 Focusing on unexplored dialects of languages. : NLP for dialects face problems akin to lowresource languages, in terms of the availability of existing resources and tools. While some dialect families, such as English and Arabic, have seen consistent efforts, dialects for other languages need more focused large-scale efforts for data curation and annotation. While English is arguably the leading language for advances in NLP, efforts remain to be done to fully represent the full diversity of the English language itself through appropriate datasets and models that are curated for specific dialectal tasks. It is not always necessary to create new datasets, given that datasets specific to particular dialects are available. However, caution is advised for dialogue systems as many existing corpora -with the exception of those focusing on English as a lingua franca (ELF) -are dominated by written texts, which may not represent the richness of dialectal variations of spoken language. 7.1.2 Rethinking the pre-training of LLMs. : Chow and Bond [2022] present a computational grammar for Singaporean English. Such dialectal representations can be useful to generalise the ability of LLMs. It would be beneficial for LLMs to be able to ingest other kinds of information such as dialect-specific grammatical structures. Ability to pre-train LLMs using data in different formats (not just modality, which is currently a popular paradigm) may improve their performance for diverse datasets such as dialects. Similar impact of pre-training language data distribution is known for cross-lingual meaning transfer within NLP tasks [Qian et al. 2024;Zerva et al. 2024] involving low-resource languages [Nigatu et al. 2024]. 7.1.3 Dialect identification as an auxiliary task. : Multi-task learning is used to train models for multiple tasks. Dialect identification could be used as one of the tasks in order to train equitable models. Lent et al. [2024] present a multi-task, multi-lingual dataset of Creole languages. They report the baseline performance of NLU and MT tasks on the dataset using appropriate models. Availability of such large benchmarks will aid the development of new methods and models. 7.1.4 Rethinking LLM Evaluation. : Xiao et al. [2023] evaluate LoRA adapters for unseen English dialects, and they say: \"a comprehensive examination of PEFT modules for dialects is needed, which we leave for future work.\". Similar evaluations can be performed for other NLP approaches. In addition, new evaluation techniques and metrics will be useful to measure dialectal variation and its potential correlation with the performance of NLP tasks. Two recent papers can be of value. Lameli and Schönberg [2023] present a measure for spatial language variation. Using distance between locations as a heuristic for dialectal similarity, they examine variations in dialects of German. Also, Keleg et al. [2023] use a dataset in Arabic labeled with the degree of dialectness, to train a BERT-based regression model."
    },
    {
      "heading": "Ethical & Social Implications",
      "text": "Overall, dialectal NLP presents an excellent avenue for research with huge social implications. We highlight three considerations of relevance. 7.2.1 Social Implications. While everyone speaks a standard dialect, most people tend to feel familiarity with people who speak specific dialects. Furthermore, certain traditions and practices are tied to localities, which are, in turn, tied to dialects. If the goal of NLP research is to make communication seamless then the correct way to do so is via a strong emphasis on dialects, by effectively engaging with speakers of the dialects [Blaschke et al. 2024]. Most dialects around the world are under-represented in modern-day NLP, which can potentially disadvantage them or leave them out of the benefits of LLMs.. There is also a growing concern among speakers of specific dialects that their language is dying either due to the pervasiveness of English via the internet, another majority language, or a related dialect, which has higher official support or recognition. We should acknowledge these concerns and make headway into preserving as many dialects as possible, at the risk of losing valuable aspects of the vast tapestry of culture and history."
    },
    {
      "heading": "Dialectal",
      "text": "Research By Dialect Speakers. Linguistic research colonisation is the process where researchers who do not speak specific languages nor have connections with them conduct research on said languages. Despite the negative connotation of colonization, this is not a bad thing, because no one should monopolise working on specific languages. However, it highlights that there are haves and have-nots, where the haves are researchers and organisations with funding who can work on dialects and the have-nots are the researchers who would like to work on dialects but simply lack funding. Recently, there has been a growing trend where language speakers are reclaiming dominion over research involving their own languages. For example, there has been an explosive growth in the number of researchers and groups like DeepLearning Indaba, Masakhane from African countries working solely on African languages and organisations like AI4Bharat in working on Indian languages. Indeed, they have shown that a dedicated focus on language research by speakers of these languages leads to better NLP systems. We, therefore, propose that the organisations with funding leverage their privilege and support those without funding so as to ensure that work on dialects is led and owned by groups that are most connected to and impacted by dialects. This will lead to true diversity, equality and inclusivity in NLP research, which will strongly impact society. Towards this, the emerging sentiment in recent thematic papers in NLP is that communities that speak the dialects must be involved in the development of language technologies for the communities [Bird 2022;Ramponi 2024]. 7.2.3 Normalising Working on and Speaking Dialects. One aspect that limits dialectal research is the concept of shame in speaking a certain language or a dialect, an aspect also known as linguistic self-hatred. For example, take the case of Mauritian Creole, whose speakers are dwindling by the day, mainly because the younger generation feels shame in speaking their native language. The same exists for Konkani. While there are no official reports highlighting the same for dialects, it is not far-fetched to consider that linguistic self-hatred will exist here as well. It is time to end this self-hatred and normalise speaking dialects. By doing so, people speaking dialects will become more enthusiastic about preserving their dialects and this will inevitably aid research on dialects, thereby positively impacting society. Dialects are closely tied to culture and such differences have not been captured explicitly beyond the works described in this paper."
    }
  ]
}