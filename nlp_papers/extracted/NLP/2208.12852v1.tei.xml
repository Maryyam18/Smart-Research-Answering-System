<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">WHAT DO NLP RESEARCHERS BELIEVE? RESULTS OF THE NLP COMMUNITY METASURVEY</title>
				<funder ref="#_K2SpRWG #_vJAdzVd #_464SUFj">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder ref="#_rbxFCpT">
					<orgName type="full">Apple</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-08-26">26 Aug 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School for Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Paul G</orgName>
								<orgName type="institution" key="instit1">Allen School for Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alicia</forename><surname>Parrish</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><surname>Mueller</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Angelica</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Divyam</forename><surname>Madaan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">WHAT DO NLP RESEARCHERS BELIEVE? RESULTS OF THE NLP COMMUNITY METASURVEY</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-08-26">26 Aug 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">C31C48E7FBB4FDB070BE18CB565A0AFB</idno>
					<idno type="arXiv">arXiv:2208.12852v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-28T12:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the results of the NLP Community Metasurvey. Run from May to June 2022, the survey elicited opinions on controversial issues, including industry influence in the field, concerns about AGI, and ethics. Our results put concrete numbers to several controversies: For example, respondents are split almost exactly in half on questions about the importance of artificial general intelligence, whether language models understand language, and the necessity of linguistic structure and inductive bias for solving NLP problems. In addition, the survey posed metaquestions, asking respondents to predict the distribution of survey responses. This allows us not only to gain insight on the spectrum of beliefs held by NLP researchers, but also to uncover false sociological beliefs where the community's predictions don't match reality. We find such mismatches on a wide range of issues. Among other results, the community greatly overestimates its own belief in the usefulness of benchmarks and the potential for scaling to solve real-world problems, while underestimating its own belief in the importance of linguistic structure, inductive bias, and interdisciplinary science.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>What do NLP researchers think about NLP?</p><p>• Are we devoting too many resources to scaling up?</p><p>• Do language models understand language? Will they ever?</p><p>• Is the traditional paradigm of model benchmarking still tenable?</p><p>• What kinds of predictive models are ethical for researchers to build and release?</p><p>• Will the next most influential advances come from industry or academic labs? These questions and many more are actively debated in the research community, and views on them are a major factor in deciding what work gets done. Understanding the prevalence of different views on these issues is valuable for understanding the trajectory of NLP research and the structure of the field. In addition, communication among researchers often rests on sociological beliefs about these questions: what people think people think. Getting these sociological beliefs wrong can slow down communication and lead to wasted effort, missed opportunities, and needless fights. For example:</p><p>• An early-career researcher may avoid researching a topic they think is important if they think that it is not valued by the community and it would be hard to get past review.</p><p>• Extra time and effort may be spent in papers and research agendas defending what is thought to be a provocative position, when it is in fact already well established and widely believed.</p><p>• Papers or public communications generally appeal to premises they believe are settled or accepted as general consensus, but if the premise is not actually settled, then the argument will not be convincing to a large portion of the community, and the discourse may become more fractured, with increasingly isolated groups of researchers forming echo chambers around different sets of assumptions.</p><p>The NLP research community gets to know itself in a variety of ways: discussions with colleagues at the same institution, presentations and interactions at conferences, invited talks and panel discussions, and interactions on social media like Twitter. All of these sources of information are biased, for example through self-selection towards similar people and amplification of already-prominent or controversial voices. These effects can make it difficult for any individual to get a sense of the NLP research community's beliefs as a whole.</p><p>For these reasons, we believe it is worth trying to objectively assess NLP researchers' collective stance on controversial issues. So from May to June 2022, we conducted the NLP Community Metasurvey. On each issue, we present a stance, such as Currently, the field focuses too much on scaling up machine learning models (Q5-1), and ask respondents to state whether they agree or disagree. Then we ask them to also predict the percentage of respondents who will agree. This gives us insight into the community's object-level beliefs as well as its sociological beliefs, and allows us to identify where the two may be misaligned.</p><p>This work is directly inspired by the PhilPapers Surveys <ref type="bibr" target="#b39">(Bourget &amp; Chalmers, 2014;</ref><ref type="bibr" target="#b56">2020)</ref>, a research effort created and maintained by philosophers to assess the philosophy community's beliefs about current topics in their field, along with a separate metasurvey to assess philosophers' sociological beliefs about their professional community. As Bourget &amp; Chalmers write:</p><p>Most of us have had the experience of reading philosophical papers that make sweeping sociological claims about the field that seem quite questionable. It is arguable that the "received wisdom" in a field (roughly, what people in a field take as a default view, one that can sometimes be presupposed) is not based on what most people in the field think, but rather is based on what most people think most people think. If the received wisdom is grounded in false sociological beliefs, that is worth knowing. It occurred to us that it would not be all that difficult to actually gather data about these matters, and that doing so might be an interesting and informative exercise.</p><p>The rest of this document reports the methodology and results of the NLP Community Metasurvey. Some key results include:</p><p>• A large majority of respondents are against the hypothesis that scaling up current systems and methods could solve "practically any important problem" in NLP, and this view is perceived as much more popular than it is ( §4.2, Q2-1). Yet, narrow majorities of respondents also regard recent progress in large-scale modeling as progress towards AGI, and think AGI should concern NLP researchers ( §4.3, Q3-1, Q3-2). • A majority of respondents think that the scientific value of the majority of work in NLP is dubious ( §4.1, Q1-5). • A large majority of respondents believe that NLP researchers should give higher priority to incorporating insights from neighboring fields, and greatly underestimate the number of other NLP researchers that share this belief ( §4.5, Q5-7). • Large majorities of respondents believe NLP research has had a positive impact on the world ( §4.6, Q6-1), will have a positive impact in the future (Q6-2), and could plausibly transform society ( §4. <ref type="bibr">3, Q3-3)</ref>. Despite this optimism, a substantial minority also foresee plausible risks of a major global catastrophe caused by ML systems (Q3-4). • A plurality of respondents think the most influential area of advances in the next 10 years will be in problem formulation and task design, as opposed to hardware and data scaling, which respondents believed would be the most popular opinion ( §4.7).</p><p>It is worth noting that our results are descriptive, not prescriptive, as these issues cannot be resolved by majority vote. By necessity, we are covering a subjectively chosen set of questions and reducing many complex issues into simplified scales, but we hope that these results can create common ground for fruitful discussion among the NLP research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head><p>Choosing Questions We aimed to ask about issues:</p><p>• which are frequently discussed in the community,</p><p>• which are the subject of public disagreement,</p><p>• about which the NLP community often reflects back on itself, especially where people seem to perceive themselves as in the minority (hot takes) or majority (taking something for granted), and • for which, if we understand the community's opinions and meta-opinions better, it may aid our ability to communicate and help people understand how to most effectively communicate about their research.</p><p>With these criteria in mind, we (the authors) brainstormed a large initial list of potential questions. After discussing, we voted on which ones to include in the survey, chose roughly the top 30 questions, finalized the agree/disagree question format, and began pilot testing (described in Appendix C), which we used to refine the set of questions, their phrasing, and their presentation format in the survey. The questions used in the survey are shown in Figure <ref type="figure">2</ref>.</p><p>Target Demographic: Active Authors in ACL Since we are interested in the public and scientific discourse of the NLP community, we target the survey at active NLP researchers. As an objective criterion, we define the target population of the survey as anyone who is an author on at least two *CL papers published in the last three years. This definition allows us to assess response bias by comparing to ACL members ( §3) and provides an objectively defined reference group for survey respondents to make predictions about in the meta-questions.</p><p>Question Format We present questions in thematic groupings (e.g., "State of the Field"), phrased as statements that people could indicate their (dis)agreement with. They can respond to each statement on a 4-point scale of AGREE, WEAKLY AGREE, WEAKLY DISAGREE, and DISAGREE. We choose not to include an option in the middle of the scale to indicate a neutral position because our intent is to push respondents to consider where they actually stand. We instruct respondents to choose WEAKLY AGREE or WEAKLY DISAGREE if they have even slight preferences for one side or the other (e.g., "depends, leaning negative"). However, it is sometimes the case that someone truly cannot make a judgment, and for these cases we include three OTHER answers: QUESTION IS ILL-POSED, INSUFFICIENTLY INFORMED ON THE ISSUE, and PREFER NOT TO SAY.</p><p>At the end of each section of the survey, we ask respondents to predict the proportion of respondents in our target population who will either AGREE or WEAKLY AGREE with each statement. Respondents can answer with one of five buckets: 0-20%, 20-40%, 40-60%, 60-80%, or 80-100%.</p><p>Respondents can also skip the meta-questions, but we encourage them to give their best guess even if they are not sure. Finally, each section has a free-response box for the respondent to provide any comments, criticism, or other feedback on the survey.</p><p>The survey instructions are reproduced in full in Appendix D.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Platform and Distribution</head><p>To host the survey, we used NYU Qualtrics. Following the guidelines set out by the NYU Institutional Review Board (protocol FY2022-6461), all respondents gave informed consent before beginning the survey and could either refuse to answer (i.e., by responding PREFER NOT TO SAY) or skip each question.</p><p>As an incentive for participation, we committed to donating $10 for each respondent to one of several non-profit organizations that the respondent chooses at the end of the survey.</p><p>1 Region of Residence 0% 10% 20% 30% 40% 50% 60% 70% 80% Percent of Population United States Europe Asia / Pacific Middle East / North Africa Canada Source America / Caribbean Sub-Saharan Africa Prefer not to say 35% 58% 29% 23% 26% 8% 4% 5% 4% 2% 2% 1% 0.5% 0.3% 2% Gender 0% 10% 20% 30% 40% 50% 60% 70% 80% Percent of Population Man Woman Non-binary Other / Prefer not to say 70% 67% 24% 25% 3% 6% 6% Survey Respondents ACL Statistics Figure 1: Basic demographics of survey respondents, compared to available statistics from the ACL.</p><p>For region, we compare to ACL memberships as of summer 2021, and for gender, we use the diversity statistics currently available from the ACL, based on attendance at ACL 2017 in Vancouver (which lacked a specific "non-binary" category).</p><p>To attempt to reach a broad audience of NLP researchers, we set up a homepage for the survey at <ref type="url" target="https://nlpsurvey.net">https://nlpsurvey.net</ref> and advertised in the following ways: (a) ACL Member Portal: we sent a call for participation to the ACL membership mailing list. The email included the details of the survey, its purpose, and the charitable donation incentive. (b) ACL 2022 in Dublin: Four of our team members advertised the survey to conference attendees in-person. They distributed flyers/posters of our survey and free stickers that said "NLP survey" or "I took the NLP survey." (c) Twitter: We released multiple tweets as advertisement, with the original being retweeted 100+ times. (d) Slack channels: We posted about the survey in the Slack channels of a few labs, as well as an NLP Slack channel with more than 470 members that was set up during ACL 2020. (e) Emails: We attempted to encourage more participants from senior authors by sending personal invitations to 568 authors that have published at least eight qualifying papers since 2019 (we did not exhaustively email all of them, as it required manually sourcing email addresses based on names in the ACL Anthology).</p><p>(f) Other social media (including posting on WeChat to encourage participation from researchers in China) and personal interactions with NLP researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DEMOGRAPHICS</head><p>480 people completed the survey, of which 327 (68%) are in our target demographic, reporting that they co-authored at least 2 ACL publications between 2019-2022. We compute that 6323 people met this requirement during the survey period according to publication data in the ACL Anthology, meaning we have survey responses from about 5% of the total. For the rest of this paper, we restrict all reported results to this subset.</p><p>Full question text and results for all demographics are available in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BASIC DEMOGRAPHICS</head><p>Figure <ref type="figure">1</ref> shows location and gender statistics. Survey respondents are mostly men (67%) and mostly from the United States (58%). To get a sense of biases in our results, we compare to official statistics from the ACL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Location</head><p>The ACL publishes statistics about the countries of origin of its members. While ACL members are not the same population as our target demographic, we can use them as a rough proxy to assess for geographic bias. Comparing to the most recent available statistics<ref type="foot" target="#foot_2">foot_2</ref> suggests that the United States is heavily overrepresented in our respondent population (58% &gt; 35%), while Asia/Pacific is underrepresented (8% &lt; 26%). Asian countries with large ACL contingents were particularly underrepresented, including China (3% &lt; 9%), India (1% &lt; 5%), and Japan (0.8% &lt; 5%). We suspect this may largely be due to biases in our survey distribution methods (particularly Twitter and our personal networks).</p><p>Gender For gender, we compare to ACL-published diversity statistics, computed from the attendee population at ACL 2017 in Vancouver, Canada. <ref type="foot" target="#foot_3">3</ref> While our gender distribution is skewed, with 67% men and 25% women, it seems to roughly match the ACL population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Underrepresented Minorities</head><p>We ask respondents if they consider themselves to be part of an underrepresented minority group in NLP, to which 26% report Yes, 63% report No, and 11% Prefer not to say.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CAREER</head><p>Job Sector 73% of respondents are from academia, with 22% from industry and 4% in non-profit or government jobs. Asked if their job is "publication-oriented," 89% answer Yes, including 62% of respondents in industry, while 9% answer No.</p><p>Seniority Faculty and senior managers form a plurality of respondents at 41%, while 23% are junior professionals (including postdocs), 33% are PhD students, and 2% are Masters students or undergraduates. Breaking these down by sector, the largest group was academic PhD students (32%), <ref type="foot" target="#foot_4">4</ref>followed by faculty (29%), senior managers (10%), postdocs or other academic researchers (10%), and junior researchers in industry (10%).</p><p>Since ACL publishes statistics on the number of student memberships and regular memberships, we can also compare these numbers to the ACL population: 35% of respondents are students, compared to 53% of ACL members as of summer 2021. While students are underrepresented in our results compared to ACL members as a whole, it is not clear whether they are underrepresented compared to our target demographic of recently published authors.</p><p>We also ask respondents to report the year they published their first research work in NLP. 20% of respondents reported a year prior to 2009, with the earliest being 1985. Another 20% were in <ref type="bibr">2010-2014, 20% in 2015-2017, 20% in 2018-2019, and 10% in 2019-2022</ref>, with the rest declining to answer. See Appendix B, Figure <ref type="figure" target="#fig_0">13</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subfields</head><p>We ask respondents to report all subfields that fit their work from the last 3 years, providing a list derived from the tracks at recent *CL conferences <ref type="bibr">(EMNLP 2021</ref><ref type="bibr">, ACL 2022</ref><ref type="bibr">, and NAACL 2022)</ref>. The most common responses are machine learning for NLP (39%), interpretability and analysis (31%), generation (28%), resources and evaluation (27%), and machine translation and multilinguality (26%). Coverage of the given subfields is broad, with each being marked by at least 20 respondents (6%). Full results are in Appendix B, Figure <ref type="figure" target="#fig_3">16</ref>.</p><p>Research Activity Respondents are highly active at ACL events, with 96% saying they have attended an ACL event in the last 3 years. Asked about their total number of peer-reviewed publications related to NLP, 13% report 1-4, 47% report 5-20, and 39% report 21 or more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">OTHER INFORMATION</head><p>Twitter Use A large majority of respondents use Twitter, with 18% saying I routinely post, 58% saying I follow but don't often post, and 21% saying I don't have a Twitter account, rarely look at it, or don't use it for research or NLP related content. While we don't know what proportion Figure <ref type="figure">2</ref>: All survey questions with agree/disagree answers. Only the full statements (not the bolded summaries) were shown to respondents. Besides these, the survey also asked for an opinion on likely sources of future advances in NLP ( §4.7) as well as respondent demographics ( §3, Appendix B).</p><p>of our target demographic uses Twitter, it seems likely that this is one of the largest sources of bias in our respondent population. At the same time, the purpose of this survey is partly to study NLP researchers' perceptions of the NLP community for the purpose of improving the public and scientific discourse. To the extent that these perceptions are formed on Twitter, and the public discourse is carried out on Twitter, our results may be useful even if biased towards Twitter users.</p><p>Finding the Survey Asked how they heard about the survey, 37% reported hearing about it through Twitter, 21% from the email we sent through the ACL Member Portal, 19% from another mailing list, a Slack channel, or other messaging forum, 15% through word of mouth or personal communication, and 3% through an advertisement at ACL 2022, where we put up flyers and passed out stickers. Again, this suggests that our results are likely skewed towards Twitter users.</p><p>Meta-Question Confidence We ask respondents to report their confidence in their meta-question predictions. 5% report being Completely confident, 32% Fairly confident, 34% Somewhat confident, 13% Slightly confident, 13% Not at all confident, and 2% Prefer not to say. Between these groups, the Completely confident had the highest mean absolute error on their meta-question predictions (20.9%), though this was only significantly (p &lt; 0.05) different from the Slightly confident group (18.5%), which performed best, despite abstaining from predictions in fewer cases (5%) than the completely confident group (11%). We considered removing meta-question answers from less confident respondents for the purpose of reporting results, but since there are few statistically significant differences and the less confident respondents actually performed better, we include all meta-question responses in the rest of this work for the sake of simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>For reference, all survey questions which took agree/disagree responses are shown in Figure <ref type="figure">2</ref>. In the rest of this section, we will discuss the results of each section of the survey in detail.</p><p>For each question (for example, in Figure <ref type="figure" target="#fig_0">3</ref>), we display the proportion of AGREE, WEAKLY AGREE, WEAKLY DISAGREE, and DISAGREE answers in a band along the bottom of the visualization. These percentages exclude those who gave one of the other answers (INSUFFICIENTLY INFORMED ON THE ISSUE, QUESTION IS ILL-POSED, or PREFER NOT TO SAY), which were relatively rare (&lt;20% of responses for all questions, &lt;10% for 75% of questions; see Appendix A). The vertical green line shows the total percentage who AGREE or WEAKLY AGREE with the statement, which was the value we asked survey respondents to predict in the meta-questions. The gray bars show the distribution of answers to the meta-questions, each bin aligned with its corresponding range of percentages (0%-20%, 20%-40%, etc.). The green and black dots and bars show the mean and 95% bootstrap confidence intervals of the true and predicted percentage of people who AGREE or WEAKLY AGREE (treating each meta-question answer bucket as its midpoint).</p><p>Unless otherwise stated, all percentages and percentage differences mentioned in this section will be in absolute terms and exclude the 'other' answers, and when we refer to respondents "agreeing" with a statement (without special typesetting) we include both AGREE and WEAKLY AGREE answers (and respectively with DISAGREE and WEAKLY DISAGREE). In this discussion we will sometimes break down results by demographic group (e.g., comparing the agreement rates of men and women); unless otherwise stated, all such comparisons correspond to statistically significant differences between the groups (p &lt; 0.05) by a bootstrap test. More information, visualizations, and confidence intervals for such comparison can be found online at <ref type="url" target="https://nlpsurvey.net/results/">https://nlpsurvey.net/results/</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">STATE OF THE FIELD (FIGURE 3)</head><p>The first set of questions asks for opinions about the health of the NLP community.</p><p>Industry's Undue Influence (Q1-1, Q1-2) Private firms are overwhelmingly seen as likely to produce the most-cited research of the next 10 years (Q1-2, 82%), but they are also seen as having too much influence (Q1-1, 74%). This suggests, as some respondents pointed out in the survey feedback, that many believe that number of citations is not a good proxy for value or importance. It also suggests a belief that industry's continued dominance will have a negative effect on the field,</p><p>61% 0% 20% 40% 60% 80% 100% 77% 1-1. Private firms have too much influence Private firms have too much influence in guiding the trajectory of the field. 64% 0% 20% 40% 60% 80% 100% 86% 1-2. Industry will produce the most widely-cited research The most widely-cited papers of the next 10 years are more likely to come out of industry than academia. 38% 0% 20% 40% 60% 80% 100% 30% 1-3. NLP winter is coming (10 years) I expect an "NLP winter" to come within the next 10 years, in which funding and job opportunities in NLP R&amp;D fall by at least 50% from their peak. 51% 0% 20% 40% 60% 80% 100% 62% 1-4. NLP winter is coming (30 years) I expect an "NLP winter" to come within the next 30 years, in which funding and job opportunities in NLP R&amp;D fall by at least 50% from their peak. 48% 0% 20% 40% 60% 80% 100% 67% 1-5. Most of NLP is dubious science A majority of the research being published in NLP is of dubious scientific value. 51% 0% 20% 40% 60% 80% 100% 63% 1-6. Author anonymity is worth it Author anonymity during review is valuable enough to warrant restrictions on the dissemination of research that is under review. Agree Weakly agree Weakly disagree Disagree Here, and in subsequent such figures, the lower number (in green) represents the fraction of respondents who agree with the position out of all those who took a side. The grey bars show the relative proportion of meta-question predictions in each bin (0-20%, 20-40%, etc.), and the upper number (in black) shows the average predicted rate of agreement, computed treating each bin as its midpoint. The green and black horizontal lines show 95% bootstrap confidence intervals.</p><p>perhaps through their singular control of foundational systems such as GPT-3 <ref type="bibr" target="#b42">(Brown et al., 2020)</ref> and PaLM <ref type="bibr">(Chowdhery et al., 2022)</ref>, or from the energy that widely-cited work in pretraining <ref type="bibr" target="#b45">(Devlin et al., 2019;</ref><ref type="bibr" target="#b65">Radford et al., 2019)</ref> draws away from other research agendas. Respondents underpredict the popularity of the majority view by more than 15% on both of these questions, suggesting they might believe alternative agendas are already under-prioritized, such as directions focusing on incorporating interdisciplinary insights as opposed to raw scaling, or problem formulation and task design-other under-predicted views, as we will see in §4.2, §4.5, and §4.7).</p><p>The under-prediction of agreement on Q1-1 and Q1-2 may also be an artifact of our sample population, which is overwhelmingly academic. Opinions are very different between job sectors, where 82% in academia agree that private firms have too much influence (Q1-1) compared to only 58% of respondents in industry.</p><p>NLP Winter, Eventually (Q1-3, Q1-4) We ask respondents whether they expect there to be an "NLP winter," where funding and job opportunities fall by at least 50% from their peak, in the near future. A substantial minority of 30% expect this to happen within the next 10 years (Q1-3), with only 7% AGREEing. For the next 30 years (Q1-4), confidence is much greater, with 62% expecting an NLP winter. Even a minority predicting such a major shift in the field reflects an overall belief that NLP research will undergo substantial changes in the near future (at least, in who is funding it and how much). Further interpretation of these results is difficult: For example, respondents may believe an NLP winter will arrive because the pace of innovation will stall (perhaps the reason they think industry research is overemphasized), because the ability to advance the state of the art will be monopolized by a small number of well-resourced industry labs (as they expect industry to continue producing widely-cited research), or because the distinction between NLP and other AI disciplines will disappear (as suggested by some respondents).</p><p>47% 0% 20% 40% 60% 80% 100% 17% 2-1. Scaling solves practically any important problem Given resources (i.e., compute and data) that could come to exist this century, scaled-up implementations of established existing techniques will be sufficient to practically solve any important real-world problem or application in NLP. 38% 0% 20% 40% 60% 80% 100% 50% 2-2. Linguistic structure is necessary Discrete general-purpose representations of language structure grounded in linguistic theory (involving, e.g., word sense, syntax, or semantic graphs) will be necessary to practically solve some important real-world problems or applications in NLP. 37% 0% 20% 40% 60% 80% 100% 51% 2-3. Expert inductive biases are necessary Expert-designed strong inductive biases (à la universal grammar, symbolic systems, or cognitively-inspired computational primitives) will be necessary to practically solve some important real-world problems or applications in NLP. 42% 0% 20% 40% 60% 80% 100% 61% 2-4. Ling/CogSci will contribute to the most-cited models It is likely that at least one of the five most-cited systems in 2030 will take clear inspiration from specific, non-trivial results from the last 50 years of research into linguistics or cognitive science. Agree Weakly agree Weakly disagree Disagree Dubious Science (Q1-5) A majority agrees that most NLP work is of "dubious scientific value" (67%). Respondents expressed uncertainty over what should count as "dubious," as well as concerns about who determines the value of research. On one hand, such research could refer to work which is fundamentally unsound with ill-posed questions and meaningless results, which would be a powerful indictment of NLP research. On the other hand, it could simply mean that many reported findings are of little importance or are not robust, which would arguably not make NLP unique among sciences <ref type="bibr" target="#b54">(Ioannidis, 2005)</ref>. Either way, this result suggests that many NLP researchers think it is worth reflecting deeply on the value of our work. As respondents see the community being less critical than it actually is (by 19% absolute), it might be that those who are critical of the scientific standards of the field are not as likely to voice their views in public, or that vocal critics who exist are seen as less representative of the population than they actually are.</p><p>Anonymity: Still Controversial (Q1-6) *CL conferences have much stricter anonymity policies than many other conferences NLP researchers submit to (e.g., NeurIPS, ICLR, and ICML). Responses suggest the community is in favor of these policies on balance (63% agree anonymity is important enough to warrant restrictions on disseminating preprints), though they are perceived as contentious: respondents guessed that around 51% of the target population would be in favor of such restrictive policies. Since the *CL anonymity policies have been subject to intense debate on platforms such as Twitter, this suggests that those critical of the policies may have been disproportionately represented in the minds of NLP researchers. This question was also split by gender, with 77% of women agreeing but only 58% of men-possibly due to concerns or experience with discrimination on the basis of author identity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SCALE, INDUCTIVE BIAS, AND ADJACENT FIELDS (FIGURE 4)</head><p>Questions and meta-questions about the long-term potential of scale, inductive bias, and linguistic structure reveal some of the most striking mismatches between respondent attitudes and beliefs about those attitudes. Broadly speaking, the pro-scale and anti-structure views were much less popular than respondents thought they would be.</p><p>A common refrain in the era of ever-larger models is the Bitter Lesson <ref type="bibr" target="#b70">(Sutton, 2019)</ref>: "General methods that leverage computation are ultimately the most effective, and by a large margin." Under this perspective, one may expect benefits from incorporating linguistic structure or expert-designed inductive biases to be superseded by learning mechanisms operating on fewer, more general principles if they have enough training data and model capacity. While the success of deep learning and large language models may be taken as supporting evidence for the Bitter Lesson, we find that the community has bought into the Lesson far less than it thinks it has.</p><p>56% 0% 20% 40% 60% 80% 100% 58% 3-1. AGI is an important concern Understanding the potential development of artificial general intelligence (AGI) and the benefits/risks associated with it should be a significant priority for NLP researchers. 57% 0% 20% 40% 60% 80% 100% 57% 3-2. Recent progress is moving us towards AGI Recent developments in large-scale ML modeling (such as in language modeling and reinforcement learning) are significant steps toward the development of AGI. 57% 0% 20% 40% 60% 80% 100% 73% 3-3. AI could soon lead to revolutionary societal change In this century, labor automation caused by advances in AI/ML could plausibly lead to economic restructuring and societal changes on at least the scale of the Industrial Revolution. 37% 0% 20% 40% 60% 80% 100% 36% 3-4. AI decisions could cause nuclear-level catastrophe It is plausible that decisions made by AI or machine learning systems could cause a catastrophe this century that is at least as bad as an all-out nuclear war. Agree Weakly agree Weakly disagree Disagree Support for scaling maximalism is greatly overestimated (Q2-1) We ask respondents for their views on a strong version of the Bitter Lesson: whether scaling up compute and data resources with established existing techniques would be sufficient to practically solve any important problem in NLP (Q2-1). Overall, this is seen as a controversial issue, with respondents predicting a roughly even split of 47% agreement (though variance among predictions was high). However, only a small minority (17%) actually agree with the position, forming the largest discrepancy between predicted and actual opinions in the entire survey. This suggests that the popular discourse around recent developments in scaling up <ref type="bibr">(Chowdhery et al., 2022)</ref> may not be reflective of the views of the NLP research community as a whole.</p><p>Trend reversals are predicted for linguistic theory and inductive bias (Q2-2, Q2-3, Q2-4) The rest of the views articulated in this section were seen as less popular than Q2-1, but in reality they were much more popular (albeit still controversial). On what it will take to practically solve any important problem in NLP, 50% agree that explicit linguistic structure will be necessary (Q2-2), and 51% say the same for expert-designed inductive biases (Q2-3). In addition, 61% of respondents say it's likely that one of the five most-cited systems in 2030 will take inspiration from clear, non-trivial results from the last 50 years of linguistics or cognitive science research (Q2-4). All of these views are under-predicted by 12-19%, though the predictions more closely match the responses given by men, as responses to these questions were split by gender. Most notably, women are significantly more likely to agree with Q2-2 that linguistic structure is necessary (65%) compared to men (42%).</p><p>Women also agreed with Q2-3 (62%) and Q2-4 (69%) more than men (49% and 57%, respectively), but these differences were not statistically significant.</p><p>Like many respondents, we find these results surprising. It seems that many believe there will be a reversal of the current trend of end-to-end modeling with low-bias neural network architectures.</p><p>The results for Q2-4 are particularly surprising to us, as even today's most cited systems seem not to satisfy this requirement, building on little more from cognitive science than a rough construal of neurons, attention, and tokens, which date back much further than 50 years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">AGI AND MAJOR RISKS (FIGURE 5)</head><p>The versatility and impressive language output of large pretrained models such as GPT-3 <ref type="bibr" target="#b42">(Brown et al., 2020)</ref> and PaLM <ref type="bibr">(Chowdhery et al., 2022)</ref> have prompted renewed discussions about artificial general intelligence (AGI), including predictions of when it might arrive, whether we are actually advancing toward it, and what its consequences would be. In this section, we ask about AGI and some of the largest possible impacts of AI technology.</p><p>One concern is that respondents' answers may depend on their definition of "artificial general intelligence," and whether they think it is well-defined at all. Our approach to this problem is to deliberately not provide a definition (which some respondents would surely find objectionable, no matter which definition we choose). Instead, we instruct respondents to answer according to their preferred definition, i.e., how they think the community should use the term, as we view this as an important issue to assess when figuring out how to talk about the issue as a community.</p><p>AGI is a known controversy (Q3-1, Q3-2) On the questions explicitly about AGI, respondents were split near the middle, with 58% agreeing that AGI should be an important concern for NLP researchers (Q3-1) and 57% agreeing that recent research has advanced us toward AGI in some significant way (Q3-2). The two views are highly correlated, with 74% of those who think AGI is important also agreeing with Q3-2 that we're progressing towards it, while only 37% of people who don't think AGI is important think we're making that kind of progress. The meta-responses split similarly to the object-level responses, indicating that the community has a good sense that this is a controversial issue.</p><p>It is worth acknowledging what this means: AGI is a controversial issue, the community in aggregate knows that it's a controversial issue, and now (courtesy of this survey) we can know that we know that it's controversial. While some may believe that AGI is obviously coming soon, and some may believe that it's obviously ill-defined, taking either position for granted in the public discourse or scholarly literature may not be an effective way to communicate to a broad NLP audience; rather, careful and considered discussion of the issue will be more productive for building common ground.</p><p>Revolutionary and catastrophic outcomes are a concern (Q3-3, Q3-4) 73% of respondents agree that labor automation from AI could plausibly lead to revolutionary societal change in this century, on at least the scale of the Industrial Revolution (Q3-3). This points to a common reason why those who agree with Q3-1 might think AGI is an important concern, especially if we are meaningfully progressing towards it (Q3-2), as it could be fundamentally transformative for society; indeed, all views expressed in this section are positively correlated (see §5). But it's worth noting that a significant fraction of respondents (23%) agree with the prospect of revolutionary change (Q3-3) while disagreeing with the importance of AGI, suggesting that discussions about long-term or large-scale impacts of our work in NLP may not need to be tied up in the AGI debate.</p><p>About a third (36%) of respondents agree that it is plausible that AI could produce catastrophic outcomes in this century, on the level of all-out nuclear war (Q3-4). While this is a much smaller proportion than those who expect revolutionary societal change (Q3-3), the stakes are extremely high and a substantial minority expressing concern about such outcomes indicates that a deeper discussion of such risks may be warranted in the NLP community. While we do not ask about specific ways in which respondents think this could happen, potential reasons for such concerns are discussed by <ref type="bibr" target="#b37">Bostrom (2014)</ref>; <ref type="bibr" target="#b31">Amodei et al. (2016)</ref> and <ref type="bibr" target="#b52">Hubinger et al. (2019)</ref>. Certain demographics, particularly women (46%) and underrepresented minority groups (53%), were more likely to agree with Q3-4, reflecting pessimism about our ability to manage dangerous future technology perhaps based in the present-day track record of disproportionate harms to these groups.</p><p>Q3-4 received a lot of critical feedback. Some respondents object to "all-out nuclear war" as far too strong, saying they would agree with less extreme phrasings of the question. This suggests that our result of 36% is an underestimate of respondents who are seriously concerned about negative impacts of AI systems. Some respondents also comment that AI/ML systems should not be discussed as if they have agency to make decisions, as all AI "decisions" can be traced back to human decisions regarding training data, architecture, how and on what phenomena models are evaluated (or not), and deployment decisions, among other factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">LANGUAGE UNDERSTANDING (FIGURE 6)</head><p>The question of whether language models understand language has been the subject of some debate in the community <ref type="bibr" target="#b33">(Bender &amp; Koller, 2020;</ref><ref type="bibr" target="#b57">Merrill et al., 2021;</ref><ref type="bibr">Bommasani et al., 2021, §2.6)</ref>. In this section, we ask some questions relevant to the issue, but one of the challenges is that their answers are highly dependent on how one defines the word "understand." For this reason, as with §4.3, we deliberately choose not to provide a definition, as doing so would risk begging the question or forcing a definition that some would certainly find objectionable. Instead, we instruct respondents to answer according to their preferred definitions, i.e., how they think the community should use the word "understand," as we view this as an important element of the discussion. Many respondents commented that this choice made it harder to respond to the questions in this section, and said</p><p>49% 0% 20% 40% 60% 80% 100% 51% 4-1. LMs understand language Some generative model trained only on text, given enough data and computational resources, could understand natural language in some non-trivial sense. 60% 0% 20% 40% 60% 80% 100% 67% 4-2. Multimodal models understand language Some multimodal generative model (e.g., one trained with access to images, sensor and actuator data, etc.), given enough data and computational resources, could understand natural language in some non-trivial sense. 47% 0% 20% 40% 60% 80% 100% 36%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4-3. Text-only evaluation can measure language understanding</head><p>We can, in principle, evaluate the degree to which a model understands natural language by tracking its performance on text-only classification or language generation benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agree</head><p>Weakly agree Weakly disagree Disagree they would have preferred a set definition, but only 3-5% responded to any of these questions with QUESTION IS ILL-POSED.</p><p>LMs understanding language is a known controversy (Q4-1, Q4-2) The question of whether language models can understand language (Q3-1) was split right down the middle, with 51% agreeing. This controversy is reflected in people's predictions as well, which average to an estimate of 49% agreement. Many more people (67%) agree once the model has access to multimodal data (images, etc.). As with the importance of AGI ( §4.3), whether language models understand language is known to be controversial, and the results of this survey can make it known that it is known. So whatever one's views are on the issue, it will likely be less useful to take those views for granted as a premise when communicating to a broad NLP audience in the public discourse or scholarly literature. Again, careful and considered discussion of the issue will likely be more productive for building common ground.</p><p>Understanding may be learnable, but not measurable, using text (Q4-3) On the question of whether text-only evaluations can measure language understanding (Q4-3), the distribution of predictions was similar to that for language understanding by LMs (Q4-1), averaging 47% predicted agreement. However, unlike Q4-1, only 36% actually agreed with the statement, suggesting that many view it as a separate issue, and that some may believe that there are things which are learnable from text alone, but cannot be measured using text alone.</p><p>Responses to questions in this section vary considerably with respondents' gender and location. On LMs understanding language (Q4-1), men are more likely to agree (58%) than women (37%), and people in the US are more likely to agree (61%) than those in Europe (31%). There is also a significant gender difference on Q4-3 regarding text-only evaluation of language understanding, where 43% of men agree as opposed to 21% of women.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">PROMISING RESEARCH PROGRAMS (FIGURE 7)</head><p>In this section, we ask respondents about the kind of research they think the community should be doing, and which research directions they believe are not heading in the right direction. We choose research agendas to ask about based on criticisms, debates, or findings in the literature and public sphere, for example regarding current practice in benchmarking <ref type="bibr" target="#b41">(Bowman &amp; Dahl, 2021;</ref><ref type="bibr" target="#b66">Raji et al., 2021)</ref>, the relative value of advances in model architectures <ref type="bibr" target="#b63">(Narang et al., 2021;</ref><ref type="bibr" target="#b71">Tay et al., 2022)</ref>, the use of language models for generation tasks <ref type="bibr" target="#b34">(Bender et al., 2021)</ref>, and explainability and interpretability of black-box models <ref type="bibr" target="#b47">(Feng et al., 2018;</ref><ref type="bibr" target="#b55">Jain &amp; Wallace, 2019;</ref><ref type="bibr" target="#b72">Wiegreffe &amp; Pinter, 2019)</ref>.</p><p>Scaling and benchmarking are seen as over-prioritized (Q5-1, Q5-2) Over 72% of respondents believe that the field focuses too much on scale (Q5-1), a view that was underestimated at 58%. This reflects the same pattern as Q2-1, where the prevalence of pro-scale views is overestimated. An even stronger majority of 88% believe there is too much focus on optimizing performance on benchmarks (Q5-2), a view that is highly correlated with Q5-1 (see §5) and is similarly under-predicted at 65%.</p><p>58% 0% 20% 40% 60% 80% 100% 72% 5-1. There's too much focus on scale Currently, the field focuses too much on scaling up machine learning models. 65% 0% 20% 40% 60% 80% 100% 88% 5-2. There's too much focus on benchmarks Currently, the field focuses too much on optimizing performance on benchmarks. 38% 0% 20% 40% 60% 80% 100% 37% 5-3. On the wrong track: model architectures The majority of research on model architectures published in the last 5 years is on the wrong track. 37% 0% 20% 40% 60% 80% 100% 41% 5-4. On the wrong track: language generation The majority of research in open-ended language generation tasks published in the last 5 years is on the wrong track. 36% 0% 20% 40% 60% 80% 100% 50% 5-5. On the wrong track: explainable models The majority of research in building explainable models published in the last 5 years is on the wrong track. 35% 0% 20% 40% 60% 80% 100% 42% 5-6. On the wrong track: black-box interpretability The majority of research in interpreting black-box models published in the last 5 years is on the wrong track. 53% 0% 20% 40% 60% 80% 100% 82% 5-7. We should do more to incorporate interdisciplinary insights Compared to the current state of affairs, NLP researchers should place greater priority on incorporating insights and methods from relevant domain sciences (e.g., sociolinguistics, cognitive science, human-computer interaction). Agree Weakly agree Weakly disagree Disagree On the wrong track? Opinions vary (Q5-{3-6}) We ask whether four specific research directions are "on the wrong track": model architectures (Q5-3), open-ended generation tasks (Q5-4), explainable models (Q5-5), and black-box interpretability (Q5-6). Respondents are divided on these questions, with agreement rates between 37% and 50%, reflecting that these are controversial issues. In most cases, respondents' predictions also reflect this divide, with a possible exception in explainability (Q5-5), where 50% true agreement is under-predicted at 36%, reflecting that more community members are critical of research in explainable modeling than expected.</p><p>While we deliberately used the vague phrase "on the wrong track" to get a sense of people's general attitudes, some respondents took issue with the framing of these questions; for example, one asks if it means asking the wrong question or finding the wrong solutions. As such, respondents' precise interpretations of these questions may vary.</p><p>Interdisciplinary insights are valued more than we think (Q5-7) The largest disparity between predicted and actual results in this section is on Q5-7, stating that NLP researchers should do more to incorporate insights from relevant domain sciences. While respondents' predictions about the community's opinions split this issue down the middle (53%), in reality 82% agree with the view (an outcome only expected by 11% of respondents).</p><p>This raises a question: If so many people agree that we should place greater priority on interdisciplinary work (Q5-7), why isn't more such work already happening? One possible explanation is that the responses to Q5-7 are a form of wishful thinking: Few believe that scale will be sufficient to solve our problems (Q2-1, Q5-1), and many think benchmarks are overemphasized (Q5-2) and insights from sciences like linguistics and cognitive science will be necessary for long-term progress (Q2-2, Q2-3). However, perhaps few know how to actually get results or useful insights from an interdisciplinary approach, leading this kind of work to be underrepresented in the literature and public discourse despite high demand for it. This suggests that the real issue may not be that NLP researchers do not assume interdisciplinary work has anything to offer so much as that we lack the knowledge and tools to make such work effective.</p><p>73% 0% 20% 40% 60% 80% 100% 89% 6-1. NLP's past net impact is good On net, NLP research has had a positive impact on the world. 71% 0% 20% 40% 60% 80% 100% 87% 6-2. NLP's future net impact is good On net, NLP research continuing into the future will have a positive impact on the world. 57% 0% 20% 40% 60% 80% 100% 59% 6-3. It is unethical to build easily-misusable systems It is unethical to build and publicly release a system which can easily be used in harmful ways. 59% 0% 20% 40% 60% 80% 100% 74% 6-4. Ethical and scientific considerations can conflict In the context of NLP research, ethical considerations can sometimes be at odds with the progress of science. 47% 0% 20% 40% 60% 80% 100% 25% 6-5. Ethical concerns mostly reduce to data quality and model accuracy The main ethical challenges posed by current ML systems can, in principle, be solved through improvements in data quality/coverage and model accuracy. 55% 0% 20% 40% 60% 80% 100% 48% 6-6. It is unethical to predict psychological characteristics It is inherently unethical to develop ML systems for predicting people's internal psychological characteristics (e.g., emotions, gender identity, sexual orientation). 58% 0% 20% 40% 60% 80% 100% 60% 6-7. Carbon footprint is a major concern The carbon footprint of training large models should be a major concern for NLP researchers. 35% 0% 20% 40% 60% 80% 100% 41% 6-8. NLP should be regulated The development and deployment of NLP systems should be regulated by governments. Agree Weakly agree Weakly disagree Disagree One caveat with this result is that responses vary significantly by job sector; 85% of those in academia agree with Q5-7 compared to 68% of those in industry, and our survey is mostly academics. Despite this difference, even the industry-only agreement rate is underpredicted, so survey response bias likely does not fully explain the mismatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">ETHICS (FIGURE 8)</head><p>NLP is seen as good, and maybe extremely good (Q6-1, Q6-2) Respondents overwhelmingly regard NLP as having a positive overall impact on the world, both up to the present day (89%, Q6-1) and going into the future (87%, Q6-2). This strong endorsement of NLP's future impact stands in contrast with more substantial worries about catastrophic outcomes (36%, Q3-4). While the views are anticorrelated,<ref type="foot" target="#foot_5">foot_5</ref> a substantial minority of 23% of respondents agreed with both Q6-2 and Q3-4, suggesting that they may believe NLP's potential for positive impact is so great that it even outweighs plausible threats to civilization. Whatever this means, it seems clear that many researchers think the stakes will be high in the near future when it comes to the impact of NLP research.</p><p>Interestingly, agreement with Q6-1 and Q6-2 are both underpredicted by more than 15%, suggesting that pessimistic voices may be overrepresented in the public discourse.</p><p>Responsibility for misuse: Researchers are somewhat split (Q6-3) In Q6-3, we ask respondents if they think "it is unethical to build and publicly release a system which can easily be used in harmful ways." This is admittedly vague, and its answer depends on many factors (e.g., how "easily" the system can be used, how it is released, etc.). Our intent with the question is to get a sense of the degree to which respondents feel that researchers bear ethical responsibility for downstream misuse of the systems that they produce, and assess whether the community's views of itself are accurate in these terms. Responses are somewhat split, with a majority of 59% agreeing, and respondent predictions were reasonably accurate, averaging at 57% predicted agreement. But responses varied by gender, with 74% of women agreeing versus 53% of men. It is worth comparing Q6-3 to Article 1.1 of the ACM Code of Ethics, <ref type="foot" target="#foot_7">6</ref> which is adopted by the ACL<ref type="foot" target="#foot_8">foot_8</ref> and states (among other things): "Computing professionals should consider whether the results of their efforts will... be used in socially responsible ways."</p><p>Belief in ethical/scientific conflict is underestimated (Q6-4) When asked if ethical considerations can sometimes be at odds with scientific progress, 74% of respondents agreed-considerably more than the average predicted agreement rate of 59%.</p><p>There are a couple of potential interpretations of disagreement with Q6-4. On one hand, respondents may believe any ethical problems that come up during the course of NLP research can be solved easily or are trumped by the benefits of scientific progress. On the other hand, they might believe that scientific 'progress' which is ethically regressive should not count as 'progress' or is inevitably pseudoscientific. Several views in line with the latter (and none with the former) were expressed in the survey feedback, suggesting that it is likely the dominant interpretation among those who disagree with Q6-4. As disagreement was significantly overpredicted by survey respondents, this view may be overrepresented in the public sphere relative to the proportion of NLP researchers who hold it.</p><p>Reduction of ethics to data/accuracy is overestimated (Q6-5) In light of public debates about the sources and nature of the harms caused by machine learning systems <ref type="bibr" target="#b56">(Kurenkov, 2020)</ref>, we ask whether the main ethical challenges posed by current ML systems can be reduced to issues with data quality and model accuracy (Q6-5). It is estimated to be a common view, averaging 47% predicted agreement, but is actually fairly uncommon, with only 25% of respondents agreeing.</p><p>Predicting psychological characteristics is controversial, with caveats (Q6-6) In light of discussions about surveillance and digital physiognomy (Agüera y Arcas et al., 2017), we ask whether it is inherently unethical to develop ML systems for predicting internal psychological characteristics like emotions, gender identity, and sexual orientation. Responses were split, with 48% agreeing.</p><p>This question received a lot of critical feedback, and it is unclear how much of this split is due to differences in opinion versus interpretations of the question. Some respondents object to grouping transient states (e.g., emotion) with persistent traits (gender identity, sexual orientation), or say their answer depends on whether the trait is legally protected. Some say it depends on the inputs available to the model, and others say that it may not be inherently unethical but is ethically permissible in only a tiny set of carefully considered use cases. Which of these elements of context respondents assumed may have played a major role in determining their answers, and future surveys on these issues might benefit from splitting Q6-6 into several different questions.</p><p>Carbon footprint is a concern for many (Q6-7) A majority of 60% agree with the statement that the carbon footprint of training large models should be a major concern for NLP researchers (Q6-8). This concern is based in part on trends in computation for machine learning at large scale, as <ref type="bibr" target="#b67">Schwartz et al. (2020)</ref> note a 300,000x increase in computation over 6 years leading up to 2019. Following this, Patterson et al. (2022) argue that advances in model efficiency and energy management can soon lead to a plateau in energy use from training machine learning models. Both argue that accountability and reporting of energy use is important for keeping the future carbon footprint of training ML models under control. The responses to Q6-8 indicate that a majority of the community would likely appreciate explicit reporting of energy use in NLP publications as well as work that increases the compute efficiency of model training. Responses to this question varied greatly by gender, with 78% of women agreeing as opposed to 51% of men. NLP researchers are skeptical of regulation (Q6-8) Finally, we ask if the development and deployment of NLP systems should be regulated by governments (Q6-8). 41% of respondents agree, and while respondents' predictions are accurate on average, a large contingent (31%) of respondents predicted a very low agreement rate of 0-20%. We intend Q6-8 as a weak statement, i.e., that there should be any regulations around the development and deployment of NLP systems. However, respondents ask for more nuance, remarking that the answer depends on development versus deployment, details about use cases, and whether we only mean NLP-specific regulations or also include more general regulations on things like energy use or data privacy. As respondents may have come to this question with different assumptions or interpretations around such issues, it is hard to read into the specific implications of this result, except that respondents express a general skepticism of government regulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">LIKELY SOURCES OF FUTURE ADVANCES (FIGURE 9)</head><p>In addition to the agree/disagree questions that constitute most of the survey, we also ask respondents where they think the most influential advances of the next 10 years will come from, providing four choices: Hardware and data scaling, Algorithmic improvements in ML, Data procurement and labeling practices, and Problem formulation and task design. We also provide an "other" option for people to specify their own answer. As the meta-question, we ask respondents to rank the answers from most popular (1) to least popular <ref type="bibr" target="#b15">(5)</ref>. <ref type="foot" target="#foot_9">8</ref>The results reveal one surprise: the popularity of the top answer, Problem formulation and task design, was greatly underestimated. A plurality of 33% of respondents gave this answer, but it was only ranked first by 12% of people and it ranked third on average in respondents' predictions. Besides this, predictions roughly tracked reality (although noisy). This suggests that there is a fairly common but underappreciated belief in the NLP community that researchers should be working on new ways of formulating the problems we're trying to solve, and that such work could have high impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CORRELATION ANALYSIS</head><p>Having each survey respondent provide opinions on a wide range of issues gives us the opportunity to examine the relationships between these opinions: Which sets of beliefs often come together, and which don't? Also, are there demographic characteristics that correlate with certain beliefs? To get a sense of this, we compute pairwise Spearman (rank-order) correlations between pairs of questions ( §5.1) and demographic characteristics ( §5.2), and perform a clustering analysis on our results using PCA ( §5.3).</p><formula xml:id="formula_0">1-1 1-2 1-3 1-4 1-5 1-6 2-1 2-2 2-3 2-4 3-1 3-2 3-3 3-4 4-1 4-2 4-3 5-1 5-2 5-3 5-4 5-5 5-6 5-7 6-1 6-2 6-3 6-4 6-5 6-6 6-7 6-8</formula><p>Question Number 5.1 QUESTION CORRELATIONS Spearman (rank-order) correlations between agree/disagree questions are shown in Figure 10. To compute these, we order the response values as [DISAGREE, WEAKLY DISAGREE, OTHER, WEAKLY AGREE, AGREE], where OTHER includes INSUFFICIENTLY INFORMED ON THE ISSUE,</p><formula xml:id="formula_1">1-1 1-2 1-3 1-4 1-5 1-6 2-1 2-2 2-3 2-4 3-1 3-2 3-3 3-4 4-1 4-2 4-3 5-1 5-2<label>5</label></formula><p>QUESTION IS ILL-POSED, and PREFER NOT TO SAY.<ref type="foot" target="#foot_10">foot_10</ref> Unsurprisingly, correlations tend to be stronger within a single section of the survey -for example, perspectives on linguistic structure and inductive bias ( §4.2), AGI ( §4.3), language understanding ( §4.4), and NLP's net impact on society ( §4.6, Q6-1, Q6-2). Beyond these, Table <ref type="table">1</ref> shows the highest-magnitude correlations between questions in different survey sections.</p><p>Concerns about private influence track concerns about scale The strongest cross-section correlation is between Q5-1 (there's too much focus on scale) and Q1-1 (private firms have too much influence, ρ s = 0.43). Regarding scale, Q5-1 was also moderately correlated with Q6-7 (carbon footprint is a major concern, ρ = 0.38). These correlations suggest that NLP researchers who see the influence of industry as problematic may hold this view in part because of concerns with the large-scale, compute-intensive research paradigm that is spearheaded largely by private firms.</p><p>Believing that LMs understand language is predictive of belief in AGI and the promise of scale Agreeing that text-only models can meaningfully "understand" language (Q4-1) is predictive of several other views. This who agree with Q4-1 are more likely to believe that scaling has moved us towards AGI (Q3-2, ρ s = 0.42) and can solve practically any NLP problem with existing techniques (Q2-1, ρ s = 0.30), and less likely to believe that there is too much focus on scale (Q5-1, ρ s = -0.35), that linguistic structure is necessary to solve important NLP problems (Q2-2, ρ s = -0.38), or that we should do more to incorporate insights from domain sciences (Q5-7, ρ s = -0.30). This suggests the existence of distinct 'LM optimist' and 'LM pessimist' positions, where people either believe that scaling up could solve most NLP problems and potentially lead to AGI, or they think scaling is overprioritized, AGI is less likely, and we should be focusing more on seeking insights Table <ref type="table">1</ref>: Top 20 Spearman correlations (ρ s ) between pairs of questions from distinct categories (i.e., with distinct first numbers). Correlations |ρ s | &gt; 0.11 are significant with p &lt; 0.05.</p><formula xml:id="formula_2">1-1 1-2 1-3 1-4 1-5 1-6 2-1 2-2 2-3 2-4 3-1 3-2 3-3 3-4 4-1 4-2 4-3 5-1 5-2 5-</formula><p>3 5-4 5-5 5-6 5-7 6-1 6-2 6-3 6-4 6-5 6-6 6-7 6-8 Question Number United States United Kingdom Germany Canada Israel France China Non-binary Man Woman No Yes Academia (incl. students) Non-profit / government Industry (for-profit) No Yes Faculty/senior role Junior role/postdoc PhD student Masters student No Yes 1 4 5 20 21 Infrequent/recreational user I routinely post I follow but don't often post Twitter Ad at ACL Mailing list/messaging Word of mouth Email from ACL Other and methods from linguistics, cognitive science, or other domain sciences. It is worth emphasizing, though, that none of our measured correlations here are extremely strong; people hold diverse sets of opinions and individuals cannot be cleanly split into these camps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">DEMOGRAPHIC CORRELATIONS</head><p>Spearman correlations between demographic variables and agree/disagree questions are shown in Figure <ref type="figure" target="#fig_8">11</ref>, with the top correlations by magnitude in Table <ref type="table" target="#tab_17">2</ref>. We rank agree/disagree answers as in §5.1, and for demographics, we treat each answer choice as a binary variable (1 if chosen by a respondent, 0 otherwise). We exclude demographic values for which we have fewer than 5 responses. Table <ref type="table">3</ref>: The top four components from running PCA on survey responses and demographic data, with human-written cluster labels, percent variance explained in parentheses, and the questions/data with the highest magnitude associations per component. We negate the statements with negative loadings so the statements for each component correspond to the set of beliefs that vary together.</p><p>Membership in demographic groups does not strongly correlate with answers to any questions in the survey. The strongest correlation is ρ s = -0.25 (Table <ref type="table" target="#tab_17">2</ref>), smaller than the top 20 correlation coefficients between pairs of questions (Table <ref type="table">1</ref>). This suggests that there is a diversity of viewpoints in each demographic category, with more variation within demographics than between demographics.</p><p>Nonetheless, there were a few demographics that were particularly predictive of responses. For example, Men and women answer many questions differently, especially regarding ethics and belief in the value of interdisciplinary research. In addition, under-represented minorities are more likely to agree that AI could have catastrophic consequences this century. Perhaps this reflects a worry that more powerful AI systems would have especially negative impacts on underrepresented minorities, or that minorities would be negatively affected before society as a whole is significantly affected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">CLUSTERING</head><p>To analyze the results beyond pairwise correlations, we identify clusters of opinions with principal component analysis (PCA). To do this, we linearize the agree/disagree questions along [-1, 1]: {DISAGREE → -1, WEAKLY DISAGREE → -0.</p><p>5, OTHER → 0, WEAKLY AGREE → 0.5, AGREE → 1}, where OTHER includes QUESTION IS ILL-POSED, INSUFFICIENTLY INFORMED ON THE ISSUE, and PREFER NOT TO SAY.</p><p>For demographics, we treat every answer choice as a 0/1 binary variable as in §5.2. This process gives us a total of 101 features for each respondent.</p><p>We run PCA using scikit-learn with 34 components, enough to explain 80% of the variance in the data. The variance in the data is fairly long-tailed, with the first 8 components covering 41.1% of the total variance and the remaining 26 explaining 38.9% (with less than 3% of variance explained by each component in the tail). This indicates that perspectives among NLP researchers may be difficult to reduce to a small number of opposing camps (e.g., pro-scale and anti-scale) without missing a great deal of internal disagreement within those groups.</p><p>The top four principal components are shown in Table <ref type="table">3</ref>. The most prominent cluster of views in the data corresponds to the belief that we should (or shouldn't) be prioritizing large-scale modeling ("Scaling Maximalism"), explaining 11.7% of the variance in the data, and aligning with the "LM optimist" perspective proposed in §5.1. Another prominent theme is concern with the pace of progress, characterized by a belief that we are making steps towards AGI and that it is an important concern for NLP researchers. While other themes seem to appear in the components after that, no individual cluster of beliefs explains a large amount of the variance in the data, so these clusters are probably not very useful for directly reasoning about the beliefs of individuals, who are combinations of all principal components.</p><p>As found in §5.2, demographic features are not as explanatory of the data as the agree/disagree questions are. Accordingly, they are not among the questions most strongly associated with the top clusters. The exception is the fourth component ("Jaded Empiricism"), for which one of the strongest associations is having a large number of publications, though this component only explains 4.0% of the total variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>This work is directly inspired by the 2009 PhilPapers Surveys <ref type="bibr" target="#b39">(Bourget &amp; Chalmers, 2014)</ref>, a survey and metasurvey of professional philosophers designed to discover and compare both their philosophical beliefs and their sociological beliefs about the philosophy community. More generally, introspective surveys to get a sense of the demographics and opinions of a field are common in many disciplines, such as economics <ref type="bibr" target="#b51">(Fuchs et al., 1998;</ref><ref type="bibr" target="#b53">Illge &amp; Schwarze, 2009;</ref><ref type="bibr">Frey et al., 2010, inter alia)</ref> and physics <ref type="bibr" target="#b69">(Sivasundaram &amp; Nielsen, 2016)</ref>. We design our survey to fill a similar role for NLP, with a special focus on controversies where the field's perception of its views may not match reality, due for example to the influence of social media or a small number of dominant voices.</p><p>The NLP Community Metasurvey overlaps slightly with other surveys of the NLP community, which are typically organized by ACL committees and focused on specific, timely issues related to the organization policy or logistics. Issues covered by such surveys include preprint posting practices <ref type="bibr" target="#b49">(Foster et al., 2017)</ref>, experiences with rolling review infrastructure <ref type="bibr" target="#b68">(Schütze, 2022)</ref>, ethical stances <ref type="bibr">(Fort &amp; Couillault, 2016;</ref><ref type="bibr" target="#b35">Benotti et al., 2022)</ref>, attitudes towards energy use and environmental impacts <ref type="bibr" target="#b32">(Arase et al., 2021)</ref>, and language diversity in NLP research <ref type="bibr" target="#b46">(Diab, 2022)</ref>. Instead of focusing on a specific issue, our aim with the NLP Community Survey is to provide a broad sense of the distribution of views (and meta-views) held by NLP researchers. To do this, we cover a range of topics with existing debate in the literature (see the subsections of §4 for references). This is related to the the NLP Scholar project, which analyzes broad demographic <ref type="bibr">(Mohammad, 2020c;</ref><ref type="bibr" target="#b70">2019)</ref>, publication (Mohammad, 2020b), and citation (Mohammad, 2020a) trends in NLP and their interplay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>With the NLP Community Metasurvey, we have made concrete numbers of many contentious issues in NLP: the necessity of expert-designed inductive bias, the importance of AGI, whether language models understand language, and more. Perhaps more interestingly, we have also made concrete numbers of the community's impressions of these controversies, in some cases confirming what we already believe and in others producing surprises. For example, the idea that mere scale will solve most of NLP is much less controversial (and much less believed) than it is thought to be, and NLP researchers unexpectedly agree that we should do more to incorporate insights and methods from domain sciences, and that we should prioritize problem formulation and task design. Interestingly, very few of the issues we ask about (only the necessity of linguistic structure and expert-designed inductive bias, Q2-2 and Q2-3) are noticeably more controversial than respondents expected them to be. This could be due to biases from the amplification of controversy (e.g., in social media), or it could just reflect mundane biases in respondent predictions, e.g., regression towards the middle of the range (∼50%) under uncertainty.</p><p>There are other biases to keep in mind when interpreting our results: people in the United States are overrepresented in our respondent population relative to ACL members as a whole, and senior researchers and academics are probably overrepresented as well (Appendix B), not to mention unmeasured population biases based in the personal networks of the authors. Many of the questions have multiple possible interpretations, many rely on vague terms like "plausible" or "major concern," and some rely on comparisons to reference points such as the Industrial Revolution (Q3-3) or "specific, non-trivial results from... linguistics or cognitive science" (Q2-4) which may carry different implications for different readers. Given these issues, it is probably reasonable to view the answers to the questions on this survey as reflecting something between objective beliefs and signaling behavior. Agreement or disagreement with a particular statement may indicate where a respondent believes they stand relative to "received wisdom," which would determine what statements would be worth asserting in the context of the status quo; or, a response could be driven by identification with (or rejection of) an already-known ideological camp that the statement is taken to refer to. While these issues affect the way we should interpret the absolute numbers in our results, they should apply equally to the meta-questions, so we believe it is meaningful to compare the survey's actual and predicted results as a way of discovering false sociological beliefs.</p><p>We hope the results of the NLP Community Metasurvey can help us update our sociological beliefs to closer match reality, creating common ground for fruitful and productive discourse among NLP researchers as we confront these issues in the course of our work.</p><p>Year of first NLP publication 0% 20% 40% 60% 80% 100% Percent of respondents (Cumulative) 0% 2% 4% 6% 8% 10% Percent of respondents Prefer not to say In what year was your first research work in NLP published? Include NLP work in non-ACL venues. Figure 13: Respondents' year of first NLP publication. Figures 14-17 show full results for the demographics questions. Results are restricted to those in the target demographic, i.e., with at least 2 *CL publications in the last three years. Numeric labels for percentages below 5% are omitted from the charts for space. 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents United States United Kingdom Germany Israel China Europe (other) Asia / Pacific (other) Sub-Saharan Africa Middle East / North Africa (other) Canada South America / Caribbean Prefer not to say 189 14 16 36 6 20 7 20 3 4 1 11 58% 11% 6% 6% Where do you live? To preserve privacy, responses given by fewer than 10 people will be aggregated into larger geographical regions in reported results. 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Man Woman Non-binary Prefer not to say 218 81 19 9 67% 25% 6% What gender should you be grouped with in our analysis? 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Yes No Prefer not to say 207 85 35 63% 26% 11% Do you consider yourself to be a member of an underrepresented minority group in NLP? Figure 14: Basic demographics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C PILOT TESTING</head><p>The first author conducted 6 pilot studies with about 26 different participants from Computer Science and Linguistics departments, mostly based in the United States, during the months of February and March of 2022. After pilot participants took the survey, they were asked for feedback in a group Zoom call. Participants were asked about any questions they perceived as leading, reasons they might have refused to answer questions, reasons they might have wanted to stop taking the survey in the middle, and whether the purpose of the survey was clear, etc. The survey instructions and question wording were updated in accordance with their feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D DATA CLEANING AND POSTPROCESSING</head><p>Likely Sources of Future Advances As mentioned in §4.7, 20% of respondents who answered the meta-question on likely sources of future advances ranked "Other" as the most common answer to the question. We assume these were mistakes, since it is unlikely that people would think a plurality of respondents would reject all of the (fairly broad) provided options. We take this, then, to mean the rankings provided by these respondents were probably reversed, with 5 being the most common and 1 the least common. So we reverse the rankings provided by these respondents for the purposes</p><p>0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Computational Social Science and C… Dialogue and Interactive Systems Discourse and Pragmatics Ethics and NLP Generation Information Extraction Information Retrieval and Text Mining Interpretability and Analysis of Model… Language Grounding to Vision, Rob… Linguistic Theories, Cognitive Modeli… Machine Learning for NLP Machine Translation and Multilinguality NLP Applications Phonology, Morphology, and Word S… Question Answering Resources and Evaluation Semantics: Lexical Semantics: Sentence-level Semantic… Sentiment Analysis, Stylistic Analysis… Speech and Multimodality Summarization Syntax: Tagging, Chunking and Pars… None of the above Prefer not to say 14% 19% 13% 13% 28% 18% 13% 31% 13% 17% 39% 26% 29% 12% 20% 27% 12% 21% 7% 6% 10% 12% 45 61 42 43 93 60 44 101 43 54 129 86 96 38 66 89 40 68 22 20 33 38 0 10 What subfields fit your work from the last 3 years? (Choose all that apply.) 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Yes No 314 13 96% Have you attended an ACL event in the last 3 years? Includes workshops, conferences, etc. held in 2019 or later. 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents ≥2 327 100% How many publications have you co-authored in core ACL venues in the last 3 years? Include anything with a publication date 2019 or later in ACL, EMNLP, NAACL, EACL, AACL, TACL, or CL (including Findings). 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents 1-4 5-20 21+ Prefer not to say 126 154 44 3 39% 47% 13% How many total peer-reviewed publications do you have related to NLP? Figure 15: Respondents' research activities. 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Academia (including students) Industry (for-profit) Non-profit / government Prefer not to say 240 72 14 1 73% 22% What sector do you primarily work in? 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Yes No Prefer not to say 290 31 6 89% 9% Is your job publication-oriented? 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Faculty / senior managerial role Junior professional / postdoc PhD student Masters student Undergraduate Prefer not to say 134 107 74 4 6 2 41% 33% 23% What is your career position? Figure 16: Career demographics. 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents I routinely post I follow but don't often post I don't have a Twitter account, rarely… Prefer not to say 58 190 69 10 18% 58% 21% Do you use Twitter to engage with the NLP research community? 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Twitter Email from the ACL Member Portal Broadcast on a mailing list, Slack ch… Word of mouth / personal communic… Advertisement at the ACL conference Other public social media post Prefer not to say 49 120 63 5 10 70 10 15% 37% 19% 21% How did you last hear about this survey before deciding to take it? 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% of analysis. Besides changing the "Other" statistics, this does not seem to have a noticeable effect on overall trends (Figure <ref type="figure" target="#fig_5">18</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Percent of respondents</head><p>1 2 3 4 5 Predicted Rank 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Percent of respondents Hardware and data scaling Algorithmic improvements in ML Data procurement and labeling … Problem formulation and task d… Other</p><p>What area will the most influential advances of the next 10 years be in?</p><p>Figure <ref type="figure" target="#fig_5">18</ref>: We postprocessed the predicted rankings for likely sources of future advances by reversing the rankings given by all respondents who placed "Other" first (20% of respondents). The rankings for the unadjusted data are shown in the faded lines; besides the change to the "Other" line, overall trends are the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The NLP Community Metasurvey</head><p>This should take ~20 minutes to complete. For the first 1,000 respondents, we will donate $10 on your behalf to one of several non-profits that you choose at the end of the survey.</p><p>This is a survey of opinions on issues being publicly discussed in NLP. We (researchers at UW and NYU) invite anyone doing NLP research to take it, though our primary target demographic is people who have authored or coauthored at least 2 publications in core ACL venues in the past 3 years.</p><p>Please share this survey widely -we hope to cover as much of the target demographic as possible.</p><p>For each statement, mark whether you agree or disagree. Then, you will report what percentage of community members you think agree with the statement. This will give a sense of whether our community's impression of itself aligns with its members' actual beliefs, and help us improve this alignment, communicate better, and motivate our work more effectively. More details about our motivation can be found at nlpsurvey.net. This was inspired by the PhilPapers surveys (philpapers.org/surveys).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How to Answer</head><p>You will be shown a statement and asked where you stand on an agree/disagree spectrum:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agree</head><p>Weakly agree Weakly disagree</p><p>Disagree Choose the answer that best reflects your views. In our analysis, we will interpret "weakly agree" and "weakly disagree" to include marginal views just</p><p>Of those on the agree/disagree spectrum, what percentage of community members do you think will mark "agree" or "weakly agree" to each statement? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State of the Field</head><p>For each of the following statements, mark the answer that best reflects your position. At the end of this section, you will predict what percentage of community members will have marked "agree" or "weakly agree" for each.</p><p>Agree Weakly agree Weakly disagree Disagree Insufficiently informed on the issue Question is ill-posed Prefer not to say Agree/Disagree Other Powered by Qualtrics A (Optional) Any comments or feedback on this section? peak.</p><p>I expect an "NLP winter" to come within the next 30 years, in which funding and job opportunities in NLP R&amp;D fall by at least 50% from their peak.</p><p>A majority of the research being published in NLP is of dubious scientific value.</p><p>Author anonymity during review is valuable enough to warrant restrictions on the dissemination of research that is under review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>← →</head><p>Figure <ref type="figure" target="#fig_6">19</ref>: How the survey looks to respondents in a web browser.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: State of the Field.Here, and in subsequent such figures, the lower number (in green) represents the fraction of respondents who agree with the position out of all those who took a side. The grey bars show the relative proportion of meta-question predictions in each bin (0-20%, 20-40%, etc.), and the upper number (in black) shows the average predicted rate of agreement, computed treating each bin as its midpoint. The green and black horizontal lines show 95% bootstrap confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Scale, Inductive Bias, and Adjacent Fields.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Artificial general intelligence (AGI) and major risks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Language Understanding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Promising Research Programs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Ethics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Likely Sources of Future Advances. The left shows the distribution of answers, and the right shows predicted ranks (mean and standard deviation) of each answer relative to its true rank.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Spearman correlations between answers to all pairs of agree/disagree questions. Lines separate sections of the survey. Question numbers are given in Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Spearman correlations between membership demographic groups and answers to agree/disagree questions. Lines separate survey sections and demographic variables. "URM" stands for under-represented minority. We only show demographic values with &gt; 5 respondents. Question numbers are given in Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Other information provided by respondents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><figDesc>To ground your judgment, "community members" = people with at least 2 publications in core ACL venues in the last 3 years. You can skip questions where you have no idea, but best guesses are highly encouraged.Private firms have too much influence in guiding the trajectory of the field.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 2 :</head><label>2</label><figDesc>Top 10 Spearman correlations (ρ s ) between membership in a demographic and answers to questions. Correlations |ρ s | &gt; 0.11 are statistically significant with p &lt; 0.05.</figDesc><table><row><cell>Demographic</cell><cell>Question</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Our final donations were $950 to the WHO COVID-19 Solidarity Response Fund (https://www.who. int/emergencies/diseases/novel-coronavirus-2019/donate), $1,650 to GiveWell's Max-</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>imum Impact Fund (https://www.givewell.org/maximum-impact-fund), $830 to GiveDirectly (https://www.givedirectly.org/), and $1,140 to the Distributed AI Research Institute (https: //www.dair-institute.org/support). 23 respondents (5%) did not provide an answer to this question, so we did not make donations on their behalf.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>https://www.aclweb.org/adminwiki/images/f/f4/Memberships_2021_by_ Country_SUMMER.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>https://www.aclweb.org/portal/content/acl-diversity-statistics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>The remaining 1% of PhD students reported being in industry or declined to report their job sector.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>32% of respondents who agreed that NLP will have a positive future impact on society (Q6-2) also agreed that there is a plausible risk of catastrophe (Q3-4), compared to</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>60% reporting a belief in plausible catastrophic risk among those who disagreed with Q6-2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_7"><p>https://www.acm.org/code-of-ethics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_8"><p>https://www.aclweb.org/portal/content/acl-code-ethics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_9"><p>20% of respondents rank "Other" on top (rank 1) for this question, even though very few actually provided it as their answer. It seems to us that these respondents probably ranked the answers backwards by mistake. To correct for this, we reverse the rankings provided by everyone who ranked "Other" first. While not a surefire fix, it doesn't seem to change any major trends in the results (Appendix D, Figure18).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_10"><p>Even though the OTHER answers may not be meaningfully "in between" agreeing and disagreeing, we find that running the analysis excluding OTHER options produces nearly identical results, so we keep them in order to apply the analysis to all of the data.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank the 480 respondents who completed the survey, as well as (especially) our 26 pilot testers and colleagues who provided feedback on the survey. This project has benefited from financial support to SB by Eric and <rs type="person">Wendy Schmidt</rs> (made by recommendation of the <rs type="programName">Schmidt Futures program</rs>) and <rs type="funder">Apple</rs>. This material is based upon work supported by the <rs type="funder">National Science Foundation</rs> under Grant Nos. <rs type="grantNumber">1746891</rs>, <rs type="grantNumber">1922658</rs> and <rs type="grantNumber">2046556</rs>. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rbxFCpT">
					<orgName type="program" subtype="full">Schmidt Futures program</orgName>
				</org>
				<org type="funding" xml:id="_K2SpRWG">
					<idno type="grant-number">1746891</idno>
				</org>
				<org type="funding" xml:id="_vJAdzVd">
					<idno type="grant-number">1922658</idno>
				</org>
				<org type="funding" xml:id="_464SUFj">
					<idno type="grant-number">2046556</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Author anonymity is worth it (1-6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">State of the Field</head><p>Scaling up ~solves NLP  Need linguistic structure  Need inductive bias <ref type="bibr" target="#b4">(2)</ref><ref type="bibr" target="#b8">(3)</ref> Ling/CogSci-inspired systems <ref type="bibr" target="#b4">(2)</ref><ref type="bibr" target="#b8">(3)</ref><ref type="bibr" target="#b12">(4)</ref> 2. Scale, Inductive Bias, and Adjacent Fields AGI is important  We're progressing towards AGI  Revolutionary change is plausible  Catastrophic risk is plausible <ref type="bibr" target="#b8">(3)</ref><ref type="bibr" target="#b12">(4)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">AGI and Major Risks</head><p>LMs understanding language (4-1)</p><p>Multimodal models understand  Text measures understanding (4-3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Language Understanding</head><p>Too much focus on scale  Too much focus on benchmarking  Wrong Track: Architectures  Wrong Track: Generation  Wrong Track: Explainability  Wrong Track: Interpretability <ref type="bibr" target="#b15">(5)</ref><ref type="bibr">(6)</ref> Prioritize interdisciplinary insights (5-7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Promising Research Programs</head><p>-1.0-0.8 -0.6 -0.4 -0.2 0.0 0.2 0.4 0.6 0.8 1.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proportion of Respondents</head><p>NLP is good (past) (6-1)</p><p>NLP is good (future)  Responsibility for misuse  Ethics and science at odds  Ethics ~reduces to data/accuracy  Don't Predict psych. chars.  Carbon footprint is important <ref type="bibr">(6)</ref><ref type="bibr">(7)</ref> NLP should be regulated (6-8)  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE NLP COMMUNITY METASURVEY</head><p>This should take ∼20 minutes to complete. For the first 1,000 respondents, we will donate $10 on your behalf to one of several non-profits that you choose at the end of the survey.</p><p>This is a survey of opinions on issues being publicly discussed in NLP. We (researchers at UW and NYU) invite anyone doing NLP research to take it, though our primary target demographic is people who have authored or co-authored at least 2 publications in core ACL venues in the past 3 years. Please share this survey widely -we hope to cover as much of the target demographic as possible.</p><p>For each statement, mark whether you agree or disagree. Then, you will report what percentage of community members you think agree with the statement. This will give a sense of whether our community's impression of itself aligns with its members' actual beliefs, and help us improve this alignment, communicate better, and motivate our work more effectively. More details about our motivation can be found at nlpsurvey.net. This was inspired by the PhilPapers surveys (philpapers.org/surveys).</p><p>How to Answer You will be shown a statement and asked where you stand on an agree/disagree spectrum:</p><p>• Agree</p><p>• Weakly agree</p><p>• Weakly disagree</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Disagree</head><p>Choose the answer that best reflects your views. In our analysis, we will interpret "weakly agree" and "weakly disagree" to include marginal views just barely agreeing or disagreeing (e.g., "depends, leaning positive/negative"). However, in case you cannot place yourself on either side of an issue, there will also be three non-answer options:</p><p>• Insufficiently informed on the issue: You don't understand the statement or its subject matter well enough to form an opinion.</p><p>• Question is ill-posed: You reject the distinction between agreeing and disagreeing, or don't think the statement admits any coherent interpretation.</p><p>• Prefer not to say: You don't feel comfortable providing any of the other answer choices.</p><p>If you pick "question is ill-posed" or "prefer not to say," we would appreciate (optional) feedback at the end of the respective section explaining your reasons so we can better interpret the results.</p><p>Meta-Questions At the end of each section, you'll be asked to predict what proportion of people on the agree/disagree spectrum will answer either "agree" or "weakly agree" to each question.</p><p>For the purpose of these questions, please predict relative to the target demographic: people with at least 2 publications in core ACL venues in the last 3 years. For our purposes, core venues are ACL, EMNLP, NAACL, EACL, AACL, TACL, and CL (including Findings). By our count from the ACL Anthology, this includes approximately 5,650 people. Even if you don't have a strong sense of the community's stance, give your best guess (unless you really feel like you have no priors, in which case you can skip these questions). At the end of the survey, you will rate your overall confidence in the meta-survey questions so we can account for it in our analysis.</p><p>Privacy Your responses are anonymous and individual responses will not be released publicly. You will have the option to de-anonymize yourself at the end; this will help us audit the results and follow up with you after the survey, but will not be released publicly or shared with anyone without your permission. In accordance with the General Data Protection Regulation (GDPR), all survey respondents have rights over their personallyidentifiable information. This form (nlpsurvey.net/gdpr.pdf) outlines those rights and how to exercise them. A list of the people who will have access to the non-anonymized data is available at nlpsurvey.net/ about.</p><p>You can reach us with questions and concerns at nlp-metasurvey-admin@nyu.edu.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The most widely-cited papers of the next 10 years are more likely to come out of industry than academia. 1-3. NLP winter is coming (10 years). I expect an &quot;NLP winter&quot; to come within the next 10 years, in which funding and job opportunities in NLP R&amp;D fall by at least 50% from their peak</title>
	</analytic>
	<monogr>
		<title level="m">Industry will produce the most widely-cited research</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">NLP winter is coming (30 years). I expect an &quot;NLP winter&quot; to come within the next 30 years, in which funding and job opportunities in NLP R&amp;D fall by at least 50% from their peak</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Most of NLP is dubious science. A majority of the research being published in NLP is of dubious scientific value</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Author anonymity is worth it. Author anonymity during review is valuable enough to warrant restrictions on the dissemination of research that is under review</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Given resources (i.e., compute and data) that could come to exist this century, scaled-up implementations of established existing techniques will be sufficient to practically solve any important real-world problem or application in NLP</title>
		<author>
			<persName><surname>Scale</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Inductive Bias, and Adjacent Fields 2-1. Scaling solves practically any important problem</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Discrete general-purpose representations of language structure grounded in linguistic theory (involving, e.g., word sense, syntax, or semantic graphs) will be necessary to practically solve some important real-world problems or applications in NLP</title>
		<imprint/>
	</monogr>
	<note>Linguistic structure is necessary</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Expert inductive biases are necessary. Expert-designed strong inductive biases (à la universal grammar, symbolic systems, or cognitively-inspired computational primitives) will be necessary to practically solve some important real-world problems or applications in NLP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">CogSci will contribute to the most-cited models. It is likely that at least one of the five most-cited systems in 2030 will take clear inspiration from specific, non-trivial results from the last 50 years of research into linguistics or cognitive science</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Risks 3-1. AGI is an important concern. Understanding the potential development of artificial general intelligence (AGI) and the benefits/risks associated with it should be a significant priority for NLP researchers</title>
		<author>
			<persName><forename type="first">Major</forename><surname>Agi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Recent progress is moving us towards AGI. Recent developments in large-scale ML modeling (such as in language modeling and reinforcement learning) are significant steps toward the development of AGI</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">AI could soon lead to revolutionary societal change. In this century, labor automation caused by advances in AI/ML could plausibly lead to economic restructuring and societal changes on at least the scale of the Industrial Revolution</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">AI decisions could cause nuclear-level catastrophe. It is plausible that decisions made by AI or machine learning systems could cause a catastrophe this century that is at</title>
		<imprint/>
	</monogr>
	<note>least as bad as an all-out nuclear war</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Language Understanding 4-1. LMs understand language. Some generative model trained only on text, given enough data and computational resources, could understand natural language in some non-trivial sense</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multimodal models understand language. Some multimodal generative model (e.g., one trained with access to images, sensor and actuator data, etc.), given enough data and computational resources, could understand natural language in some non-trivial sense</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Text-only evaluation can measure language understanding. We can, in principle, evaluate the degree to which a model understands natural language by tracking its performance on text-only classification or language generation benchmarks</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Promising Research Programs 5-1. There&apos;s too much focus on scale. Currently, the field focuses too much on scaling up machine learning models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">There&apos;s too much focus on benchmarks. Currently, the field focuses too much on optimizing performance on benchmarks</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m">On the wrong track: model architectures. The majority of research on model architectures</title>
		<imprint/>
	</monogr>
	<note>published in the last 5 years is on the wrong track</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On the wrong track: language generation. The majority of research in open-ended language generation tasks published in the last 5 years is on the wrong track</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note>On the wrong track: explainable models. The majority of research in building explainable models published in the last 5 years is on the wrong track</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">On the wrong track: black-box interpretability. The majority of research in interpreting black-box models published in the last 5 years is on the wrong track. 5-7. We should do more to incorporate interdisciplinary insights. Compared to the current state of affairs, NLP researchers should place greater priority on incorporating insights and methods from relevant domain sciences</title>
		<imprint>
			<biblScope unit="page" from="5" to="6" />
		</imprint>
	</monogr>
	<note>e.g., sociolinguistics, cognitive science, human-computer interaction</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ethics 6-1. NLP&apos;s past net impact is good</title>
	</analytic>
	<monogr>
		<title level="m">On net, NLP research has had a positive impact on the world</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">On net, NLP research continuing into the future will have a positive impact on the world</title>
		<imprint/>
	</monogr>
	<note>NLP&apos;s future net impact is good</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">It is unethical to build easily-misusable systems. It is unethical to build and publicly release a system which can easily be used in harmful ways</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Ethical and scientific considerations can conflict</title>
		<imprint/>
	</monogr>
	<note>In the context of NLP research, ethical considerations can sometimes be at odds with the progress of science</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Ethical concerns mostly reduce to data quality and model accuracy. The main ethical challenges posed by current ML systems can, in principle, be solved through improvements in data quality/coverage and model accuracy</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">It is unethical to predict psychological characteristics. It is inherently unethical to develop ML systems for predicting people&apos;s internal psychological characteristics (e.g., emotions, gender identity</title>
		<imprint>
			<biblScope unit="page" from="6" to="6" />
		</imprint>
	</monogr>
	<note>sexual orientation</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Carbon footprint is a major concern. The carbon footprint of training large models should be a major concern for NLP researchers</title>
		<imprint>
			<biblScope unit="page" from="6" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">NLP should be regulated. The development and deployment of NLP systems should be regulated by governments. Q1 Q2 ρ s Q1-1. Private firms have too much influence. Q5-1. There&apos;s too much focus on scale. +0.43 Q3-2. Recent progress is moving us towards AGI. Q4-1. LMs understand language. +0.42 Q1-5. Most of NLP is dubious science</title>
		<imprint>
			<biblScope unit="page" from="6" to="8" />
		</imprint>
	</monogr>
	<note>Q5-3. On the wrong track: model architectures</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Most of NLP is dubious science. Q5-4. On the wrong track: language generation. +0.33 Q1-1. Private firms have too much influence. Q5-7. We should incorporate more interdisciplinary insights. +0.30 Q4-2. Multimodal models understand language</title>
		<imprint>
			<biblScope unit="page" from="5" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multimodal models understand language. -0.30 Q2-1. Scaling solves practically any important problem. Q4-2. Multimodal models understand language. +0.29 Q4-2. Multimodal models understand language. Q6-7. Carbon footprint is a major concern. -0.28 Q3-2. Recent progress is moving us towards AGI. Q4-3. Text-only evaluation can measure language understanding</title>
		<idno>+0.28</idno>
	</analytic>
	<monogr>
		<title level="m">Linguistic structure is necessary</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">We should incorporate more interdisciplinary insights. Q6-3. It is unethical to build easily misusable systems. +0.28 REFERENCES Blaise Agüera y Arcas, Margaret Mitchell, and Alexander Todorov. Physiognomy&apos;s new clothes</title>
		<ptr target="https://medium.com/@blaisea/physiognomys-new-clothes-f2" />
		<imprint>
			<date type="published" when="2017-05">May 2017</date>
			<biblScope unit="page" from="5" to="7" />
		</imprint>
	</monogr>
	<note>d4b59fdd6a</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Concrete problems in ai safety</title>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Mané</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1606.06565" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Yuki</forename><surname>Arase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Rücklé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/portal/content/efficient-nlp-survey" />
		<title level="m">Efficient NLP survey</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Climbing towards NLU: On meaning, form, and understanding in the age of data</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.463</idno>
		<ptr target="https://aclanthology.org/2020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="5185" to="5198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the dangers of stochastic parrots: Can language models be too big?</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shmargaret</forename><surname>Shmitchell</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445922</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445922" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT &apos;21</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Benotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Drezde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karën</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malvina</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<title level="m">ACL ethics survey</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeannette</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Brunskill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dallas</forename><surname>Buch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niladri</forename><forename type="middle">S</forename><surname>Castellon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annie</forename><forename type="middle">S</forename><surname>Chatterji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><forename type="middle">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Creel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dora</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moussa</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esin</forename><surname>Doumbouya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kawin</forename><surname>Etchemendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Ethayarajh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><forename type="middle">E</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shelby</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saahil</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyusha</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fereshte</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Khani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><forename type="middle">Wei</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranjay</forename><surname>Krass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohith</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Kuditipudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mina</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><surname>Levent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suvir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Mirchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zanele</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Munyikwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avanika</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allen</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hamed Nilforoshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giray</forename><surname>Nyarko</surname></persName>
		</author>
		<author>
			<persName><surname>Ogut ; Rohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><forename type="middle">W</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rose</forename><forename type="middle">E</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Matei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://crfm.stanford.edu/assets/report.pdf" />
		<editor>Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Robert Reich, Hongyu Ren, Frieda Rong, Yusuf H. Roohani, Camilo Ruiz, Jack Ryan, Christopher R&apos;e, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishna Parasuram Srinivasan, Alex Tamkin,</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Kaitlyn Zhou, and Percy Liang. On the opportunities and risks of foundation models. ArXiv</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Superintelligence: Paths, Dangers, Strategies</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Bostrom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Oxford University Press, Inc</publisher>
		</imprint>
	</monogr>
	<note>USA, 1st edition</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">On the conception and design of the PhilPapers Survey</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bourget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<ptr target="https://philpapers.org/surveys/designthoughts.html" />
		<imprint>
			<date type="published" when="2022-08">August 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">What do philosophers believe?</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bourget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11098-013-0259-7</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="465" to="500" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Philosophers on philosophy: The PhilPapers 2020 survey</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bourget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">What will it take to fix benchmarking in natural language understanding?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.385</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.385" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06">June 2021</date>
			<biblScope unit="page" from="4843" to="4855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><surname>Eck</surname></persName>
		</author>
		<imprint>
			<pubPlace>Jeff Dean, Slav Petrov</pubPlace>
		</imprint>
	</monogr>
	<note>and Noah Fiedel. PaLM: Scaling language modeling with pathways</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><surname>Corr</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2204.02311</idno>
		<ptr target="https://arxiv.org/abs/2204.02311" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<ptr target="https://forms.office.com/pages/responsepage" />
		<title level="m">Language diversity in our ACL community</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAAN_ _oJ4BAFUNlVMMFpOVlkzM1FSRlZaUlo0VEI4OEI5Ty4u</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pathologies of neural models make interpretations difficult</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Shi Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Grissom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1407</idno>
		<ptr target="https://aclanthology.org/D18-1407" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">October-November 2018</date>
			<biblScope unit="page" from="3719" to="3728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Yes, we care! Results of the ethics and natural language processing surveys</title>
		<author>
			<orgName type="collaboration">Karën Fort and Alain Couillault</orgName>
		</author>
		<ptr target="https://aclanthology.org/L16-1252" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05">May 2016</date>
			<biblScope unit="page" from="1593" to="1600" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA)</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marti</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqi</forename><surname>Zhao</surname></persName>
		</author>
		<title level="m">Report on ACL survey on preprint publishing and reviewing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">What is economics? Attitudes and views of German economists</title>
		<author>
			<persName><forename type="first">Silke</forename><surname>Bruno S Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Friedrich</forename><surname>Humbert</surname></persName>
		</author>
		<author>
			<persName><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Methodology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="332" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Economists&apos; views about parameters, values, and policies: Survey results in labor and public economics</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">B</forename><surname>Victor R Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><surname>Poterba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Literature</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1387" to="1425" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Risks from learned optimization in advanced machine learning systems</title>
		<author>
			<persName><forename type="first">Evan</forename><surname>Hubinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Van Merwijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joar</forename><surname>Skalse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Garrabrant</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1906.01820" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A matter of opinion-How ecological and neoclassical environmental economists and think about sustainability and economics</title>
		<author>
			<persName><forename type="first">Lydia</forename><surname>Illge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reimund</forename><surname>Schwarze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Economics</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="594" to="604" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Why most published research findings are false</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><surname>Ioannidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Medicine</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Attention is not Explanation</title>
		<author>
			<persName><forename type="first">Sarthak</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1357</idno>
		<ptr target="https://aclanthology.org/N19-1357" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3543" to="3556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Lessons from the PULSE model and discussion. The Gradient</title>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Kurenkov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Provable Limitations of Acquiring Meaning from Ungrounded Form: What Will Future Language Models Understand?</title>
		<author>
			<persName><forename type="first">William</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00412</idno>
		<ptr target="https://doi.org/10.1162/tacl_a_00412" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1047" to="1060" />
			<date type="published" when="2021-09">09 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><surname>Mohammad</surname></persName>
		</author>
		<idno>1911.03562</idno>
		<title level="m">The state of NLP literature: A diachronic analysis of the ACL Anthology</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Examining citations of natural language processing literature</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><surname>Mohammad</surname></persName>
		</author>
		<idno>doi: 10.18653</idno>
		<ptr target="1/2020.acl-main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="5199" to="5209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<ptr target="https://aclanthology.org/2020.acl-main.464" />
		<title level="m">URL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">NLP scholar: A dataset for examining the state of NLP research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><surname>Mohammad</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.109" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
			<biblScope unit="page" from="979" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Gender gap in natural language processing research: Disparities in authorship and citations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><surname>Mohammad</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.702</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.702" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="7860" to="7870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Do transformer modifications transfer across implementations and applications?</title>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Fevry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karishma</forename><surname>Malkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.465</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.465" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="5758" to="5773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The carbon footprint of machine learning training will plateau, then shrink</title>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urs</forename><surname>Hölzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluis-Miquel</forename><surname>Munguia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rothchild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maud</forename><surname>Texier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="DOI">10.1109/MC.2022.3148714</idno>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">AI and the everything in the whole wide world benchmark</title>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Inioluwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amandalynne</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><surname>Paullada</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=j6NxpQbREA1" />
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><forename type="middle">Etzioni</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename></persName>
		</author>
		<idno type="DOI">10.1145/3381831</idno>
		<ptr target="https://doi.org/10.1145/3381831" />
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="54" to="63" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<ptr target="https://www.cis.lmu.de/~hs/acl22/panel/survey.html" />
		<title level="m">Survey on the future of reviewing</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Surveying the attitudes of physicists concerning foundational issues of quantum mechanics</title>
		<author>
			<persName><forename type="first">Sujeevan</forename><surname>Sivasundaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Hvidtfelt Nielsen</surname></persName>
		</author>
		<idno>1612.00676</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">The bitter lesson</title>
		<author>
			<persName><forename type="first">Rich</forename><surname>Sutton</surname></persName>
		</author>
		<ptr target="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Vinh Q Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.10551</idno>
		<title level="m">Scaling laws vs model architectures: How does inductive bias influence scaling? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Attention is not not explanation</title>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Pinter</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1002</idno>
		<ptr target="https://aclanthology.org/D19-1002" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">A OVERVIEW OF RESPONSES A full overview of the responses to agree/disagree questions is shown in Figure 12. The OTHER answers were fairly uncommon-never above 20% of all answers-and the most frequent one was INSUFFICIENTLY INFORMED ON THE ISSUE, which many respondents gave for the questions about an NLP winter (Q1-3, Q1-4) and the</title>
		<imprint/>
	</monogr>
	<note>wrong track&quot; questions (Q5-{3-6}</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Most NLP is dubious science</title>
		<imprint>
			<biblScope unit="issue">1-5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
