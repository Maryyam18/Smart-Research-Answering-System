<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models and Challenges</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-07-30">30 Jul 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Farid</forename><surname>Ariai</surname></persName>
							<email>f.ariai@uq.edu.au</email>
							<idno type="ORCID">0009-0000-6617-0756</idno>
						</author>
						<author>
							<persName><forename type="first">Joel</forename><surname>Mackenzie</surname></persName>
							<email>joel.mackenzie@uq.edu.au</email>
							<idno type="ORCID">0000-0001-7992-4633</idno>
						</author>
						<author>
							<persName><forename type="first">Gianluca</forename><surname>Demartini</surname></persName>
							<email>g.demartini@uq.edu.au</email>
							<idno type="ORCID">0000-0002-7311-3693</idno>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The University of Queensland</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<region>Queensland</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models and Challenges</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-07-30">30 Jul 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">02A294FD52DCA84FD9BDFB19BD53B9E3</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2410.21306v3[cs.CL]</idno>
					<note type="submission">Manuscript submitted to ACM Manuscript submitted to ACM</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-28T12:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural Language Processing</term>
					<term>Artificial Intelligence</term>
					<term>Legal Domain</term>
					<term>Law</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural Language Processing (NLP) is revolutionising the way both professionals and laypersons operate in the legal field. The considerable potential for NLP in the legal sector, especially in developing computational assistance tools for various legal processes, has captured the interest of researchers for years. This survey follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework, reviewing 154 studies, with a final selection of 131 after manual filtering. It explores foundational concepts related to NLP in the legal domain, illustrating the unique aspects and challenges of processing legal texts, such as extensive document lengths, complex language, and limited open legal datasets. We provide an overview of NLP tasks specific to legal text, such as Document Summarisation, Named Entity Recognition, Question Answering, Argument Mining, Text Classification, and Judgement Prediction. Furthermore, we analyse both developed legal-oriented language models, and approaches for adapting general-purpose language models to the legal domain. Additionally, we identify sixteen open research challenges, including the detection and mitigation of bias in artificial intelligence applications, the need for more robust and interpretable models, and improving explainability to handle the complexities of legal language and reasoning.</p><p>CCS Concepts: ‚Ä¢ General and reference ‚Üí Surveys and overviews; ‚Ä¢ Applied computing ‚Üí Law; ‚Ä¢ Computing methodologies ‚Üí Natural language processing; Artificial intelligence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Advancements in Natural Language Processing (NLP) have significantly impacted the legal domain by simplifying complex tasks, such as Legal Document Summarisation (LDS), Legal Argument Mining (LAM), enhancing legal text comprehension for laypersons, and improving Legal Question Answering (LQA) and Legal Judgement Prediction (LJP) <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b107">107,</ref><ref type="bibr" target="#b116">116]</ref>. These improvements -like in many other data-driven fields -are primarily attributed to advancements in Neural Network (NN) architectures, such as transformer models <ref type="bibr" target="#b134">[134]</ref>. NLP techniques now enable machines to generate text, answer legal questions, draft regulations, and simulate legal reasoning, which have the potential to revolutionise legal practices <ref type="bibr" target="#b60">[61]</ref>. Applications, such as contract review <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b133">133]</ref> and case prediction <ref type="bibr" target="#b96">[96,</ref><ref type="bibr" target="#b136">136]</ref> have been automated to a large extent, speeding up processes, reducing human error, and cutting operational costs <ref type="bibr" target="#b154">[154]</ref>. Additionally, the use of NLP allows lawyers and legal professionals to reduce their workload, enhance their efficiency, and minimise errors in decision-making processes <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b116">116]</ref>. Despite rapid developments in NLP technology, significant challenges remain in the legal context due to lengthy documents, complex legal language, and complicated document structures <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b95">95,</ref><ref type="bibr" target="#b125">125,</ref><ref type="bibr" target="#b136">136,</ref><ref type="bibr" target="#b147">147]</ref>. Despite these advantages, the integration of NLP in the legal domain is not without challenges, especially in terms of fairness, bias, and explainability issues <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b121">121,</ref><ref type="bibr" target="#b129">129]</ref>. The use of Artificial Intelligence (AI) in legal applications must follow strict standards of accuracy, fairness, and transparency, given the potential impact on clients' lives and rights. Nonetheless, Large Language Models (LLMs) have demonstrated potential to enhance the efficiency, fairness, and precision of legal tasks <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b57">58]</ref>. This survey article explores the current landscape of NLP applications within the legal domain. It discusses its potential benefits and the practical challenges it poses. NLP is a broad field covering a wide range of techniques for processing, analysing, and understanding human language. By examining the latest advancements and applications of NLP in law, this article provides a comprehensive overview of the field. Table <ref type="table">1</ref> summarises the scope of the survey and categorise the research into several areas: LQA, LJP, Legal Text Classification (LTC), LDS, legal Named Entity Recognition (NER), LAM, legal corpora and legal Language Models (LMs). Each category lists relevant projects and papers, and shows the work being done in each sub-field. Notably, there is comparatively less research in NER and legal corpora, whereas LDS and LQA have seen extensive research activity, with a substantial number of datasets and research contributions. This summary provides an overview of how NLP techniques are applied to various challenges in the legal domain and offers insights into future directions of AI in legal practice.</p><p>Table <ref type="table">1</ref>. An overview of the research areas in legal NLP and the key publications discussed in this survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Legal Natural Language Processing Language Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Li et al. <ref type="bibr" target="#b73">[74]</ref>, Mamakas et al. <ref type="bibr" target="#b84">[85]</ref> Models Al-qurishi et al. <ref type="bibr" target="#b1">[2]</ref>, Chalkidis et al. <ref type="bibr" target="#b19">[20]</ref>, Colombo et al. <ref type="bibr" target="#b26">[27]</ref>, Shi et al. <ref type="bibr" target="#b122">[122]</ref>, Xiao et al. <ref type="bibr" target="#b140">[140]</ref> Datasets For Pre-training Henderson et al. <ref type="bibr" target="#b55">[56]</ref>, Niklaus et al. <ref type="bibr" target="#b98">[98]</ref> Benchmarks Barale et al. <ref type="bibr" target="#b8">[9]</ref>, Chalkidis et al. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, Goebel et al. <ref type="bibr" target="#b50">[51]</ref>, Niklaus et al. <ref type="bibr" target="#b97">[97]</ref>, Park and James <ref type="bibr" target="#b104">[104]</ref>, Rabelo et al. <ref type="bibr" target="#b111">[111]</ref>, Xiao et al. <ref type="bibr" target="#b141">[141]</ref>, Zheng et al. <ref type="bibr" target="#b151">[151]</ref>, √ñstling et al. <ref type="bibr" target="#b157">[157]</ref> Tasks Argument Mining Habernal et al. <ref type="bibr" target="#b54">[55]</ref>, Palau and Moens <ref type="bibr" target="#b101">[101]</ref>, Poudyal et al. <ref type="bibr" target="#b108">[108]</ref>, Santin et al. <ref type="bibr" target="#b115">[115]</ref> Named Entity Recognition Au et al. <ref type="bibr" target="#b6">[7]</ref>, Dozier et al. <ref type="bibr" target="#b34">[35]</ref>, Kalamkar et al. <ref type="bibr" target="#b64">[65]</ref>, Leitner et al. <ref type="bibr" target="#b71">[72]</ref>, PƒÉis et al. <ref type="bibr" target="#b110">[110]</ref>, SmƒÉdu et al. <ref type="bibr" target="#b123">[123]</ref> Document Summarisation Farzindar and Lapalme <ref type="bibr" target="#b39">[40]</ref>, Gelbart and Smith <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref>, Jain et al. <ref type="bibr" target="#b59">[60]</ref>, Liu et al. <ref type="bibr" target="#b77">[78]</ref>, Moens et al. <ref type="bibr" target="#b91">[91]</ref>, Moro et al. <ref type="bibr" target="#b93">[93]</ref>, Polsley et al. <ref type="bibr" target="#b106">[106]</ref>, Schraagen et al. <ref type="bibr" target="#b117">[117]</ref>, Shen et al. <ref type="bibr" target="#b120">[120]</ref>, Zhong and Litman <ref type="bibr" target="#b156">[156]</ref> Text Classification Bambroo and Awasthi <ref type="bibr" target="#b7">[8]</ref>, Bhattacharya et al. <ref type="bibr" target="#b12">[13]</ref>, Chalkidis et al. <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, Elnaggar et al. <ref type="bibr" target="#b36">[37]</ref>, Galassi et al. <ref type="bibr" target="#b42">[43]</ref>, Grabmair et al. <ref type="bibr" target="#b51">[52]</ref>, Graham et al. <ref type="bibr" target="#b52">[53]</ref>, Lee and Lee <ref type="bibr" target="#b70">[71]</ref>, Mamooler et al. <ref type="bibr" target="#b85">[86]</ref>, Nguyen et al. <ref type="bibr" target="#b94">[94]</ref>, Papaloukas et al. <ref type="bibr" target="#b102">[102]</ref>, Song et al. <ref type="bibr" target="#b124">[124]</ref>, Tuggener et al. <ref type="bibr" target="#b133">[133]</ref>, Wang et al. <ref type="bibr" target="#b137">[137]</ref> Judgement Prediction Chalkidis et al. <ref type="bibr" target="#b16">[17]</ref>, Feng et al. <ref type="bibr" target="#b40">[41]</ref>, Liu et al. <ref type="bibr" target="#b80">[81]</ref>, Luo et al. <ref type="bibr" target="#b82">[83]</ref>, Ma et al. <ref type="bibr" target="#b83">[84]</ref>, Medvedeva et al. <ref type="bibr" target="#b90">[90]</ref>, Niklaus et al. <ref type="bibr" target="#b96">[96]</ref>, Semo et al. <ref type="bibr" target="#b118">[118]</ref>, Tong et al. <ref type="bibr" target="#b132">[132]</ref>, Xu et al. <ref type="bibr" target="#b142">[142]</ref>, Yang et al. <ref type="bibr" target="#b143">[143]</ref>, Ye et al. <ref type="bibr" target="#b144">[144]</ref>, Zhang et al. <ref type="bibr" target="#b149">[149]</ref>, Zhong et al. <ref type="bibr" target="#b152">[152,</ref><ref type="bibr" target="#b153">153]</ref> Question Answering Askari et al. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, B√ºttner and Habernal <ref type="bibr" target="#b14">[15]</ref>, Chen et al. <ref type="bibr" target="#b22">[23]</ref>, Huang et al. <ref type="bibr" target="#b58">[59]</ref>, Khazaeli et al. <ref type="bibr" target="#b67">[68]</ref>, Louis et al. <ref type="bibr" target="#b81">[82]</ref>, Sovrano et al. <ref type="bibr" target="#b125">[125,</ref><ref type="bibr" target="#b126">126]</ref>, Yuan et al. <ref type="bibr" target="#b146">[146]</ref>, Zhang et al. <ref type="bibr" target="#b150">[150]</ref>, Zhong et al. <ref type="bibr" target="#b155">[155]</ref> This document is organised as follows. Firstly, In Section 2, we discuss previous surveys in this multidisciplinary domain. In Section 3, we provide a detailed overview of legal language and the basic principles of NLP as they apply to the legal domain. In Section 4, we briefly explain the research methodology of this work and how we extracted the resources. In sections 5-11, we explore various NLP tasks that are tailored for legal applications, focusing on their for training and evaluating legal NLP tasks, emphasising their characteristics and the implications they have for model performance. Following this, in Section 12, we investigate the development of LMs that have been specifically adapted to the legal field. Finally, in Section 13, we address the key challenges associated with deploying NLP technologies in legal settings, discussing both current issues and potential solutions. Since this survey contains many acronyms, Table <ref type="table" target="#tab_0">2</ref> provides the list of acronyms and their meanings to make it easier to follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Several studies have examined the use of NLP in the legal domain, each focusing on different problems and applications.</p><p>To provide a comprehensive understanding of the existing research on integrating AI within the legal domain, we present an overview of recent literature reviews, as summarised in Table <ref type="table">3</ref>. Most survey papers on intelligent legal systems focus either on traditional NLP technologies for specific tasks, such as LJP and LDS, or adopt a broader approach but still overlook certain applications. As illustrated in Table <ref type="table">3</ref>, there is yet to be a comprehensive survey that thoroughly examine all facets of this multidisciplinary field; Our current work aims to bridge this gap by offering a comprehensive survey of all NLP tasks, existing datasets and corpora and LMs in the legal domain.</p><p>Dias et al. <ref type="bibr" target="#b32">[33]</ref> discussed AI and NLP concepts and their applications in the legal domain. Their study did not analyse legal datasets, specific NLP tasks, or legal LLMs. Our work, in contrast, reviews NLP tasks in the legal domain, including LQA, LDS and LTC, along with legal datasets and corpora. Sun <ref type="bibr" target="#b128">[128]</ref> examined two NLP tasks in the legal domain, such as LJP and statutory reasoning. Their study reviewed three datasets and two LLMs related to these tasks. Unlike Sun's work, our survey covers a wider range of NLP tasks and includes legal corpora and datasets. Cui et al. <ref type="bibr" target="#b27">[28]</ref> focused on LJP, reviewing 43 datasets in nine languages. Their study evaluated classification, text generation and regression tasks. It also discussed pre-trained LMs used for LJP. Our work differs by covering multiple NLP tasks, legal corpora and dataset availability.</p><p>Anh et al. <ref type="bibr" target="#b3">[4]</ref> explored challenges in legal language processing and how LLMs can address them. Their study summarised six NLP tasks and discussed ethical concerns, including bias, privacy and transparency. While these issues are relevant, our survey focuses on existing NLP methods, datasets and legal corpora for pre-training and fine-tuning;</p><p>we discuss elements of bias, fairness, privacy, interpretability, and explainability in Section 13.</p><p>Table <ref type="table">3</ref>. An overview of existing surveys on NLP in the legal domain. We use a check mark (‚úì) to indicate papers that study the most of the existing research on each subject in legal NLP. Papers that do not address a subject receive a cross (‚úó), and those that partially cover specific subjects are marked with a dash (-).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Covered Subjects in the Legal Domain Published Year Dataset NLP Tasks LM Large Corpora Dias et al. [33] ---‚úó 2022 Sun [128] ‚úì -‚úì ‚úó 2023 Cui et al. [28] ‚úì -‚úì ‚úó 2023 Anh et al. [4] ‚úó ‚úì ‚úì ‚úó 2023 Ganguly et al. [45] --‚úì ‚úó 2023 Chen et al. [25] ‚úì ‚úì ‚úì ‚úó 2024 Krasadakis et al. [69] ----2024 Ganguly et al. [45] surveyed legal text processing challenges, such as NER and sentence boundary detection. Their study reviewed historical developments in AI and law research, as well as recent NLP advancements. It covered LDS and LJP but did not examine LQA, LTC or legal corpora. Our work covers all of these areas.</p><p>Chen et al. <ref type="bibr" target="#b24">[25]</ref> studied LLMs in finance, healthcare and law. While attempting to provide a broad view of LLM applications in the legal domain, their study's scope resulted in a less detailed review of specific NLP tasks and datasets.</p><p>Additionally, it did not examine large legal corpora or pre-training methods, aspects that our survey addresses.</p><p>Krasadakis et al. <ref type="bibr" target="#b68">[69]</ref> focused on challenges and advancements in some NLP tasks, such as NER and Relation</p><p>Extraction. Unlike our study, which reviews all NLP tasks alongside datasets and legal corpora, their work primarily investigated existing LLMs for the legal domain.</p><p>The main difference between our work and previous surveys is that our survey aims to provide a more general view of all aspects of NLP tasks in the legal domain, rather than focusing solely on specific applications. The main contributions of this survey are summarised as follows: <ref type="bibr" target="#b0">(1)</ref> This article extends previous surveys by examining a broad spectrum of studies and applications of legal NLP. By discussing datasets and large corpora in 24 languages and exploring popular legal LMs, this survey establishes itself as an important resource in the field of legal NLP. <ref type="bibr" target="#b1">(2)</ref> The survey offers an in-depth look at the challenges of integrating NLP with legal applications, with detailed discussions on technical solutions that tackle these issues, thereby enhancing understanding and encouraging further research in this evolving field. <ref type="bibr" target="#b2">(3)</ref> This survey also highlights the existing research gaps in legal NLP, identifying areas that require further exploration and development and providing a road-map for future research efforts in the legal NLP domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background and Foundational Concepts</head><p>In this section, we explain how NLP can be applied within the legal domain. We begin by outlining the unique characteristics of legal documents and legal language, highlighting the challenges these features pose for NLP applications.</p><p>We then introduce core NLP concepts, methods, and paradigms relevant to legal texts, before discussing the recent impact of LLMs in the legal sector. Finally, we summarise key journals, conferences, and workshops that shape the field of legal NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Legal Documents</head><p>Legal documents, such as court filings, judicial judgements, statutes, treaties, contracts, and formal legal correspondence encode the authoritative rules, rights, and duties that underpin our legal systems. They transmit legally operative information, including procedural requirements, enforceable obligations, and interpretative reasoning. Lawyers, judges, regulators, and academics consult these sources to analyse cases, interpret legislation, draft or negotiate agreements, verify compliance, and support teaching. Access is typically provided through official court portals, statutory databases, and commercial research platforms.</p><p>3.1.1 Legal language and its characteristics. Legal language is characterised by unique features that distinguish it from everyday language, primarily because of its role within the legal system. One prominent feature is its formality, where legal texts often employ a more formal vocabulary and syntax to ensure precision and avoid ambiguity <ref type="bibr" target="#b49">[50]</ref>.</p><p>This formality is important, as the meaning of terms can have legal effects. Specialised vocabularies, fixed syntactic patterns, and even punctuation are chosen to maximise precision and avoid ambiguity, as small drafting choices can decisively alter legal consequences. One such example appeared in the 2006 dispute between Rogers Communications and Bell Aliant, <ref type="foot" target="#foot_0">1</ref> where a single comma in the English version of a termination clause was interpreted to permit early cancellation of a multimillion-dollar pole-access contract, whereas the absence of that comma in the equally-authentic</p><p>French text preserved the original five-year lock-in. This case illustrates how punctuation alone can shift rights and liabilities. Legal documents also typically use passive constructions and complex sentence structures to provide detailed and comprehensive descriptions <ref type="bibr" target="#b49">[50]</ref> without directly attributing actions or intentions to specific parties.</p><p>Another distinctive aspect of legal language is its reliance on specialised words and phrases. These include terms with specific legal meanings, archaic words rarely used in everyday language, and standardised phrases embedded in legal tradition <ref type="bibr" target="#b49">[50]</ref>. Such language can make legal documents less accessible to non-specialists, necessitating accurate interpretation by legal professionals.</p><p>Furthermore, legal language is heavily intertextual, frequently referencing other legal texts, such as statutes, regulations, and case law. This ensures that legal arguments are grounded in existing legal frameworks and previous cases.</p><p>The extensive use of citations and references situates each document within a wider legal discourse. Such intertextuality requires legal professionals to understand both the texts themselves and the broader legal context in which they operate.</p><p>To illustrate the intertextuality of legal language, Figure <ref type="figure" target="#fig_1">1</ref>  This citation refers to section 212 of the Immigration and Nationality Act, subsection (a), paragraph <ref type="bibr" target="#b4">(5)</ref>, which outlines conditions for inadmissibility to the US. In the "Source" section, the citation "56 FR 30422, July 2, 1991," indicates a Federal Register publication: "56 FR" is the volume number, "30422" the page where the document begins and "July 2, 1991" the publication date.</p><p>Disambiguation titles and nested entities are other issues in legal contexts <ref type="bibr" target="#b68">[69]</ref>. Disambiguation titles, such as "The President of USA" require precise identification based on contextual details, such as time and location. Nested entities, where titles of legislative articles refer to other laws, introduce further complexity. To further complicate matters, legal documents are frequently provided in non-machine-readable PDF formats, complicating data extraction and processing. Additionally, the variation in legal reasoning, which includes rule-based, analogical and evidentiary arguments, along with changes in legal standards, creates challenges for applying conventional NLP models <ref type="bibr" target="#b41">[42]</ref>. Elements such as the peculiar use of punctuation affecting text segmentation and the frequent presence of digits and numbers, can also disrupt traditional NLP pipelines. These challenges demonstrate the need for specialised NLP solutions tailored to the legal domain.</p><p>3.1.2 Domains with Shared Characteristics. Other domains exhibit features similar to those of legal texts, such as specialised vocabularies, large-scale corpora and cross-referencing. In the medical domain, texts -including clinical notes, patient records, and research articles -rely on domain-specific terminology, diagnostic labels, and biological taxonomies, often involving case-based analyses akin to legal reasoning. Similarly, software documentation and source code contain specialised programming terms and algorithmic descriptions and are characterised by large repositories with numerous cross-references to libraries and functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Legal NLP</head><p>The legal sector has been exploring AI-driven solutions since the late 20th century, applying NLP techniques to automate legal processes. NLP applications in the legal field include drafting client briefs and analysing large document sets, enabling smaller firms to compete more effectively with larger ones <ref type="bibr" target="#b88">[89]</ref>. These applications are also very important for compliance and due-diligence checks -required when companies merge their business, for instance -and greatly supports legal education and learning in fast-changing fields <ref type="bibr" target="#b88">[89]</ref>. Legal NLP can also enhance the analysis of complex legal documents, thereby assisting with complex decision-making processes <ref type="bibr" target="#b57">[58]</ref>.</p><p>The foundation of NLP is text and the legal domain primarily consists of textual data <ref type="bibr" target="#b2">[3]</ref>, including statutes, case law, contracts and regulations. Given the text-intensive nature of the legal field, NLP offers potential to change how legal professionals interact with and use this information. By leveraging advanced algorithms and Machine Learning (ML) models, legal NLP aims to make legal texts more accessible, interpretable and actionable <ref type="bibr" target="#b57">[58]</ref>.</p><p>3.2.1 Basic foundations and concepts of NLP. The integration of NLP in the legal domain relies on foundational techniques that enable the processing and analysis of legal texts. These techniques form the basis for various applications, transforming unstructured legal documents into structured, actionable information. This section introduces key NLP methods, ML paradigms and text retrieval technique.</p><p>(1) Core NLP methods:</p><p>‚Ä¢ Tokenization: Tokenization is the process of breaking text into smaller units, typically words or subwords, known as tokens. It is a fundamental step in NLP, allowing structured or unstructured text to be analysed. In legal NLP, tokenization facilitates processing lengthy documents by segmenting them into manageable parts and prepares the input text for numerical representation through word embeddings. ‚Ä¢ Word Embeddings: Embeddings represent words as continuous (numeric) vectors in a high-dimensional space, designed to capture semantic relationships. These embeddings enable models to encode word meanings and relationships, which are essential for tasks such as legal text similarity analysis and document classification.</p><p>‚Ä¢ Transformers: The transformer architecture is a NN model designed to process text by first identifying connections between input words using self-attention. In this process, it computes attention weights (which determine the importance of each word based on its context) across the entire input sequence before generating output representations. Transformers operate on word embeddings and refine these embeddings by incorporating context from the entire sequence.</p><p>‚Ä¢ PLMs: PLMs, such as Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" target="#b31">[32]</ref>, are transformerbased models pre-trained on large text corpora using self-supervised objectives. These models learn linguistic patterns and can be fine-tuned for specific legal NLP tasks. PLMs leverage transformer architectures and pre-trained embeddings to perform NLP tasks.</p><p>(2) ML paradigms for NLP:</p><p>‚Ä¢ Multi-task Learning (MTL): MTL is an approach where a model learns multiple related tasks simultaneously, leveraging shared knowledge across tasks. This technique improves model robustness and efficiency, particularly in data-scarce legal NLP applications <ref type="bibr" target="#b23">[24]</ref>. ‚Ä¢ Parameter-Efficient Fine-Tuning (PEFT): PEFT is a method for adapting PLMs to new tasks that involves freezing the majority of the model's parameters, relying on updating just a small subset "fine-tuned" to the downstream task. This approach significantly reduces the computational resources and time required for fine-tuning, making it particularly effective in resource-limited scenarios, while still achieving competitive performance in tasks, such as text generation <ref type="bibr" target="#b74">[75]</ref>.</p><p>These ML paradigms enhance the performance of core NLP methods, particularly PLMs, by tailoring models to specific tasks and optimising their training efficiency.</p><p>(3) Text retrieval technique:</p><p>‚Ä¢ Retrieval-Augmented Generation (RAG): RAG combines traditional Information Retrieval (IR) methods with generative NLP models, allowing systems to retrieve external knowledge before generating responses.</p><p>Text retrieval techniques, such as RAG complement the core NLP methods by providing additional context and external information that enhances the generation and refinement of texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.2</head><p>LLMs as an application of NLP in the legal sector. LLMs are a category of Deep Learning (DL)-based NLP models trained on extensive text corpora to process and generate human-like language. These models, typically based on Transformer architectures, learn linguistic patterns from diverse sources, enabling them to perform tasks, such as text summarisation, document analysis and Question Answering (QA). LLMs have gained widespread attention in NLP applications, particularly following the release of ChatGPT in November 2022 <ref type="bibr" target="#b99">[99]</ref>.</p><p>A notable demonstration of NLP's potential in the legal sector occurred when GPT-4 was reported to have passed the Uniform Bar Exam near the 90th percentile, underscoring the technology's potential <ref type="bibr" target="#b66">[67]</ref>. However, subsequent analyses by Mart√≠nez <ref type="bibr" target="#b87">[88]</ref> suggest that its actual performance may be considerably lower, possibly around the 48th percentile overall and 15th percentile on essays. Similarly, further research reveals that although ChatGPT can achieve moderate success on certain legal classification tasks, smaller fine-tuned models still outperform it by about 30 percentage points <ref type="bibr" target="#b15">[16]</ref>. Another study highlights a tendency for LLMs to hallucinate legal content at high rates-up to 58% in some cases, raising reliability concerns for complex tasks <ref type="bibr" target="#b28">[29]</ref>. Despite these drawbacks, lawyers and law students remain conscious of the broader impact of such models: a recent LexisNexis survey <ref type="bibr" target="#b72">[73]</ref> shows that about half of all lawyers believe LLMs will transform legal practice, with 92% anticipating at least some impact. Furthermore, 77% of respondents foresee efficiency gains for legal professionals and 63% predict changes in how law is taught and studied.</p><p>3.2.3 Key publications and conferences in legal NLP. This section highlights the key journals, conferences and workshops that serve as platforms for sharing advancements and insights at the intersection of NLP and the legal domain. These resources provide opportunities for researchers to engage with cutting-edge work in legal NLP. Several leading journals focus on the intersection of AI, NLP and the legal domain. "Artificial Intelligence and Law, " published by Springer, is a leading journal that features research articles on legal reasoning, legal IR and legal knowledge representation. A recent special issue, Applications and Evaluation of LLMs in the Legal Domain, examines the use of LLMs in legal tasks such as summarisation, judgement prediction and contract drafting, while also addressing concerns, such as bias, misinformation and regulatory compliance. Additionally, the "Journal of Law and Information Technology" focuses on the application of information technology in law, including research AI. Conferences significantly advance research and promote collaboration in legal NLP. The International Conference on Artificial Intelligence and Law (ICAIL) is a biennial event showcasing advances in AI applications for the legal domain, including NLP and ML. The Conference on Legal Knowledge and Information Systems (JURIX) is an annual event that focuses on legal informatics and NLP technologies. In addition to these dedicated venues, prominent legal NLP research has also been published in broader AI, NLP and IR conferences, including NeurIPS, ACL (and its associated workshops), NAACL, EMNLP, SIGIR, IJCAI, AAAI and LREC. In legal NLP, workshops also attract strong research contributions. The workshop on Automated Semantic Analysis of Information in Legal Texts focuses on NLP and semantic analysis of legal documents. The International workshop on Juris-Informatics (JURISIN) brings together researchers from law, social science and technology to discuss foundational and practical issues at the intersection of legal theory and informatics. The Natural Legal Language Processing (NLLP) workshop provides a platform for discussing NLP technologies tailored for legal texts and is often part of major NLP conferences. The EXplainable AI in Law (XAILA) workshop focuses on the explainability of AI systems in legal contexts, aiming to improve transparency and trust in AI applications. The Competition on Legal Information Extraction/Entailment (COLIEE) is an annual event that challenges participants to develop innovative solutions for legal information extraction and entailment tasks. Additionally, the Legal Track at the Text Retrieval Conference (TREC), which ran from 2006 to 2011, focused on evaluating IR techniques for legal document review, providing a venue for researchers to test and Manuscript submitted to ACM</p><p>compare methods in the context of e-discovery. Its contributions include benchmark datasets and evaluation metrics that were used to assess retrieval performance in legal text processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>This survey follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework <ref type="bibr" target="#b100">[100]</ref>.</p><p>It ensures a transparent and comprehensive assessment of research on NLP tasks within the legal sector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Search Strategy</head><p>We performed a systematic search across two academic databases to identify relevant studies, including: Google Scholar and IEEE Xplore. Then, search queries were crafted to capture studies that focused on the application of NLP to legal tasks. The search was defined by the following two queries:</p><p>‚Ä¢ Query 1: ("Natural Language Processing" OR "NLP") AND ("Legal" OR "Law")</p><p>‚Ä¢ Query 2: ("Legal" AND ("Named Entity Recognition" OR "NER" OR "Document Summarisation" OR "Text Classification" OR "Document Classification" OR "Judgement Prediction" OR "Question Answering" OR "Corpus" OR "Language Model" OR "Argument Mining"))</p><p>Our search covered publications within the following date ranges for each NLP task: LQA from 2020-2024, LJP from 2017-2024, LTC from 2018-2023, LDS from 2016-2024, legal NER from 2010-2022, and LAM from 2009-2024. Furthermore, we limited our search for legal corpora to 2021-2024 and legal LMs from 2020-2024. This approach ensured the inclusion of recent advancements. Peer-reviewed journal articles and high-quality conference proceedings were prioritised, with secondary consideration given to relevant non-peer-reviewed sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Study Selection</head><p>A total of 154 studies were initially identified from the database search. To refine this list, we applied manual review. This process involved:</p><p>(1) Title and Abstract Screening: We reviewed the titles and abstracts of all retrieved studies to assess their relevance to the predefined legal NLP tasks. Studies unrelated to the core legal NLP and its tasks were excluded.</p><p>(2) Full-Text Review: Articles that passed the initial screening underwent a detailed full-text review to confirm their relevance, quality and alignment with the inclusion criteria. During this phase, we also examined the literature review sections of each paper to ensure that the studies not only contributed original findings but also demonstrated a comprehensive understanding of the existing legal NLP research landscape.</p><p>(3) Final Selection: Of the original 154 studies, 131 met the inclusion criteria and were retained. These studies were selected for their direct relevance to key legal NLP tasks, methodological quality, and engagement with existing literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Eligibility Criteria</head><p>To determine which studies were included in the final synthesis, we established the following criteria:</p><p>‚Ä¢ Inclusion Criteria:</p><p>-The study must focus on at least one of the target NLP tasks (LQA, legal NER, LJP, LDS, LTC, LAM), or it must focus on legal LMs or legal corpora.</p><p>-The study must present empirical research or significant methodological contributions to legal NLP.</p><p>-Both peer-reviewed and non-peer-reviewed studies were considered if they provided valuable insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>‚Ä¢ Exclusion Criteria:</head><p>-Studies focused exclusively on unrelated areas such as IR methods, pattern mining, information extraction or similarity detection without a clear application to the specific legal NLP tasks mentioned.</p><p>-General NLP studies without a focus on legal applications.</p><p>-Editorials, opinion pieces or other non-research articles.</p><p>-Papers that did not meet basic methodological standards were not included in the final analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Legal Question Answering</head><p>LQA involves responding to legal queries, a task typically performed by professionals with domain expertise. It requires a comprehensive review of relevant laws, careful interpretation of statutes and regulations, and the application of legal principles and precedent to the facts. LQA aims to provide legal advice, helping individuals and businesses navigate the complex legal landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>LQA datasets are a specialised resource designed to facilitate research in the domain of legal NLP. They consist of a collection of legal questions and corresponding answers, drawn from various legal documents and case law. Most questions in the LQA datasets fall into two main categories: knowledge-driven questions (KD-questions) and caseanalysis questions (CA-questions) <ref type="bibr" target="#b155">[155]</ref>. KD-questions are centred around the understanding of specific legal concepts, whereas CA-questions involve the analysis of actual legal cases. Both categories demand advanced reasoning skills and a deep comprehension of the text, making LQA a particularly challenging task in the field of NLP.</p><p>Zhong et al. <ref type="bibr" target="#b155">[155]</ref> introduce JEC-QA, a dataset with 26,365 multiple-choice questions from the National Judicial Examination of China and related websites. Each question provides four possible answers and is annotated with the type of reasoning required, such as word matching, conceptual understanding, numerical analysis, multi-paragraph comprehension and multi-hop inference. This dataset poses challenges for QA models, highlighting the gap between machine performance and human expertise in legal reasoning. Sovrano et al. <ref type="bibr" target="#b125">[125]</ref> present the Q4PIL dataset, designed to evaluate automated QA systems in the domain of Private International Law. It includes 17 carefully selected questions based on key EU regulations -Rome I, Rome II and Brussels I bis -with answers derived directly from these regulations. The questions are classified based on their specificity, allowing for nuanced analysis of context-dependency in legal reasoning. This dataset supports the assessment of QA systems intended for legal professionals navigating complex cross-border issues.</p><p>EQUALS <ref type="bibr" target="#b22">[23]</ref> is a large-scale annotated LQA dataset in Chinese law, containing 6,914 question-answer pairs with answers based on specific law articles. Curated by senior law students, it covers 10 collections of Chinese laws and includes annotations indicating the type of reasoning required for each question. The dataset ensures that answers are precise excerpts from relevant law articles, making it valuable for developing advanced LQA systems that can aid in legal research and decision-making.</p><p>B√ºttner and Habernal <ref type="bibr" target="#b14">[15]</ref> introduce GerLayQA, a dataset supporting LQA for laypersons in Germany, focusing on the civil-law system. It contains 21,538 real-world questions posed by laypersons, paired with expert answers from lawyers grounded in specific paragraphs of German legal codes. The dataset was constructed through filtering and quality assurance to ensure accuracy and relevance, making it a valuable resource for developing LQA systems that interpret and apply German law to everyday legal inquiries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Approaches</head><p>Recently, DL has been applied in LQA through NN models trained on large datasets to identify complex patterns and relationships. These models analyse posed questions, recognise relevant legal topics, and generate appropriate answers based on learned patterns and memory.</p><p>Modern ML approaches to LQA use NN architectures to process natural language. Popular architectures include Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and Convolutional Neural Networks (CNN), which can be fine-tuned for QA tasks. These models adapt to new patterns, capture contextual information and generate more accurate responses. Transformer-based models, such as BERT and, more recently, ChatGPT, have proven particularly effective in NLP tasks. These models use the transformer architecture and self-attention mechanisms to learn the context of text to model the patterns and word dependencies in text. This allows them to provide relevant answers by weighting the importance of different parts of the input based on its contextual importance. In the following paragraphs, we will study the existing LQA works in the legal domain.</p><p>Huang et al. <ref type="bibr" target="#b58">[59]</ref> introduce the Artificial Intelligence Law Assistant, the first Chinese LQA system that integrates a legal Knowledge Graph (KG) to enhance query comprehension and answer ranking. The system collects a largescale QA corpus from an online legal forum and constructs a legal KG with over 42,000 legal concepts. It employs a knowledge-enhanced interactive attention network using Bidirectional LSTM (Bi-LSTM) and co-attention mechanisms to enrich semantic representations of question-answer pairs with legal domain knowledge. Additionally, it provides visual explanations for selected answers, offering users a clear understanding of the QA process.</p><p>Khazaeli et al. <ref type="bibr" target="#b67">[68]</ref> develop an IR-based QA system tailored to the legal domain, combining sparse term-based search (BM25) and dense vector techniques (semantic embeddings) as input to a BERT-based answer re-ranking module. The system utilises Legal GloVe and Legal Siamese BERT embeddings to enhance retrieval performance. An "answer finder" component computes the probability that a passage answers the question using a BERT sequence classifier fine-tuned</p><p>on question-answer pairs, thereby enhancing the model's ability to discriminate relevant answers.</p><p>Li et al. <ref type="bibr" target="#b75">[76]</ref> introduce a retrieve-then-answer framework featuring a Graph-Based Evidence Retrieval and Aggregation Network (GESAN) to enhance LQA on the JEC-QA dataset <ref type="bibr" target="#b155">[155]</ref>. The framework leverages legal knowledge by predicting question topics and retrieving relevant paragraphs using BM25. GESAN aggregates the evidence and processes it along with the question and options to generate accurate predictions, demonstrating improved reasoning capabilities in LQA.</p><p>Askari et al. <ref type="bibr" target="#b4">[5]</ref> tackle legal expert finding on QA platforms by building query-dependent textual profiles for lawyers.</p><p>Using data from the Avvo forum,<ref type="foot" target="#foot_3">foot_3</ref> they represent each lawyer with four facets -comment content, positive sentiment, negative sentiment, and answer recency -derived from past answers and comments. A separate BERT model is fine-tuned for each facet and the scores are linearly combined with a document-based BERT ranker to produce the final ranking.</p><p>Zhang et al. <ref type="bibr" target="#b150">[150]</ref> re-frame LQA as a generation task with GLQA, a retrieve-then-generate framework that runs both retrieval and generation in a single T5 model via MTL. A knowledge retriever encodes questions and law articles into dense embeddings, then retrieves the top-ùëò relevant statutes. These articles are concatenated with the question and passed to a knowledge-enhanced generator that produces an answer grounded in the retrieved text.</p><p>Louis et al. <ref type="bibr" target="#b81">[82]</ref> propose an end-to-end "retrieve-then-read" system that generates long-form answers to statutory questions. A lightweight bi-encoder first retrieves the most relevant French legal provisions, after which an instructiontuned LLM, adapted via in-context learning and PEFT, composes detailed answers that cite those statutes. To ensure transparency, the model also outputs extractive rationales, listing the exact paragraphs that justify each response. Sovrano et al. <ref type="bibr" target="#b126">[126]</ref> propose DiscoLQA, a discourse-based LQA system that focuses on important discourse elements, such as Elementary Discourse Units and Abstract Meaning Representations. This approach helps the answer retriever identify the most relevant parts of the discourse, enhancing retrieval accuracy. They introduce the Q4EU dataset, containing over 70 questions and 200 answers on six European norms, demonstrating improved performance in LQA even without domain-specific training.</p><p>Yuan et al. <ref type="bibr" target="#b146">[146]</ref> present a three-step approach to bridge the legal knowledge gap by creating CLIC-pages-snippets that explain technical legal concepts in layperson's terms. They construct a legal question bank containing legal questions answered by CLIC-pages, using GPT-3 <ref type="bibr" target="#b13">[14]</ref> to generate machine-generated questions. The study shows that machine-generated questions improve scalability and access to legal information for non-experts.</p><p>Askari et al. <ref type="bibr" target="#b5">[6]</ref> propose a cross-encoder re-ranker (ùê∂ùê∏ ùêπùëÜ ) for legal answer retrieval, incorporating fine-grained structured inputs from community QA data to enhance retrieval performance. They introduce the LegalQA dataset containing 9,846 questions and 33,670 lawyer-curated answers. The approach involves a two-stage ranking pipeline with a BM25 retriever followed by a re-ranker, showing that integrating question tags into the input structure can bridge the knowledge gap and improve retrieval in the legal domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Legal Judgement Prediction</head><p>LJP is a key task in legal NLP, particularly in civil-law jurisdictions where judgements rely on case facts and statutory provisions <ref type="bibr" target="#b154">[154]</ref>. It seeks to predict legal outcomes from case descriptions and the applicable legislation <ref type="bibr" target="#b154">[154]</ref>. The topic has attracted growing interest from AI researchers and legal professionals because of its potential to help judges, lawyers and scholars anticipate case results based on historical data <ref type="bibr" target="#b24">[25]</ref>.</p><p>LJP is clearly a demanding and complex problem. Historical legal data can contain inherent biases that can create feedback loops and amplify discrimination if not managed carefully <ref type="bibr" target="#b68">[69]</ref>. Therefore, ensuring the impartiality of predicted rulings is crucial <ref type="bibr" target="#b68">[69]</ref>. At present, LJP is still performed chiefly by legal experts who require extensive specialised training to identify relevant statutes, define charge ranges, and set penalty terms <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>The LJP datasets are specialised resources designed to advance research in predicting judicial outcomes within the domain of legal NLP. These datasets are categorised into four main types: court view generation, law articles, charge prediction and prison term prediction. Court view datasets contain judicial opinions and summaries. Law articles datasets focus on predicting outcomes based on specific statutes or regulations. Charge prediction datasets aim to identify the charges appropriate to the case details. Prison term datasets estimate likely sentence durations given the crime and legal context. Each category presents unique challenges, requiring not only text comprehension but also the ability to apply complex legal reasoning.</p><p>The Court View Gen <ref type="bibr" target="#b144">[144]</ref> dataset is an innovative resource containing 171,981 Chinese legal cases, each involving a single defendant and a corresponding charge, covering a total of 51 charge categories. It is specifically curated to support the generation of court opinions based on charge labels. All cases were collected from the publicly available China Judgements Online repository.</p><p>Niklaus et al. <ref type="bibr" target="#b96">[96]</ref> introduce a multilingual LJP dataset from the Federal Supreme Court of Switzerland (FSCS), containing over 85,000 cases in German, French, and Italian. The dataset is annotated with publication years, legal areas, and cantons of origin, making it suitable for NLP applications in judgement prediction.</p><p>Semo et al. <ref type="bibr" target="#b118">[118]</ref> introduce the first LJP dataset centred on US class-action lawsuits. Unlike prior work that relies on court-written summaries of facts, this dataset targets outcome prediction directly from plaintiffs' complaints. A rule-based extraction system identifies the relevant text spans within each complaint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Approaches</head><p>Luo et al. <ref type="bibr" target="#b82">[83]</ref> propose an attention-based NN to enhance charge prediction by jointly modelling charge prediction and relevant law article extraction. They used Bidirectional Gated Recurrent Units (Bi-GRUs) to encode fact descriptions and an article extractor to identify top relevant law articles. The model employs an attention mechanism guided by context vectors to combine embeddings for prediction. Evaluations on Chinese judgement documents showed improved accuracy in predicting charges and providing relevant legal articles.</p><p>Zhong et al. <ref type="bibr" target="#b152">[152]</ref> introduce TopJudge, a topological MTL framework that models dependencies among subtasks in LJP, such as law article prediction, charge prediction and penalty terms. Using a directed acyclic graph, TopJudge processes subtasks in a topological order reflecting real-world legal decision-making. Evaluated on large-scale Chinese criminal case datasets, it outperformed previous models in predicting legal outcomes.</p><p>Ye et al. <ref type="bibr" target="#b144">[144]</ref> tackle court view generation from criminal case fact descriptions to improve the interpretability of charge prediction systems and support automatic legal document drafting. They frame the task as a text-to-text natural language generation problem, employing a label-conditioned sequence-to-sequence model with attention to generate court views from encoded charge labels. Their approach advances automatic legal document generation by providing explicit justifications for charge decisions.</p><p>Yang et al. <ref type="bibr" target="#b143">[143]</ref> propose a Multi-Perspective Bi-Feedback Network (MPBFN) with a Word Collocation Attention mechanism to improve LJP. The MPBFN addresses the challenges of multiple subtasks and their dependencies by using a bi-feedback mechanism for forward prediction and backward verification among subtasks. The Word Collocation Attention integrates word collocation features and numerical semantics to better predict penalties. Evaluated on the CAIL datasets <ref type="bibr" target="#b141">[141]</ref>, their model outperformed baselines in predicting law articles, charges, and penalty terms.</p><p>Chalkidis et al. <ref type="bibr" target="#b16">[17]</ref> introduce an English LJP dataset containing approximately 11,500 cases from the European Court of Human Rights (ECHR). They evaluated various neural models on this dataset, including a hierarchical version of BERT (HIER-BERT) to handle long legal documents. Their models outperformed previous feature-based approaches in tasks, such as violation classification and case importance prediction. They also explored potential biases in legal predictive models using data anonymization.</p><p>Medvedeva et al. <ref type="bibr" target="#b90">[90]</ref> use a linear Support Vector Machine (SVM) to predict whether the ECHR will find a violation of any of nine Convention articles. Trained on the textual proceedings, the model achieves an average 75% accuracy, yet performance drops to 58-68% when predicting future cases. They also found that predicting outcomes based solely on judges' surnames could achieve accuracy of 65%, highlighting potential biases in LJP data.</p><p>Zhong et al. <ref type="bibr" target="#b153">[153]</ref> introduce QAjudge, a reinforcement learning (RL)-based model designed to provide interpretable legal judgements by visualising the prediction process. QAjudge uses a Question Net to iteratively select relevant yes-no questions about case facts, an Answer Net to provide answers and a Predict Net to generate the final judgement.</p><p>The model aims to minimise the number of questions asked. Evaluated on real-world datasets, QAjudge demonstrated potential in providing reliable and transparent legal judgements.</p><p>Xu et al. <ref type="bibr" target="#b142">[142]</ref> propose the Law Article Distillation based Attention Network (LADAN), an end-to-end model addressing the issue of confusing charges in LJP by distinguishing similar law articles. The model uses a novel graph NN to learn differences between confusing law articles and an attention mechanism to extract discriminative features from fact descriptions. Experiments on real-world datasets showed that LADAN improved performance over previous methods in law article prediction, charge prediction and penalty term prediction.</p><p>Ma et al. <ref type="bibr" target="#b83">[84]</ref> introduce MSJudge, a MTL framework designed to predict legal judgements by leveraging multi-stage judicial data, including pre-trial claims and court debates. MSJudge consists of components to encode multi-stage context, model interactions among claims, facts and debates and predict judgements. Evaluated on a large civil trial dataset, MSJudge more accurately characterises the interactions among claims, facts and debates for judgement prediction, achieving improvements over state-of-the-art (SOTA) baselines.</p><p>Feng et al. <ref type="bibr" target="#b40">[41]</ref> address limitations of SOTA LJP models by proposing an event-based prediction model with constraints to improve performance. The model extracts fine-grained key events from case facts and predicts judgements based on these events rather than the entire fact statement. They manually annotated a legal event dataset and introduced output constraints to guide learning. Their method leverages event information and cross-task consistency constraints.</p><p>Tong et al. <ref type="bibr" target="#b132">[132]</ref> introduce GJudge, a graph boosting framework incorporating constraints to address shortcomings of traditional LJP methods. GJudge features a multi-perspective interactive encoder and a Multi-Graph Attention Network (MGAT) consistency expert module. The encoder integrates fact descriptions with label similarity connections, while the expert module differentiates similar labels and preserves task consistency. Experiments on the CAIL datasets show that GJudge outperforms other models, including the SOTA RLJP <ref type="bibr" target="#b139">[139]</ref>, achieving higher F1 scores.</p><p>Previous works mainly focused on creating accurate representations of a case's fact description to enhance judgement prediction performance. However, these methods often overlook the practical judicial process, where human judges compare similar law articles or potential charges before making a decision. To address this gap, Zhang et al. <ref type="bibr" target="#b149">[149]</ref> propose CL4LJP, a supervised contrastive learning framework to improve LJP by capturing fine-grained differences between similar law articles and charges. The framework includes contrastive learning tasks at the article, charge and label levels, enhancing the model's ability to model relationships between fact descriptions and labels.</p><p>Liu et al. <ref type="bibr" target="#b80">[81]</ref> propose ML-LJP, a multi-law aware LJP method that expands law article prediction into a multilabel classification task incorporating both charge-related and term-related articles. The approach uses label-specific representations and contrastive learning to distinguish similar definitions. A Graph Attention Network (GAT) is employed to learn interactions among multiple law articles for prison term prediction. Experiments showed that ML-LJP outperformed SOTA models, particularly in prison term prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Legal Text Classification</head><p>LTC is an important task within the domain of NLP that involves categorising legal documents based on their content, a foundational aspect of building intelligent legal systems. With the exponential growth of legal documents, it has become increasingly challenging for legal professionals to locate relevant rulings in similar cases for argumentation.</p><p>LTC addresses this challenge by automatically associating legal texts with predefined categories, such as criminal, civil or administrative cases, thereby simplifying legal research and decision-making processes.</p><p>In the legal field, this process is often referred to as predictive coding, where ML algorithms are trained through supervised learning to classify documents into specific categories. The broader task of text classification in NLP involves assigning one or multiple categories to a document from a set of predefined options and it can take various forms, including binary classification (predicting whether a document is in a given class or not), multi-class classification (predicting which one of many classes a document belongs to) and multi-label classification (predicting which set of classes a document belongs to). Legal document classification often falls under large multi-label text classification, where the label space can consist of thousands of potential categories, adding complexity to the task <ref type="bibr" target="#b119">[119]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Datasets</head><p>LTC datasets are characterised by their domain-specific vocabulary and multi-label nature, requiring models to interpret complex legal texts and categorise them into single or multiple legal themes.</p><p>Chalkidis et al. <ref type="bibr" target="#b17">[18]</ref> release EURLEX57K, a dataset containing 57,000 EU legislative documents from the EUR-Lex portal <ref type="foot" target="#foot_4">4</ref> , annotated with EuroVoc<ref type="foot" target="#foot_5">foot_5</ref> concepts. This dataset facilitates research in LTC, including extreme multi-label text classification, few-shot and zero-shot learning, with documents tagged with an expansive set of descriptors.</p><p>Tuggener et al. <ref type="bibr" target="#b133">[133]</ref> introduce LEDGAR, a multi-label corpus of legal provisions from contracts scraped from the the US Securities and Exchange Commission's website. The dataset includes over 846,000 provisions across 60,540 contracts, with an extensive label set suitable for text classification and legal studies. Graham et al. <ref type="bibr" target="#b52">[53]</ref> develop a domain-specific dataset for LTC that focuses on deontic modalities in contract sentences.</p><p>They manually annotated sentences from the CUAD dataset <ref type="bibr" target="#b56">[57]</ref> for permissions, obligations and prohibitions, providing a resource for modelling and studying these functional categories in legal analysis.</p><p>Galassi et al. <ref type="bibr" target="#b42">[43]</ref> extend the Claudette<ref type="foot" target="#foot_6">foot_6</ref> corpus from 25 to 50 ToS per language (English, German, Italian, and Polish).</p><p>Each sentence is labelled according to nine categories of potential unfairness, with annotations indicating the degree of unfairness. The dataset was carefully compiled based on language availability, structural similarity and version correspondence. Cross-lingual analysis revealed notable differences between languages -particularly in Germanincluding variations in length, structure, missing clauses, and legal terminology that reflect manual drafting adjustments rather than simple automated translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Approaches</head><p>DL methods typically requires extensive data to yield effective results, but MTL can help mitigate data scarcity. Elnaggar et al. <ref type="bibr" target="#b36">[37]</ref> leverage transfer learning and MTL to perform tasks such as translation and multi-label classification within legal document corpora. They employ theMultiModel algorithm <ref type="bibr" target="#b63">[64]</ref>, a fully convolutional sequence-to-sequence architecture that integrates multiple modality networks. The model maps legal texts into a shared embedding space, enabling task switching and improving generalisation across tasks to make efficient use of limited legal data.</p><p>Lee and Lee <ref type="bibr" target="#b70">[71]</ref> examine LTC in Korean by comparing three DL architectures: CNN with ASCII encoding, CNN with Word2Vec embeddings, and RNN with Word2Vec embeddings. Each model assigns case documents to civil, criminal, or administrative categories. Using a dataset of nearly 60,000 past case documents, the study finds that the RNN model with Word2Vec embedding achieves the highest classification accuracy.</p><p>Bambroo and Awasthi <ref type="bibr" target="#b7">[8]</ref> introduce an architecture that integrates long attention mechanisms with a distilled BERT model pre-trained on legal domain-specific corpora. Their model employs a combination of local windowed attention and task-motivated global attention to handle inputs up to eight times longer than standard BERT models.</p><p>The architecture, based on the lightweight DistilBERT transformer <ref type="bibr" target="#b114">[114]</ref>, and incorporating LongformerSelf-Attention, is optimised for legal document classification, outperforming a fine-tuned BERT model and other transformer-based models in both speed and performance.</p><p>Song et al. <ref type="bibr" target="#b124">[124]</ref> present a DL-based system built on top of RoBERTa <ref type="bibr" target="#b79">[80]</ref> for multi-label legal document classification. They enhance the model with domain-specific pre-training, a label-attention mechanism and MTL to improve classification accuracy, particularly for low-frequency classes. The label-attention mechanism uses label embeddings to bridge the semantic gap between samples and class labels, addressing class imbalance issues.</p><p>Wang et al. <ref type="bibr" target="#b137">[137]</ref> introduce a Document-to-Graph Classifier to classify legal documents based on facts and reasons rather than topics. They extract key entities and represented legal documents using four distinct relation graphs capturing different aspects of entity relationships. A graph attention network <ref type="bibr" target="#b135">[135]</ref> is used to learn document representations from the combined graph, improving classification by focusing on factual content.</p><p>Mamooler et al. <ref type="bibr" target="#b85">[86]</ref> propose an active learning pipeline to fine-tune PLMs for LTC, thereby addressing the challenges of a specialised vocabulary and high annotation costs. Their method involves continual pre-training of RoBERTa on legal texts, knowledge distillation using a pre-trained sentence transformer, and an initial sampling strategy based on clustering unlabelled data. This approach reduces the number of labelling actions required for LTC tasks, reducing the overall cost of the LTC process.</p><p>Grabmair et al. <ref type="bibr" target="#b51">[52]</ref> introduce LUIMA, a system designed for conceptual legal document retrieval, focusing on vaccine injury decisions. LUIMA employs a multi-level classification pipeline: rule-based sub-sentence annotations tag legal concepts, such as terms and mentions, while ML classifiers categorise sentences into argumentative roles, such as legal rules or evidence-based findings. These annotations feed into a sentence-level indexing process using Apache Lucene, enabling semantic querying beyond traditional keyword search. A learning-to-rank module refines the retrieved results by leveraging hand-crafted features such as sentence match counts and term similarity scores.</p><p>Galassi et al. <ref type="bibr" target="#b42">[43]</ref> explore the binary classification task of detecting potentially unfair clauses in online Terms of Service (ToS) at the sentence level. Sentences are labelled as either unfair, potentially unfair, or fair. Starting from an English-trained model, the authors compare four cross-lingual approaches: (1) training separate models on each language, (2) projecting annotations from English to another language, (3) translating English training documents and using their original annotations and (4) translating query documents into English during prediction. The evaluation shows scenario (4) achieves similar or better results than scenario (1) when translation quality is high. If the translation quality is low, scenario (1) can produce better results. Scenarios (2) and (3) perform slightly below scenario (1) but remain viable alternatives. Rhetorical role labelling is the task of classifying sentences in legal documents based on their functional roles, such as fact, argument or ruling, to structure and analyse judicial decisions. The Artificial Intelligence for Legal Assistance (AILA) shared task series focuses on advancing legal NLP by introducing datasets and challenges that address core legal text processing tasks. The latest edition, AILA 2021 <ref type="bibr" target="#b103">[103]</ref>, featured a rhetorical role labelling task that required classifying sentences into seven predefined roles. Building on these challenges, DeepRhole <ref type="bibr" target="#b12">[13]</ref> introduces a transformer-based framework that fine-tunes domain-adapted models such as LegalBERT to capture the semantics of legal texts. The system applies different word embedding strategies, including Law2Vec and embeddings from Google News, to model legal language variability. An inter-annotator study examines the subjectivity in rhetorical role assignment, further assessing the model's performance in different judicial contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Legal Document Summarisation</head><p>LDS is a specialised branch of automatic summarisation that condenses legal texts, such as court judgements, into clear and informative summaries. Unlike general text summarisation, which extracts key details without following specific formatting rules, LDS must accommodate the distinct structure and specialised content of legal documents. These documents often include complex elements that are essential for presenting the legal arguments and decisions accurately, such as article numbers, statutory language, and citations. The inherent complexity of legal texts, characterised by their length and detailed internal structures (sections, articles, and paragraphs), demands customised summarisation techniques. This requirement is reinforced by the hierarchical significance of documents based on judicial origin, where interpretations may differ between higher and lower court opinions <ref type="bibr" target="#b65">[66]</ref>.</p><p>LDS can be approached through extractive and abstractive methods. Extractive techniques identify and select the most important sentences or phrases directly from the text, preserving original wording and meaning. Abstractive methods, by contrast, generate new sentences that paraphrase the key information, aiming for conciseness while maintaining the essence of the legal text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Datasets</head><p>LDS datasets are largely built from structured court proceedings and decisions, providing rich sources for both extractive and abstractive summarisation methods. These datasets often use abstractive summarisation to achieve concise, readable summaries that transform the original legal language into more accessible forms <ref type="bibr" target="#b120">[120]</ref>.</p><p>Shen et al. <ref type="bibr" target="#b120">[120]</ref> introduce Multi-LexSum, an abstractive summarisation dataset tailored for the US federal civil rights lawsuits, containing 40,000 source documents and 9,000 expert-written summaries of diverse lengths.</p><p>Liu et al. <ref type="bibr" target="#b77">[78]</ref> published the Common Law Court Judgement Summarisation (CLSum), a dataset designed for summarising multi-jurisdictional common law court judgements from Australia, Hong Kong, the United Kingdom, and Canada. This dataset utilises LLMs for data augmentation and incorporates legal knowledge to enhance summary generation and evaluation. This dataset addresses the challenge of sparse labelled data in legal domains. CLSum includes a collection of judgements and summaries from prominent court websites. They employ a two-stage summarisation process with techniques such as sparse attention mechanisms and efficient training methods to process lengthy legal documents with limited computational resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Approaches</head><p>Several systems have been specifically designed to summarise legal documents. One of the first systems in this field was the Fast Legal EXpert CONsultant (FLEXICON), created by Gelbart and Smith in 1991 <ref type="bibr" target="#b45">[46]</ref>. FLEXICON utilises a keyword-based approach <ref type="bibr" target="#b46">[47]</ref>, scanning a database of terms to pinpoint crucial segments of text. Following this, Moens et al. <ref type="bibr" target="#b91">[91]</ref> introduced the SALOMON system in 1999, which employs cosine similarity to cluster similar text regions, aiming to highlight relevant topics within the documents. This method aligns with other abstraction-oriented techniques seen in the work of Erkan and Radev <ref type="bibr" target="#b37">[38]</ref>. LetSum <ref type="bibr" target="#b39">[40]</ref>, developed by Farzindar and Lapalme in 2004, also adopts a keyword-centric strategy but uses "cue phrases" to identify text related to specific themes such as 'Introduction', 'Context' and 'Conclusion'. Although LetSum approximated human-written summaries reasonably well, it often produced documents that were longer than desired.</p><p>Building on previous developments in LDS, Polsley et al. <ref type="bibr" target="#b106">[106]</ref> introduce Casesummarizer, a tool designed for the legal domain that pre-processes legal texts into sentences, scores them using a TF-IDF matrix from extensive legal case reports and enhances sentence scoring by identifying entities, dates and section headings. The tool provides a user-friendly interface with scalable summaries, lists of entities and abbreviations and a significance heat map.</p><p>Nguyen et al. <ref type="bibr" target="#b94">[94]</ref> propose an RL framework to enhance deep summarisation models for the legal domain, utilising Proximal Policy Optimisation with a reward function that integrates both lexical and semantic criteria. They fine-tune an extractive summarisation backbone based on BERTSUM <ref type="bibr" target="#b78">[79]</ref>, employing a reward model that includes lexical, sentence, and keyword-level semantics to produce better legal summaries. Schraagen et al. <ref type="bibr" target="#b117">[117]</ref> apply an RL approach with a Bi-LSTM and a DL approach based on the BART transformer model to abstractive summarisation of the Dutch case verdict database Rechtspraak.nl, combining extractive and abstractive summarisation to retain core facts while creating concise summaries.</p><p>Zhong and Litman <ref type="bibr" target="#b156">[156]</ref> focus on extractive summarisation of legal case decisions, proposing an unsupervised graphbased ranking model that leverages a re-weighting algorithm to utilise document structure properties. They extend the HipoRank model <ref type="bibr" target="#b33">[34]</ref> with a novel re-weighting algorithm to improve sentence selection, reducing redundancy and enhancing the inclusion of argumentative sentences from underrepresented sections. Moro et al. <ref type="bibr" target="#b93">[93]</ref> introduce a transfer learning approach that combines extractive and abstractive summarisation techniques to address the lack of labelled legal summarisation datasets, outperforming previous results on the Australian Legal Case Reports dataset and establishing a new baseline for abstractive summarisation. Jain et al. <ref type="bibr" target="#b59">[60]</ref> propose a sentence scoring approach, DCESumm, which combines supervised sentence-level summary relevance prediction with unsupervised clustering-based document-level score enhancement. It utilises a Legal BERTbased Multi-Layer Perceptron model to estimate the summary relevance of each sentence, then refines these scores through deep embedded sentence clustering to incorporate the document's global context. 9 Legal Named Entity Recognition NER identifies and categorises textual mentions into predefined types such as organisations, persons and locations <ref type="bibr" target="#b69">[70]</ref>.</p><p>In the legal domain, NER extends to specialised recognition tasks that focus on extracting entities unique to legal texts, such as laws, legal norms, and procedural terms. This specialised form of NER is crucial for structuring legal documents and enhancing legal IR systems. Unlike general NER systems that handle common entity types, legal NER must navigate the complex language and structured format of legal documents, motivating the need for systems and methodologies specifically tailored to the legal context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Datasets</head><p>Leitner et al. <ref type="bibr" target="#b71">[72]</ref> release a German legal NER corpus drawn from federal court decisions, comprising about 67,000 sentences and more than two million tokens. It contains roughly 54,000 manually annotated entities across 19 finegrained, domain-specific classes, such as court, judge, lawyer, law, person and legal literature, alongside over 35,000 TimeML-based <ref type="bibr" target="#b109">[109]</ref> time expressions. The annotations cover both broad categories, such as location, person and organisation and more specialised ones, such as legal norms and case-by-case regulations, distinguishing between different types of legal acts and literature. Annotation proceeded through multiple iterations to refine guidelines and ensure high-quality labels.</p><p>PƒÉis et al. <ref type="bibr" target="#b110">[110]</ref> introduce the LegalNERo corpus, a manually annotated resource for NER in the Romanian legal domain, featuring 370 legal documents annotated with five entity types: person, location, organisation, time expressions and legal references. This corpus was developed to support both specific legal domain NER tasks and more general NER applications by enabling compatibility with existing general-purpose NER systems. The corpus includes rich entity annotations, with legal references showing the highest token count per entity, indicating their complexity and length.</p><p>The annotation workflow involved several refinement cycles, inter-annotator agreement measured by Cohen's kappa and conversion of entities to RDF, ensuring accuracy and usefulness for legal NER research.</p><p>Au et al. <ref type="bibr" target="#b6">[7]</ref> present the E-NER dataset, an annotated collection derived from the US Securities and Exchange Commission's EDGAR filings, designed for legal NER. This dataset contains filings that are rich in text, such as quarterly reports and significant event announcements, from which sentences were extracted and annotated with seven named entity classes more tailored to legal content than those in the standard CoNLL dataset <ref type="bibr" target="#b131">[131]</ref>. The entities include person, location, organisation, government, court, business and legislation/act, adjusting the CoNLL classes to better suit legal documents. E-NER contains longer sentences compared to CoNLL and includes detailed annotations of financial entities from legal company filings. This dataset not only facilitates training and evaluation of NER models specific to the legal domain but also provides a structured framework for assessing the performance of NER systems on legal texts. Their approach leverages a combination of manual annotation and ML techniques to ensure the precision of entity recognition in legal judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Approaches</head><p>Dozier et al. <ref type="bibr" target="#b34">[35]</ref> conduct early research on NER in legal texts, including US case law and pleadings, by combining lookup methods, contextual rules and statistical models to identify entities such as judges, attorneys and legal terms.</p><p>Their system adapts these approaches to the specialised context of legal texts, processing various types of documents and extracting legal entities. This work highlights the challenges and necessary adaptations for deploying NER in the legal domain, where the specialised language and high accuracy are required for successful legal analysis. PƒÉis et al. <ref type="bibr" target="#b110">[110]</ref> develop a legal NER model that combines Bi-LSTM layers with a Conditional Random Field (CRF) output layer and leverages multiple data sources and embedding types. The architecture integrates pre-trained word embeddings, character embeddings, and gazetteer entries from GeoNames<ref type="foot" target="#foot_7">foot_7</ref> and JRC-Names <ref type="bibr" target="#b127">[127]</ref>, along with known legal affixes, to enrich text representations. During training, word embeddings are fine-tuned while character embeddings are learned dynamically through the Bi-LSTM layers, improving generalisation to unseen texts. Built on a modified version of NeuroNER <ref type="bibr" target="#b29">[30]</ref>, the system supports online serving and employs dropout for regularisation and gradient clipping to mitigate exploding gradients. The authors also explore ensembles of different model configurations, evaluating performance via precision, recall and F1 scores against a gold-standard corpus.</p><p>SmƒÉdu et al. <ref type="bibr" target="#b123">[123]</ref> explore domain adaptation in legal NER, focusing on the Romanian and German languages. Their architecture combines a pre-trained BERT layer for feature extraction with Bi-LSTM networks to handle sequence dependencies and CRFs for sequence tagging. Their approach employs domain adaptation techniques through a gradient reversal layer connected to a domain discriminator, aimed at reducing domain-specific biases and enhancing feature transferability across domains. The model is trained on both legal and general corpora through adversarial learning, aiming to improve transferability across domains. Results show marginal gains for German but a performance drop on the Romanian legal dataset, indicating that benefits vary by language and domain.</p><p>Adhikary et al. <ref type="bibr" target="#b0">[1]</ref> publish LeDa, a legal data annotation system designed to address the challenges of extracting legal entities and concepts from case documents. Unlike traditional sequence labelling tools, LeDA enables annotators to dynamically define new legal concepts during annotation. The system also incorporates a meta-annotation mechanism for adjudicating conflicting annotations.</p><p>10 Legal Argument Mining LAM applies NLP to identify and extract arguments from legal documents, automating the detection of claims, premises, and their interrelations to enhance legal research and practice. By reconstructing both the local structure of individual arguments and the global network of relations between them, it supports legal reasoning, exposing chains of reasoning that inform judicial decisions and support tasks such as conflict resolution and why-question answering <ref type="bibr" target="#b101">[101]</ref>. To meet these demands, recent work focuses on domain-specific annotation schemes and advanced DL models capable of handling the intricacies of legal language and argument structure. Effective argument mining therefore relies on identifying elementary argumentative units, modelling their rhetorical relations and determining whether these structures can be derived automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1">Datasets</head><p>Poudyal et al. <ref type="bibr" target="#b108">[108]</ref> present the ECHR corpus for LAM, a structured dataset of 42 decisions from ECHR, annotated with argumentative components: premises, conclusions and non-argumentative text. The corpus facilitates research on argument mining by enabling three key tasks: argument clause recognition, clause relation prediction and premise/conclusion classification. The annotation process involved legal experts, with iterative refinements leading to 80% inter-annotator agreement. Habernal et al. <ref type="bibr" target="#b54">[55]</ref> develop an annotation scheme for ECHR judgements, grounded in legal argumentation theory and designed to capture argument spans such as claims, premises and their interrelations. Using this scheme, the authors compile and manually annotate a large corpus of 373 ECHR decisions, comprising approximately 2.3 million tokens and over 15,000 argument spans. Six law students performed the annotation under expert supervision and achieved high inter-rater agreement (as measured via Krippendorff's alpha, with values close to 0.80).</p><p>Grundler et al. <ref type="bibr" target="#b53">[54]</ref> introduce Demosthenes, a corpus of 40 Court of Justice of the European Union (CJEU) decisions on fiscal state aid, annotated at the sentence level for argument mining. Each decision (written in English and spanning 2000-2018) was obtained from EUR-Lex and manually annotated to capture its argumentative reasoning, focusing on the "Findings of the Court" section where the judgement's legal arguments are laid out. Using an iteratively refined annotation guideline, two experts with legal domain expertise labelled each sentence in this section as an argumentative element (premise or conclusion), further denoting each premise as legal or factual and assigned each argument to a category in a legal argumentation scheme typology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2">Approaches</head><p>Palau and Moens <ref type="bibr" target="#b101">[101]</ref> present pioneering research in LAM, focusing on detecting, classifying and structuring arguments within legal texts. Their work introduces methods to automatically identify arguments, distinguish argumentative from non-argumentative sentences and classify argumentative propositions as either premises or conclusions using statistical classifiers such as maximum entropy models, Naive Bayes classifiers and SVM. The authors utilise the Araucaria and the ECHR corpora for evaluation. Results demonstrate that statistical methods can distinguish argumentative sentences, achieving approximately 80% accuracy on the ECHR corpus. Additionally, they discuss methods to resolve argument segmentation challenges through structural and semantic analyses, proposing that semantic relatedness measures (based on ontology or corpus-derived statistics) can enhance argument boundary detection. Finally, they investigate detecting argument structures through rhetorical pattern analysis and suggest employing context-free grammars as an initial step toward full argumentative parsing.</p><p>Zhang et al. <ref type="bibr" target="#b148">[148]</ref> propose a graph-based framework for LAM that replaces the traditional pipeline approach with an end-to-end architecture. By modelling each legal document as a graph -where nodes represent text segments and edges capture sequential or semantic relationships -they mitigate error propagation across sub-tasks. Their method employs virtual node graph augmentation, which adds a global node connected to all text segments and a collective classification algorithm that iteratively refines predictions using neighbouring node labels. They evaluate on the ECHR and the CJEU datasets using Graph Convolutional Network (GCN) and Residual Gated GCN (ResGCN) models. In particular, ResGCN demonstrates better performance on both datasets, surpassing baseline methods in classifying premises, conclusions and non-argumentative text.</p><p>Santin et al. <ref type="bibr" target="#b115">[115]</ref> propose a novel annotation scheme for predicting argument structures in CJEU fiscal state aid decisions, addressing the scarcity of annotated resources and the complexity of legal reasoning. Building on the Demosthenes corpus, they refine their previous dataset by distinguishing a richer set of inferential relations, including direct support, indirect support (support from failure), rebuttal, undercut and rephrase links, which captures the logical and discursive connections support judicial arguments. Using the extended dataset, they conducted an empirical study comparing DistilRoBERTa <ref type="bibr" target="#b113">[113]</ref> with an ensemble of attentive residual networks <ref type="bibr" target="#b43">[44]</ref> (ResAttArg) for link prediction, exploring variations in training (with/without oversampling and different link distance thresholds). The ResAttArg ensemble outperforms the distilled transformer and does so with lower computational demand.</p><p>Habernal et al. <ref type="bibr" target="#b54">[55]</ref> utilise advanced NLP techniques to mine legal arguments from ECHR decisions. Specifically, they employ a multi-task transformer-based model, which is a DL approach designed for both argument identification and classification. This model leverages the capabilities of transformers to process and understand complex legal texts, outperforming previous legal NLP models according to expert evaluations. Table <ref type="table" target="#tab_3">4</ref> maps each dataset to every cited study that employs it, covering both the current task and other legal NLP tasks discussed in the survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Large Legal Datasets</head><p>Training LLMs for legal NLP requires extensive legal corpora that are transparent in sourcing, safeguard privacy and minimise bias to ensure fairness and accuracy. These corpora serve as the foundation for developing models capable of handling diverse legal tasks. To assess model performance, evaluation benchmarks provide structured datasets and standardised metrics for tasks such as judgement prediction, QA, case retrieval and entailment. Together, large legal corpora and evaluation benchmarks can support the advancement of reliable legal AI applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.1">Evaluation benchmarks</head><p>Zheng et al. <ref type="bibr" target="#b151">[151]</ref> introduce CaseHOLD, a novel benchmark for evaluating NLP models in the legal domain, designed to address the challenge of identifying the legal holdings from case texts. The dataset contains over 53,000 multiple-choice questions derived from the US case law citations, where each question requires the identification of the correct holding from a set of potential answers. This task, simulating a fundamental skill taught in law school, involves contextual understanding and application of legal rules to factual situations. CaseHOLD is aimed at enhancing model training by focusing on semantic matching and the ability to discern legal principles. The dataset is structured to provide a challenging yet accessible resource for NLP researchers, with a clear focus on promoting deeper understanding and application of legal rules in automated systems. Each item presents a cited passage as a prompt followed by one correct holding and four closely related incorrect options, encouraging models to demonstrate genuine legal reasoning.</p><p>Chalkidis et al. <ref type="bibr" target="#b20">[21]</ref> introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a comprehensive suite of datasets aimed at assessing the capabilities of NLP models across various legal tasks. The benchmark covers datasets, such as ECHR <ref type="bibr" target="#b16">[17]</ref>, SCOTUS,<ref type="foot" target="#foot_8">foot_8</ref> EUR-Lex, LEDGAR <ref type="bibr" target="#b133">[133]</ref>, UNFAIR-ToS <ref type="bibr" target="#b76">[77]</ref> and CaseHOLD <ref type="bibr" target="#b151">[151]</ref>, each chosen for its complexity, relevance, and need for legal expertise. These datasets cover a range of tasks from multi-label Chalkidis et al. <ref type="bibr" target="#b21">[22]</ref> introduce FairLex, a multilingual benchmark suite of four legal datasets: ECHR <ref type="bibr" target="#b16">[17]</ref>, SCOTUS, FSCS and CAIL. The suite evaluates fairness in NLP across several jurisdictions (Europe, the United States, Switzerland, and China) and five languages (English, German, French, Italian, and Chinese). Each dataset is aligned with a specific legal task: ECHR violation prediction for ECHR; issue-area classification for SCOTUS; case-approval prediction for FSCS; and crime-severity prediction for CAIL. All datasets are chronologically split into training, development and test sets. FairLex supports demographic, regional and topical fairness analysis by recording sensitive attributes, including defendant state in ECHR, decision direction in SCOTUS, legal area in FSCS, and gender and region of origin in CAIL.</p><p>Rabelo et al. <ref type="bibr" target="#b111">[111]</ref> summarise the 8th Competition on Legal Information Extraction and Entailment (COLIEE 2021), which featured five tasks across case and statute law, engaging participants from various teams to apply diverse NLP approaches. The competition tasks included case law retrieval and entailment, as well as statute law retrieval and entailment with and without prior retrieved data. Specifically, task 1 focused on extracting relevant supporting cases from a corpus, while task 2 involved identifying paragraphs from cases that entail a given new case fragment. For statute law, tasks 3 and 4 entailed retrieving and answering questions based on civil code statutes, with task 5 challenging participants to answer without pre-retrieved statutes. The datasets used varied in complexity, from 4,415 case files in task 1 with a need to identify noticed cases without relying on citations, to the civil code-based tasks 3, 4 and 5 which adapted to recent legal revisions in Japanese law and excluded untranslated parts, reflecting the ongoing evolution and challenge in legal NLP applications.</p><p>Barale et al. <ref type="bibr" target="#b8">[9]</ref> present AsyLex, a pioneering dataset tailored for refugee law applications, featuring 59,112 documents from Canadian refugee status determinations spanning from 1996 to 2022. This dataset is designed to enhance the Where possible, it preserves existing train, development and test splits, otherwise creating random splits.</p><p>Park and James <ref type="bibr" target="#b104">[104]</ref> explore the creation of a Natural Language Inference (NLI) dataset within the legal domain, focusing on criminal court verdicts in Korean. Their methodology includes the innovative use of adversarial hypothesis generation to challenge annotators and enhance the robustness of the dataset, supported by visual tools for hypothesis network construction. The data collection involves extracting context from verdicts and augmenting it using Easy Data Augmentation <ref type="bibr" target="#b138">[138]</ref> techniques and round-trip translation to generate a dataset for training and testing NLI models.</p><p>The study highlights issues such as annotators' limited domain knowledge and challenges in handling long contexts but provides solutions, such as targeted data collection and the use of gamification to boost annotator engagement and productivity.</p><p>Goebel et al. <ref type="bibr" target="#b50">[51]</ref> summarise COLIEE 2023, featuring four tasks across case and statute law with participation from ten different teams engaging in multiple tasks. task 1 involves legal case retrieval, requiring participants to extract supporting cases from a corpus and task 2 focuses on legal case entailment, identifying paragraphs that entail aspects of a new case. Task 3 and 4, based on Japanese civil code statutes from the bar exam, involve retrieving relevant articles and verifying statements, respectively. The competition leverages a dataset of over 5,700 case law files and introduces new query cases and test questions sourced from recent bar exams, testing the efficacy of different teams' approaches in handling complex legal texts and hypotheses in a controlled competitive environment.</p><p>√ñstling et al. <ref type="bibr" target="#b157">[157]</ref> introduce the Cambridge Law Corpus (CLC), a legal dataset featuring 258,146 cases from UK courts, dating from the 16th century to the present. The corpus includes raw text and metadata across various court types and is structured in XML format for ease of use and annotated for case outcomes in a subset of 638 cases. Additionally, the CLC is supported by a Python library for data manipulation and ML applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.2">Large corpora for pre-training</head><p>Henderson et al. <ref type="bibr" target="#b55">[56]</ref> introduce the "Pile of Law, " the first at-scale legal text collection, containing a 256 GB dataset of open-source English-language legal and administrative data. This dataset includes contracts, court opinions, legislative records, and administrative rules, curated to explore data sanitation norms across legal and administrative settings and serve as a tool for pre-training legal LLMs. They emphasise the legal norms governing privacy and toxicity filtering, detailing how the dataset reflects these norms through built-in filtering mechanisms in the collected data, which include court filings, legal analyses and government publications. By analysing how legal and administrative entities handle sensitive information and potentially offensive content, the paper provides actionable insights for researchers to improve content filtering practices before pre-training LLMs, thereby enhancing the ethical use of NLP in legal applications.</p><p>Niklaus et al. <ref type="bibr" target="#b98">[98]</ref> present the MultiLegalPile, the largest open-source multilingual legal corpus available, totalling 689 GB and spanning 17 jurisdictions across 24 languages. This extensive dataset is designed to facilitate training of LLMs within the legal domain, featuring diverse legal text types including case law, legislation and contracts, predominantly in English due to the integration of the "Pile of Law" <ref type="bibr" target="#b55">[56]</ref> dataset. Through careful regex-based filtering from the mC4 corpus and manual reviews, the team ensures high precision in legal content selection.</p><p>12 Legal Language Models and Methods for Legal Domain Adaptation</p><p>In the fast-moving field of NLP, LLMs have become a key tool for processing and understanding large amounts of unstructured text data. These models, initially trained on broad datasets such as Wikipedia, have shown great skill across various language tasks. Building on this success, the legal technology community is increasingly interested in using these powerful models for legal NLP applications. This involves adapting these general-domain models to legal texts and further training them on specialised legal documents. Such efforts aim to reduce the domain gap and customise the models to better understand the complex language used in legal documents. In this section, we will explore how these so-called "foundation" models are being adapted and applied within the legal domain to enhance legal NLP applications.</p><p>Following the methodology of this survey, this section studies all peer-reviewed LMs or related methods. However, due to the challenges present in the legal domain, there are many legal LMs that have not undergone peer review. Given the scarcity of adequate peer-reviewed resources, our research has focused on the investigation of, in order of priority, the peer-reviewed sources, then the most well-known and widely used non-peer-reviewed legal LMs. Despite their lack of formal peer review, these models have gained considerable attention and usage in the field, and some are expected to be published in peer-reviewed venues in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12.1">Language Models</head><p>Chalkidis et al. <ref type="bibr" target="#b19">[20]</ref> present an in-depth analysis of applying BERT in the legal domain, showcasing the need for domain-specific adaptation to enhance performance on legal NLP tasks. They explore three strategies: using standard BERT directly, further pre-training a BERT model on legal corpora, and pre-training from scratch with legal-specific data. Their study found that both further pre-training and pre-training from scratch generally outperform the use of BERT directly. They introduce legal-bert, which includes versions for varied computational capacities and demonstrates competitive performance with a lower environmental impact.</p><p>Xiao et al. <ref type="bibr" target="#b140">[140]</ref> introduce Lawformer, a Longformer-based <ref type="bibr" target="#b9">[10]</ref> LM adapted for Chinese legal texts, designed to handle extensive document lengths common in legal data. Recognising the limitation of standard PLMs with shorter token capacities, Lawformer employs a unique combination of sliding window, dilated sliding window, and global attention mechanisms to process long texts, making it suitable for legal AI tasks, such as LJP and LQA. Pre-trained on a vast corpus of Chinese legal documents segmented into criminal and civil cases, Lawformer integrates complex sequential dependencies across tokens using these attention techniques, enhancing model performance for legal-specific tasks.</p><p>In the development of specialised NLP tools for Arabic legal texts, a model specifically tailored to the unique linguistic features of Arabic jurisprudence was designed called AraLegal-BERT <ref type="bibr" target="#b1">[2]</ref>. This model enhances NLP applications within the legal field by adapting BERT technology to Arabic's specific content needs, involving pre-training BERT from scratch using a broad range of legal documents, including legislative materials and contracts.</p><p>Colombo et al. <ref type="bibr" target="#b26">[27]</ref> introduce SaulLM-7B, a novel LLM specifically designed for legal text comprehension and generation, built on the 7 billion parameter Mistral <ref type="bibr" target="#b61">[62]</ref> architecture. This model is trained on an extensive English legal corpus, designed to meet the unique challenges of legal syntax and terms. SaulLM-7B uses a two-tier training approach: continued pre-training on a carefully curated 30 billion token legal dataset and an innovative instruction fine-tuning method, incorporating both generic and legal-specific instructions to enhance the model's performance on legal tasks. Shi et al. <ref type="bibr" target="#b122">[122]</ref> develop Legal-LM, a specialised LM tailored for Chinese legal consulting, enhanced with a KG to address domain-specific challenges such as data veracity and non-expert user interaction. The framework involves several steps: extensive pre-training on a rich corpus of legal texts integrated with a legal KG, keyword extraction and Direct Preference Optimisation to refine responses and the use of an external legal knowledge base for data retrieval and response validation. This multi-faceted approach ensures that Legal-LM not only comprehends complex legal language but also generates precise and user-aligned legal advice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12.2">Methods for Improving In-Domain Adaptability of Legal Language Models</head><p>Li et al. <ref type="bibr" target="#b73">[74]</ref> explore a novel adaptation of LMs for the legal domain by integrating domain-specific unsupervised data from public legal forums to optimise prefix domain adaptation, a parameter-efficient learning approach that trains only about 0.1% of the model's parameters. They introduce a training methodology where a deep prompt is specifically tuned using a domain-adapted prefix from legal forums and then utilised in various legal tasks, demonstrating improved few-shot performance compared to full model tuning methods, such as legal-bert <ref type="bibr" target="#b19">[20]</ref>. This approach reduces computational overhead while maintaining or exceeding performance metrics across multiple legal tasks, suggesting an efficient and scalable model for legal NLP applications.</p><p>Mamakas et al. <ref type="bibr" target="#b84">[85]</ref> explore strategies for adapting pre-trained transformers to cope with the challenges of long legal texts within the LexGLUE benchmark, focusing on extending input capabilities and enhancing efficiency. They modify Longformer <ref type="bibr" target="#b9">[10]</ref>, originally extending up to 4,096 subwords, to process up to 8,192 subwords by reducing local attention window size and incorporating a global token at the end of each paragraph to facilitate information flow across longer texts. Additionally, they adapt legal-bert to employ TF-IDF representations to manage longer documents, introducing variants, such as TF-IDF-SRT-LegalBERT, which deduplicates and sorts subwords by TF-IDF scores; and TF-IDF-EMB-LegalBERT, which incorporates a TF-IDF embedding layer. These adaptations aim to combine the robust capabilities of transformers with the practical requirements of handling extensive legal documents, surpassing the performance of traditional linear classifiers while maintaining computational efficiency.</p><p>Despite researchers' efforts in the this interdisciplinary field and extensive advancements in AI techniques, a number of open research challenges (ORCs) still exist. In this section, we identify the key ORCs, and provide advice and directions for future work to overcome these challenges.</p><p>ORC1: Bias and Fairness. Bias and fairness are crucial concerns in the field of AI, especially at the intersection with the legal domain where decisions can deeply impact individuals' lives. The scarcity of unbiased data in legal domains such as case law complicates the training of AI models, as these models often learn from historical decisions that may reflect existing human biases <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b130">130]</ref>. This reliance on biased datasets can, in turn, lead to unfair and biased outcomes in downstream classification and prediction tasks. Addressing these issues is critical to ensure that AI-driven legal decisions uphold the standards of impartiality and fairness required for justice.</p><p>ORC2: Privacy Concerns. Privacy concerns in legal NLP are critical, as models often handle highly sensitive documents such as court records <ref type="bibr" target="#b145">[145]</ref>. Beyond basic anonymization, advanced techniques -such as differential privacy -add statistical noise during training to ensure that individual data points have minimal influence on the model's output.</p><p>Adversarial training further bolsters privacy by simulating potential attacks and guiding the model to suppress identifiable attributes in its representations. Privacy-preserving fine-tuning methods -such as applying differential privacy during fine-tuning, federated learning or knowledge distillation -allow models to adapt to new legal tasks without exposing sensitive data. However, implementing these techniques requires careful calibration, as excessive privacy constraints may degrade model accuracy. This challenge motivates the need for continued research into privacy-preserving NLP methods tailored to the unique demands of the legal domain.</p><p>ORC3: Interpretability and Explainability. The ability to interpret and explain the outputs of AI-powered systems is of critical importance across various applications in legal NLP, yet these aspects remain underexplored in many contexts.</p><p>Relating to ORC1, the ability to trace and comprehend the decision-making process of AI systems is essential for identifying and mitigating biases. Transparent and understandable AI systems help build trust and ensure they are used responsibly, which is particularly important in legal contexts where decisions significantly impact people's lives.</p><p>Improving these aspects of AI models is necessary to their ethical use, ensuring they meet the high standards of fairness required in legal proceedings. In turn, this will promote wider adaption, allowing the promises of these systemsincreased productivity, fairness, and reduced costs -to be realised in practice.</p><p>ORC4: Annotation Process and Transparency. Annotation quality and transparency are critical challenges in legal NLP. A growing discussion in the community focuses on descriptive versus prescriptive annotation <ref type="bibr" target="#b112">[112]</ref>. Descriptive annotation captures the full spectrum of annotator subjectivity, preserving diverse interpretations of legal texts and proving valuable for interpretative tasks such as LQA or contract analysis. In contrast, prescriptive annotation enforces a single, consistent standard that is essential for tasks requiring strict adherence to legal norms, such as LJP or statute classification. The choice between these paradigms depends on the specific task, domain context and intended downstream application.</p><p>Equally, transparent annotation practices are rarely documented in legal NLP studies, with many reports omitting details about annotators' backgrounds and the procedures employed. Comprehensive documentation of the annotation process is important for assessing dataset quality, ensuring fairness and building trust in legal NLP systems. Ultimately, explicit decisions regarding both the annotation paradigm and transparency measures are necessary to produce reliable, suitable datasets.</p><p>Manuscript submitted to ACM ORC5: Scarcity of Reliable Annotated data. One of the key ORCs in legal NLP is the scarcity of annotated data, which limits the development of robust models due to the high cost and expertise required for labelling complex legal texts.</p><p>Data augmentation can offer a promising approach to mitigate this issue, yet it introduces its own set of challenges.</p><p>The complexity of legal texts complicates the application of general augmentation techniques. Ensuring the quality of augmented data remains critical, with efforts focusing on preserving semantic and syntactic integrity to prevent models from learning incorrect patterns <ref type="bibr" target="#b105">[105]</ref>. Additionally, the effectiveness of augmentation varies across models, necessitating tailored strategies, while scalability concerns arise with computationally intensive methods <ref type="bibr" target="#b48">[49]</ref>. The predominant focus on English limits applicability to multilingual legal contexts and in extremely low-resource scenarios, there is a risk of overfitting to augmented data <ref type="bibr" target="#b48">[49]</ref>. Future research should prioritise developing domain-specific augmentation techniques that maintain the nuances of legal text, explore flexible approaches, enhance scalability, and extend support diverse languages, thereby addressing these persistent challenges in legal NLP.</p><p>ORC6: Multilingual Capabilities. In legal NLP, enhancing multilingual capabilities remains an underdeveloped area.</p><p>While efforts, such as MultiLegalPile <ref type="bibr" target="#b98">[98]</ref> have begun to address this, there remains a gap in research for many languages, including, but not limited to, Persian and Arabic. These limitations restrict the application of legal NLP across diverse legal systems worldwide, hampering broader adoption and accessibility. Multilingual capabilities introduce unique challenges for legal NLP models, primarily due to the distinct linguistic structures of each language, which often require extensive fine-tuning to ensure accuracy and relevancy in legal contexts. Furthermore, each legal system possesses its own set of terms and document standards, which can vary dramatically from one language to another. Therefore, expanding research into these and other underserved languages is essential for making NLP tools universally applicable.</p><p>ORC7: Ontologies and Knowledge Graphs. The use of ontologies in the legal domain is relatively sparse, yet it holds considerable potential to enhance the robustness of AI methodologies. Ontologies or knowledge graphs can also enable AI models to draw accurate inferences regarding the relationships between entities, thereby improving reasoning and decision making over complicated legal texts. However, utilising ontologies in legal NLP faces unique challenges. The complexity of legal language and the concept of "open texture, " where the meaning of legal terms can evolve over time, can complicate the creation of static ontological models <ref type="bibr" target="#b92">[92]</ref>. Legal ontologies must be dynamic, reflecting changes in law and its interpretation over time. Additionally, the integration of real-world and legal concepts within ontologies presents further complexity, as it requires accommodating both legal terms and their relevant real-world contexts <ref type="bibr" target="#b92">[92]</ref>.</p><p>ORC8: Pre-processing Legal Text. Pre-processing legal texts is challenging because legal documents often consist of raw texts that requires extensive cleaning and transformation before use in ML models. Their complex, nested structures, such as clauses within clauses and cross-references to other cases, statutes or provisions, make it hard to segment them into coherent units for analysis. Without addressing these complexities, fine-tuning LMs on raw legal data becomes impractical, limiting the performance of legal NLP applications.</p><p>ORC9: Reinforcement Learning from Human Feedback (RLHF). The use of RLHF within the legal domain is notably scarce.</p><p>Currently, there is only one peer-reviewed work <ref type="bibr" target="#b94">[94]</ref> available that explores this approach. This indicates an opportunity for research and development in this area, as RLHF could potentially enhance the capability of NLP models to learn and to make decisions based on complex legal data under human guidance. Further exploration into this method could lead to more responsive and adaptable legal NLP systems. However, due to the complex nature of legal reasoning and the need for accurate legal knowledge in the human feedback phase, integrating RLHF into legal NLP pipelines poses some challenges. In particular, legal experts such as lawyers and judges must provide guidance to ensure the AI models accurately interpret and apply complex legal concepts, which is a barrier due to the significant cost of employing such professionals. Nonetheless, if RLHF can demonstrate further downstream savings due to improved worker efficiency, the up-front cost of employing legal professionals for data annotation tasks may be a worthwhile investment. ORC10: Expanding Legal Domain Coverage. There is a noticeable gap in the research across various areas of the legal domain, including Intellectual Property, Criminal Law, Banking Law, Family Law, and Human Rights Law. These fields have seen limited exploration across all legal NLP tasks, such as LQA and other applications. Expanding research into these areas is essential for developing comprehensive automated legal systems that can provide tailored solutions and insights highly relevant to these sectors of law.</p><p>ORC11: Small Language Models (SLMs). Research into SLMs specific to the legal domain is notably absent. Although some work explored notions of distillation and the use of smaller transformers, there has not been a significant exploration into the efficiency considerations of employing large language models in the legal domain. Addressing this gap could lead to more efficient, resource-conscious solutions that still maintain high performance in legal text processing and analysis. The development of SLMs tailored for legal applications could revolutionise the accessibility and scalability of legal NLP tools.</p><p>ORC12: Domain-Specific Efficient Fine-Tuning. Domain-specific efficient fine-tuning within the legal field remains underexplored, with only two known studies addressing it <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b81">82]</ref>. Legal texts feature complex structures and specialised vocabulary that standard LLMs may not capture without substantial adaptation. Moreover, the legal domain covers a vast array of document types, such as case law, statutes and contracts, each requiring tailored model strategies. This diversity makes it imperative to develop fine-tuning methods that not only adapt a model generally but also tailor it to the specific characteristics of each document type. Most existing approaches fine-tune the entire model, which can be resource intensive. More focused research could enable efficient fine-tuning of legal LLMs using fewer resources and improve their practical deployment.</p><p>ORC13: Legal Logical Reasoning. Complex legal logical reasoning remains a challenge in LJP, particularly in predicting prison terms. Current SOTA methods struggle to achieve high accuracy in this area, highlighting a clear need for improved approaches that better handle legal reasoning. Multi-hop QA Models with knowledge graphs, or reasoning LMs, may be an avenue worth investigating here.</p><p>ORC14: Legal Named Entity Recognition. Legal NER focuses on specific challenges such as disambiguating titles, resolving nested entities, handling co-references and processing PDFs that are not machine-readable. Despite its crucial role in structuring and interpreting legal documents, research on legal NER remains limited, as shown in Figure <ref type="figure" target="#fig_1">1</ref>.</p><p>ORC15: Stochastic Parrots. The concept of "Stochastic Parrots" pertains particularly to LLMs. It shows the concern that these models often do not truly understand language but merely mimic human patterns. This mimicry can lead to unreliable outcomes, especially in critical legal situations, if the models are not trained on high-quality, unbiased datasets.</p><p>The risk is notably significant in LJP, where training on biased or unfair data could lead to irreversible outcomes, as discussed in Bender et al. <ref type="bibr" target="#b10">[11]</ref>'s work on the limitations of LLMs. Ultimately, we must ensure that tools and algorithms aimed at automating legal processes do not become decision makers, rather that they are framed as decision support tools. More research is required to fully grasp the sociotechnical aspects of NLP in the legal domain.</p><p>Manuscript submitted to ACM ORC16: Retrieval-Augmented Generation. The legal domain presents particular challenges because documents are lengthy, contain numerous cross-references, and exhibit complex linguistic structures. These characteristics can cause LLMs to hallucinate when asked for precise answers. RAG offers a promising remedy by incorporating relevant passages directly into the generation process, overcoming LLM input-length limits and improving both relevance and contextual accuracy. However, applying RAG in legal settings still poses challenges: handling documents from multiple jurisdictions, ensuring that retrieved material remains temporally current, addressing multilingual texts, and mitigating retrieval biases are all significant problems that must be resolved.</p><p>Summary. Table <ref type="table" target="#tab_4">5</ref> illustrates the connections between ORCs and the discussed research areas. As shown, most ORCs are related to LJP, LQA, LTC and LLMs, indicating more extensive research in these areas. Nonetheless, it is evident that there remains significant work to be done in all areas of focus, and this work is likely to be of a cross-disciplinary nature, spanning a number of research communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="14">Conclusion</head><p>Advances in AI and NLP have improved legal NLP techniques and models, reducing the difficulty of engaging in legal processes for laypersons, and easing workloads and manual labour for professionals. This survey provides a comprehensive overview of the advancements in NLP techniques used in the legal domain, paying special attention to the unique characteristics of legal documents. We also reviewed existing datasets and LLMs tailored for the legal domain.</p><p>Legal NER research spans multiple languages and utilises diverse methods, from rule-based to BERT-based models.</p><p>LDS has largely focused on extractive and abstractive methods, ranging from TF-IDF to transformer-based models.</p><p>LAM now automates the detection of claims, premises, and their links through domain-specific annotation schemes and graph-based or residual-network approaches, supporting legal reasoning tasks such as conflict resolution. In LTC, multi-class classification dominates, with DL architectures, such as CNNs and Bi-LSTMs widely used. LJP primarily focuses on Chinese datasets with DL approaches, such as CNNs. LQA often leverages IR techniques such as BM25, with a significant focus on statutory law. Finally, we explored key ORCs, such as the need for domain-specific fine-tuning strategies, addressing bias and fairness in legal datasets and the importance of interpretability and explainability. Other challenges include the development of more robust pre-processing techniques, handling multilingual capabilities and integrating ontology-based methods for more accurate legal reasoning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>shows a sample page from the Code of Federal Regulations (CFR) of the US, extracted from the Electronic CFR 2 , which displays ¬ß 40.51, Labour Certification, of 22 CFR. This section is part of Title 22 of the CFR, which governs foreign relations and specifically details the requirements and procedures for labour certification. The text includes underlined references to other legal sources, such as INA 212(a)<ref type="bibr" target="#b4">(5)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A sample page from the CFR, illustrating the structured and referenced nature of legal documents.</figDesc><graphic coords="6,131.58,95.04,385.56,214.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Chalkidis et al.<ref type="bibr" target="#b18">[19]</ref> present MULTI-EURLEX, a multilingual dataset containing 65,000 EU laws translated into 23 official EU languages, annotated with EuroVoc labels. The dataset emphasises temporal concept drift by adopting chronological splits, enhancing its utility for sophisticated LTC tasks requiring understanding legal terms across different time periods.Papaloukas et al.<ref type="bibr" target="#b102">[102]</ref> introduce the Greek Legal Code dataset, categorising approximately 47,000 Greek legislative documents into a detailed multi-level classification system. The dataset is structured into volumes, chapters and subjects, each containing diverse legal documents from Greek legislation history, supporting LTC in the Greek legal domain.Song et al.<ref type="bibr" target="#b124">[124]</ref> introduce POSTURE50K, a legal dataset containing 50,000 the US legal opinions annotated with Legal Procedural Postures ranging from common to rare motions. The dataset includes an innovative split strategy to support supervised and zero-shot learning evaluations, ensuring infrequent categories are adequately represented, enhancing model generalizability and testing accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>Kalamkar et al. [65] release a legal NER corpus with 46,545 entities of 14 types extracted from Indian High Court and Supreme Court judgements. The corpus is divided into preamble and judgement sections and covers entities such as court, petitioner, respondent, and statute. The training set, drawn from judgements between 1950 and 2017, contains 29,964 entities, while the development and test sets cover cases from 2018 to 2022, ensuring no training leakage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>and multi-class classification to multiple-choice questions and are split chronologically into training, development and test sets to provide standardised evaluation metrics. For instance, ECHR datasets focus on violations of European Convention of Human Rights provisions; theSCOTUS database classifies the US Supreme Court opinions by legal issues; the EUR-Lex database involves labelling EU laws with EuroVoc concepts; LEDGAR classifies provisions of the US contracts; UNFAIR-ToS identifies unfair terms in online service agreements; and CaseHOLD involves QA about legal rulings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>capabilities of NLP models in legal research by providing 19,115 gold-standard human-annotated and 30,944 inferred labels for entity extraction and LJP. Key contributions include anonymizing decision documents, employing a robust annotation methodology and creating datasets for specific NLP tasks, such as entity extraction and judgement prediction. Niklaus et al. [97] present LEXTREME, a multilingual benchmark for evaluating LMs on legal NLP tasks. Drawing on legal NLP research published between 2010 and 2022, they curate 11 human-annotated datasets spanning 24 languages and multiple legal domains. To ensure fair comparison across models, the authors introduce two aggregate metrics-the dataset aggregate score and the language aggregate score-and show that performance on LEXTREME rises with model size. The benchmark covers three task types: single-label text classification, multi-label text classification and NER.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>List of acronyms used in the survey.</figDesc><table><row><cell cols="2">Acronyms Meaning</cell></row><row><cell>CFR</cell><cell>Code of Federal Regulations</cell></row><row><cell>CJEU</cell><cell>Court of Justice of the European Union</cell></row><row><cell>ECHR</cell><cell>European Court of Human Rights</cell></row><row><cell>FSCS</cell><cell>Federal Supreme Court of Switzerland</cell></row><row><cell>JEC-QA</cell><cell>Judicial Examination of Chinese Question Answering</cell></row><row><cell>LAM</cell><cell>Legal Argument Mining</cell></row><row><cell>LDS</cell><cell>Legal Document Summarisation</cell></row><row><cell>LJP</cell><cell>Legal Judgement Prediction</cell></row><row><cell>LQA</cell><cell>Legal Question Answering</cell></row><row><cell>LTC</cell><cell>Legal Text Classification</cell></row><row><cell>ML-LJP</cell><cell>Multi-Law aware Legal Judgement Prediction</cell></row></table><note><p>unique requirements and the methodologies employed to address them. Additionally, we study the datasets available</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Overview of datasets and their usage across different legal NLP tasks and cited studies.</figDesc><table><row><cell cols="2">Task Datasets</cell><cell>Identified Studies</cell></row><row><cell></cell><cell></cell><cell>Feng et al. [41], Tong et al. [132], Xu et al.</cell></row><row><cell>LJP</cell><cell>CAIL datasets by Xiao et al. [141]</cell><cell>[142], Yang et al. [143, 143], Zhang et al.</cell></row><row><cell></cell><cell></cell><cell>[149], Zhong et al. [152, 153]</cell></row><row><cell>LTC</cell><cell cols="2">LEDGAR by Tuggener et al. [133] EURLEX57K by Chalkidis et al. [18] Song et al. [124] Mamooler et al. [86]</cell></row><row><cell>NER</cell><cell>LegalNERo by PƒÉis et al. [110] German LER by Leitner et al. [72]</cell><cell>SmƒÉdu et al. [123]</cell></row><row><cell>LAM</cell><cell>ECHR by Poudyal et al. [108] Demosthenes by Santin et al. [115]</cell><cell>Zhang et al. [148] Santin et al. [115], Zhang et al. [148]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Summary of existing ORCs in each area. A direct relationship is denoted with a check-mark (‚úì).</figDesc><table><row><cell>Open Research Challenges</cell><cell cols="8">LQA LJP LTC LDS NER AM LLMs Corpora</cell></row><row><cell>Bias and Fairness</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>Privacy Concern</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>Interpretability and Explainability</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>Annotation Process and Transparency</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>Scarcity of Reliable Annotated data</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>Multilingual Capabilities</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>Ontology</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>Pre-processing Legal Text</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>RLHF</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>Expanding Legal Domain Coverage</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell></row><row><cell>SLMs</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>Domain-Specific Efficient Fine-Tuning</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>Legal Logical Reasoning</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>Legal NER</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>-</cell></row><row><cell>Stochastic Parrots</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>-</cell></row><row><cell>RAG</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>‚úì</cell><cell>‚úì</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://crtc.gc.ca/eng/archive/2007/dt2007-75.htm   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.ecfr.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Manuscript submitted to ACM</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>https://www.avvo.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>https://eur-lex.europa.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>https://op.europa.eu/en/web/eu-vocabularies</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>https://claudette.eui.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>https://www.geonames.org/ Manuscript submitted to ACM</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>https://www.supremecourt.gov Manuscript submitted to ACM</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Leda: a system for legal data annotation</title>
		<author>
			<persName><forename type="first">Subinay</forename><surname>Adhikary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dwaipayan</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debasis</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouvik</forename><surname>Kumar Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kripabandhu</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Legal Knowledge and Information Systems</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="367" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">AraLegal-BERT: A pretrained language model for Arabic Legal text</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Al-Qurishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Alqaseemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riad</forename><surname>Souissi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop</title>
		<meeting>the Natural Legal Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Legal Judgment Prediction for Canadian Appeal Cases</title>
		<author>
			<persName><forename type="first">Intisar</forename><surname>Almuslim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 7th International Conference on Data Science and Machine Learning Applications (CDMA)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="163" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Impact of Large Language Modeling on Natural Language Processing in Legal Texts: A Comprehensive Survey</title>
		<author>
			<persName><forename type="first">Dang</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Dinh-Truong</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tran</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 15th International Conference on Knowledge and Systems Engineering (KSE)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Expert Finding in Legal Community Question Answering</title>
		<author>
			<persName><forename type="first">Arian</forename><surname>Askari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriella</forename><surname>Pasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval: 44th European Conference on IR Research</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="22" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Answer Retrieval in Legal Community Question Answering</title>
		<author>
			<persName><forename type="first">Arian</forename><surname>Askari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval: 46th European Conference on Information Retrieval</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page" from="477" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">E-NER -An Annotated Named Entity Recognition Corpus of Legal Text</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terence</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasileios</forename><surname>Lampos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingemar</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="246" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">LegalDB: Long DistilBERT for Legal Document Classification</title>
		<author>
			<persName><forename type="first">Purbid</forename><surname>Bambroo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditi</forename><surname>Awasthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">AsyLex: A Dataset for Legal Language Processing of Refugee Claims</title>
		<author>
			<persName><forename type="first">Claire</forename><surname>Barale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Klaisoongnoen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Rovatsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nehal</forename><surname>Bhuta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2023</title>
		<meeting>the Natural Legal Language Processing Workshop 2023</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="244" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shmargaret</forename><surname>Shmitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Comparative Study of Summarization Algorithms Applied to Legal Case Judgments</title>
		<author>
			<persName><forename type="first">Paheli</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaustubh</forename><surname>Hiware</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subham</forename><surname>Rajgaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nilay</forename><surname>Pochhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kripabandhu</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="413" to="428" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">DeepRhole: deep learning for rhetorical role labeling of sentences in legal case documents</title>
		<author>
			<persName><forename type="first">Paheli</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shounak</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kripabandhu</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Alec Radford, Ilya Sutskever, and Dario Amodei</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><surname>Mccandlish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Neural Information Processing Systems</title>
		<meeting>the 34th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Language models are few-shot learners Article 159</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Answering legal questions from laymen in German civil law system</title>
		<author>
			<persName><forename type="first">Marius</forename><surname>B√ºttner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Conference of the European Chapter</title>
		<meeting>the 18th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2015" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">ChatGPT may Pass the Bar Exam soon</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12202</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>but has a Long Way to Go for the LexGLUE benchmark</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural Legal Judgment Prediction in English</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4317" to="4323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extreme Multi-Label Legal Text Classification: A Case Study in EU Legislation</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanouil</forename><surname>Fergadiotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop</title>
		<meeting>the Natural Legal Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MultiEURLEX -A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manos</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6974" to="6996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manos</forename><surname>Fergadiotis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>LEGAL-BERT: The Muppets straight out of Law School In Findings of the Association for Computational Linguistics: EMNLP 2020</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LexGLUE: A Benchmark Dataset for Legal Language Understanding in English</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhik</forename><surname>Jana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hartung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bommarito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4310" to="4330" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, Daniel Katz, and Nikolaos Aletras</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing</title>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Pasini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Letizia</forename><surname>Tomada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Schwemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>S√∏gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">EQUALS: A Real-world Dataset for Legal Question Answering via Reading Chinese Laws</title>
		<author>
			<persName><forename type="first">Andong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yating</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changlong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weixing</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Nineteenth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-Task Learning in Natural Language Processing: An Overview</title>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhiyu Zoey Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinlu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armineh</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianjun</forename><surname>Nourbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Petzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.01769</idno>
		<title level="m">A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Odysseas</surname></persName>
		</author>
		<author>
			<persName><surname>Chlapanis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.08502</idno>
		<title level="m">Ion Androutsopoulos, and Dimitrios Galanis. 2024. Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pessoa</forename><surname>Telmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malik</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominic</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Culver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caio</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName><surname>Corro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Andre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vera</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sofia</forename><surname>L√∫cia Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Morgado</surname></persName>
		</author>
		<author>
			<persName><surname>Desa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.03883</idno>
		<title level="m">SaulLM-7B: A pioneering Large Language Model for Law</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges</title>
		<author>
			<persName><forename type="first">Junyun</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaochun</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="102050" to="102071" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Magesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Legal Analysis</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="93" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">NeuroNER: an easy-to-use program for named-entity recognition based on neural networks</title>
		<author>
			<persName><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Young</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?</title>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Deroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhankar</forename><surname>Maity</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.00554</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jo√£o</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">A</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Antunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Baptista</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.07047</idno>
		<imprint/>
	</monogr>
	<note>and Carlos Gon√ßalves. 2022. State of the Art in Artificial Intelligence applied to the Legal Domain</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Discourse-Aware Unsupervised Summarization for Long Scientific Documents</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Mircea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackie</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kit</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
		<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1089" to="1102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Named Entity Recognition and Resolution in Legal Text</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dozier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravikumar</forename><surname>Kondadadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Vachher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriharsha</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramdev</forename><surname>Wudali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Processing of Legal Texts: Where the Language of Law Meets the Law of Language</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="27" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Just cognition: scientific research on bias and some implications for legal procedure and decision-making</title>
		<author>
			<persName><forename type="first">Gary</forename><surname>Edmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristy</forename><forename type="middle">A</forename><surname>Martire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The modern law review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="633" to="664" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multi-Task Deep Learning for Legal Document Translation, Summarization and Multi-Label Classification</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Elnaggar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Gebendorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Matthes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Artificial Intelligence and Cloud Computing Conference</title>
		<meeting>the 2018 Artificial Intelligence and Cloud Computing Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName><forename type="first">G√ºnes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A View of How Language Models Will Transform Law</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Fagan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.07826</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">LetSum, an automatic Legal Text Summarizing system</title>
		<author>
			<persName><forename type="first">Atefeh</forename><surname>Farzindar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Legal knowledge and information systems: JURIX 2004, the seventeenth annual conference</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Legal Judgment Prediction via Event Extraction with Constraints</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Legal Tech, Civil Procedure, And The Future Of Adversarialism</title>
		<author>
			<persName><forename type="first">Freeman</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonah</forename><forename type="middle">B</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><surname>Gelbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">University of Pennsylvania Law Review</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="1001" to="1099" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Unfair clause detection in terms of service across multiple languages</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Lagioia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agnieszka</forename><surname>Jab≈Çonowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multi-Task Attentive Residual Networks for Argument Mining</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio, Speech and Lang. Proc</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1877" to="1892" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Legal IR and NLP: The History, Challenges, and State-of-the-Art</title>
		<author>
			<persName><forename type="first">Debasis</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">G</forename><surname>Conrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kripabandhu</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paheli</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Kumar Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shounak</forename><surname>Paul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval (ECIR)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Flexicon, a new legal information retrieval system</title>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Gelbart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can. L. Libr</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Beyond boolean search: FLEXICON, a legal tex-based intelligent system</title>
		<author>
			<persName><forename type="first">Dephne</forename><surname>Gelbart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Artificial Intelligence and Law</title>
		<meeting>the 3rd International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="225" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gesnouin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Gomes Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hatim</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camille</forename><surname>Tapory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Brier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Rozenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><forename type="middle">El</forename><surname>Woehrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Yakaabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilie</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathile</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laure</forename><surname>Fontas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Puydebois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Theophile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mael</forename><surname>Morandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pauline</forename><surname>Creissac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elise</forename><surname>Ennouchy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Celine</forename><surname>Valetoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Severine</forename><surname>Visade</surname></persName>
		</author>
		<author>
			<persName><surname>Balloux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.16182</idno>
		<title level="m">LLaMandement: Large Language Models for Summarization of French Legislative Proposals</title>
		<editor>
			<persName><forename type="first">Emmanuel</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pierre-Etienne</forename><surname>Devineau</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ulrich</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Esther</forename><forename type="middle">Mac</forename><surname>Namara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Su</forename><surname>Yang</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">DALE: Generative Data Augmentation for Low-Resource Legal NLP</title>
		<author>
			<persName><forename type="first">Sreyan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Kiran Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Evuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramaneswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Utkarsh</forename><surname>Sakshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<author>
			<persName><forename type="first">John</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Teresa</forename><surname>Turell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dimensions of Forensic Linguistics</title>
		<title level="s">AILA Applied Linguistics Series</title>
		<imprint>
			<publisher>John Benjamins Publishing Company</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="317" />
		</imprint>
	</monogr>
	<note>1 ed.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Overview and Discussion of the Competition on Legal Information, Extraction/Entailment (COLIEE) 2023</title>
		<author>
			<persName><forename type="first">Randy</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi-Young</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliano</forename><surname>Rabelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Satoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaharu</forename><surname>Yoshioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Socionetwork Strategies</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Introducing LUIMA: an experiment in legal conceptual retrieval of vaccine injury decisions using a UIMA type system and tools</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Grabmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preethi</forename><surname>Sureshkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vern</forename><forename type="middle">R</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Artificial Intelligence and Law</title>
		<meeting>the 15th International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
	<note>Manuscript submitted to</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Natural language processing for legal document review: categorising deontic modalities in contracts</title>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Georgette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamidreza</forename><surname>Soltani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olufemi</forename><surname>Isiaq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Detecting Arguments in CJEU Decisions on Fiscal State Aid</title>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Grundler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piera</forename><surname>Santin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Galli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Godano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Lagioia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Sartor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Workshop on Argument Mining</title>
		<meeting>the 9th Workshop on Argument Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="143" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mining legal arguments in court decisions</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
			<affiliation>
				<orgName type="collaboration">Indra Spiecker genannt D√∂hmann, and Christoph Burchard</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Faber</surname></persName>
			<affiliation>
				<orgName type="collaboration">Indra Spiecker genannt D√∂hmann, and Christoph Burchard</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Recchia</surname></persName>
			<affiliation>
				<orgName type="collaboration">Indra Spiecker genannt D√∂hmann, and Christoph Burchard</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Bretthauer</surname></persName>
			<affiliation>
				<orgName type="collaboration">Indra Spiecker genannt D√∂hmann, and Christoph Burchard</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
			<affiliation>
				<orgName type="collaboration">Indra Spiecker genannt D√∂hmann, and Christoph Burchard</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Pile of Law: Learning Responsible Data Filtering from the Law and a 256GB Open-Source Legal Dataset</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Krass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Cuad: An expert-annotated nlp dataset for legal contract review</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Ball</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06268</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models</title>
		<author>
			<persName><forename type="first">Jia-Hong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao-Chun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessio</forename><forename type="middle">M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><surname>Pacces</surname></persName>
		</author>
		<author>
			<persName><surname>Kanoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 33rd ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="4554" to="4562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">AILA: A Question Answering System in the Legal Domain</title>
		<author>
			<persName><forename type="first">Weiyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A sentence is known by the company it keeps: Improving Legal Document Summarization Using Deep Clustering</title>
		<author>
			<persName><forename type="first">Deepali</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malaya</forename><surname>Dutta Borah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Biswas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="165" to="200" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">Samyar</forename><surname>Janatian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannes</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinzhe</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaromir</forename><surname>Savelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karim</forename><surname>Benyekhlef</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.04911</idno>
		<title level="m">From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06825</idno>
	</analytic>
	<monogr>
		<title level="j">Mistral</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling</title>
		<author>
			<persName><forename type="first">Hang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiajie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">'</forename><surname>Sandy' Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jad</forename><surname>Kabbara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.17019</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05137</idno>
		<title level="m">Llion Jones, and Jakob Uszkoreit</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>One model to learn them all</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Named Entity Recognition in Indian court judgments</title>
		<author>
			<persName><forename type="first">Prathamesh</forename><surname>Kalamkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Astha</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smita</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Karn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="184" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Text summarization from legal documents: a survey</title>
		<author>
			<persName><forename type="first">Ambedkar</forename><surname>Kanapala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sukomal</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajendra</forename><surname>Pamula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="371" to="402" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">GPT-4 passes the bar exam</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">James</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Bommarito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><surname>Arredondo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">382</biblScope>
			<biblScope unit="page">2270</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A Free Format Legal Question Answering System</title>
		<author>
			<persName><forename type="first">Soha</forename><surname>Khazaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janardhana</forename><surname>Punuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chad</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename><surname>Staub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunny</forename><surname>Chiu-Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Sakalley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2021</title>
		<meeting>the Natural Legal Language Processing Workshop 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="107" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A Survey on Challenges and Advances in Natural Language Processing with a Focus on Legal Informatics and Low-Resource Languages</title>
		<author>
			<persName><forename type="first">Panteleimon</forename><surname>Krasadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><surname>Sakkopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilios</forename><forename type="middle">S</forename><surname>Verykios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER</title>
		<author>
			<persName><forename type="first">Amirhossein</forename><surname>Layegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Payberah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihhail</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName><surname>Matskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="241" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A Comparison Study on Legal Document Classification Using Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Jihoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyukjoon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Information and Communication Technology Convergence (ICTC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="926" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A Dataset of German Legal Documents for Named Entity Recognition</title>
		<author>
			<persName><forename type="first">Elena</forename><surname>Leitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Rehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Moreno-Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<meeting>the Twelfth Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4478" to="4485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName><surname>Lexisnexis</surname></persName>
		</author>
		<ptr target="https://www.lexisnexis.com/community/pressroom/b/news/posts/lexisnexis-international-legal-generative-ai-survey-shows-nearly-half-of-the-legal-profession-believe-generative-ai-will-transform-the-practice-of-law" />
		<title level="m">International Legal Generative AI Report</title>
		<imprint>
			<date type="published" when="2024-07-22">July 22. 2024</date>
		</imprint>
	</monogr>
	<note>n. d.</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Parameter-Efficient Legal Domain Adaptation</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Bhambhoria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="119" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Pre-Trained Language Models for Text Generation: A Survey</title>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">BERT-CNN based evidence retrieval and aggregation for Chinese legal multi-choice question answering</title>
		<author>
			<persName><forename type="first">Yanling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaye</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xudong</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="5909" to="5925" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">CLAUDETTE: an automated detector of potentially unfair clauses in online terms of service</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Przemys≈Çaw</forename><surname>Pa≈Çka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Contissa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Lagioia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Wolfgang</forename><surname>Micklitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Sartor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="117" to="139" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Low-resource court judgment summarization for common law systems</title>
		<author>
			<persName><forename type="first">Shuaiqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiannong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page">103796</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Fine-tune BERT for extractive summarization</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10318</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">ML-LJP: Multi-Law Aware Legal Judgment Prediction</title>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yating</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changlong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1023" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gijs</forename><surname>Van Dijck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerasimos</forename><surname>Spanakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Learning to Predict Charges for Criminal Cases with Legal Basis</title>
		<author>
			<persName><forename type="first">Bingfeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianbo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2727" to="2736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Legal Judgment Prediction with Multi-Stage Case Representation Learning in the Real Court Setting</title>
		<author>
			<persName><forename type="first">Luyao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yating</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changlong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="993" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Processing Long Legal Documents with Pre-trained Transformers: Modding LegalBERT and Longformer</title>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Mamakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petros</forename><surname>Tsotsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="130" to="142" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, and Ilias Chalkidis</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">An Efficient Active Learning Pipeline for Legal Text Classification</title>
		<author>
			<persName><forename type="first">Sepideh</forename><surname>Mamooler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R√©mi</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Massonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="345" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Legal-Tech Open Diaries: Lesson learned on how to develop and deploy light-weight models in the era of humongous Language Models</title>
		<author>
			<persName><forename type="first">Stelios</forename><surname>Maroudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sotiris</forename><surname>Legkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop</title>
		<meeting>the Natural Legal Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, and Ilias Chalkidis</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Re-evaluating GPT-4&apos;s bar exam performance</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Mart√≠nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Suzanne</forename><surname>Mcgee</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Generative</surname></persName>
		</author>
		<author>
			<persName><surname>Law</surname></persName>
		</author>
		<ptr target="https://www.lexisnexis.com/html/lexisnexis-generative-ai-story" />
		<imprint>
			<date>July 22</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Using machine learning to predict decisions of the European Court of Human Rights</title>
		<author>
			<persName><forename type="first">Masha</forename><surname>Medvedeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Vols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martijn</forename><surname>Wieling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="237" to="266" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Abstracting of legal cases: the potential of clustering based on the selection of representative objects</title>
		<author>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos</forename><surname>Dumortier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="151" to="161" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Ontologies in the Legal Domain</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Mommers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="265" to="276" />
			<pubPlace>Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Multi-language transfer learning for low-resource legal case summarization</title>
		<author>
			<persName><forename type="first">Gianluca</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Piscaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Ragazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Italiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Robust Deep Reinforcement Learning for Extractive Legal Summarization</title>
		<author>
			<persName><forename type="first">Duy-Hung</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bao-Sinh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dung</forename><surname>Nghiem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dung</forename><surname>Tien Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mim</forename><surname>Amina Khatun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Tien</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="597" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Attentive deep neural networks for legal document retrieval</title>
		<author>
			<persName><forename type="first">Ha-Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manh-Kien</forename><surname>Phi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan-Bach</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vu</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le-Minh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Phuong</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="57" to="86" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Swiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>St√ºrmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop</title>
		<meeting>the Natural Legal Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veton</forename><surname>Matoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pooja</forename><surname>Rani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>St√ºrmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3016" to="3054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<author>
			<persName><forename type="first">Joel</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veton</forename><surname>Matoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>St√ºrmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.02069</idno>
		<title level="m">MultiLegalPile: A 689GB Multilingual Legal Corpus</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Paul F Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">The PRISMA 2020 statement: an updated guideline for reporting systematic reviews</title>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanne</forename><forename type="middle">E</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">M</forename><surname>Bossuyt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Boutron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tammy</forename><forename type="middle">C</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><forename type="middle">D</forename><surname>Mulrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larissa</forename><surname>Shamseer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">M</forename><surname>Tetzlaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elie</forename><forename type="middle">A</forename><surname>Akl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sue</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Glanville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">M</forename><surname>Grimshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asbj√∏rn</forename><surname>Hr√≥bjartsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Manoj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjing</forename><surname>Lalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Loder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Mayo-Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><forename type="middle">A</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lesley</forename><forename type="middle">A</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivian</forename><forename type="middle">A</forename><surname>Tricco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Penny</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName><surname>Moher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systematic Reviews</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Argumentation mining: the detection, classification and structure of arguments in text</title>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Mochales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Palau</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Artificial Intelligence and Law</title>
		<meeting>the 12th International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Multi-granular Legal Topic Classification on Greek Legislation</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Papaloukas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Athinaios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Despina</forename><surname>Pantazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manolis</forename><surname>Koubarakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2021</title>
		<meeting>the Natural Legal Language Processing Workshop 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="63" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">AILA 2021: Shared task on Artificial Intelligence for Legal Assistance</title>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Upal</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parth</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayan</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paheli</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kripa</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual Meeting of the Forum for Information Retrieval Evaluation</title>
		<meeting>the 13th Annual Meeting of the Forum for Information Retrieval Evaluation</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="12" to="15" />
		</imprint>
	</monogr>
	<note>Arindam Pal, Arnab Bhattacharya, and Prasenjit Majumder</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Lessons learned building a legal inference dataset</title>
		<author>
			<persName><forename type="first">Sungmi</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">I</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Combining WordNet and Word Embeddings in Data Augmentation for Legal Texts</title>
		<author>
			<persName><forename type="first">Sezen</forename><surname>Per√ßin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Lagioia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piera</forename><surname>Santin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Sartor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">CaseSummarizer: A System for Automated Summarization of Legal Texts</title>
		<author>
			<persName><forename type="first">Seth</forename><surname>Polsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pooja</forename><surname>Jhunjhunwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="258" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Dal Pont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Galli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Loreggia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Pisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Rovatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Sartor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.04416</idno>
		<title level="m">Legal Summarisation through LLMs: The PRODIGIT Project</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">ECHR: Legal Corpus for Argument Mining</title>
		<author>
			<persName><forename type="first">Jaromir</forename><surname>Prakash Poudyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aagje</forename><surname>Savelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><forename type="middle">Francine</forename><surname>Ieven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teresa</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Argument Mining</title>
		<meeting>the 7th Workshop on Argument Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="67" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">TimeML: Robust Specification of Event and Temporal Expressions in Text</title>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jos√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Casta√±o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roser</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Directions in Question Answering</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Named Entity Recognition in the Romanian Legal Domain</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Vasile PƒÉis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><surname>Mitrofan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Luca Gasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandru</forename><surname>Coneschi</surname></persName>
		</author>
		<author>
			<persName><surname>Ianov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2021</title>
		<meeting>the Natural Legal Language Processing Workshop 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Overview and discussion of the competition on legal information extraction/entailment (COLIEE) 2021</title>
		<author>
			<persName><forename type="first">Juliano</forename><surname>Rabelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randy</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi-Young</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaharu</forename><surname>Yoshioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Satoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Socionetwork Strategies</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="111" to="133" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>R√∂ttger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janet</forename><surname>Pierrehumbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter</title>
		<meeting>the 2022 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<title level="m">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<title level="m">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Argumentation Structure Prediction in CJEU Decisions on Fiscal State Aid</title>
		<author>
			<persName><forename type="first">Piera</forename><surname>Santin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Grundler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Galli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Lagioia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Sartor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Nineteenth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<author>
			<persName><forename type="first">Jaromir</forename><surname>Savelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><forename type="middle">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannes</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huihui</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.09525</idno>
		<title level="m">Explaining Legal Concepts with Augmented Large Language Models (GPT-4)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Abstractive Summarization of Dutch Court Verdicts Using Sequence-to-sequence Models</title>
		<author>
			<persName><forename type="first">Marijn</forename><surname>Schraagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Floris</forename><surname>Bex</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="76" to="87" />
		</imprint>
	</monogr>
	<note>Nick Van De Luijtgaarden, and Dani√´l Prijs</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">ClassActionPrediction: A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US</title>
		<author>
			<persName><forename type="first">Gil</forename><surname>Semo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dor</forename><surname>Bernsohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Hagag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gila</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Niklaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="31" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">Large scale legal text classification using transformer models</title>
		<author>
			<persName><forename type="first">Zein</forename><surname>Shaheen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Wohlgenannt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erwin</forename><surname>Filtz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12871</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Multi-LexSum: Real-world Summaries of Civil Rights Lawsuits at Multiple Granularities</title>
		<author>
			<persName><forename type="first">Zejiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Dahlberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margo</forename><surname>Schlanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13158" to="13173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">The Woman Worked as a Babysitter: On Biases in Language Generation</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3407" to="3412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Legal-LM: Knowledge Graph Enhanced Large Language Models for Law Consulting</title>
		<author>
			<persName><forename type="first">Juanming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinglang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenglin</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Intelligent Computing Technology and Applications</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Legal Named Entity Recognition with Multi-Task Domain Adaptation</title>
		<author>
			<persName><forename type="first">RƒÉzvan-Alexandru</forename><surname>SmƒÉdu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion-Robert</forename><surname>DinicƒÉ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei-Marius</forename><surname>Avram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dumitru-Clementin Cercel, Florin Pop, and Mihaela-Claudia Cercel</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>Proceedings of the Natural Legal Language Processing Workshop</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Multi-label legal document classification: A deep learning-based approach with label-attention and domain-specific pre-training</title>
		<author>
			<persName><forename type="first">Dezhao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Vold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanika</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">101718</biblScope>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">A dataset for evaluating legal question answering on private international law</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Sovrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><surname>Palmirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biagio</forename><surname>Distefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Sapienza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Vitali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Eighteenth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="230" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">DiscoLQA: zero-shot discourse-based legal question answering on European Legislation</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Sovrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><surname>Palmirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Sapienza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vittoria</forename><surname>Pistone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Highly Multilingual Named Entity Resource</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mijail</forename><surname>Kabadjov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenya</forename><surname>Belyaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Van Der Goot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
	<note>JRC-NAMES: A Freely Available</note>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<author>
			<persName><forename type="first">Zhongxiang</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.09136</idno>
		<title level="m">A Short Survey of Viewing Large Language Models in Legal Aspect</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Tamkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.02503</idno>
		<title level="m">Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Biases in legal decision-making: Comparing prosecutors, defense attorneys, law students, and laypersons</title>
		<author>
			<persName><forename type="first">Doron</forename><surname>Teichman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eyal</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilana</forename><surname>Ritov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of empirical legal studies</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="852" to="894" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fien</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meulder</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Legal Judgment Prediction via graph boosting with constraints</title>
		<author>
			<persName><forename type="first">Suxin</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingling</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">LEDGAR: A Large-Scale Multi-label Corpus for Text Classification of Legal Provisions in Contracts</title>
		<author>
			<persName><forename type="first">Don</forename><surname>Tuggener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Pius Von D√§niken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Peetz</surname></persName>
		</author>
		<author>
			<persName><surname>Cieliebak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<meeting>the Twelfth Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1235" to="1241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">≈Å Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veliƒçkoviƒá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">A topic discovery approach for unsupervised organization of legal document collections</title>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Vianna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edleno</forename><surname>Silva De Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Altigran</forename><surname>Soares Da Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">D2GCLF: Document-to-Graph Classifier for Legal Document Classification</title>
		<author>
			<persName><forename type="first">Qiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Amor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruofan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2208" to="2221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Towards Interactivity and Interpretability: A Rationale-based Legal Judgment Prediction Framework</title>
		<author>
			<persName><forename type="first">Yiquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yating</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changlong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Lawformer: A pre-trained language model for Chinese legal long documents</title>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="79" to="84" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02478</idno>
		<title level="m">CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Distinguish Confusing Law Articles for Legal Judgment Prediction</title>
		<author>
			<persName><forename type="first">Nuo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinghui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3086" to="3095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Legal judgment prediction via multi-perspective bi-feedback network</title>
		<author>
			<persName><forename type="first">Wenmian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4085" to="4091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions</title>
		<author>
			<persName><forename type="first">Hai</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhunchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1854" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Privacy-Preserving Models for Legal Natural Language Processing</title>
		<author>
			<persName><forename type="first">Ying</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="172" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model</title>
		<author>
			<persName><forename type="first">Mingruo</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien-Hsuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><forename type="middle">S Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">W H</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxi</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">ChatGPT by OpenAI: The End of Litigation Lawyers</title>
		<author>
			<persName><forename type="first">Yuen</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vanessa</forename><surname>Iu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Man-Yi</forename><surname>Wong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Argument Mining with Graph Representation Learning</title>
		<author>
			<persName><forename type="first">Gechuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Nulty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lillis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Nineteenth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Contrastive Learning for Legal Judgment Prediction</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhicheng</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">GLQA: A Generation-based Method for Legal Question Answering</title>
		<author>
			<persName><forename type="first">Weiqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hechuan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dezhong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">When does pretraining help? assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings</title>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Eighteenth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Legal Judgment Prediction via Topological Learning</title>
		<author>
			<persName><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3540" to="3549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction</title>
		<author>
			<persName><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1250" to="1257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence</title>
		<author>
			<persName><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5218" to="5230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">JEC-QA: A Legal-Domain Question Answering Dataset</title>
		<author>
			<persName><forename type="first">Haoxi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9701" to="9708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Computing and Exploiting Document Structure to Improve Unsupervised Extractive Summarization of Legal Case Decisions</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022</title>
		<meeting>the Natural Legal Language Processing Workshop 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="322" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">The cambridge law corpus: a dataset for legal AI research</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>√ñstling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holli</forename><surname>Sargeant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Bull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Terenin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leif</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M√•ns</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Steffek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Neural Information Processing Systems</title>
		<meeting>the 37th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
