<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tian</forename><surname>Liang</surname></persName>
							<email>liangt21@mails</email>
						</author>
						<author>
							<persName><forename type="first">Zhiwei</forename><surname>He</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Jiao</orgName>
								<orgName type="institution">Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xing</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Jiao</orgName>
								<orgName type="institution">Tong University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
							<email>yang.yujiu@sz.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
							<email>zptu@tencent.com</email>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8350E2940EB499E98BE2F96401BF0952</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-28T12:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern large language models (LLMs) like ChatGPT have shown remarkable performance on general language tasks but still struggle on complex reasoning tasks, which drives the research on cognitive behaviors of LLMs to explore human-like problem-solving strategies. Along this direction, one representative strategy is self-reflection, which asks an LLM to refine the solution with the feedback generated by itself iteratively. However, our study shows that such reflection-style methods suffer from the Degeneration-of-Thought (DoT) problem: once the LLM has established confidence in its solutions, it is unable to generate novel thoughts later through reflection even if its initial stance is incorrect. To address the DoT problem, we propose a Multi-Agent Debate (MAD) framework, in which multiple agents express their arguments in the state of "tit for tat" and a judge manages the debate process to obtain a final solution. Clearly, our MAD framework encourages divergent thinking in LLMs which would be helpful for tasks that require deep levels of contemplation. Experiment results on two challenging datasets, commonsense machine translation and counterintuitive arithmetic reasoning, demonstrate the effectiveness of our MAD framework. Extensive analyses suggest that the adaptive break of debate and the modest level of "tit for tat" state are required for MAD to obtain good performance. Moreover, we find that LLMs might not be a fair judge if different LLMs are used for agents. Code is available at <ref type="url" target="https://github.com/Skytliang/Multi-Agents-Debate">https://github.  com/Skytliang/Multi-Agents-Debate</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large language models (LLMs) have shown remarkable performance on general language tasks <ref type="bibr" target="#b14">(Jiao et al., 2023;</ref><ref type="bibr" target="#b29">Wu et al., 2023;</ref><ref type="bibr" target="#b0">Bang</ref> 0.00 0.25 0.50 0.75 1.00 1 2 3 4 5 Multi-Agent Debate Self-Reflection Iteration Avg. Disagreement et al., 2023) but still struggle on complex reasoning tasks <ref type="bibr">(Zhu et al., 2023a;</ref><ref type="bibr" target="#b9">Gou et al., 2023)</ref>, which drives the research on cognitive behaviors of LLMs to explore human-like problem-solving strategies. In particular, self-reflection <ref type="bibr" target="#b19">(Madaan et al., 2024;</ref><ref type="bibr" target="#b23">Shinn et al., 2024)</ref>, a concept that usually refers to the process of introspection and examination of a person's own thoughts, has been explored to solve intricate tasks that could be challenging for a zeroshot generation or even chain-of-thought (CoT) prompting <ref type="bibr" target="#b28">(Wei et al., 2022)</ref>. Specifically, selfreflection involves an iterative refinement process such that the LLM generates a new answer based on the answers and feedback in previous iterations and then provides feedback for the new answer. While self-reflection can be effective in creating better answers, it is highly dependent on the self-evaluation capabilities of LLMs, which are not formally guaranteed <ref type="bibr" target="#b23">(Shinn et al., 2024)</ref>.</p><p>In this work, we focus on the Degeneration-of-Thought (DoT) problem in self-reflection, which is proposed and defined by us for the first time. Formally, DoT describes the following scenario:</p><p>Once the LLM-based agent has established confidence in its answers, it is unable to generate novel thoughts later through self-reflection even if the initial stance is incorrect.</p><p>To demonstrate this problem, we force the agents to engage in a debate or self-reflection for 5 rounds before reaching an answer. Next, we manually determine the disagreement as 1 and agreement as 0 between two adjacent iterations. We define the average disagreement in iteration i as the percentage of opposition occurring between two debaters across multiple debates (or self-confliction in selfreflection). We show the trends in Figure <ref type="figure" target="#fig_1">1</ref>. The low disagreement of self-reflection suggests that the LLM sticks to the incorrect answers predicted by CoT and is unable to engage in meaningful selfreflection.</p><p>There are various factors <ref type="bibr" target="#b1">(Bortolotti, 2011;</ref><ref type="bibr" target="#b15">Keestra, 2017)</ref> that could result in DoT, and we outline three here: (1) Bias and Distorted Perception. Self-perception can be influenced by biases, preconceived notions, and distorted thinking patterns, which can be learned from the massive amount of data during pretraining. If an LLM's self-reflection is clouded by such biases or distorted thinking, it can lead to inaccurate conclusions instinctively. (2) Rigidity and Resistance to Change. Self-reflection often involves challenging one's beliefs, assumptions, and behaviors. If an LLM is resistant to change or holds rigid beliefs, it may struggle to engage in meaningful self-reflection that leads to better answers. (3) Limited External Feedback. Selfreflection is primarily an internal process, but external feedback can provide valuable perspectives and insights. Without considering external feedback, an LLM may miss important blind spots or alternative viewpoints that can enrich its self-reflection.</p><p>To address the DoT issue, we leverage another fundamental characteristic of human problemsolving, i.e., debate, to encourage divergent thinking in LLMs. Specifically, we propose the MAD framework, short for Multi-Agent Debate, where two agents express their own arguments in the state of "tit for tat" and a judge monitors and manages the debate process to obtain a final solution. The nature of MAD determines that (1) The distorted thinking of one agent can be corrected by the others; (2) The resistance to change of one agent will be complemented by the others; and (3) each agent can obtain external feedback from the others. Therefore, MAD is less susceptible to the factors of DoT, and can explore divergent chain-of-thoughts to achieve accurate answers.</p><p>We conducted experiments on both natural language generation and understanding through two challenging tasks, namely, Commonsense Machine Translation (Common MT) and Counter-Intuitive Arithmetic Reasoning (Counter-Intuitive AR). The common characteristic of the two tasks is that our instincts are mostly incorrect based on only the superficial expressions of the questions, and deeper levels of contemplation are required for better answers. Experimental results demonstrate that our MAD framework outperforms the baseline methods, especially, GPT-3.5-Turbo with MAD can surpass the performance of GPT-4 on Common MT.</p><p>The contributions of this work are summarized as follows:</p><p>• We propose and define the Degeneration-of-Thought (DoT) problem in self-reflection, and address it by proposing the Multi-Agent Debate (MAD) framework to explore divergent chain-of-thoughts.</p><p>• We demonstrate the effectiveness of MAD on two challenging tasks, and find that GPT-3.5-Turbo with MAD can even surpass GPT-4 on the Common MT dataset.</p><p>• Experimental results show that the adaptive break strategy and the modest level of "tit for tat" state are required for performance improvement. In addition, we find that the llm-based judge shows a preference to the side with the same LLM as the backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Multi-Agent Debate Framework</head><p>Figure <ref type="figure">2</ref> illustrates the general framework of MAD, where two debaters and a judge are involved in a debate to resolve a math problem while self-reflection descends into the trap of DoT. Generally, our MAD framework is composed of three components which are elaborated as follows:</p><p>Meta Prompts. We use meta prompts to introduce the topic to be solved, the number of debaters, the iteration limit, and other requirements. An exampe of meta prompts for the arithmetic reasoning task in Figure <ref type="figure">2</ref> is:</p><p>You are a debater. Hello and welcome to the debate competition. It's not necessary to fully agree with each other's perspectives, as our objective is to find the correct answer. The debate topic is stated as follows: &lt;debate topic&gt;.</p><p>As seen, we require the agents to "tit for tat" (e.g. contents underlined in meta prompts above) so as to create an atmosphere of debate.</p><p>Reflection:</p><p>(1) I have a clear understanding of the problem.</p><p>(2) I have used the correct formula for the circumference of a circle and applied it to both circles to find the number of revolutions.</p><p>(3) I have correctly calculated the number of revolutions of circle A.</p><p>Based on the results of my selfreflection, I am confident that my answer is correct. Therefore, circle A will revolve 3 times in total as it rolls around circle B once.</p><p>Let the radius of circle A be r and the radius of circle B be 3r. The distance circle A travels along the circumference of circle B is equal to the circumference of circle B, which is 6πr. The number of revolutions = (6πr) / (2πr) = 6πr / 2πr = 3. So, circle A will revolve 3 times in total as it rolls around circle B once.</p><p>That's a valid point, however... I disagree with you. To find the total number of revolutions, we need to consider both the rotation around circle B and the rotation of circle A itself. Therefore, circle A will revolve 3 times around its own center and 1 time around circle B, making a total of 4 revolutions.</p><p>The two circles are externally tangent and there is no relative sliding. The radius of circle A is 1/3 the radius of circle B. Circle A rolls around circle B one trip back to its starting point. How many times will circle A revolve in total?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Agent Debate</head><p>Counter-Intuitive Question Self-Reflection I see your point, but...</p><p>The negative side correctly considers both the rotation of circle A around its own center and its rotation around circle B, while the affirmative side only considers the rotation around circle B.</p><p>Therefore, the answer is 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chain-of-Thought</head><p>Figure <ref type="figure">2</ref>: Framework of Multi-Agent Debate. Here we designate the devil ( ) as the affirmative side while the angel ( ) as the negative side. We want the angel to correct the devil's mistakes.</p><p>Debaters. There are</p><formula xml:id="formula_0">N debaters D = {D i } N i=1</formula><p>involved in the framework. In each debate iteration, the debaters D i speak one by one in a fixed order and express their arguments based on the previous debate history H, i.e., D i (H) = h. An example of a debater prompt appears below:</p><p>• Prompt for Affirmative Debater ( )</p><p>You are affirmative side. Please express your viewpoints.</p><p>• Prompt for Negative Debater ( )</p><p>You are negative side. You disagree with the affirmative side's points. Provide your reasons and answer.</p><p>Judge. We also design a judge J to manage and monitor the whole debate process. The judge contains two different modes: (a) Discrinative Mode, in which the judge J decides whether the correct solution can be obtained after all the debaters finish their arguments in the current iteration:</p><formula xml:id="formula_1">J d (H) = True, solution obtained False, otherwise<label>(1)</label></formula><p>If it is True, the debate is over. Otherwise, the debate continues. (b) Extractive Mode, in which the judge J needs to extract the final solution based on the whole debate history: J e (H) = a, since no correct solution is identified within the iteration limit of debate. An example of a judge prompt ( ) appears below:</p><p>You are a moderator. There will be two debaters involved in a debate competition. They will present their answers and discuss their perspectives on the &lt;debate topic&gt;.</p><p>At the end of each round, you will evaluate both sides' answers and decide which one is correct.</p><p>3 Experiment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Challenging Testbeds</head><p>We conduct experiments on two challenging tasks, namely, commonsense machine translation (i.e., Common MT), and counter-intuitive arithmetic reasoning (i.e., Counter-Intuitive AR), which require deep levels of contemplation for LLMs. Please refer to Appendix A for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Commonsense Machine Translation</head><p>The Common MT dataset is composed of Chinese⇒English translation examples <ref type="bibr" target="#b10">(He et al., 2020)</ref>, which are used to examine three types of ambiguity resolution abilities of translation models, covering lexical and contextless/contextual syntactic ambiguity. Within the challenging part of Common MT, the authentic translation of each source sentence requires a proper understanding of common sense knowledge. While these ambiguous sentences might appear to have a straightforward translation, such a literal interpretation is erroneous. Failure to address such ambiguities may result in inaccurate translations.</p><p>Counter-Intuitive Arithmetic Reasoning Previous studies on thinking hierarchy <ref type="bibr" target="#b3">(Daniel, 2017)</ref> suggest that we humans have a fast and intuitive system and a slow and logical system, and tend to run the lower level system before the higher level one. Inspired by this, we created a more challenging dataset named Counter-Intuitive Arithmetic Reasoning (CIAR) to evaluate the reasoning abilities of LLMs at deep levels. Our Counter-Intuitive AR dataset contains 200 questions collected from elicitation questions <ref type="bibr" target="#b17">(Kong et al., 2022)</ref> <ref type="foot" target="#foot_0">foot_0</ref> , web data<ref type="foot" target="#foot_1">foot_1</ref> and additional manual derivatives of these questions. Compared to the commonly-used datasets, e.g., MultiArith <ref type="bibr" target="#b22">(Roy and Roth, 2015)</ref>, GSM8K <ref type="bibr" target="#b2">(Cobbe et al., 2021)</ref>, our dataset presents two distinct challenges:</p><p>• Resistance to Intuition. The questions are embedded in hidden traps designed to elicit intuitive and appealing answers that are often incorrect. This feature evaluates the abilities of LLMs to resist the traps of superficial expressions.</p><p>• Multi-Step Reasoning. Each correct answer within the dataset requires a rigorous multi-step reasoning process, thereby evaluating the capacity of LLMs to engage in complex decisionmaking and problem-solving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Setups</head><p>Input Format. Our experiments are performed in zero-shot instructions (setting temperature to 0). For all used datasets, we use a unified prompt to make LLMs give explanations and answers. We present the inputs to agents through &lt;debate topic&gt; as mentioned in Section 2. For example, if we want to translate "吃掉敌人一个师" from Chinese to English, we will set the &lt;debate topic&gt; as "What is the correct English translation of the following Chinese text: 吃掉敌人一个师". For QA task, we employ the same prompt except set the &lt;debate topic&gt; to the arithmetic question.</p><p>Backbone Models. In this work, we mainly use three agents in our MAD framework, including two debaters (i.e., affirmative and negative) and a judge. We assess two open-source (i.e., vicuna-7b-v1.5-16k<ref type="foot" target="#foot_2">foot_2</ref> and vicuna-13b-v1.5-16k<ref type="foot" target="#foot_3">foot_3</ref> ) and two apibased LLMs (i.e., GPT-3.5-Turbo-0301 and GPT-4-0314).</p><p>Compared Methods. Generally, we compare our MAD framework with baseline models and Self-Reflect on both tasks. We also include other baseline methods individually, namely, Rerank and MAPS for Common MT, CoT and Self-Consistency for Counter-Intuitive AR. Below elaborates the details of them:</p><p>• Self-Reflect <ref type="bibr" target="#b23">(Shinn et al., 2024)</ref>: This approach requires the LLM to refine its translation until it deems the current output satisfactory.</p><p>• Rerank <ref type="bibr" target="#b11">(He et al., 2024)</ref>: We sample the translations from the LLM for four times, from which we select the best candidate based on a quality estimation (QE) HUMANr<ref type="foot" target="#foot_4">foot_4</ref> . This approach can be seen as analogous to self-consistency <ref type="bibr" target="#b27">(Wang et al., 2022)</ref>, where the majority voting is replaced by an external QE HUMANr.</p><p>• MAPS <ref type="bibr" target="#b11">(He et al., 2024)</ref>: This method enables LLMs to mimic the human translation process: analyze before translate, which can be viewed as a chain-of-thought method applied to translation.</p><p>• CoT <ref type="bibr" target="#b16">(Kojima et al., 2022)</ref>: This approach concatenates a trigger sentence "Let's think step by step" to the test question.</p><p>• Self-Consistency <ref type="bibr" target="#b27">(Wang et al., 2022)</ref>: This method samples multiple responses and determines the final answer through a majority vote.</p><p>All agents in our experimental setup, such as debaters and judge, are large language models. Here, we implement the methods on top of GPT-3.5-Turbo and Vicuna models. like COMET 6 and BLEURT 7 , which are widely adopted evaluation metrics for LLM-based translation literature <ref type="bibr" target="#b11">(He et al., 2024;</ref><ref type="bibr" target="#b12">Hendy et al., 2023;</ref><ref type="bibr" target="#b8">Garcia et al., 2023;</ref><ref type="bibr" target="#b21">Pilault et al., 2023)</ref>. In addition, we also employ professional human translators to directly assess the translation results, measuring translation quality on a scale ranging from 1 to 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results on Common MT</head><p>Results. In Common MT test set, we focus more on the translation accuracy of specific words and whether they conform to common sense. However, such minor variations at token level are difficult to reflect on automatic metrics. We therefore provide human HUMAN to evaluate these methods more accurately. Table <ref type="table" target="#tab_0">1</ref> presents the experimental results. MAPS and Self-Reflec achieve improvements over baseline GPT-3.5-Turbo. Remarkably, our proposed MAD, by utilizing GPT-3.5 as the backbone model, has demonstrated significant advancements over GPT-4 across both automatic and human evaluation metrics.</p><p>Case Study. Table <ref type="table">2</ref> shows example translations generated by baseline GPT-3.5-Turbo and the proposed MAD. We can find that the baseline GPT-3.5-Turbo (even the more powerful GPT-4) incorrectly translates the source words literally. Because of the DoT issue, Self-Reflect cannot rectify the literal translation.</p><p>The proposed MAD framework, which explores divergent chain-of-thoughts, 6 <ref type="url" target="https://github.com/Unbabel/COMET/">https://github.com/Unbabel/COMET/</ref>, Unbabel/wmt22-comet-da 7 <ref type="url" target="https://github.com/google-research/bleurt">https://github.com/google-research/bleurt</ref>, BLEURT-20</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>吃掉敌人一个师。 Correct Ref.</p><p>Destroy a division of the enemy. Incorrect Ref.</p><p>Eat up an enemy division.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-4</head><p>Eat up an enemy division. GPT-3.5-Turbo Eat up an enemy division. + Self-Reflect Eat up an enemy division. + MAD Eliminate an enemy division.</p><p>Table 2: Example translations generated by different methods. Best viewed in color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method ACC (%)</head><p>GPT-4 51.0 GPT-3.5-Turbo 26.0 + CoT 28.0 + Self-Consistency 29.5 + Self-Reflect 27.5 + MAD 37.0</p><p>Table 3: Accuracy on Counter-Intuitive AR.</p><p>can generate the free translation of the underlined words within the source sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results on Counter-Intuitive AR</head><p>Results. Table <ref type="table">3</ref> lists the results in terms of reasoning accuracy. We can observe that Self-Reflect only marginally improves over the baseline GPT-3.5-Turbo, while CoT and Self-Consistency bring more improvements. Our MAD framework, though not as good as GPT-4, outperforms all the other compared methods based on GPT-3.5-Turbo, which further demonstrates its effectiveness. We also validate MAD on math and symbolic reasoning tasks and report our results in Appendix C. Case Study. Figure <ref type="figure">2</ref> shows an example on Counter-Intuitive AR. We find both CoT and Self-Reflect fail to reach the right answer by mistakenly outputing 3. With divergent thinking, our MAD framework emerges "we need to consider both the rotation around circle B and the rotation of circle A itself " and find the correct answer 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head><p>In this section, we present a qualitative analysis to provide some insights how MAD works. Unless otherwise stated, we report the overall results on the Common MT dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mitigation of DoT</head><p>As mentioned in the Section 1, the DoT problem originates from three factors: (1) Bias and Distorted Perception, (2) Rigidity and Resistance to Change, and (3) Limited External Feedback. In our MAD framework, we introduce the views of other agents in the form of debates, solving the phenomenon of limited external feedback (problem 3).</p><p>Next, this section will delve into the mitigation of problems 1 and 2 through experiments.</p><p>• Bias: We observe that LLMs often rely on direct intuition, which can lead to incorrect or inappropriate responses. To address this problem, we use human evaluation to determine the ambiguity error rate of LLMs' responses, examining if the LLM's output is biased.</p><p>• Diversity: LLMs are resistant to changing their answers and lack diverse reflection. The diversity of the translations is evaluated using the Self-BLEU score <ref type="bibr" target="#b32">(Yin et al., 2020)</ref>. In other words, methods lacking diverse reflection produce more similar translation candidates. Consequently, higher Self-BLEU scores mean lower diversity. We calculate text diversity via:</p><formula xml:id="formula_2">Diversity = 100 -Self_BLEU (Cand 1 , Cand 2 ) (2)</formula><p>In formula (2), candidates 1 and 2 represent the initial translation (base answer in Self-Reflection or affirmative side's response in MAD) and the current</p><p>Judge LLM COMET HUMAN Vicuna-13b as Debaters Vicuna-13b 79.9 3.20 GPT-3.5-Turbo 80.4 3.25 GPT-3.5-Turbo as Debaters Vicuna-13b 83.2 3.47 GPT-3.5-Turbo 84.4 3.69</p><p>Table 5: Translation performance with different judge.</p><p>translation (possible modified answer after Self-Reflection or negative side's response in MAD).</p><p>As shown in Table <ref type="table" target="#tab_4">4</ref>, Bias and Rigidity are significant factors causing DoT. In addition, addressing these biases and stereotypes through self-reflection can be challenging. MAD framework effectively corrects inherent biases in translation, mitigates DoT, and considerably improves performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis of Judge</head><p>In this section, we analyze the behavior of the judge for different settings of the debaters.</p><p>Strong debaters with a weak judge work better than the reverse. To understand the roles of debaters and judge in MAD, we employ various combinations of models to initialize the agents. Specifically, we utilize the smaller language model (vicuna-13b-v1.5-16k) as a judge to evaluate the debate results of the more powerful LLMs (GPT-3.5-Turbo), and vice versa.</p><p>The detailed experimental findings are presented in Table <ref type="table">5</ref>. The quality of the debaters' responses significantly impact the performance ceiling of MAD. Regardless of the model chosen for the judge, Turbo debaters consistently generate superior translations compared to Vicuna. In addition, the selection of the judge agent plays a secondary role. When Turbo debaters are involved, Vicuna, serving as the judge, underperforms Turbo across all test sets. LLM may not act as an impartial judge when different LLMs are used as debaters. We study the behavior of agents by calculating how many times the judge chooses the answers of each debater as the final solution in different scenarios. The results are listed in Table <ref type="table">6</ref> and we have the following observations:</p><p>• Same LLM for All Agents (Rows 1 ⃝ and 2 ⃝): We find that the judge consistently favors the ID Jud Debater Winner Aff Neg Aff Neg Tie 1 ⃝ Turbo Turbo Turbo 87 104 9 2 ⃝ GPT-4 GPT-4 GPT-4 67 124 9 3 ⃝ GPT-4 Turbo GPT-4 52 136 12 4 ⃝ GPT-4 Turbo 120 77 3</p><p>Table 6: Number of times the judge chooses the answers of each debater based on different LLM.</p><p>negative side, which is believed to contribute to the performance improvement in MAD. When encountering complex tasks, the affirmative side tends to make mistakes that should be corrected by the opposing side to achieve improvements.</p><p>• Debaters of Different LLMs (Rows 3 ⃝ and 4 ⃝): We find that the judge shows a preference to the side with the same LLM as the backbone. This bias indicates that LLMs might not be a fair judge <ref type="bibr" target="#b26">(Wang et al., 2023)</ref> when different LLMs are used for the agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis of Debaters</head><p>In this section, we will discuss several factors of debaters that would affect the performance of MAD: debater number, debate level, and debate iteration.</p><p>Increasing the number of debaters fails when backbone LLMs are poor at long-text modeling. It seems intuitive that increasing the number of debaters would enhance diversity of thought and subsequently improve performance. However, as shown in Table <ref type="table">7</ref>, an increase in the number of debaters has resulted in varying degrees of performance reduction.</p><p>To address this issue, we manually analyze the debate processes in approximately 10% of the test</p><p>Human Score 2.5 3.0 3.5 4.0 4.5 Number of Samples 0 50 100 150 200 Iteration 1 2 3 Number of Samples Baseline MAD 3.25 3.72 3.81 2.88 3.00 3.16 # of Debaters COMET HUMAN 2 (Default) 84.4 3.69 3 83.1 3.58 4 82.9 3.49</p><p>Table 7: Translation performance with more debaters.</p><p>subset. As the number of debaters increases, the length and complexity of the text also increase. Such LLM-based debaters tend to forget the views of other debaters during the debate. Moreover, it becomes more challenging for the judge to extract information from the debates for summarization. This suggests that the key challenge of MAD with more debaters lies in the limitations of the LLMs to handle long texts <ref type="bibr" target="#b18">(Liu et al., 2024)</ref>.</p><p>Appropriate "tit for tat" is beneficial for effective debate. We then study how the intensity of "tit for tat" affects the performance of MAD. To achieve so, we design different instructions (see Table <ref type="table" target="#tab_0">11</ref> in Appendix) to initialize the debaters' meta prompt. As shown in Figure <ref type="figure" target="#fig_3">3</ref>, asking the debaters to "tit for tat" (i.e., higher disagreement) is necessary for MAD to achieve good performance. However, we find that "must disagree with each other on every point " (with a disagreement of 0.988) does not lead to the best performance. We speculate that continuous disagreement without finding common ground can contribute to polarization, where the debate becomes more about winning the argument than seeking truth or understanding. This can reinforce pre-existing biases and make it difficult to reach a meaningful consensus.</p><p>Complex questions require more iteration rounds of debate. In our experimental setup, we did not implement any additional stopping strate- gies besides setting the maximum debate iteration to 3. In other words, the judge can take an adaptive break if it believes the optimal answer has already been obtained, efficiently ending the debate early.</p><p>To understand the distribution of iteration rounds and factors contributing to a longer debate process, we analyze the experimental results and present them in Figure <ref type="figure" target="#fig_5">4</ref>. In the majority of cases, the optimal answer can be achieved through a single round of debate, demonstrating the efficiency of MAD. However, when translating more complex sentences (subsets with lower human scores), the judge requires additional iterations to gather adequate information from the debaters before making a final decision. We also find that our MAD framework consistently brings performance improvements across all the three subsets, demonstrating its effectiveness.</p><p>Adaptive break plays an important role to conclude the debate in the optimal moment. Intuitively, longer debates would encourage more diverse thinking. It raises the question of how the model's performance would be affected if constrained to conclude at a specific debate round. For each iteration, we force the judge J to extract the final answer (a = J e (H)) instead of adaptively breaking the debate as in MAD.</p><p>As shown in figure <ref type="figure" target="#fig_6">5</ref>, we can observe that MAD performs better than self-reflection as the iteration increases. However, the highest COMET score appears at the first iteration and is also lower than the result of the adaptive break. It indicates that, for most examples, MAD can generate good translations at the first iteration such that the debate should be stopped. Forcing the debate to continue will harm the translation results, which demonstrates the reasonableness of our adaptive break strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Chain-of-Thought Prompting. Recently, <ref type="bibr" target="#b28">(Wei et al., 2022)</ref> has proposed chain-of-thought (CoT) prompting to improve the reasoning ability of LLMs. Specifically, CoT prompts LLMs to generate a series of intermediate steps that lead to the final answer of a multi-step problem. Most earlier work primarily concentrates on two main aspects: prompt design and decoding strategies. Zero-shot CoT <ref type="bibr" target="#b16">(Kojima et al., 2022)</ref> employs the trigger sentence "Let's think step by step" to provide guidance for the decoding of LLMs. Advanced sampling strategies have been explored to improve CoT by generating diverse reasoning paths, e.g., Self-Consistency <ref type="bibr" target="#b27">(Wang et al., 2022)</ref>, Auto-CoT <ref type="bibr" target="#b34">(Zhang et al., 2022)</ref>, Active-Prompting <ref type="bibr" target="#b4">(Diao et al., 2023)</ref>, Complexity-based Consistency <ref type="bibr" target="#b7">(Fu et al., 2022</ref><ref type="bibr">), Multi-Chain Reasoning (Yoran et al., 2023)</ref>, and Progressive-Hint Prompting <ref type="bibr" target="#b35">(Zheng et al., 2023)</ref>.</p><p>With the emergence of powerful LLMs, approaches based on self-evaluation have attracted increasing attention. These approaches involve the generation of initial output, followed by evaluating the output to acquire feedback, which is then utilized to refine the output. Evaluation feedback can come from the model itself, e.g., Self-refine <ref type="bibr" target="#b19">(Madaan et al., 2024)</ref> and Tree of Thoughts <ref type="bibr" target="#b31">(Yao et al., 2024)</ref>) or external environments, e.g., QAaP <ref type="bibr">(Zhu et al., 2023b)</ref> and Reflection <ref type="bibr" target="#b23">(Shinn et al., 2024)</ref>. The intuition behind these approaches involves the utilization of robust LLMs to mimic the human cognition process.</p><p>Generative Agents. Recently, LLM-based multiagent intelligent, e.g., Generative Agents <ref type="bibr" target="#b20">(Park et al., 2023)</ref>, Ghost in the Minecraft <ref type="bibr">(Zhu et al., 2023c)</ref>, GPT-Bargaining <ref type="bibr" target="#b6">(Fu et al., 2023)</ref>, has drawn significant attention for enabling simulations of human behavior. Our work follows this research line to address the DoT problem of LLMs. Concurrent with our work, a few studies <ref type="bibr" target="#b30">(Xiong et al., 2023;</ref><ref type="bibr" target="#b5">Du et al., 2023</ref>) also explore the multi-agent debate framework to enhance the reasoning ability of LLMs. The main differences between our MAD framework and these works are: (1) we introduce an additional judge with an adaptive break mechanism to decide the optimal moment to conclude the debate; (2) our work aims to address the DoT problem, which is an inherent deficiency of LLMs; and (3) we empirically find that our MAD framework can yield enhanced performance by employing agents with the identical backbone LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose and define the Degeneration-of-Thought (DoT) problem in self-reflection, and address it by proposing the Multi-Agent Debate (MAD) framework to explore divergent chainof-thoughts. We demonstrate the effectiveness of MAD on two challenging tasks and find that GPT-3.5-Turbo with MAD can even surpass GPT-4 on the Common MT dataset. Extensive analyses suggest that the adaptive break strategy of debate and the modest level of "tit for tat" state are required for MAD to obtain good performance. Complex samples require more rounds of debate. More interestingly, we find that LLMs might not be a fair judge if different LLMs are used for agents.</p><p>Future work includes scheduling more agents in the debate in an appropriate manner, multi-agent intelligence for board games, and AI feedback for model alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>A limitation of this work is that our method requires more time cost, as agents need to engage in multiple rounds of interaction to present and refute arguments. Moreover, current LLM-based agents may struggle to maintain coherence and relevance in long context scenarios, leading to potential misunderstandings and loss of context. Enhancing long-text modeling capability of large language models remains a future challenge. LLM-based judge may have a preference for outputs generated by itself. To mitigate this bias within the MAD framework, we recommend that all roles, including both the judge and debaters, utilize the same LLM, or alternatively, that the judge and debaters employ distinct LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Challenging Testbeds</head><p>We conduct experiments on two challenging tasks, namely, commonsense machine translation (i.e., Common MT), and counter-intuitive arithmetic reasoning (i.e., Counter-Intuitive AR), which require deep levels of contemplation for LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Commonsense Machine Translation</head><p>Ambiguity Type Source Sentence Correct Reference Incorrect Translation Lexical 吃掉敌人一个师。 Destroy a division of the enemy. Eat up an enemy division. 他喜欢吃苹果。 He likes to eat apples. He likes to destory apples. Contextless 正在手术的 是 健 康 的 医生。 A healthy doctor is doing surgery. What is undergoing surgery is a doctor who is healthy. 正在手术的 是 生 命 垂 危的病人。 What is undergoing surgery is a patient whose life is dying. A patient whose life is dying is doing surgery. Contextual 当 地 震 袭 击 中 国 时，援助的是中国。 When the earthquake hit China, China was aided. When the earthquake hit China, China has assisted. 当 地 震 袭 击 日 本 时，援助的是中国。 When the earthquake hit Japan, China has assisted. When the earthquake hit Japan, China was aided.</p><p>Table 8: Examples of lexical, contextual and contextless syntactic ambiguity from the Common MT dataset. The underlined Chinese words are translated into the corresponding colored words in English. Best viewed in color.</p><p>The Common MT dataset is composed of Chinese⇒English translation examples <ref type="bibr" target="#b10">(He et al., 2020)</ref>, which are used to examine three types of ambiguity resolution abilities of translation models. Specifically, The Common MT test set we used covers 200 examples of lexical ambiguity, 450 examples of contextless syntactic ambiguity, and 350 examples of contextual syntactic ambiguity. Within the challenging part of Common MT, the authentic translation of each source sentence requires a proper understanding of common sense knowledge. While these ambiguous sentences might appear to have a straightforward translation, such a literal interpretation is erroneous. Failure to identify and address such ambiguities may result in inaccurate translations.</p><p>Table <ref type="table">8</ref> lists some examples of these three types of ambiguity. Lexical ambiguity refers to words with multiple meanings in different contexts. Contextless and contextual syntactic ambiguity involve sentences with multiple interpretations, which can be resolved by context or common sense. As the lexical ambiguity of "吃掉敌人一个师" shows, the source word "吃掉" should be translated to "destroy" rather than the straightforward translation "eat up" by considering the common sense in the real world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Counter-Intuitive Arithmetic Reasoning</head><p>Previous studies on thinking hierarchy <ref type="bibr" target="#b3">(Daniel, 2017)</ref> suggest that we humans have a fast and intuitive system and a slow and logical system, and tend to run the lower level system before the higher level one. Inspired by this, we created a more challenging dataset named Counter-Intuitive Arithmetic Reasoning (CIAR) to evaluate the reasoning abilities of LLMs at deep levels.</p><p>Dataset Description. Our Counter-Intuitive AR dataset contains 200 questions collected from elicitation questions <ref type="bibr" target="#b17">(Kong et al., 2022)</ref> <ref type="foot" target="#foot_5">foot_5</ref> , web data<ref type="foot" target="#foot_6">foot_6</ref> and additional manual derivatives of these questions. Compared to the commonly-used datasets, e.g., MultiArith <ref type="bibr" target="#b22">(Roy and Roth, 2015)</ref>, GSM8K <ref type="bibr" target="#b2">(Cobbe et al., 2021)</ref>, our dataset presents two distinct challenges:</p><p>• Resistance to Intuition. The questions in our dataset are embedded in hidden traps designed to elicit intuitive and appealing answers that are often incorrect. This feature evaluates the abilities of LLMs to resist the traps of superficial expressions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Disagreement between two adjacent iterations with respect to the iteration of debate/self-reflection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Translation performance with respect to the debate level on Lexical.</figDesc><graphic coords="7,104.46,103.93,152.13,53.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Distribution of iteration rounds and a human score of each iteration subset.</figDesc><graphic coords="7,338.70,89.78,152.39,98.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance with respect to the iteration of debate or self-reflection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Translation performance on Common MT. Note that Rerank and MAPS use the external quality estimation tool to select the best translation from multiple translation candidates. HUMAN: direct assessment of translation quality from human evaluators on a scale ranging from 1 to 5.</figDesc><table><row><cell>Evaluation Metrics. For Counter-Intuitive AR, we report the accuracy (ACC) of predictions.</cell></row><row><cell>For Common MT, we adopt automatic metrics</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Mitigation of Degeneration-of-Thought.</figDesc><table><row><cell cols="2">Bias↓ Diversity↑</cell></row><row><cell>Self-Reflect 29.0 MAD 24.8</cell><cell>19.3 49.7</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://elicitation.info/questionnaire/1/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.geeksforgeeks.org/puzzles/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://huggingface.co/lmsys/vicuna-7b-v1.5-16k</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://huggingface.co/lmsys/vicuna-13b-v1.5-16k</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>We use wmt21-comet-qe-da as the QE HUMANr.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>https://elicitation.info/questionnaire/1/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>https://www.geeksforgeeks.org/puzzles/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Components</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Content</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>When Alice walks up the hill, her speed is 1 m/s and when she goes down the hill, her speed is 3 m/s. Then when Alice walks up and down the hill, what is her average speed? Correct Answer 1.5 m/s Explanation If Alice covers a distance of d going up and down the hill, then her total distance is 2d. Her time going up the hill is d/1 = d, and her time going down the hill is d/3. So, her total time is d + d/3 = 4d/3. Therefore, her average speed is 2d / (4d/3) = 3/2 m/s. Incorrect Answer 2 m/s Explanation Alice's average speed can be calculated by adding her speed going up the hill and her speed going down the hill, and then dividing by 2. So, (1 m/s + 3 m/s) / 2 = 2 m/s. Therefore, Alice's average speed is 2 m/s. • Multi-Step Reasoning. Each correct answer within the dataset requires a rigorous multi-step reasoning process, thereby evaluating the capacity of LLMs to engage in complex decision-making and problemsolving.</p><p>Dataset Format. In our Counter-Intuitive AR dataset, each example contains three key components (see Table <ref type="table">9</ref> for an example). We elaborate on the details below:</p><p>• Questions. The questions in our dataset are designed to stimulate counter-intuitive thinking, which aims to challenge conventional decision-making by presenting situations where the immediate, intuitive response is often incorrect.</p><p>• Answers. Each question is provided with a correct answer, which requires deep comprehension of the question and commonsense knowledge. Additionally, we also provide a plausible yet incorrect answer for comparison.</p><p>• Explanations. We offer comprehensive explanations for each correct answer, detailing the step-by-step rationale that leads to the right solution. We also provide the seemingly logical reasoning process behind incorrect answers. This reasoning process highlights the potential pitfalls and misconceptions during decision-making, especially when intuition is prioritized over rigorous logical reasoning.</p><p>Experimental Settings. During our experiments, we did not utilize the explanations from the dataset. We provided detailed explanations to facilitate subsequent researchers to understand how the correct answer was derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Human Evaluation Details</head><p>We implement human evaluation as follows:</p><p>• Human Score: We randomly shuffled the display order of the translated sentences from all methods in an anonymous manner. Then, employed three professional human translators (Krippendorff's Alpha = 0.76) to directly assess all methods together. Finally, we calculated the average scores for each methods.</p><p>• Bias: We also focus on whether the translation of specific words in CommonMT conforms to commonsense. Table <ref type="table">8</ref> lists an example of lexical ambiguity, where the source word "吃掉" should be translated to "destroy" rather than the straightforward translation "eat up". Here, we asked the annotators to label each sentence as 1 (not conforming to commonsense) or 0 (conforming to commonsense), and report the degree of bias for the whole test set.  <ref type="bibr" target="#b2">(Cobbe et al., 2021)</ref> and AddSub <ref type="bibr" target="#b13">(Hosseini et al., 2014)</ref>) and symbolic reasoning (three datasets from Big-Bench <ref type="bibr" target="#b24">(Srivastava et al., 2023;</ref><ref type="bibr" target="#b25">Suzgun et al., 2023)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Results on math and symbolic reasoning tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Prompts for Different Debate Levels</head><p>Level Prompt 0 Both sides must reach a full consensus on every point of the debate. Every statement must be agreed upon by both sides.</p><p>1 Most of the debate should be characterized by disagreements, but there may still be a small amount of consensus on less significant points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">(Default)</head><p>It's not necessary to fully agree with each other's perspectives, as our objective is to find the correct answer.</p><p>3 Both sides must disagree with each other on every point of the debate. There should be no consensus whatsoever.</p><p>Table <ref type="table">11</ref>: Prompts for different levels of "tit for tat" state. We modulate the level of "tit for tat" state outlined in Section 2 through appending natural language instructions to the debaters' meta prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Extra Computational Cost</head><p>Method Cost (# Generated Tokens) We measure the inference cost by the number of generated tokens. As listed in Table <ref type="table">12</ref>, the selfreflection cost is 1.83 times that of the baseline COT method. Meanwhile, our MAD approach incurs an additional 0.63 times the inference cost. This increase in cost is deemed acceptable given the significant benefit our approach offers in enhancing LLMs' divergent thinking capabilities without requiring external signals (interaction with humans).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Debate Process F.1 Commonsense Machine Translation</head><p>Table <ref type="table">13</ref> presents the debate process of example translation discussed in Section 3.3. In this debate, both sides disputed the English translation of the Chinese sentence "吃掉敌人一个师". The affirmative side proposed "eat up an enemy division", advocating for a more literal translation to depict the consumption or devouring of the enemy. In contrast, the negative side suggested "eliminate an enemy division", arguing this expression better conveys the destruction of the enemy in a military context. After the debate, the judge favored "eliminate", as it accurately reflected the severity and intent of the original military language. This debate highlights the complexities of translation, where context and nuance significantly impact the selection of appropriate words. In response to this issue, our MAD method helps LLMs understand semantics correctly and generate highly authentic translations.</p><p>&lt;Debate Topic&gt;: What is the correct English translation of the following text: 吃掉敌人一个师? I believe the correct translation of the Chinese text "吃掉敌人一个师" is "Eat up an enemy division." The word "吃掉" literally means "eat up" or "consume." I disagree with your translation. I believe the correct translation of the Chinese text "吃掉 敌人一个师" is "Eliminate an enemy division." While "吃掉" can be translated as "eat up" or "consume", it can also mean "eliminate" or "annihilate" in a military context. In this case, it is more appropriate to use "eliminate" as it conveys the idea of completely destroying the enemy division.</p><p>Both sides presented valid arguments and translations that accurately convey the meaning of the original Chinese text. The choice between "eat up" and "eliminate" may depend on the context and tone of the text. Therefore, there is no clear preference for either side at this time.</p><p>While "eliminate" does convey the idea of completely destroying the enemy division, it doesn't capture the connotation of consuming or devouring the enemy that is implied by "吃掉".</p><p>In a military context, "吃掉" is often used to describe the complete destruction of the enemy, rather than the consumption of their resources or territory.</p><p>Both sides presented valid arguments, but the negative side's argument that "eliminate" better captures the intensity and seriousness of the military language used in the original Chinese text was more convincing. Additionally, "eliminate" accurately conveys the idea of completely destroying the enemy division. Therefore, the correct English translation of the Chinese text "吃掉敌人一个 师" is "Eliminate an enemy division."</p><p>Table <ref type="table">13</ref>: The debate process of translation example on Chinese sentence "吃掉敌人一个师".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Counter-Intuitive Arithmetic Reasoning</head><p>Table <ref type="table">14</ref> shows the debate process of example answer in Table <ref type="table">9</ref>. This debate is about calculating Alice's average speed while walking up and down a hill, with speeds given as 1 m/s uphill and 3 m/s downhill. Initially, it was incorrectly proposed by affirmative side to just average the uphill and downhill speeds. The negative side, which is correct, states that average speed is total distance divided by total time. Given that the distances up and down the hill are equal, we must calculate the total time taken for the two directions before finding the average speed. Therefore, the average speed is calculated using the sum of the uphill and downhill distances (twice the distance of the hill) and the sum of the time taken for each (d/1 for uphill and d/3 for downhill). This leads to an average speed of 1.5 m/s, not 2 m/s as the affirmative side proposed. And the judge also supports the response from the negative side. Here, LLMs made a common mistake initially in understanding the concept of average speed. Our MAD method encourages divergent thinking and effectively prevents intuitive but incorrect responses, leading to the correct method for calculating average speed.</p><p>&lt;Debate Topic&gt;: When Alice walks up the hill, her speed is 1 m/s and when she goes down the hill, her speed is 3 m/s. Then when Alice walks up and down the hill, what is her average speed?</p><p>Alice's average speed can be calculated by adding her speed going up the hill and her speed going down the hill, and then dividing by 2. So, (1 m/s + 3 m/s) / 2 = 2 m/s. Therefore, Alice's average speed is 2 m/s. I disagree with your answer. The problem doesn't give us any information about the distance Alice covers while going up and down the hill. So, we cannot simply add her speeds and divide by 2 to get her average speed. We need to know the distance she covers to calculate her average speed.</p><p>The average speed is calculated by dividing the total distance by the total time taken. As Alice walks up and down the hill, the distance covered in both directions is the same. Therefore, the total distance covered is 2 times the distance of either direction.</p><p>That's a good point. But we can assume that Alice covers the same distance going up and down the hill. In that case, we can use the formula for average speed, which is total distance divided by total time. If Alice covers a distance of d going up and down the hill, then her total distance is 2d. Her time going up the hill is d/1 = d, and her time going down the hill is d/3. So, her total time is d + d/3 = 4d/3. Therefore, her average speed is 2d/(4d/3) = 3/2 m/s. Thank you for providing your answer. This average speed of 1.5 m/s takes into account both the uphill and downhill speeds, providing a balanced representation of Alice's overall performance while walking up and down the hill.</p><p>Yes. Let's assume the distance is d. The time taken to walk up the hill is d/1 and the time taken to walk down the hill is d/3. The total time taken is d/1 + d/3 = 4d/3. Therefore, the average speed is (2d)/(4d/3) = 1.5 m/s. Hence, the negative side is correct. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity</title>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Wilie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holy</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter</title>
		<meeting>the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="675" to="718" />
		</imprint>
		<respStmt>
			<orgName>Long Papers</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Does reflection lead to wise choices?</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Bortolotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Explorations</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="313" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Training verifiers to solve math word problems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow. Farrar</title>
		<author>
			<persName><forename type="first">Kahneman</forename><surname>Daniel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Straus and Giroux</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Active prompting with chain-ofthought for large language models</title>
		<author>
			<persName><forename type="first">Shizhe</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12246</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improving factuality and reasoning in language models through multiagent debate</title>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14325</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Improving language model negotiation with self-play and in-context learning from ai feedback</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10142</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Yao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.00720</idno>
		<title level="m">Complexity-based prompting for multi-step reasoning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of fewshot learning for machine translation</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yamini</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="10867" to="10878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Critic: Large language models can self-correct with tool-interactive critiquing</title>
		<author>
			<persName><forename type="first">Zhibin</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The box is in the pen: Evaluating commonsense reasoning in neural machine translation</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.327</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3662" to="3672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploring humanlike translation strategy with large language models</title>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="229" to="246" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Amr</forename><surname>Hendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Abdelrehim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Sharaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Gabr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hitokazu</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Afify</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hany</forename><surname>Hassan Awadalla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.09210</idno>
		<title level="m">How good are gpt models at machine translation? a comprehensive evaluation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to solve arithmetic word problems with verb categorization</title>
		<author>
			<persName><forename type="first">Mohammad Javad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="523" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jen-Tse</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.08745</idno>
		<title level="m">Is chatgpt a good translator? yes with gpt-4 as the engine</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Metacognition and reflection by interdisciplinary experts: Insights from cognitive science and philosophy</title>
		<author>
			<persName><forename type="first">Machiel</forename><surname>Keestra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Issues in Interdisciplinary Studies</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="121" to="169" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Eliciting thinking hierarchy without a prior</title>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinzhao</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13329" to="13341" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lost in the middle: How language models use long contexts</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Nelson F Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-refine: Iterative refinement with self-feedback</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skyler</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shrimai</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generative agents: Interactive simulacra of human behavior</title>
		<author>
			<persName><forename type="first">Sung</forename><surname>Joon</surname></persName>
		</author>
		<author>
			<persName><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">Jun</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive-chain-prompting: Ambiguity resolution for crosslingual conditional generation with interaction</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Pilault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Bražinskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="455" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Solving general arithmetic word problems</title>
		<author>
			<persName><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1743" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reflexion: Language agents with verbal reinforcement learning</title>
		<author>
			<persName><forename type="first">Noah</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">Aarohi</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abu</forename><surname>Awal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abubakar</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Adam R Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrià</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Garriga-Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Challenging big-bench tasks and whether chain-of-thought can solve them</title>
		<author>
			<persName><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="13003" to="13051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zefan</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binghuai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunbo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17926</idno>
		<title level="m">Large language models are not fair evaluators</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13648</idno>
		<title level="m">Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Diving into the inter-consistency of large language models: An insightful analysis through debate</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11595</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Meta-cotgan: A meta cooperative training paradigm for improving adversarial text generation</title>
		<author>
			<persName><forename type="first">Haiyan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9466" to="9473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Answering questions by meta-reasoning over multiple chains of thought</title>
		<author>
			<persName><forename type="first">Tomer</forename><surname>Ori Yoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Deutch</surname></persName>
		</author>
		<author>
			<persName><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5942" to="5966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Automatic chain of thought prompting in large language models</title>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03493</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Chuanyang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.09797</idno>
		<title level="m">Progressive-hint prompting improves reasoning in large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">2023a. Solving math word problems via cooperative reasoning induced language models</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 61st Annual Meeting Of The Association For Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">2023b. Question answering as programming for solving time-sensitive questions</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="12775" to="12790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">2023c. Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory</title>
		<author>
			<persName><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenxin</forename><surname>Hao Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17144</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
