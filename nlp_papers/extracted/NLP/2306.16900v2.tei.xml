<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research</title>
				<funder ref="#_TUa5YHU">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ji-Ung</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<addrLine>2 Hessian AI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haritz</forename><surname>Puerto</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<addrLine>2 Hessian AI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Betty</forename><surname>Van Aken</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Berliner Hochschule fÃ¼r Technik</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuki</forename><surname>Arase</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Osaka University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jessica</forename><forename type="middle">Zosa</forename><surname>Forde</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">IT University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>RÃ¼cklÃ©</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Darmstadt</orgName>
								<address>
									<addrLine>2 Hessian AI</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emma</forename><surname>Strubell</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>10 Amazon</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="institution">Allen Institute for AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
							<affiliation key="aff8">
								<orgName type="institution">Allen Institute for AI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5582A1ABEDFECC26B59A1A884D347CFD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-28T12:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many recent improvements in NLP stem from the development and use of large pretrained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in hardware and algorithms have transformed the field of NLP. Whereas NLP practitioners and researchers used to be able to develop and use cutting-edge NLP technology on relatively affordable hardware such as a laptop or a commodity server, modern state-of-the-art approaches have evolved to require more substantial computational power, typically achieved by specialized tensor processing hardware such as a GPU or TPU. This shift has raised at least two concerns among members of the NLP community (Strubell et al., 2019; Schwartz    â€¡ This work does not relate to AR's position at Amazon.</p><p>0 50 100 0 50 100 % GPU % Participants Actual distribution Equal distribution</p><p>Figure <ref type="figure">1</ref>: Distribution of available GPUs across our participants (in %). As can be seen, 87.8% of our survey participants have access to less than 10% of the total number of <ref type="bibr">GPUs. et al., 2020;</ref><ref type="bibr" target="#b1">Arase et al., 2021)</ref> and the AI community <ref type="bibr" target="#b9">(Patterson et al., 2022;</ref><ref type="bibr" target="#b17">Wu et al., 2022)</ref>: (1) Understanding and mitigating the environmental cost of NLP research and use, in terms of greenhouse gas (GHG) emissions, and (2) equity of access: the extent to which increasing computational requirements restricts who has access to develop and use modern NLP.</p><p>In response to these concerns, we formed a working group within ACL with the goal of better understanding the challenges surrounding efficient NLP and establishing policies to address them. In order to quantify views and impacts in the NLP community related to these concerns, we conducted a survey of the ACL community in July 2021, the results of which we report here. Besides concerns about the (1) environmental impact and (2) equity, we further solicit answers about their (3) impact on the whole peer reviewing process, as this is an important matter for inclusiveness. Overall, we elicited 312 responses from a distributed range of junior and senior researchers hailing from industry and academia. Some of our key findings include:</p><p>â€¢ More than 50% of the survey participants are moderately or very concerned about the envi-arXiv:2306.16900v2 [cs.CL] 9 Nov 2023 ronmental footprint of NLP research; mostly with respect to training and model selection.</p><p>â€¢ Overall, âˆ¼62% of our respondents have access to less than eight GPUs and moreover, over 90% have access to less than 10% of the total GPU power (Fig. <ref type="figure">1</ref>). As a frame of reference, recent work <ref type="bibr" target="#b5">(Izsak et al., 2021)</ref> showed that a clever set of techniques can be used to train BERT in 24 hours on 8 GPUs, and it takes about 7 minutes to fine-tune a RoBERTa LARGE model on the MNLI natural language inference dataset (about 400k training sentences) on one GPU (GTX 2080 Ti) to an accuracy of 85% <ref type="bibr" target="#b19">(Zhou et al., 2021)</ref>.</p><p>â€¢ A majority (76%) our respondents believe that it would be beneficial to have smaller versions of pre-trained models released together with larger ones. In fact, 33% of our free-text respondents emphasised the importance of sharing artifacts (such as code, models, training logs, etc.).</p><p>â€¢ The group that suffers most from lack of resources are students, who struggle to reproduce previous results when compared to researchers from large industry.</p><p>â€¢ While we find disparities between different groups-especially regarding the job sectorour analysis shows that most of them are not statistically significant. Instead, we find outliers across all groups showing that there exist disparities within. We find no evidence in our survey responses that "industry" has access to significantly more compute power than "academia". Instead, this mostly seems to be the case for very few extreme outliers (6%).</p><p>With this survey, we hope to provide a more solid foundation to back-up the ongoing discussion in the community and for devising concrete actions to make research more inclusive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Survey Description</head><p>The survey was open over a period of 17 days, from Monday, July 12, 2021 to Thursday, July 29, 2021. It was conducted via Microsoft Forms and distributed across the *CL community by mass mailing to ACL membership, and shared on Twitter. During that time, we collected 312 responses. The creation of the survey indicated that, "input will remain anonymous and the responses will also be summarized in aggregate form". 1 Therefore the data will be made available on request with a statement of intended purpose, due to privacy and ethical restrictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Questionnaire</head><p>The questions were divided into four categories. First, we collected some general information about our participants, like their current position and seniority ( Â§2.2). Second, we asked our participants about their concerns regarding the environmental impact of NLP experiments ( Â§3) and their access to computational resources ( Â§4). Finally, we asked about the impact of compute-intensive experiments on the reviewing process as well as about specific measurements to alleviate them ( Â§5).</p><p>To keep a low-effort for our participants, we crafted most of the (ğ‘„)uestions as simple yes/no/unsure questions. For subjects that require a more fine-grained analysis (e.g., environmental concerns) we used five point scales (either numeric or text-based). Overall, we asked a total of 19 questions from which 15 were multiple-choice questions (13 with a single answer possibility and two with multiple possible answers). ğ‘„4 (available compute resources) and ğ‘„11 (number of times reviewers asked for expensive experiments) required a numeric answer. Finally, ğ‘„9, ğ‘„18, and ğ‘„19 allowed free text answers. Participants were asked to provide answers to 13 questions, while six questions (ğ‘„4, ğ‘„9, ğ‘„11, ğ‘„12, ğ‘„14, ğ‘„19) were optional. All questions are provided in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Demographic Overview</head><p>In our first three questions, we asked the participants about their seniority, job sector, and geographic location (Fig. <ref type="figure" target="#fig_1">2</ref>).</p><p>Seniority. We asked our participants about the number of active years in the *CL community as an author, reviewer, or in a related role (ğ‘„1). Overall, a little over half (53.5%) indicated they were junior members of the community, while the remainder were fairly evenly split across mid-and late-career.</p><p>Job Sector. We further asked our participants about the current position they are holding (ğ‘„2). Possible responses were student, academic post-doc (Aca. PD), researcher from small (s) and large (l)</p><p>1 <ref type="url" target="https://www.aclweb.org/portal/content/efficient-nlp-survey">https://www.aclweb.org/portal/   content/efficient-nlp-survey</ref> Demographics Q1. Years active. How many years have you been active in the ACL community (as an author/reviewer/area chair/etc.)? Answer: [1-5], [6-10], [11-15], [16+]. Q2. Current Role. Answer: Student, Academic Postdoc, Academic PI, Researcher in large industry, Research in small industry, other. Q3. Geographic Location. Answer: Americas, Europe/Middle East, Africa, Asia/Oceania. Equity Q4. Available compute resources. Please provide a rough estimate of the average number of GPUs or equivalent accelerators that are available to you (for students / researchers) or to each researcher in your lab/group (for PIs / managers). If you cannot quantify the amount of compute resources, leave this field empty. Answer: Numeric response (optional). Q5. Unable to run experiments. In the last year, have you been unable to run experiments important for one of your projects due to lack of computational resources? Answer: Yes, No, Unsure. Q6. More resources would make your work more valuable. How often do you feel like your work would have been valued more by the community (e.g., accepted instead of rejected to some venue) if you had access to more computational resources? Answer: Five point scale. Environmental Concern Q7. Concern about environmental footprint. How concerned are you by the environmental footprint of the field of NLP? Answer: Five point scale. Q8. Most pressing factor. Which of the following do you feel is the most pressing factor with respect to the environmental impact of NLP? Answer: Choose all that apply: Training, Inference, Model selection, None, Other). Q9. Why? Optionally explain the reasons for your choices above. Answer: Free text (optional).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reviewing Process</head><p>Q10. Did reviewers ask for too expensive experiments? In the past 3 years, have you received feedback from reviewers who requested experiments that were too expensive for your budget for a particular paper? Answer: Yes, No, Not sure. Q11. If yes, how many times? Q12. Was the critique justified? If yes, do you feel the critique was justified? I.e., that the main scientific claims in your paper (e.g., that your approach was better than some baseline) were not sufficiently supported by the original, smaller-budget experiments? Answer: Yes, No, Not sure. Q13. Lack of resources prevents reproduction of previous results. How often do you find yourself unsuccessful in reproducing a previous result due to lack of computational resources? Answer: Never, Rarely, Sometimes, Often, Always. Q14. Efficiency Track. If you have work on efficient methods and/or enhanced reporting, would you consider submitting it to a dedicated track? Answer: Yes, No, N/A. Q15. Justify allocation of budget for experiments. As a reader, would you prefer authors to be requested to justify the way they allocate their budget to run experiments which adequately support their scientific claims? Answer: Yes, No, Not sure. Q16. Reviewers should justify the petition for additional experiments. As an author, would you prefer it if reviewers took up space in their review to justify their suggestions for additional experiments in terms of the evidence that those additional experiments would provide? I.e., what is currently missing in terms of lack of evidence to support the main claims of the paper, and how the additional experiments would provide evidence for the paper's research questions? Answer: Yes, No, Not sure. Q17. Releasing small versions of pretrained models. Would your work benefit from smaller versions of pretrained models released alongside larger ones? Answer: Yes, No, Not sure. Q18. How to encourage the release of models. Which of these solutions would you endorse for encouraging the release of trained models? Answer: Choose all that apply: Best artifact award, Instruct reviewers to reward papers who share/promise to share models, Visible branding of the paper in conference proceedings, None of the above, Other) Q19. Any other thoughts or suggestions? Answer: Free text (optional).</p><p>Table <ref type="table">1</ref>: List of questions in the survey. Summaries of the questions in bold. Only full questions were shown to the participants. industries (Ind.), and academic PI (Aca. PI). The largest group of participants were students (38.5%), followed by academic postdocs and PIs (34.3%), and industry researchers (24.7%). Eight participants (2.5%) responded with "other" from which seven were affiliated with academia (e.g., lecturers) and one with industry (consultant). For the finegrained analysis, we merge each response of "other" into the most fitting group in the survey (one student, five academic PIs, one academic post-doc, and one small industry researcher). For our analysis, we do not merge the academic and industry subgroups, as this may obfuscate existing disparities; e.g., between small and large industry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Geographic location.</head><p>We further asked respondents to share their geographic location (ğ‘„3). Overall, 45.8% of responses came from the Americas (AM), 40.4% from Europe (EU) and the Middle East (ME), and 13.8% from Asia (AS) and Australia (Aus). We received no responses from researchers in Africa (AF). The heavily skewed responses in terms of geographic location limits the expressiveness of this factor and thus, will not be considered for our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Methodology</head><p>In the following sections, we analyse and discuss the participants' responses with respect to the remaining three categories (environmental concerns, equity, and impact on the reviewing process). For each section, we first provide an overview of the distribution in the responses and then provide a finegrained analysis with respect to the seniority and job sector. The goal of the fine-grained analysis is to investigate if we can observe any statistically significant differences across different groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical tests.</head><p>Due to the explorative nature of our survey, the collected data violates the necessary conditions on homoscedasticity <ref type="bibr" target="#b7">(Levene, 1960)</ref> and normality <ref type="bibr" target="#b11">(Shaphiro and Wilk, 1965)</ref> that are required to conduct an analysis of variances <ref type="bibr">(ANOVA, Fisher 1921</ref>). Instead, we perform a Kruskal-Wallis test <ref type="bibr" target="#b6">(Kruskal and Wallis, 1952)</ref> as an indicator for any statistically significant differences 2 and if so, perform pairwise Welch's t-tests <ref type="bibr" target="#b16">(Welch, 1951)</ref> against a Bonferroni corrected ğ›¼ = 0.05 ğ‘š where ğ‘š is the number of pairwise comparisons; i.e., for ğ‘› 2 This is the case when ğ» &gt; ğ» ğ‘› 0 with ğ» ğ‘› 0 âˆ¼ ğœ’ 2 ğ‘›-1 for ğ‘› groups. For ğ›¼ = 0.05, we get ğ» 5 0 = 9.488 (job sector) and ğ» 4 0 = 7.815 (seniority) <ref type="bibr" target="#b0">(Abramowitz, 1974)</ref>.</p><p>groups, ğ‘š = ğ‘›â‹…(ğ‘›-1) 2 <ref type="bibr" target="#b2">(Bonferroni, 1936)</ref>. This results in corrected ğ›¼ = 0.0083 for seniority with ğ‘› = 4 and ğ›¼ = 0.005 for the job sector with ğ‘› = 5 (not merging academia and industry sectors). For the numerical questions (ğ‘„4 and ğ‘„11), we further analyze if there exist disparities within each group, using interquartile ranges with ğ‘˜ = 1.5 to detect outliers <ref type="bibr" target="#b15">(Tukey, 1977)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Environmental Footprint</head><p>We quantified existing concerns about the environmental impact of NLP experiments using a five point Likert scale (ğ‘„7) and asked our participants to select the most pressing issue in the typical life cycle of an NLP model (ğ‘„8) between (Train)ing, model (Select)tion, and (Infer)ence. Participants were allowed to select all applicable answers and could select (None) or provide (Other) pressing issues. They could also provide a textual justification of their answer(s) (ğ‘„9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Analysis</head><p>Figure <ref type="figure">3a</ref> shows that more than 50% of our participants were moderately (28.2%) or very (27.9%) concerned about the environmental footprint of NLP, while around 33% of them were slightly (14.7%) or somewhat (18.6%) concerned. 10.6% of participants were not concerned at all. Our participants further agreed that training (75.3%) and model selection (59.9%) are the most pressing issues (Fig. <ref type="figure">3b</ref>). <ref type="foot" target="#foot_0">3</ref> Inference took third place with 20.2%, while 6.1% of our participants selected none.</p><p>The smallest number responses was given for other with hyperparameter tuning and travelling (6 mentions each) being the most frequent ones. Also mentioned were storage consumption, hardware, expectations about large data experiments, and scale. Interestingly, many respondents considered inference less pressing than training and model selection.</p><p>Job Sector. Although we do not find significant differences by seniority, we see larger (although not statistically significant) differences when looking at the responses grouped by researchers from different job sectors (Fig. <ref type="figure">4a</ref>). We find that respondents from the large industry sector were mostly somewhat concerned, while the median for all other groups lies at often concerned. Similarly, we also see larger differences in the most pressing issues between different groups. For instance, small and large industries were substantially more concerned with respect to inference and much less concerned with respect to model selection than academia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discussion and Recommendations</head><p>An analysis of the 81 (26%) free-text responses (ğ‘„9) reveals diverse opinions about the environmental impact of NLP and the reasons behind the most pressing factors. For instance, among respondents that stated to be not at all concerned about NLP's environmental footprint, a majority considered the impact of NLP research on climate change to be negligible compared to other factors. Factors mentioned as being more relevant to climate change include air travel (also mentioned twice in the general responses ğ‘„19), cars, and more cost intensive computations from other areas (of science). Another argument brought up multiple times in this group of respondents is that the ACL is not the right institution to tackle challenges of climate change. Some responses alternatively suggested to push for regulatory changes, since big tech companies might not be affected by decisions made by the ACL.</p><p>Regarding the most pressing factors, one of the main arguments provided for inference was that industry spends most time on inference, hence it is the most expensive one. However, participants also argued that there exist various methods for efficient inference (see, e.g., <ref type="bibr" target="#b14">Treviso et al., 2023)</ref>. Prominent arguments with respect to training and model selection were that the pressure to achieve state-of-theart performance leads to extensive hyperparameter tuning and that a large variety of models are being trained during research and development (even if just for debugging) without being ever deployed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Equity</head><p>The (in)equity of the available compute resources across groups (e.g., academia and industry) is an increasingly brought up topic in discussions. While the general gist seems to be that many researchers feel excluded by not having access to substantially large compute power (e.g., thousands of GPUs), it often remains unclear whether this is really the case. One of the main objectives of this survey was therefore to quantify such potential disparities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Analysis</head><p>For ğ‘„4, 229 participants responded (73.4%) with the number of GPUs they have access to. Fig. <ref type="figure">1</ref> shows the distribution of the total number of GPUs across our participants (in %). Overall, we observe a high disparity across our participants in terms of access to GPUs. For instance, 62% of the participants had access to less than eight GPUs (Fig. <ref type="figure" target="#fig_3">6a</ref>), the number used for training academic BERT <ref type="bibr" target="#b5">(Izsak et al., 2021)</ref>, and 87.8% of the participants had access to only 9.7% of the total number of GPUs. 15 participants (6.6%) had access to more than 100 GPUs, up to 3000 GPUs, representing 85.6% of the total GPU count (âˆ¼11.2k). An outlier analysis shows that 13.1% of the respondents had access to a substantially higher number of GPUs (more than 22 GPUs) than the rest. We further find that 57.4% of our participants were unable to run experiments due to the lack of computational resources, and 36.2% had no lack of resources (ğ‘„5). Finally, Fig. <ref type="figure">5</ref> shows that 31.4% of our respondents never or rarely thought that more resources could make their work valuable, while 34.3% of respondents answered sometimes, and 34.3% answered often or always (ğ‘„6). (a) ğ‘„7: Concerns by job sector N o t a t a l l 1 2 3 4 5 V e r y S t u d e n t A c a . P D A c a . P I I n d . ( s ) I n d . ( l ) (b) ğ‘„8: Pressing issues by job sector % Participants 0 20 40 60 80 T r a i n S e l e c t I n f e r O t h e r N o n e Student Aca. PD Aca. PI Ind. (s) Ind. (l) Figure 4: Concerns and pressing issues, grouped by positions. Q6: Would more resources make work more valuable? % Participants 0 10 20 30 40 N e v e r R a r e l y S o m e t i m e s O f t e n A l w a y s Figure 5: Lack of resources for more valuable work.</p><p>Job Sector. As in Â§3, our analysis shows no significant differences w.r.t. the seniority, and we find larger disparities by job sector. As we can observe in Fig. <ref type="figure" target="#fig_3">6c</ref>, respondents in industry (large) had access to a higher number of GPUs than industry (small) and academia. This is one of the few cases where we have to resort to pairwise testing, as the Kruskal-Wallis test indicates that the Null hypothesis cannot be rejected with ğ» 5 = 16.976 &gt; ğ» 5 0 = 9.488. While we do not find significant differences in our pairwise comparisons, there are still substantial differences between Ind. (l) and Aca. PI (p-value = 0.0827), as well as Ind. (s) and Ind. (l) (p-value = 0.0850). Even though students reported the lowest number of available GPUs, the differences seem less substantial compared to researchers at small industry (p-value = 0.110). Additionally, we find that large industry has the highest percentage of outliers and the largest in-group disparity. Interestingly, researchers from small industry seem to have the least issues when running experiments; a stark contrast considering they are among those who reported the fewest GPU resources (ğ‘„5). Regarding ğ‘„6, researchers from large industry responded slightly less often than other groups that their research could be more valuable if they had access to more compute power. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discussion and Recommendations</head><p>While our survey highlights existing disparities, particularly between small industry or academic researchers and large industry, we also find that there exist substantial disparities within each group. Most surprising might be the general disparity we find across the field, as 87.8% of our participants had access to less than 10% of the total number of GPUs, and 62% had access to less then 8 GPUs. Only a very small faction of researchers (2.2% of our respondents) had access to GPU compute (1000 or more) to train models with several hundreds of billion parameters for several days or weeks. Many researchers, hence, could only finetune models-which requires far fewer resources than pre-training <ref type="bibr" target="#b19">(Zhou et al., 2021)</ref>-which is only possible when pre-trained model weights are available. Unfortunately, many recent models are being kept private, which has intensified the discussion about equity in the field <ref type="bibr" target="#b13">(Togelius and Yannakakis, 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Impact on Reviewing</head><p>Finally, we quantified how the concerns about the environmental impact and differences in terms of available compute resources affect peer reviewing (ğ‘„10-ğ‘„13). We further asked our participants four questions (ğ‘„14-ğ‘„17) which relate to concrete ideas that would change the reviewing process and encourage model release (ğ‘„18).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Analysis</head><p>Figure <ref type="figure" target="#fig_4">7a</ref> shows that 30.1% of the participants experienced being asked (during peer-review) to conduct additional experiments that were too expensive for them (ğ‘„10) with 77 respondents having experi-enced this more than once (ğ‘„11) and 19.2% having a substantially higher number (five or more times) according to our outlier analysis. Most participants (65.9%) further thought that this criticism was unjustified (ğ‘„12). Figure <ref type="figure" target="#fig_4">7b</ref> (ğ‘„13) shows that 34.3% of the respondents often or always lacked resources to reproduce previous experiments and 41.4% sometimes. Only 7.7% never or 16.7% rarely faced a lack of resources to reproduce experiments.</p><p>With respect to the concrete reviewing actions, Fig. <ref type="figure">9a</ref> shows that a large majority (89.8%) of our participants would consider submitting their work to a dedicated track on efficient methods (ğ‘„14). Following up on the results from the survey, such an efficiency track was implemented at EMNLP 2022. 35.9% of our participants were unsure about requesting authors to justify the allocation of budget for experiments (ğ‘„15), with 41% voting for yes. Also, even though 52.6% of the participants had not been asked for experiments that were too expensive for them, a clear majority of the participants (83.7%) would like to require reviewers to justify their petitions for more experiments (ğ‘„16). Lastly, we also see a large majority (75.6%) that believed that their work could benefit from the release of small versions of pretrained models alongside large ones (ğ‘„17). To promote this, a majority of our respondents thought that venues should have a visible branding of papers to release a model (59.3%) and that reviewers should be instructed to reward model release (50.6%). 42.6% of respondents thought that the venues should grant a best artifact award. 11.5% of respondents supported none of the options. A first step towards increasing the reproducibility and ensuring the submission of experimental code was implemented at NAACL  <ref type="formula">ğ‘„10</ref>) and if so, if they felt the critique was justified (ğ‘„12). In (b), we show how often our participants could not reproduce previous results due to a lack of computational resources (ğ‘„13).</p><p>2022 by introducing a badge system at the reproducibility track. 4 Upon acceptance, the authors could follow specific procedures to earn three types of badges: 1) open-source code, 2) trained model, and 3) reproducible results.</p><p>Seniority. We find no significant differences w.r.t. the seniority of our participants regarding ğ‘„10-ğ‘„18. However, junior researchers (1-5 years) showed a substantially higher tendency towards requesting authors to justify their compute budget (ğ‘„15) against all other age groups (p-values &lt; 0.035). We also observe in Figure <ref type="figure">9c</ref> diverging preferences between junior and senior groups in terms of ideas to improve the reviewing process (ğ‘„18). Junior researchers (1-5 years) seemed to be more inclined towards a visual branding as well as instructing reviewers than senior researchers (11-15 years with a p-value of 0.089 and 16+ years with a p-value of 0.085).</p><p>Job Sector. In terms of the job sector, we again find no significant differences with respect to reviewers asking for too expensive experiments (ğ‘„10) or critique being justified (ğ‘„12). Interestingly, respondents from small industry received fewer such requests (ğ‘„11) compared to post-docs (p-value = 0.024), PIs (p-value = 0.061), and larger industry (p-value = 0.087). The most concerning trend can be observed when comparing the different groups with respect to their lack of compute resources to reproduce experiments (ğ‘„13, Fig. <ref type="figure" target="#fig_6">8</ref>); where we find significant differences and conduct pairwise analyses. 5 In general, students suffered most, with a significant difference compared to the large industry sector with a p-value of 0.002 &lt; 0.005 = ğ›¼ <ref type="bibr">(Bonferroni-corrected)</ref>. We further find substantial differences between students and academic PIs (pvalue = 0.026) and between academic post-docs and large industry labs (p-value = 0.088).</p><p>We find no substantial differences when it comes to actionable items for the *CL community (ğ‘„14-ğ‘„17), indicating that implementing popular ideas would be welcomed by all groups. However, we find some differences when it comes to encouraging the release of models (ğ‘„18). For instance, Figure <ref type="figure">9d</ref> shows that academic post-docs had a higher preference towards reviewers rewarding papers that promise to release models than academic PIs. Also, participants from small industry would prefer visual branding over awards in contrast to large industry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discussion and Recommendations</head><p>Our analysis shows that the two most pressing issues among our respondents are the lack of resources to reproduce results and reviewers requesting for too expensive experiments without proper justification. This is reflected in the large support for both respective counter measures; namely, asking reviewers to provide justification and the release of smaller models that would allow researchers to at least reproduce some experiments. Considering the success of badges at NAACL 2022 with 175 code, 98 model and 20 reproducibility badges, introducing an explicit badge for small model release could boost inclusiveness and reproducibility. 6 To improve peer reviewing, one immediate action could be to adapt the ARR reviewing guidelines and instruct reviewers to consider the compute budget reported in a paper when asking for more experiments. 7 Among the 22 additional suggestions for ğ‘„18, we find a high emphasis (68.2%) towards the release of artifacts-both because this facilitates future research and helps reproducibility. Moreover, 22 of the 67 general suggestion (ğ‘„19) also touched upon issues about model release and reviewing, highlighting the importance of both topics. The responses mentioned a remarkably wide variety of artifacts: code; trained models; system outputs (to facilitate comparative evaluations without rerunning the code); training checkpoints (to study the training dynamics); and proper documentation of training data (including crowdsourcing questions). In addition to simply releasing trained models, several respondents also wished for a sufficiently high quality of the released models complemented by code and documentation. One particular concern was how the release of artifacts should be integrated into the reviewing process. On the one hand, it seems useful to submit artifacts together with the paper before reviewing, so that reviewers can access them and to prevent breaking promises of future code release. On the other hand, this needs to happen within the constraints of double-blind 6 <ref type="url" target="https://naacl2022-reproducibility-track.github.io/results/">https://naacl2022-reproducibility-track.   github.io/results/</ref> 7 <ref type="url" target="https://aclrollingreview.org/reviewertutorial">https://aclrollingreview.org/   reviewertutorial</ref> reviewing. Finally, 12 of the free-text responses of ğ‘„18 and ğ‘„19 suggested that artifact release should be mandatory for acceptance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Further Considerations</head><p>Finally, we discuss suggestions (ğ‘„19) that do not fit into any of the previously discussed topics. From the 67 free-text responses (21.5%), the two most prominent topics were evaluation (11 respondents) and emphasizing research over engineering (7 respondents).</p><p>Evaluation. 16.4% of the free-text respondents touched upon the issue of evaluation and model comparability; as current benchmarks often focus on improving a single metric. One measure to counter this trend would be to report performance based on Pareto frontiers and to consider the compute budget along with the model performance. To promote such curves, it would also be important to release metadata including preprocessing and hyperparameter choices that allows future research to draw proper comparisons as well as to provide concrete guidelines for reviewers.</p><p>Research vs. engineering. 10.4% of the free-text respondents further noted that the field seemed to have drifted more towards engineering by primarily chasing high performance; straying away from producing meaningful scientific insights. The respondents brought forward various suggestions to combat this; for instance that authors should clearly state their scientific hypothesis and then report research that tests this hypothesis using the lowest appropriate amount of resources. Other suggestions were to actively promote more theoretical, or more non deep learning work.</p><p>Other suggestions. Another suggestion worth mentioning was the creation of a separate track (four respondents); either specifically for small models or for industry that cannot publish their models. Finally, there was also a call for more shared tasks with limited resources such as the efficient NMT challenge <ref type="bibr">(Heafield et al., 2022)</ref> or the efficient inference task <ref type="bibr">(Moosavi et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a first attempt to capture and quantify existing concerns about the environmental impact and equity within the *CL community. We further investigated the resulting implications on peer reviewing considering the increasing computational Figure <ref type="figure">9</ref>: Analysis of responses on how to improve the reviewing process. In (a), we show the distribution of our participants' responses for ğ‘„14-ğ‘„17 (in %). A majority of our participants would submit to an efficiency track (ğ‘„14) and would prefer reviewers to justify a request for more experiments (ğ‘„16). They further would benefit from a release of smaller models (ğ‘„16). In contrast, the responses are more mixed about the authors justifying the compute budget (ğ‘„15). In (b-d), we show our participants' responses on how to encourage the release of models (in %): (b) overall, (c) by seniority, (d) by job sector. Multiple responses were allowed for ğ‘„18.</p><p>demand. A majority of our respondents were concerned regarding the environmental footprint of NLP experiments with model training and model selection being the most pressing issues. We also found a high disparity among our respondents with students and small industry researchers suffering most from a lack of resources. There was a large support for measures to improve equity and accessibility across all respondents; most prominently for an efficiency track, asking reviewers to justify the petition for additional experiments, and the release of small versions of pretrained models.</p><p>Considering the continuous increase of param-eters in PLMs <ref type="bibr" target="#b18">(Zhao et al., 2023)</ref>, one danger we face is that existing disparities may intensify even further. However, we find that much can be done to combat this, even on an individual level. As a researcher, by making our model weights, code, and data publicly available; and as a reviewer, by being considerate towards the available compute budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>To receive a large number of responses, this survey was advertised throughout various channels. Hence, this is by no means a representative study within the whole *CL community. This is partially reflected in the evaluation of the geographic locations, e.g., they were too coarse to capture a more precise picture about existing geographic inequalities. Nonetheless, the fact that we did not receive any responses from bodies located in Africa indicates that there may exist high disparities in terms of geographic location. For the same reason, the disparities found in this survey are more indicative than representative. Consequently, any action that is being implemented should not be solely derived from the survey data and carefully considered beforehand.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Demographic statistics: (a) describes the seniority, (b) the job sector, and (c) the geographic location of our participants (in %).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :Figure 5 :</head><label>345</label><figDesc>Figure 3: Environmental concerns and pressing issues (in % of participant answers).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Distribution of GPUs among participants: (a) overall, (b) by seniority, (c) by job sector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure7: Analysis on how of a lack of resources can affect research. In (a), we show what percentage of participants had been asked by reviewers for too expensive experiments (ğ‘„10) and if so, if they felt the critique was justified (ğ‘„12). In (b), we show how often our participants could not reproduce previous results due to a lack of computational resources (ğ‘„13).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4</head><figDesc>https://2022.naacl.org/blog/ reproducibility-track/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5Figure 8 :</head><label>8</label><figDesc>Figure 8: ğ‘„13: Lack of resources by job sector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>consider submitting to efficiency track? Q15: Authors to justify budget allocation? Q16: Reviewers to justfy petition for more experiments? Q17: Benefit from releasing smaller models?Possible answers: yes (â—¼), not sure (â—¼), no (</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>Note that 39.7% of our participants selected exactly these two as the only pressing factors.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was initiated at and benefited substantially from the <rs type="grantName">Dagstuhl Seminar 22232: Efficient and Equitable Natural Language Processing</rs> in the Age of <rs type="person">Deep Learning</rs>. We further thank <rs type="person">Niranjan Balasubramanian</rs>, <rs type="person">Jonathan Frankle</rs>, <rs type="person">Michael Hassid</rs>, <rs type="person">Kenneth Heafield</rs>, <rs type="person">Sara Hooker</rs>, <rs type="person">Alexander Koller</rs>, <rs type="person">Alexandra Sasha Luccioni</rs>, <rs type="person">Alexander LÃ¶ser</rs>, <rs type="person">AndrÃ© F. T. Martins</rs>, <rs type="person">Colin Raffel</rs>, <rs type="person">Nils Reimers</rs>, <rs type="person">Leonardo Riberio</rs>, <rs type="person">Anna Rogers</rs>, <rs type="person">Edwin Simpson</rs>, <rs type="person">Noam Slonim</rs>, <rs type="person">Noah A. Smith</rs>, and <rs type="person">Thomas Wolf</rs> for a fruitful discussion and helpful feedback at the seminar. We further thank <rs type="person">Leshem Choshen</rs> for helpful feedback on this work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_TUa5YHU">
					<orgName type="grant-name">Dagstuhl Seminar 22232: Efficient and Equitable Natural Language Processing</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Milton</forename><surname>Abramowitz</surname></persName>
		</author>
		<title level="m">Handbook of Mathematical Functions, With Formulas, Graphs, and Mathematical Tables</title>
		<imprint>
			<publisher>Dover Publications, Inc., USA</publisher>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Yuki</forename><surname>Arase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>RÃ¼cklÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Efficient NLP policy document</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Teoria statistica delle classi e calcolo delle probabilita</title>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Bonferroni</surname></persName>
		</author>
		<idno type="DOI">10.4135/9781412961288.n455</idno>
	</analytic>
	<monogr>
		<title level="j">Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commericiali di Firenze</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="3" to="62" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the&quot; probable error&quot; of a coefficient of correlation deduced from a small sample</title>
		<author>
			<persName><forename type="first">Roland</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metron</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3" to="32" />
			<date type="published" when="1921">1921</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Jelmer Van Der Linde, and Nikolay Bogoychev. 2022. Findings of the WMT 2022 shared task on efficient translation</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graeme</forename><surname>Nail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Machine Translation (WMT)</title>
		<meeting>the Seventh Conference on Machine Translation (WMT)<address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates (Hybrid). Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How to train BERT with an academic budget</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Izsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moshe</forename><surname>Berchansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.831</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10644" to="10652" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Use of Ranks in One-Criterion Variance Analysis</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">H</forename><surname>Kruskal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Allen</forename><surname>Wallis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">260</biblScope>
			<biblScope unit="page" from="583" to="621" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust tests for equality of variances</title>
		<author>
			<persName><forename type="first">Howard</forename><surname>Levene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to probability and statistics</title>
		<imprint>
			<date type="published" when="1960">1960</date>
			<biblScope unit="page" from="278" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m">Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Nafise Sadat</forename><surname>Moosavi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Goran</forename><surname>GlavaÅ¡</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</editor>
		<meeting>SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The carbon footprint of machine learning training will plateau, then shrink</title>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urs</forename><surname>HÃ¶lzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluis-Miquel</forename><surname>Munguia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rothchild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maud</forename><surname>David R So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Texier</surname></persName>
		</author>
		<author>
			<persName><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Green ai</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="54" to="63" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An analysis of variance test for normality</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shaphiro</surname></persName>
		</author>
		<author>
			<persName><surname>Wilk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="591" to="611" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Energy and policy considerations for deep learning in NLP</title>
		<author>
			<persName><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mc-Callum</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1355</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3645" to="3650" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Julian</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><forename type="middle">N</forename><surname>Yannakakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06035</idno>
		<title level="m">Choose your weapon: Survival strategies for depressed ai academics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Treviso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Ung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianchu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Betty</forename><surname>Van Aken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingqing</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">R</forename><surname>Ciosici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hassid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hooker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">H</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>AndrÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Zosa Forde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edwin</forename><surname>Milder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Slonim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niranjan</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><surname>Schwartz</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00577</idno>
	</analytic>
	<monogr>
		<title level="m">Efficient Methods for Natural Language Processing: A Survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="826" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<title level="m">Exploratory Data Analysis</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the Comparison of Several Mean Values: An Alternative Approach</title>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Welch</forename></persName>
		</author>
		<idno type="DOI">10.1093/biomet/38.3-4.330</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="330" to="336" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sustainable ai: Environmental implications, challenges and opportunities</title>
		<author>
			<persName><forename type="first">Carole-Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramya</forename><surname>Raghavendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bilge</forename><surname>Acun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newsha</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiwan</forename><surname>Maeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gloria</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona</forename><surname>Aga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinshi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="795" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zican</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18223</idno>
		<title level="m">A survey of large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">HULK: An energy efficiency benchmark platform for responsible natural language processing</title>
		<author>
			<persName><forename type="first">Xiyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-demos.39</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="329" to="336" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
