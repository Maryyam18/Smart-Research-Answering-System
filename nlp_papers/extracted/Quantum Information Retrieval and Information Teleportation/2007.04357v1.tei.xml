<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
				<funder ref="#_EPQDERD">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_dXwc6wE">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-05-20">May 20, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">DIMITRIS GKOUMAS</orgName>
								<orgName type="laboratory">Survey of Quantum Theory Inspired Approaches to Information Retrieval * † SAGAR UPRETY</orgName>
								<orgName type="institution">The Open University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">DAWEI SONG</orgName>
								<orgName type="institution">The Open University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Sagar Uprety</orgName>
								<orgName type="institution">The Open University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Dimitris Gkoumas</orgName>
								<orgName type="institution">The Open University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Dawei Song</orgName>
								<orgName type="institution">The Open University</orgName>
								<address>
									<addrLine>Milton Keynes</addrLine>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">The Open University</orgName>
								<address>
									<region>Milton Keynes, UK</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-05-20">May 20, 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">2B993E36E19591F739192D228A4189FC</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2007.04357v1[cs.IR]</idno>
					<note type="submission">Manuscript submitted to ACM Manuscript submitted to ACM</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-28T12:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>Information systems → Information retrieval</term>
					<term>Document representation</term>
					<term>Retrieval models and ranking</term>
					<term>Language models</term>
					<term>Multimedia and multimodal retrieval</term>
					<term>Users and interactive retrieval</term>
					<term>Information Retrieval, Quantum Theory, Quantum-inspired models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Since 2004, researchers have been using the mathematical framework of Quantum Theory (QT) in Information Retrieval (IR). QT offers a generalized probability and logic framework. Such a framework has been shown capable of unifying the representation, ranking and user cognitive aspects of IR, and helpful in developing more dynamic, adaptive and context-aware IR systems. Although Quantum-inspired IR is still a growing area, a wide array of work in different aspects of IR has been done and produced promising results. This paper presents a survey of the research done in this area, aiming to show the landscape of the field and draw a road-map of future directions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Information Retrieval (IR) is the process of finding information that is relevant to the need of a user. The last two decades have completely changed how humans consume and interact with information. This change has been driven by the advances in web search engines, the ease of access to the Internet and the explosion of information available online.</p><p>Information pertaining to a variety of needs is available -from lecture slides to news articles to descriptions and reviews of items, and so on. It becomes imperative that the IR systems continually improve to accommodate such information needs, which have been growing both qualitatively (in terms of complexity) and quantitatively. Essentially, the task of IR systems can be reduced to two aspects. One is how to efficiently and effectively represent and rank the variety of unstructured information being created at each instant. This involves tasks like indexing and improved understanding of the content through advanced representation methods, as well as ranking of the information items based on the representation. For example, representation of textual information can be improved with better understanding of natural language. The second is how to make an IR system better understand user's complex information need and information seeking behaviour. This involves understanding user's search context, search task and intent, and ability to measure task completion and user satisfaction through user interactions.</p><p>IR researchers have been investigating different approaches to improve IR systems from both the system point of view (representation and ranking) and the user point of view. Various areas in IR, for example, Neural IR <ref type="bibr" target="#b53">[Mitra and Craswell 2018;</ref><ref type="bibr" target="#b54">Onal et al. 2018]</ref>, Interactive IR <ref type="bibr" target="#b9">[Borlund 2013;</ref><ref type="bibr" target="#b68">Ruthven 2009]</ref>, Cognitive IR <ref type="bibr" target="#b31">[Ingwersen 1996;</ref><ref type="bibr" target="#b33">Järvelin and Ingwersen 2012;</ref><ref type="bibr" target="#b74">Sutcliffe and Ennis 1998]</ref>, and Dynamic IR <ref type="bibr" target="#b70">[Sloan and Wang 2015;</ref><ref type="bibr">Yang et al. 2016b]</ref>, have been developed. Quantum-inspired IR (QIR) is one such area, where the mathematical framework of Quantum Theory (QT) is utilized to develop representation and user models in IR that are expected to better align with human cognitive information processing. It is different from the field of Quantum Computing in that it does not involve computations based on physical quantum states.</p><p>The benefits of using QT in IR are many-folds. It offers a new way of representing events and computing probabilities of events. Instead of the set-theoretic method of representing events as subsets of a larger sample space, QT represents events as subspaces of an abstract, complex vector space (called Hilbert space) <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref>. Moreover, the same event can have multiple representations in multiple basis of the Hilbert space. This method of representation can help in the abstraction and contextualization of information objects like documents and queries <ref type="bibr" target="#b84">[van Rijsbergen 2004]</ref>. For example, if a set of basis vectors correspond to a set of documents, another set of basis vectors in the same Hilbert space can represent the same set of documents in a different context. Hence a query (as an event) will be represented by these different basis depending upon the context of retrieval. The Hilbert space representation of events also leads to a generalized method of calculating probabilities (Born rule) <ref type="bibr">[Born 1926]</ref>, by taking into account interference between events. This can model a user's decisions under ambiguity better than traditional probability models <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref>. Such a representation method can inherently model incompatible variables -those where measurement on one variable affects the outcome of the other. For two such incompatible variables A and B, measuring A would alter the state of the system, so that the subsequent measurement of B would be different than if it was measured alone or before A. Thus these two variables cannot be measured simultaneously or jointly, and different orders of measurement would lead to different outcomes. Traditional probability theory assumes that for any pair of events, p(A, B) = p(B, A), which would be incorrect for incompatible variables. The cognitive phenomenon of order effect is generally considered to be a consequence of incompatibility in measuring human decisions <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref>. There has been a lot of research in recent years, which shows the presence of Order Effects in relevance judgment of documents (detailed in Section 3).</p><p>Correspondingly, the application of QT to IR can be broadly divided into two subareas: (1) Representation and Ranking, and (2) User Interaction. Figure <ref type="figure" target="#fig_1">1</ref> shows a sketch of the overlap between traditional IR and Quantum-inspired IR, and their underlying components. We show traditional IR in terms of the two sub-areas, which overlap because user interactions like relevance feedback are often used in re-ranking tasks. In this sense, QIR overlaps with traditional IR as it is also divided into these two sub-areas. The difference comes in the tools used by QIR. It utilises the mathematical framework of QT including complex Hilbert space models for representation learning and quantum probability rules to model cognitive interference in document ranking.</p><p>QIR borrows heavily from concepts, models and techniques developed in the field of Quantum Cognition, especially in the modelling and incorporating the user interactions in IR. QT has been successfully applied to model and predict irrational human decision making and explain cognitive biases in human judgments <ref type="bibr" target="#b14">[Busemeyer et al. 2011;</ref><ref type="bibr">Pothos and</ref><ref type="bibr">Busemeyer 2011, 2009;</ref><ref type="bibr" target="#b65">Pothos et al. 2013;</ref><ref type="bibr" target="#b76">Trueblood and Busemeyer 2011;</ref><ref type="bibr" target="#b92">Wang and Busemeyer 2013]</ref>   <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref> studies such quantum-like phenomena in cognitive and decision sciences. There is already a growing community of researchers, under the umbrella of Quantum Interaction (see <ref type="url" target="http://www.quantuminteraction.org/home">http://www.quantuminteraction.org/home</ref>), who are applying QT to various disciplines such as Biology, Cognition, Economics, Natural Language Processing and Information Retrieval. In 2017, a major project which seeks to investigate a Quantum Theoretical approach to IR (QUARTZ -see <ref type="url" target="http://www.quartz-itn.eu/">http://www.quartz-itn.eu/</ref>) has started, under the Marie Skłodowska Curie Actions scheme of the European Union's Horizon 2020 programme, with 7 participating universities all over Europe and several external partners around the world.</p><p>QIR is a growing multi-disciplinary area and has been attracting an increasing attention of researchers in IR. Especially, the recent several years have witnessed a large number of models and applications of QIR which have shown good results and a great potential. However, the field lacks a comprehensive review of the literature, and the individual works are largely segmented. This is why a survey paper is urgently needed. It is important and timely to review the literature systematically to provide a clear picture of the landscape and a road-map for the future. Although this is not the first work to accumulate findings in QIR. Around ten years ago, a position paper <ref type="bibr" target="#b71">[Song et al. 2010]</ref>, organised QIR into three themes: frameworks, spaces, and interference. However, it was more on a conceptual level and the field of QIR was in its infancy. After a decade of development since then, the landscape of QIR research has significantly changed. A large number of more comprehensive and larger scale QIR approaches have been developed covering different aspects of IR, and have achieved remarkable experimental results.</p><p>The next section introduces the basic concepts and notations of QT, to enable readers to understand their usage in IR.</p><p>Section 3 reviews the literature of Quantum-inspired IR, followed by a discussion on its shortcomings and benefits in Section 4. Section 5 concludes the paper by discussing future work directions in Quantum-inspired IR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">QUANTUM THEORY PRELIMINARIES</head><p>Quantum Theory is also regarded as a theory for calculating probabilities <ref type="bibr" target="#b56">[Pitowsky 2006</ref>], which was developed in the first half of the twentieth century to explain the counter-intuitive probabilistic outcomes of experiments on microscopic particles. These results could not be explained using standard probabilistic models. Quantum Mechanics was later axiomatically organized by <ref type="bibr">John von Neumann [von Neumann 1955]</ref>, thus enabling it to be used as an abstract probabilities lies in the representation of events. In the classical probability theory, events are represented as subsets of a sample space. In the quantum probability theory, events are represented as subspaces of an abstract vector space.</p><p>As such, the quantum probability theory is a generalization of the classical probability theory, and can be useful in calculating the probabilities of events which cannot be represented in a set-theoretic formalism due to their inherent structure. The use of QT for applications beyond Physics was first suggested by Niels Bohr <ref type="bibr">[Bohr 1937] (pg. 294-295, 297)</ref>, one of the founding fathers of Quantum Mechanics. He mentioned the existence of complementary variables in Psychology as similar to the incompatible properties of quantum systems. As we will discuss in this section, QT provides a method to model incompatible variables naturally. In the sub-sections to follow, a brief description of the need for the quantum probabilistic framework is provided and the formal concepts underlying QT are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Double Slit Experiment</head><p>The earliest experiment on microscopic particles which puzzled physicists was the Double Slit Experiment. Consider Figure <ref type="figure" target="#fig_2">2</ref>, in which microscopic particles, say electrons, are fired from a source to a screen consisting of two slits. On the right of this screen is another screen made up of detectors, which can detect the arrival of a particle as a function of its distance x from the center of this screen. By measuring the mean number of pulses, one can measure the probability of the electron reaching the detector screen as a function of x. When only one slit is open, the probability distribution obtained looks like the one in Figure <ref type="figure" target="#fig_2">2</ref>(A) and 2(B) for slits A and B respectively. Now, according to the classical probability theory, opening both slits at the same time should lead to the sum of the probability distributions as shown in Figure <ref type="figure" target="#fig_2">2</ref>(C). However, it was actually seen that on opening both slits, one obtains a distribution of electrons as 2(D).</p><p>It is a complicated curve having several maxima and minima, indicating that there are some locations on the detector screen that electrons never register. This distribution is the same as obtained in the case of interference of waves. The interference pattern is produced by adding the amplitudes of two waves and the squaring the sum to get the intensity.</p><p>Hence the data of curve 2(D) can be explained by assuming that the electrons behave like waves when traveling from the source through the slits to the detector screen. In doing so, it is as if a single electron goes through both the slits at the same time -a fundamental quantum property called superposition. A complex number called the probability amplitude is ascribed to the electron corresponding to the two possible paths. Let ϕ a be the probability amplitude for the path S → A → X and ϕ b be the probability amplitude of the electron for the path S → B → X , when the slits A and B are opened respectively, S being the source.</p><p>The amplitudes differ because of the difference in the complex phase for the two paths taken. The probabilities are calculated, according to the Born rule <ref type="bibr">[Born 1926</ref>], as the square of the amplitudes. Thus the probability of detecting an electron at a position X from the center of the detector screen, when</p><formula xml:id="formula_0">only slit A is open, is p(A) = |ϕ a | * |ϕ † a | = |ϕ a | 2 (</formula><p>where ϕ † a is the complex conjugate of ϕ a ). When both slits are open, the probabilities are calculated by following the Law of Total Amplitude <ref type="bibr" target="#b19">[Feynman et al. 2011</ref>]. The probability amplitudes for the two paths are added up and then the probability is calculated by taking the square of the sum:</p><formula xml:id="formula_1">p(X ) = |ϕ a + ϕ b | 2 (1) = |ϕ a | 2 + |ϕ b | 2 + 2|ϕ a | * |ϕ b | = p(A) + p(B) + 2 p(A) p(B) cos(θ )</formula><p>where θ is the phase difference between the two paths. The negative values of cos θ are responsible for the minima obtained in the curve 2(D). For θ = π 2 , we get the classical probabilities as a special case. Thus we see that the origin of quantum probabilities lies in the Law of Total Amplitude and the Born rule. When a quantum entity can take one or more paths, it takes all of them at the same time, and the quantum entity is said to be in a superposition state of all possible paths. These paths influence each other, in a phenomenon called quantum interference, which gives rise to the extra terms in the calculation of probabilities.</p><p>It should be noted that when we say quantum probabilities, the concept of probability remains the same as classical probabilities. To paraphrase Richard Feynman, "If the probability of a certain outcome of an experiment is p, then if the experiment is repeated many times one expects that the fraction of those which give the desired outcome is p. What changes in QT is only the method of calculating probabilities" <ref type="bibr" target="#b19">[Feynman et al. 2011</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2</head><p>The Axioms of Quantum Theory 2.2.1 Representation of Events. QT provides a new method of assigning probabilities to events. In the classical method of calculating probabilities, we assume a finite sample space consisting of N points. The collections of all the points in the space is described as a set X = {x 1 , x 2 , ..., x N }. An event is any subset of X , say A ⊆ X . For two such events A ⊆ X and B ⊆ X , A ∪ B and A ∩ B are also events. Atomic events are given by singletons.</p><p>Instead of the sample space of events, a complex Hilbert space of infinite dimensions is used in QT. A Hilbert space is an abstract vector space, which includes a complex inner product between any two vectors in the space. For simplicity, we deal with a finite dimensional Hilbert space here. A N -dimensional Hilbert space comprises N orthonormal basis vectors X = |X i ⟩ , i = 1, ..., N . The choice of basis is arbitrary and there can be any number of basis for a Hilbert space. Here |X ⟩ is the way to denote a vector in the Dirac notation <ref type="bibr" target="#b17">[Dirac 1982</ref>]. An event A is defined not by the subset of vectors X A ⊆ X , but rather by a subspace spanned by this subset. If A is an event spanned by X A ⊆ X and B is an event spanned by X B ⊆ X , the intersection of the two events, also called the "meet" and denoted as A ∧ B, is given by the span of vectors in the subset X A ∩ X B . Similarly, the union of the events, called the "join" and denoted as X A ∨ X B , is given by the span of vectors in X A ∪ X B . Note how the set theoretical intersection and union of points are replaced by the span of the intersection and union of vectors. This structural property leads to the violation of the distributive axiom <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref>. Before talking about that further, we first discuss the concept of states and projectors in the quantum framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2.2</head><p>States of a Quantum System. In the classical framework, we have the concept of a probability distribution function p(X i ), which assigns real numbers to each point X i of a sample space. In the quantum framework, we define a state vector |S⟩ of unit length in a Hilbert space X , which induces a probability distribution over the subspaces of the Hilbert space (Figure <ref type="figure">3a</ref>). A subspace is represented in term of a projection operator P, which is Hermitian (P † = P, where P † denotes the complex conjugate of the transpose of P) and Idempotent (PP = P). The probability induced by a state vector |S⟩ onto a subspace is given by the square of the projection of the vector onto the subspace. It is calculated as:</p><formula xml:id="formula_2">|P |S⟩ | 2 = ⟨S | P † P |S⟩ (2) = ⟨S | P |S⟩ Figure 3(b)</formula><p>shows a two-dimensional Hilbert space with state vector |S⟩ projected onto a one-dimensional subspace, A 2 . In this case the projector is given by P A 2 = |A 2 ⟩ ⟨A 2 | and the probability distribution of the state given by the vector</p><formula xml:id="formula_3">|S⟩ is: |P A 2 |S⟩ | 2 = ⟨S | P A 2 |S⟩ (3) = ⟨S |A 2 ⟩ ⟨A 2 |S⟩ = | ⟨A 2 |S⟩ | 2</formula><p>Here the quantity ⟨A 2 |S⟩ is the probability amplitude of the state |S⟩ for the event A 2 . The state of a quantum system |S⟩ is in general a superposition of all possible events (see the next subsection for a discussion on superposition). As discussed before, the events are given by all the vectors of an orthonormal basis. In the basis |A 1 ⟩ , |A 2 ⟩ , the state of the system is represented as:</p><formula xml:id="formula_4">|S⟩ = a 1 |A 1 ⟩ + a 2 |A 2 ⟩ (4)</formula><p>where a 1 = ⟨A 1 |S⟩ and a 2 = ⟨A 2 |S⟩ are the probability amplitudes and |a 1 | 2 , |a 2 | 2 represent the probabilities for events A 1 and A 2 to occur for the state |S⟩.</p><formula xml:id="formula_5">Hence |a 1 | 2 + |a 2 | 2 = 1.</formula><p>2.2.3 Superposition and Collapse of a Quantum State. In models based on the classical probability theory, like Bayesian networks, a state of a system evolves from "moment to moment, but any given point of time the system is in a definite state" <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref>. To deal with uncertainty about which state the system is in, probabilities are assigned to each state. Thus, a dynamic system is in a definite state at each point of its evolution and is governed by a probability distribution over the states.</p><p>A quantum system is different from classical systems because of its ability to be in a superposition of all the possible states at the same time. This superposed state is a new state, which is not the same as any of the possible states of a classical system. Rather, it encapsulates the possibilities of being in all possible states. When a measurement is performed on a quantum system to learn its state, the superposed state collapses into one of the possible states with a certain probability. As an example, the system with state |S⟩ in Figure <ref type="figure">3</ref>(a) is a superposition of the basis vectors |A 1 ⟩ and |A 2 ⟩. It is neither in state |A 1 ⟩ nor in |A 2 ⟩. It is a new state with probabilities |a 1 | 2 and |a 2 | 2 for the system to be in state |A 1 ⟩ or |A 2 ⟩ upon measurement. Changing the probability amplitudes a 1 and a 2 leads to a new state, different from |S⟩. This concept of collapse of a superposed state into one of the constituent states upon measurement is referred to as the Copenhagen Interpretation of Quantum Theory. (a) (b) Fig. 4. Two basis representing incompatible events showing order effects p(A) = p(A ∩ X ) = p(A ∩ (B ∪ B)) (5) = p((A ∩ B) ∪ (A ∩ B)) = p(A ∩ B) + p(A ∩ B) = p(B)p(A|B) + p( B)p(A| B)</p><p>In simple terms, this law states that if an event A occurs, it can occur along with B or without B. In the quantum framework, consider a two dimensional Hilbert space with two basis vectors |A 1 ⟩ and |A 2 ⟩, as in Figure <ref type="figure">3a</ref>. The intersection and union of two subspaces (called as meet and join, respectively) is defined as the intersection and union of the set of vectors spanning the subspaces, respectively (Section 2.2.1). Denoting the one-dimensional subspaces of this Hilbert space by their projectors P S , P A 1 , P A 2 , the meet of the subspaces P S ∧ P A 1 = 0 and P S ∧ P A 2 = 0. The meet of two subspaces thus works the same way as intersection in set theory. The difference comes from the definitions of union and complement. The union or join of the two subspaces P A 1 ∨ P A 2 is the whole two-dimensional Hilbert Space, not just the set of two vectors |A 1 ⟩ and |A 2 ⟩ as in the set theory. Thus we get</p><formula xml:id="formula_6">P S ∧ (P A 1 ∨ P A 2 ) = P S<label>(6)</label></formula><p>which violates the distributive axiom, as (P S ∧ P A 1 ) ∨ (P S ∧ P A 2 ) = 0.</p><p>2.2.5 Compatible and Incompatible Events. Classical systems follow the principle of unicity [Griffiths 2001], which states that there is always a single sample space "which provides an exhaustive description of all the events that can happen in an experiment" <ref type="bibr" target="#b13">[Busemeyer and Bruza 2012]</ref>. Therefore a single probability distribution function is sufficient to calculate the probabilities for all the events.</p><p>In the quantum framework, a state vector is represented as a superposition of all the basis vectors. One can choose to represent this state vector in any arbitrary basis. Thus the same state vector is expressed in different basis and each basis represents a particular property of the quantum system. The state vector induces different probabilities onto different basis of the Hilbert space. The state vector is thus an abstract entity. It does not have any fixed representation.</p><p>A particular representation conceptualizes when we talk of a particular basis.</p><p>In Figure <ref type="figure">4</ref>, we show a Hilbert space with two basis. One with orthonormal vectors |A⟩ and A and another basis with orthonormal vectors |B⟩ and B . Consider the following events, in a particular order -A and B. To calculate the probability that these two events occur, the state vector |S⟩ is projected onto the vector |A⟩ and the new collapsed state is projected onto the vector |B⟩. Hence we get the probability for A and B to occur as p(A, B) = |P B P A |S⟩ | 2 , and using Equation 3, we get</p><formula xml:id="formula_7">p(A, B) = | ⟨B|A⟩ | 2 .| ⟨A|S⟩ | 2 (7)</formula><p>Now, if the same two events occur in the reverse order, i.e., B and then A, then the probability of them occurring is given by p(B, A)</p><formula xml:id="formula_8">= |P A P B |S⟩ | 2 , which, using Equation 3, is p(B, A) = | ⟨A|B⟩ | 2 .| ⟨B|S⟩ | 2 (8)</formula><p>Now, Equations 7 and 8 will assign different values to the left-hand side when the value of the terms ⟨B|S⟩ and ⟨A|S⟩ are different. Which is the case if A and B are vectors in different basis. In the classical theory, we can assign joint probability distributions to two events occurring together regardless of their order, i.e., p(A, B) = p(B, A), but such a joint probability distribution does not exist for events belonging to two different basis in a Hilbert space. We call these events as incompatible events. In the language of linear algebra, the projectors corresponding to these events do no commute, i.e., P A P B P B P A . A geometrical explanation can be obtained from Figure <ref type="figure">4</ref>. In Figure <ref type="figure">4a</ref>, the order of projections is S → A → B and in Figure <ref type="figure">4b</ref>, it is S → B → A. We can see that the final projections (indicated by thick blue lines) in the two cases are different (and hence different probabilities) and depend upon the geometry of the Hilbert space (specifically, the angle between the vectors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.6">Density Matrices and Trace</head><p>Rule. Another way of representing a quantum state, apart from the vector representation, is the density matrix or the density operator ρ. For a state |ψ ⟩, the density matrix is given by ρ</p><formula xml:id="formula_9">= |ψ ⟩ ⟨ψ | (9)</formula><p>which is a square matrix. The probability induced by the state represented by ρ onto a subspace represented by the projector P follows from the Gleason's Theorem <ref type="bibr" target="#b25">[Gleason 1957</ref>], and is given by Pr = tr (ρP)</p><p>where tr (x) is the trace of a matrix x, i.e. the sum of its principle diagonal elements. If we denote P = |ϕ⟩ ⟨ϕ |, then the trace can be written as tr</p><formula xml:id="formula_11">(ρP) = tr (ρ |ϕ⟩ ⟨ϕ |) = ⟨ϕ | ρ |ϕ⟩ which, for ρ = |ψ ⟩ ⟨ψ | is tr(ρP) = | ⟨ψ |ϕ⟩ | 2 (11)</formula><p>This is the same probability as calculated using the Born rule described earlier.</p><p>Density Matrix gives us the advantage of representing a mixture of classical and quantum systems. For example, if there is a mixture of n quantum systems, with the probability of each system being present in the mixture denoted by p i , then this mixed system can be represented by a density matrix:</p><formula xml:id="formula_12">ρ = p 1 ρ 1 + p 2 ρ 2 + ... + p n ρ n (12)</formula><p>where ρ i is the density matrix of the i-th quantum system, which has a classical probability p i to belong to the mixture.</p><p>Manuscript submitted to ACM 2.2.7 Composite Quantum Systems. Multiple quantum systems can be considered as a single system by combining their Hilbert spaces using a tensor product of the individual Hilbert spaces. If |S⟩ 1 , |S⟩ 2 , ..., |S⟩ n represent the states of n distinct quantum systems, the state of the composite quantum system of all these individual systems is given by |S⟩ 1 ⊗ |S⟩ 2 ⊗ ... ⊗ |S⟩ n , also denoted as |S⟩ 1 |S⟩ 2 .. |S⟩ n . For example, consider two quantum systems represented by two dimensional Hilbert spaces with |A⟩ and Ã as the basis vectors. Note that this is different from the system represented in Figure 3(b). Instead of multiple states in one Hilbert space, here we have multiple Hilbert spaces each with a state |S⟩ i . The state of each of the systems (identical Hilbert spaces in this case) are given by:</p><formula xml:id="formula_13">|S⟩ 1 = 1 √ 2 |A⟩ + 1 √ 2</formula><p>|A⟩ and</p><formula xml:id="formula_14">|S⟩ 2 = 1 √ 2 |A⟩ + 1 √ 2</formula><p>|A⟩. Then the composite system is given by:</p><formula xml:id="formula_15">|S⟩ 1 ⊗ |S⟩ 2 = 1 2 (|A⟩ |A⟩ + |A⟩ |A⟩ + |A⟩ |A⟩ + |A⟩ |A⟩) (13)</formula><p>The above composite state is a separable state. It can be factorized into two separable components as:</p><formula xml:id="formula_16">( 1 √ 2 |A⟩ + 1 √ 2 |A⟩) ⊗ ( 1 √ 2 |A⟩ + 1 √ 2</formula><p>|A⟩). There exists some composite systems for which it is not possible to separate the composite state back into single systems. A famous example of such states are Bell states:</p><formula xml:id="formula_17">S ± = 1 √ 2 (|A⟩ |A⟩ ± |A⟩ |A⟩)<label>(14)</label></formula><p>These states are called Entangled states and this property of Entanglement is a unique and a fundamental feature of Quantum Physics. When a measurement is performed on one part of the entangled system, the state of the other system can be known instantaneously, even if the two individual components are separated by a large distance. For example, consider two experimenters Alice and Bob who possess quantum states which are entangled with each other:</p><formula xml:id="formula_18">|S⟩ = 1 √ 2 (|A⟩ 1 |A⟩ 2 + |A⟩ 1 |A⟩ 2 ),</formula><p>where subscripts 1 and 2 denote that the states are possessed by Alice and Bob respectively. Now initially both the systems are in a superposition state. One cannot tell if it is in state |A⟩ i or state |A⟩ i (i ∈ 1, 2). If Alice measures her system and it collapses to, say, state |A⟩ 1 (it can collapse to either |A⟩ 1 or |A⟩ 1 with equal probability), then the state of the composite system collapses to state |A⟩ 1 |A⟩ 2 . Alice can instantaneously know that Bob's state has collapsed to state |A⟩ 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">QUANTUM THEORY INSPIRED INFORMATION RETRIEVAL</head><p>The application of QT to Information Retrieval (IR) can be broadly divided into two major aspects. The first is the Quantum-inspired representation of entities like documents, queries, etc. in IR. Related to the representational aspect is that of Ranking in IR. The way the documents and queries are represented often determines the method for ranking documents. The second aspect is User interactions, including relevance feedback, query expansion, and user cognitive modeling. Projection models using the Hilbert space and multiple basis to represent states are used in both aspects: in representation -for abstraction of documents and queries, and in modeling user's dynamic and contextual information needs. Representation and user interaction areas in Quantum-inspired IR can be further sub-divided based on the specific approaches and applications (Figure <ref type="figure" target="#fig_4">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Representation and Ranking</head><p>3.1.1 Subspace Representation and Projection Models. The first ideas regarding using the mathematical framework of QT in IR were described in the van Rijsbergen's pioneering book, The Geometry of Information Retrieval <ref type="bibr" target="#b84">[van Rijsbergen 2004]</ref>. It addresses the need to develop a formal theory unifying different IR models, namely logic, vector space, and probabilistic models. It also sought to explore a formal description of user interactions and the abstraction of the concept</p><p>Quantum-inspired IR Representation and Ranking Projection Models Quantum Language Models Quantuminspired Ranking Multimodal IR Content level fusion Decision level fusion Quantuminspired Representation learning User Interactions Projection Models Feedback Context Effects of a document in IR. Hence we find that the user is at center of most of the Quantum-inspired models and user interactions permeate all the representation and ranking methodologies, which we will discuss in the rest of this subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subspace Representation</head><p>A representation of document is usually related to the text it contains, but a document is in general a more abstract entity. To quote <ref type="bibr" target="#b84">[van Rijsbergen 2004]</ref>, "it is a set of ideas, a set of concepts, a story, etc. " A document is defined as an abstract object that encapsulates answers to all possible queries. This is similar to a state vector in QT, which encodes information about all possible outcomes of measurement. The user interaction with an IR system is considered akin to measurement in QT, and the abstract document materializes to the specific information need of the user upon interaction. The Hilbert space representation of the Quantum framework is utilized to represent documents and queries in IR. It might seem similar to the Vector Space Model (VSM). However, instead of modeling documents as vectors in a term space, they are represented as subspaces of a concept space, spanned by a set of basis vectors.</p><p>Note that the documents and queries are themselves abstract and are defined in terms of the choice of basis. The same query or documents can be defined in different basis depending upon the user's point of view. The existence of multiple basis for the same state vector causes abstraction of objects in a Hilbert space. This, coupled with the fact that documents and queries are not merely vectors but subspaces in a complex, infinite dimensional vector space, gives us the leverage over the classical Vector Space Model. Besides providing a theoretical modification of the representational concepts of traditional IR, [van Rijsbergen 2004] also shows how the existing IR tasks like co-ordination level matching, feedback, clustering, etc. can be performed using the Quantum-like formulation.</p><p>Modeling queries and documents as multiple basis in IR was also investigated in <ref type="bibr">[Melucci 2005a</ref>]. Documents and queries are modeled using certain semantic descriptors. However the semantic descriptors used for the same query or document may be different for different users, or different for same user in a different time, location or need. Therefore the use of descriptors depend upon the context. Since descriptors are modeled as basis vectors in a VSM, one can extend the VSM to include multiple basis, where each basis corresponds to a context. <ref type="bibr" target="#b0">[Melucci 2005b</ref>] provides a method to Manuscript submitted to ACM discover different contexts from data to model them as different basis, using a matrix decomposition algorithm (i.e., Cholesky's decomposition).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information Need Spaces</head><p>A further development of the Quantum-inspired IR paradigm <ref type="bibr">[Piwowarski and Lalmas 2009b]</ref> advocates the use of an information need space to model user interaction and evolving information need (IN) as part of representation. An IN is represented as a state in the form of a density matrix. For an ambiguous needs, the state is a mixed state, and if the IN is completely specified, it is a pure state. Before any user interaction, the IR system starts as a mixed state of all possible IN states. Consider the example when a user wants to order a pizza. In the beginning, the IN is in a mixture of all possible states, but a query "pizza" restricts the information need space to a subspace. Further interactions like knowing the time of the day, location of the user, etc. leads to smaller subspaces. Hence the evolution of information need is captured in the geometry. The representation of documents is proposed as in Structured Information Retrieval (SIR), which breaks away from representing the whole document as a single retrieval unit and uses document fragments like sections or paragraphs in response to a user query. It has been shown in <ref type="bibr" target="#b62">[Piwowarski et al. 2008</ref>] that answers to queries may correspond to document fragments and not the whole document.</p><p>The specific details of building the information need spaces are given in <ref type="bibr">[Piwowarski et al. 2010b</ref>]. The documents are modeled as a set of INs, with each IN being a vector. Using the SIR approach, documents are divided into fragments -paragraphs, sentences, sections or the document itself. Each document is converted into a vector using traditional techniques like tf-idf. Each of these fragments can satisfy an information need. Further, spectral decomposition of this set of vectors is performed to construct the document subspace. If the set of vectors for a document is U d , then a subspace S d comprises the span of the eigenvectors of the matrix u ∈U d uu T . Only the eigenvectors corresponding to the top k eigenvalues are considered, since the low eigenvalues can be associated with noise.</p><p>[ <ref type="bibr">Piwowarski et al. 2010c</ref>] extend this work to include representation for queries. As a document is represented as a "set of pure IN vectors corresponding to different fragments of the document, a query term t is represented as a set U t of IN vectors that correspond to document fragments containing the term t" <ref type="bibr">[Piwowarski et al. 2010c</ref>]. Consider two documents D 1 and D 2 consisting of three different paragraphs each. Let U 1 = {v 1 , v 2 , v 3 } and U 2 = {v 4 , v 5 , v 6 } be the IN vectors corresponding to the documents. Taking the simpler case of a single term query, suppose the term occurs in paragraphs corresponding to the vectors v 2 , v 5 , v 6 . Assuming that each fragment is equally likely to be a pure IN and a part of the user's actual IN, the density matrix for the query is written as:</p><formula xml:id="formula_19">ρ q = 1 N t φ ∈U t φφ T<label>(15)</label></formula><p>where N t = 3 is the number of document fragments a term occurs in. Denoting the S d = u ∈U d uu T as projector for a document as explained above, we can calculate the probability of relevance of the document for the query as:</p><formula xml:id="formula_20">p(Rel |q, d) = tr (ρ q S d )<label>(16)</label></formula><p>For queries with multiple terms, either a weighted mixture of density matrices for the terms, or in an interesting case, the density matrix for a superposition of pure IN vectors can be used. Consider the three dimensional subspace of an information need space as shown in Figure <ref type="figure" target="#fig_5">6</ref>. Let the vectors φ p , φ uk , φ us correspond to the INs "Pizza delivery", "Cambridge (US)" and "Cambridge (UK)" respectively. Then the IN for "Pizza delivery in Cambridge (UK)" would be represented by a superposition of φ p and φ uk vectors, as it is about both Pizza and Cambridge (UK). However the IN "Cambridge" represents classical ambiguity regarding the country, and thus it is represented as a mixture of pure IN vectors φ uk and φ us . Thus a query "Pizza delivery in Cambridge" will be a mixture of superpositions.</p><p>This approach is later extended from a single Hilbert space of IN to multiple Hilbert spaces in <ref type="bibr">[Piwowarski et al. 2010a</ref>]. User IN is considered to be composed of several "aspects", which need to be addressed by the relevant documents.</p><p>Each aspect is represented in a separate Hilbert space made up of IN aspect vectors for the aspect. For example, consider a query "What tropical storms (hurricanes and typhoons) have caused significant property damage and loss of life?". It comprises two IN aspects: "tropical storms" and "significant damage/loss of life" <ref type="bibr">[Piwowarski et al. 2010a</ref>]. The vectors for "hurricane" and "typhoons" are the IN aspect vectors for the tropical storm aspect of the query. As different aspect vectors belong to separate Hilbert spaces, the composite system corresponding to all IN aspects for the query is:</p><formula xml:id="formula_21">φ q = φ 1 ⊗ φ 2 (17)</formula><p>where φ 1 and φ 2 are constructed in the same way as Equation <ref type="formula" target="#formula_19">15</ref>. The probability of relevance of a document defined by the subspace S d in each Hilbert space would be p(⊗S</p><formula xml:id="formula_22">d |φ q ) = p(S d |φ 1 ) × p(S d |φ 2 ).</formula><p>The query representations for the above two approaches consider uniform weights to terms in mixtures and superpositions. However, the case of compound terms is not considered in <ref type="bibr">[Piwowarski et al. 2010a</ref>]. The issue is dealt with in <ref type="bibr" target="#b15">[Caputo et al. 2011]</ref>, which provides a sophisticated representation of query density matrices. The paper introduces a query algebra, which can be "used to express relationship between query terms, thus allowing for more complex representations" <ref type="bibr" target="#b15">[Caputo et al. 2011</ref>]. Several natural language processing (NLP) techniques such as Chunking and Dependency</p><p>Parsing, are involved to identify different IN aspects and to characterize the relationship among terms within each aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Polyrepresentation</head><p>The concept of representing information systems as composite systems in separate Hilbert spaces is explored in <ref type="bibr" target="#b20">[Frommholz et al. 2010]</ref> for polyrepresentation of documents. A document may have different representations, based on different information sources, for example, text, author profiles, reviews and rating, etc. Each representation can correspond to different aspects of the information need of the user. Assume we have two Hilbert spaces representing a collection of books, one representing the authors and another for reviews. We have two authors |Smith⟩ and |Jones⟩</p><p>Manuscript submitted to ACM and two types of reviews |Good⟩ and |Bad⟩. Then a composite system of the two Hilbert spaces will be:</p><formula xml:id="formula_23">(|Smith⟩ + |Jones⟩) ⊗ (|Good⟩ + |Bad⟩) = (18) |Smith⟩ |Good⟩ + |Smith⟩ |Bad⟩ + |Jones⟩ |Good⟩ + |Jones⟩ |Bad⟩</formula><p>where the user is uncertain whether to read a book by James or Smith and also unaware of their ratings. However, an interesting case is that of non-separable states, where a user wants a book by Smith which is rated good or wants a book by Jones which is rated as bad. The composite system of user's IN in this case is given by a non-separable state:</p><formula xml:id="formula_24">|Smith⟩ |Good⟩ + |Jones⟩ |Bad⟩ (19)</formula><p>which reduces the uncertainty from the system point of view.</p><p>3.1.2 Quantum inspired Language Models and Applications. The Quantum Language Model (QLM) proposed by <ref type="bibr">[Sordoni et al. 2013b</ref>] combines the Vector Space Model and Probabilistic Language Model of classical IR via the Hilbert space formalism. The Quantum generalization of probabilities comes in the form of representing compound terms in queries and documents as superposition events, which have no classical analogue. This generalized Quantum probability model reduces to classical in case of using single terms only. More recently, a number of extensions of QLM have been made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic QLM</head><p>In QLM proposed in <ref type="bibr">[Sordoni et al. 2013b</ref>], a document or query is represented as a sequence of projectors. A projector represents a single term or compound term from the document/query. A document d containing words from a vocabulary of size N is represented as:</p><formula xml:id="formula_25">P d = {π i : i = 1, ..., M } where M ≤ N<label>(20)</label></formula><p>The Hilbert space is a term space of dimensionality N , where each vector |v s ⟩ represents a term from the vocabulary.</p><p>Thus the projector for a single term is π w = |v s ⟩ ⟨v s |. The vector for a compound term v s 1 ..s k is the superposition of all the vectors corresponding to the single terms:</p><formula xml:id="formula_26">v s 1 ..s k = k i=1 σ i v s i (<label>21</label></formula><formula xml:id="formula_27">)</formula><p>where σ i quantifies how much the compound term represents the single term s i , and k i=1 |σ i | 2 = 1. Thus in the same subspace, the representation of new term is created. This is not possible in traditional Vector Space Models because for every new term, single or compound, one has to add a new dimension to the vector space. Representing compound terms as superposition events solves that problem. Also, the compound term and the single terms in it are not disjoint and are related by the σ i s.</p><p>Practically, in order to construct the projectors for a document, the terms co-occurring in the document within a fixed window of size L are considered as compound terms. A language model is essentially a density matrix ρ, and for a document it is represented by projectors P d = {π 1 , π 2 , ..., π M }. It is obtained by maximizing the following function:</p><formula xml:id="formula_28">L P d (ρ) = M i=1 tr (ρπ i ) (22)</formula><p>The language model is estimated using a generalization of an Expectation-Maximization based algorithm, called the RρR algorithm <ref type="bibr" target="#b45">[Lvovsky 2004</ref>].</p><p>The language model for a query ρ q can be estimated in a similar way. The relevance of a document for a query can be calculated using a generalization of the KL divergence method called quantum relative entropy or Von-Neumann(VN)</p><p>divergence <ref type="bibr" target="#b78">[Umegaki 1962</ref>]. Given two language models ρ q and ρ d , the scoring function is:</p><formula xml:id="formula_29">∆ V N (ρ q ||ρ d ) = -tr (ρ q log ρ d )<label>(23)</label></formula><p>where tr (x) denotes the trace of the matrix x. Experimentally, the QLM has been shown to outperform a baseline language model and a Markov random fields (MRF) based model <ref type="bibr" target="#b52">[Metzler and Croft 2005]</ref> (which was state-of-the-art at the time of publication of <ref type="bibr">[Sordoni et al. 2013b]</ref>) for document ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extended QLMs</head><p>Several extensions have been made to the basic QLM described above. <ref type="bibr" target="#b95">[Xie et al. 2015]</ref> propose to augment the QLM by making use of "entangled" terms. Based on the relation between Unconditional Pure Dependence (UPD) and Quantum entanglement <ref type="bibr" target="#b28">[Hou and Song 2009;</ref><ref type="bibr" target="#b29">Hou et al. 2013]</ref>, the UPD patterns are extracted from queries and documents, and the corresponding projectors are constructed. Instead of considering arbitrary compound terms, these UPD patterns are used as they show a statistical relationship similar to entangled systems.</p><p>Moreover, the RρR algorithm used in QLM has a disadvantage in that it does not always converge. Hence a new global convergence algorithm is used in <ref type="bibr">[Zhang et al. 2018b</ref>] for a Global Quantum Language Model (GQLM) but applied on twitter sentiment analysis tasks. Two dictionaries of positive and negative sentiment words are constructed. The global convergence algorithm constructs density matrices for the dictionaries and documents. Then using the quantum relative entropy, a document is projected onto each dictionary to determine its sentiment class.</p><p>A Quantum language model based Query expansion approach is presented in <ref type="bibr">[Li et al. 2018a</ref>]. Using the GQLM described earlier, the language models for documents and query are constructed. The initial ranking is achieved using the Quantum relative entropy. Then a density matrix is constructed for the top k retrieved documents. The top n non-query terms, corresponding to the top n diagonal elements of the density matrix, are selected as expanded terms. The top n diagonal elements are in the order of the Quantum probabilities of the terms. Hence the advantage of using Quantum probabilities can be intuitively understood from here -the quantum probability reflects both the single term occurrence and the co-occurrence between terms. Hence, "a term with a high frequency but a low co-occurrence with other terms may as well have a lower quantum probability than a terms with lower frequency but higher co-occurrence" <ref type="bibr">[Li et al. 2018a</ref>]. After having formed the expanded query, a new GQLM is constructed for the expanded query and the documents are re-ranked accordingly. Experiments on the TREC 2013 and 2014 session track datasets show a better performance than the original QLM and another quantum model proposed in <ref type="bibr" target="#b91">[Wang et al. 2018]</ref>, which is based on user interactions.</p><p>Indeed, there have been various extensions of QLM that adapt to user interactions <ref type="bibr" target="#b37">[Li et al. 2016</ref><ref type="bibr" target="#b39">[Li et al. , 2015;;</ref><ref type="bibr" target="#b90">Wang et al. 2017</ref>], which will be discussed in Section 3.2.</p><p>The QLM is also extended within a neural network structure in <ref type="bibr">[Zhang et al. 2018a]</ref> for Question Answering (QA), while the authors mention that the model can also be applied to other IR tasks, such as ad-hoc retrieval. Using word embeddings as vectors, a density matrix for each sentence is constructed, for both questions (as queries) and answers (as documents). The density matrix represents a mixture of semantic spaces. A joint representation of queries and documents is constructed by multiplying the density matrices for queries and documents. Then a convolution layer is applied over this joint representation followed by pooling, a fully connected layer and a softmax layer. The binary output of the softmax layer represents probabilities of relevance and non-relevance of the answer with respect to the question. This process is repeated for each question and answer pair and a ranking based on their relevance probabilities is produced. This model achieved MAP and MRR scores of 0.7589 and 0.8254 on the TREC-QA dataset, which was 2.46%</p><p>Manuscript submitted to ACM and 3.24% improvement over a neural model TANDA <ref type="bibr">[Yang et al. 2016a</ref>], which was state-of-art at the time when the paper was published<ref type="foot" target="#foot_1">foot_1</ref> .</p><p>A Quantum many body wave function based language model is presented in <ref type="bibr">[Zhang et al. 2018d</ref>]. The aim is to create a language model which addresses the challenges in word combinations, where each of the individual words can possess multiple meanings. Different meanings of a word are represented as different basis vectors of a Hilbert space. The state vector for a word is a superposition of different base vectors corresponding to different meanings of the word. The state vector of sentence is represented as a tensor product of the individual word's state vectors. This is termed as a local representation, and a similar global representation of the language model is constructed using another corpora, to account for unseen words and unseen compound words. The global representation is projected onto the local representation akin to the smoothing process in classical language models. As the global representation is a higher rank tensor, it is decomposed using tensor decomposition techniques. The projection of the reduced tensor onto the local representation tensor is realized in the form of a convolutional neural network. While it is unable to outperform the above mentioned model <ref type="bibr">[Zhang et al. 2018a</ref>] on the TREC-QA dataset, it performs significantly better on the WikiQA dataset<ref type="foot" target="#foot_2">foot_2</ref> .</p><p>Other Quantum-inspired language models</p><p>In <ref type="bibr" target="#b8">[Blacoe et al. 2013</ref>], the Quantum theoretic framework is used to construct a syntax-aware semantic model. It also takes word order into account, unlike the QLM. Firstly, for each sentence, dependency parsing is performed and a set of dependency relations are extracted. This set is partitioned into clusters of syntactically similar relations, and each cluster is assigned a Hilbert space. Each Hilbert space has the word vectors as the basis vectors. The state vector in each Hilbert space is a superposition of the word vectors, which are dependencies of the same word. The state vector for a given word is written as a tensor product of the state vectors in all the Hilbert spaces. A complex phrase is ascribed to the state vector. A word occurring in different senses will have different state vectors, which are then superposed to get the final vector for each word. It is then converted into a density matrix, and the density matrices of the occurrences of the word in different documents are added up. The similarity between two words can be measured using the trace rule, which essentially takes the pair-wise inner products of the state vectors. This allows the words to "select" each other's context and should lead to more accurate similarity values. Experiments done on word similarity and word association tasks reveal a better performance than some classical models. This method is extended in <ref type="bibr" target="#b7">[Blacoe 2015</ref>] to construct density matrices for sentences. To create a density matrix for a sentence, first the dependency parsing tree is constructed. For each node in the tree, its dependencies are projected onto it and the post projection states are summed up together with the density matrix of the node. This procedure is performed recursively until the whole sentence is covered. The method is tested on the paraphrase detection task with the Microsoft Paraphrase Detection dataset, and</p><p>shows better accuracy and F1 scores than a recent neural network model reported in <ref type="bibr" target="#b69">[Shen et al. 2018]</ref>.</p><p>In <ref type="bibr" target="#b6">[Basile and Tamburini 2017]</ref>, an n-gram language model inspired from QT is introduced, with application to speech recognition. Unlike the quantum inspired language models presented earlier, this paper makes use of the unitary evolution of a quantum state in time, e.g. ρ t +1 = U ρ t U † , where U is a unitary operator which changes the state of a system ρ t . To measure the probability of a word w, the system state is projected onto the state of the word w using the projector Π w = |w⟩ ⟨w |. Probabilistic information about a sequence of words w 1 , w 2 , ..., w n is encoded in a density matrix built using the following process:</p><formula xml:id="formula_30">p(w 1 ; ρ 0 , U ) = tr (ρ 0 , Π w 1 ) ρ ′ 1 = Π w 1 ρ 0 Π w 1 tr (Π w 1 ρ 0 Π w 1 )<label>(24)</label></formula><formula xml:id="formula_31">ρ 1 = U ρ ′ 1 U †</formula><p>where ρ 0 is the initial state of the system, and ρ 1 is state of the system after processing the first word in the sequence.</p><p>The unitary matrix U is responsible for the time evolution of the system and tr (x) stands for the trace operation. The final probability of the whole sequence becomes:</p><formula xml:id="formula_32">p(w i |w 1 , ..., w i-1 ) = tr (ρ i-1 Π w i )<label>(25)</label></formula><p>One possible issue arises here. Continuously projecting and collapsing the system state to individual words may remove any quantum effects from the system, i.e. the system reduces to a classical markov model like system. To address the issue, the system is coupled with an ancillary system to avoid the complete collapse. A D-dimensional Hilbert space represents the ancillary system and thus the composite system has the Hilbert space H 2 = H ancill a ⊗ H . The new projectors for the composite space are given by Π</p><p>(2)</p><formula xml:id="formula_33">w = I D ⊗ Π w .</formula><p>The advantage of doing this is that the time evolution of the composite system can give rise to non-trivial correlations between them (analogous to non-separability and entanglement) so that even when the state of the word sequence is collapsed, some information is retained in the ancillary part (owing to their non-trivial correlations). The words are represented in low-dimensional vectors and for each dimension, a unitary matrix is assigned for the composite system. The parameters are learned by minimizing the perplexity of the corpus of sentences. The perplexity is given by:</p><formula xml:id="formula_34">Γ(ρ 0 , U ) = exp(- 1 C w ∈S log p(w |ρ 0 , U )<label>(26)</label></formula><p>Experiments on the TIMIT dataset show that this n-gram quantum language model has a lower perplexity than the state-of-the-art deep neural network architectures like RNN and RNN-LSTM. Although the paper reports an application of the proposed language model in speech recognition, it would be interesting to use it to construct document and query language models.</p><p>3.1.3 Quantum-inspired Ranking. The research on quantum-inspired ranking has been done from two perspectives: quantum probability ranking principle and quantum-like measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantum Probability Ranking Principle</head><p>According to the Probability Ranking Principle <ref type="bibr" target="#b67">[Robertson 1977</ref>], an IR system should rank the documents for a user IN in a decreasing order of their probability of relevance. It makes the assumption that "the relevance of a document to an information need does not depend on other documents" <ref type="bibr" target="#b112">[Zuccon et al. 2009</ref>]. However, in real world situations, judgment of documents by a user is influenced by its previously judged documents <ref type="bibr" target="#b18">[Eisenberg and Barry 1988]</ref>. "The utility of a document may become void if the user has already obtained the same information" <ref type="bibr" target="#b112">[Zuccon et al. 2009</ref>].</p><p>This 'interference' between documents can be due to information overlap between documents or a change in the IN, and is accounted for in a Quantum Probability Ranking Principle (QPRP) <ref type="bibr" target="#b112">[Zuccon et al. 2009</ref>]. QPRP draws an analogy <ref type="bibr" target="#b50">[Melucci 2010</ref>] with the Double Slit Experiment by assuming the two slits to be two documents A and B which the user judges for a query. The position x on the screen corresponds to the event that the user is satisfied by the documents A and B, and decides to stop the search. If A is first document presented to the user, we have p AB (x) as the Manuscript submitted to ACM probability that the user stops the search at document B. In the Double slit experiment, if slit A is fixed and slit B is varied in dimensions, which is analogous to having different documents listed after document A, we get p AB i (x) as "the probability of stopping the search process after seeing documents A and B i " <ref type="bibr" target="#b112">[Zuccon et al. 2009</ref>]. The problem then boils down to finding which configuration of slits (set of documents) AB i exhibits maximum value of p AB i (x).</p><p>For the classical case, if there is no interference, i.e. only one of the B i slit is opened at a time, we have "p AB i (x) = p A (x) + p B i (x)" <ref type="bibr" target="#b112">[Zuccon et al. 2009</ref></p><formula xml:id="formula_35">]: arg max x (p AB i (x)) = arg max x (p A (x) + p B i (x)) = arg max x (p B i (x))<label>(27)</label></formula><p>However, in the quantum case, with all slits open, or all documents considered by the user till B i ,</p><formula xml:id="formula_36">p AB i (x) = p A (x) + p B i (x) + I AB i (x)</formula><p>, where I AB i (x) is the interference term. Thus:</p><formula xml:id="formula_37">arg max x (p AB i (x)) = arg max x (p A (x) + p B i (x) + I AB i (x)) (28) = arg max x (p B (x) + I AB i (x))</formula><p>Hence the best choice of document to rank after A is not the one whose relevance probability is maximum, but rather the one whose sum of individual relevance probability and the interference term with A is maximum. Hence, between two documents B and C, B is ranked before C if and only if:</p><formula xml:id="formula_38">p B (x) + I AB ≥ p C (x) + I AC (x)<label>(29)</label></formula><p>Recall from Equation 1 that the interference term depends upon the phase difference of the probability amplitudes of two quantum systems. Thus:</p><formula xml:id="formula_39">p AB (x) = p A (x) + p B (x) + 2 p A (x) p B (x) cos(θ AB )<label>(30)</label></formula><p>In <ref type="bibr" target="#b112">[Zuccon et al. 2009</ref>], the authors did not give details of how to estimate the interference term. This estimation is done in an application of the QPRP to subtopic retrieval <ref type="bibr" target="#b111">[Zuccon and Azzopardi 2010]</ref>. Subtropic retrieval is a task of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantum Measurement inspired Ranking</head><p>Another method for document ranking using Quantum probabilities is discussed in <ref type="bibr" target="#b109">[Zhao et al. 2011]</ref>, called Quantum Measurement inspired Ranking (QMR). Document retrieval process is considered to be similar to a photon polarization process. A photon has a Horizontal or Vertical polarization, which can be measured by a polarizer. There also exist superposition states of both vertical and horizontal polarizations, which is detected by a horizontal or vertical polarizer rotated at a 45 degree angle.</p><formula xml:id="formula_40">|↖⟩ = 1 √ 2 (|↑⟩ + |↓⟩)<label>(31)</label></formula><p>Superposition states can be generated by passing a horizontal or vertically polarized photon through the rotated polarizer. Mathematically, the vertical and horizontal polarizers form an orthonormal basis of a two dimensional Hilbert space. The rotated polarization state forms another orthonormal basis in the same Hilbert space. In the analogy, the first round of document retrieval for a query is analogous to the measurement along the vertical or horizontal basis.</p><p>Then, a second round retrieval is performed to re-rank the documents by comparing all retrieved documents with the top k documents. This is analogous to passing the photons coming from a horizontal or vertical polarizer through the rotated polarizer. Mathematically this is formulated as projecting a vector represented in one basis onto the subspace generated by another rotated basis.</p><p>In the first round of retrieval, let |↑⟩ and |↓⟩ denote relevance and non-relevance of document respectively for a query. Then a document d with relevance probability |α d | 2 is represented in the first round as:</p><formula xml:id="formula_41">|d⟩ = α d |↑⟩ + β d |↓⟩<label>(32)</label></formula><p>Taking the simple case of k = 1, let the topmost document in the first round of retrieval be represented as:</p><formula xml:id="formula_42">|t⟩ = α t |↑⟩ + β t |↓⟩<label>(33)</label></formula><p>Then, re-ranking is done by representing the document d in terms of t:</p><formula xml:id="formula_43">|d⟩ = λ |t⟩ + µ t<label>(</label></formula><p>34) where λ = α d α t + β d β t (see appendix in [Uprety and Song 2018] for a proof). The probability of relevance of the document d when re-ranking is performed using the top-ranked document of first round is the square of the projection of d onto t, which is |λ| 2 , multiplied by the probability of relevance of t, which is |α t | 2 : p(d |t) = |λα t | 2 (35)</p><p>When d = t, then λ = 1 and the probability becomes |α t | 2 , the original probability of relevance of the top-ranked document. The QMR approach performs significantly better than the QPRP on four TREC collections -WSJ9872, AP8889, ROBUST04 and WT10G on MAP ranking metric.</p><p>Quantum-inspired ranking has also been used to solve the query drift problem, which is defined as the inferiority of results obtained on query expansion, than the original query. This is because the underlying intent of the query might change upon expansion. Several solutions have been proposed for the query drift problem using pseudo relevance feedback <ref type="bibr" target="#b110">[Zighelnic and Kurland 2008]</ref>, focusing on the combination of document scores in the ranked lists of documents based on the original query and the expanded query. For example:</p><p>• CombMNZ rewards documents that are ranked higher in both original retrieval list and second retrieval list by adding the relative score of a document in each of the two lists.</p><p>• Interpolation technique makes a weighted addition of relative scores in the two lists.</p><p>In <ref type="bibr" target="#b102">[Zhang et al. 2011</ref>], a document d is represented in terms of relevance and non-relevance for a query q:</p><formula xml:id="formula_44">|d⟩ = a d |q⟩ + b d | q⟩<label>(36)</label></formula><p>where |q⟩ and | q⟩ represent the vectors for relevance and non-relevance of d with respect to q, respectively. In terms of the expanded query q e , the document is represented as:</p><formula xml:id="formula_45">d e = a e d q e + b e d q e<label>(37)</label></formula><p>"To prevent query drift, the existing fusion models in <ref type="bibr" target="#b110">[Zighelnic and Kurland 2008]</ref> directly combine the two probabilities |a d | 2 and |a e d | 2 " <ref type="bibr" target="#b102">[Zhang et al. 2011</ref>]. The CombMNZ reduces to:</p><formula xml:id="formula_46">(δ q (d) + δ e q (d)).(δ q (d)|a d | 2 + δ e q (d)|a e d | 2 ) (<label>38</label></formula><formula xml:id="formula_47">)</formula><p>where δ q (d) = 1 if d is relevant to query q. Similarly, the interpolation method becomes:</p><formula xml:id="formula_48">λδ q (d)|a d | 2 + (1 -λ)δ e q (d)|a e d | 2 0 ≤ λ ≤ 1 (39)</formula><p>However, the two probabilities |a d | 2 and |a e d | 2 are under different basis and we need to write one in terms of the other. The Quantum Fusion Model (QFM) proposed in <ref type="bibr" target="#b102">[Zhang et al. 2011</ref>] does that and the final outcome combines the probabilities in the following way:</p><formula xml:id="formula_49">(δ q (d)|a d | 2 ).(δ e q (d)|a e d | 2 ) (40)</formula><p>Thus the Quantum based model is a multiplicative model, while the classical models are additive. Another slightly modified version is:</p><formula xml:id="formula_50">(δ q (d)|a d | 2 ).(δ e q (d)|a e d | 2 ) 1/η (41)</formula><p>where "a small η can make scores of different documents retrieved for q e more separated from each other, leading to more distinctive scores" <ref type="bibr" target="#b102">[Zhang et al. 2011</ref>]. The QFM achieves a better performance than the CombMNZ and interpolation methods in terms of Mean Average Precision (MAP) of retrieved documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Multimodal Information</head><p>Retrieval. Despite the wide application of QT in text-based IR, limited attention has been paid to multimodal IR, which is of increasing significance in many applications. The work in this area can be divided into feature level fusion and decision level modality fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Level Fusion</head><p>Initially, Wang et al. <ref type="bibr" target="#b1">[Wang et al. 2010a</ref>] exploited tensor product of Hilbert spaces to fuse textual and image features for circumventing the heuristic combination of uni-modal feature spaces. In particular, textual and visual features are combined in a similar way as non-separable states of a Quantum system. The authors claim that the proposed modality fusion approach is able to capture cross-modal dynamics, i.e., interactions across different modalities (e.g., text and image modalities). In each single modality feature space, documents are formulated as a superposition of terms.</p><p>These terms are words from a vocabulary for the text representation and visual words for the image representation. For instance, in the textual feature Hilbert space denoted as H T :</p><formula xml:id="formula_51">|d T ⟩ = i w t i |t i ⟩,<label>(42)</label></formula><p>where the squared amplitude w 2 t i equals the probability of a document to be about the term t i with i w 2 t i = 1. Similarly, for the image modality the formulation is as follows:</p><formula xml:id="formula_52">|d V ⟩ = i w v i |v i ⟩,<label>(43)</label></formula><p>where v i represents visual words in the image Hilbert space H V . Each pure state is modelled through a density matrix.</p><p>In mathematical language, each density matrix is defined as the outer product of a superposition state. For example, for the textual representation, the density matrix is:</p><formula xml:id="formula_53">ρ d T = i p i d T i d T i ,<label>(44)</label></formula><p>where p i is the probability of the state being in the basis state d T i . Then, the text and image modalities are fused by taking the tensor product of the text and image Hilbert spaces as follows:</p><formula xml:id="formula_54">ρ d T V = ρ d T ⊗ ρ d V + ρ cor r el at ion ,<label>(45)</label></formula><p>where ρ d T andρ d V are the textual and visual density matrices respectively, and ρ cor r el at ion is the density matrix capturing cross-modal interactions between the text and image features. The resultant product is still a valid density matrix. Finally, for measuring the similarity between a multimodal document and query, the trace rule is used as follows:</p><formula xml:id="formula_55">sim(d, q) = trace(ρ d T V • ρ q ),<label>(46)</label></formula><p>where ρ d T V and ρ q are multimodal document and query density matrix representations respectively.</p><p>For capturing cross-modal interactions across the two modalities, two statistical approaches were explored: (a)</p><p>the maximum feature likelihood that associates text with the maximal likely image features; and (b) the mutual information matrix that measures the mutual dependence between the two modalities. Experiments show that even without considering the correlation between text and image features, the pure tensor product approach outperforms other methods such as the use of image features or text features individually, or the concatenation of text and image features. However, such a method suffers from exponentially increasing computational complexity, as the outer product over multiple modalities results in high dimensional tensor representations. The experiments also show that the two proposed statistical methods are trivial to capture cross-modal interactions. For example, simple visual features were used, such as colour histograms, which can hardly be associated with high-level semantics. A more robust statistical approach, such as the cross-modal factor analysis <ref type="bibr" target="#b5">[Atrey et al. 2010]</ref>, might be more effective. Another issue was that images with limited or no annotation were lowly ranked or not retrieved at all. This implies that tensor product cannot manipulate missing values, which becomes a common problem in a real-world scenario. An automatic annotation task might circumvent the above problem. Also, assuming orthogonality of dimensions disregards any semantic overlap.</p><p>This was an issue for textual space as the dimensions representing words need to represent language attributes such as polysemy and synonymy. Nowadays, we can address such issue by exploiting neural network language technologies <ref type="bibr" target="#b16">[Devlin et al. 2019;</ref><ref type="bibr" target="#b55">Pennington et al. 2014]</ref> for constructing text vector spaces with compact semantic information.</p><p>Kaliciak et al. <ref type="bibr" target="#b36">[Kaliciak et al. 2011</ref>] followed up with the previous model, aiming to solve the problem of missing modalities, e.g., when images are not annotated. They proposed two approaches to alleviate this problem, which can be easily integrated with the tensor-based fusion method. The first approach projects an un-annotated image onto a subspace generated by subsets of annotated images. In particular, by exploiting the Born rule, the square projection on the basis states results in a probability distribution of terms for each un-annotated image. The second approach alternatively utilizes the trace rule to calculate the similarity between an annotated and un-annotated image. Images are formulated as density matrices, entailing a probability distribution of terms. The results showed that such approaches under-performed the standard clustering techniques. The result might be related to the assumption that "the correlation at the image-level (i.e., images referring to the same topic) are stronger than the correlations based on the proximity between image terms (i.e., instances of image words)" <ref type="bibr" target="#b36">[Kaliciak et al. 2011</ref>].</p><p>Later on, Kaliciak et al. <ref type="bibr" target="#b35">[Kaliciak et al. 2013]</ref> proposed a quantum-inspired framework for a cross-modal retrieval task. That is, given a text query, to retrieve the most relevant images. They first constructed a common Hilbert space by taking the tensor product of image and text density matrices. Both text queries and image documents are represented in the joint Hilbert space. In this joint space, they also utilized a mechanism of trans-media pseudo-relevance for re-ranking retrieved images. Then, a projection measurement measures the relevance between the text query and each image document represented on the same space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision-level Fusion</head><p>Decision level fusion combines uni-modal classification results to reach a final decision. Despite being a common approach for fusing different modalities, only preliminary studies have investigated quantum-inspired decision level approaches for IR tasks. <ref type="bibr" target="#b24">Gkoumas et al. [Gkoumas et al. 2018</ref>] investigated non-classical correlations between mono-modal decisions on a pair of text-image documents for a multi-modal retrieval task. In principle, non-classical correlations Manuscript submitted to ACM or quantum correlations are stronger than classical correlations due to latent contextual influences. In that study, the authors investigated the existence of this kind of non-classical correlation through the Bell inequality (CHSH inequality) violation in a small-scale experiment on the ImageCLEF dataset. Although they did not find a violation of the CHSH inequality, the experiment design provides useful insights for future investigations into such non-classical contextual correlations.</p><p>Quantum-inspired modality fusion models have also been developed for multimodal sentiment analysis. Sentiment is one of the factors considered by users in judging certain types of documents (e.g. news articles, blogs). Sentiment label can be considered as a feature in predicting relevance <ref type="bibr" target="#b22">[Fuhr et al. 2018</ref>].</p><p>Zhang et al. <ref type="bibr">[Zhang et al. 2018c</ref>] proposed a quantum-inspired decision level modality fusion approach for image-text sentiment analysis. Even this task is far from IR tasks, the approach could be fruitful for IR tasks as well. In particular, both text and image information is associated with density matrices which use the same globally convergent algorithm mentioned earlier in the case of extended QLMs to estimate the density matrices. In this way, density matrices capture the cross-modal interactions. Additionally, the human cognitive interference phenomenon caused when a user is exposed to conflicting text and image information channels, is also considered as analogous to quantum interference.</p><p>Though, the interference term is treated as a single parameter and adjusted experimentally. The results suggest that, when the Cosine of the interference term equals 0.3, the model achieves the best performance. Moreover, the accuracy is the highest when a user pays more attention to the text instead of image modality, assigning weights 0.7 and 0.3 for the text and visual representation respectively. When the weights are reversed, the model performs the lowest. This is an interesting outcome since it helps us understand under which conditions the quantum-like interference works at the decision level and enhances explainability over the modality fusion process. Overall, large-scale experiments show that the proposed approach outperforms a wide range of state-of-the-art baselines.</p><p>A combination of Long Short Term Memory (LSTM) and a quantum-inspired framework for conversational sentiment analysis was proposed in <ref type="bibr">[Zhang et al. 2019a</ref>]. In particular, words are represented as pure states in a real-valued Hilbert space. Then, a sentence is formulated as a mixture density matrix of pure states, i.e., unit vectors, which further is processed by a CNN, resulting in a dense representation. Next, the output of CNN is fed into an LSTM cell to make a decision. Considering conversation sentiment analysis contains time-series and thus requiring fusing time-varying signals, the authors exploited a sequence of LSTM cells and the concept of quantum-inspired measurement, namely weak measurement, to model inter-speaker sentiment influences over a dialogue.</p><p>[ <ref type="bibr" target="#b106">Zhang et al. 2020</ref>] is a follow up of <ref type="bibr">[Zhang et al. 2019a</ref>] by extending the framework with two modalities, namely, text and visual modalities. Specifically, each modality is represented in an individual real-valued Hilbert space. The exact pipeline with <ref type="bibr">[Zhang et al. 2019a</ref>] is followed to predict unimodal sentiment judgments. Then, the concept of quantum interference has been exploited to fuse text and visual sentiment judgements. Comprehensive experiments on two benchmarking datasets for conversational human language analysis showed that the proposed quantuminspired framework beats the state-of-the-art performance for the video emotion recognition task. It is to be noted that conversational sentiment analysis is an important feature in conversational IR tasks.</p><p>3.1.5 Quantum inspired Representation Learning. The quantum-inspired representation and ranking models depend on the construction and learning of Hilbert spaces. These are developed or applied in areas like lexical semantic spaces, topic modelling, word embeddings, and text classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexical Semantic Spaces</head><p>The first connections between QT and semantic spaces were established in <ref type="bibr">[Aerts and Czachor 2004]</ref>. In [Bruza and</p><p>Cole 2005], one such connection is presented using the Hyperspace Analogue to Language (HAL) model <ref type="bibr" target="#b12">[Burgess et al. 1998;</ref><ref type="bibr" target="#b44">Lund and Burgess 1996]</ref>. For a vocabulary of N words, the HAL algorithm constructs an N × N matrix by sliding a window of length l over a text corpus, thus capturing word co-occurrences within the window. Each element of the matrix measures word co-occurrence and in one way, word similarity. Each window is considered as a semantic space and approximates the context or the sense associated with the word. The semantic space for a word is computed in terms of the sum of semantic spaces. If there are y windows around the word w and x of them deal with a particular context i, then the semantic space S i occurs with probability p i = x y and the semantic space for word w can be written in terms of context semantic spaces as:</p><formula xml:id="formula_56">S w = m i=1 p i S i (<label>47</label></formula><formula xml:id="formula_57">)</formula><p>This formula is the same as that of a mixed density matrix written as a mixture of density matrices of pure states. Thus the context of words can be considered as pure states. HAL is also used in <ref type="bibr" target="#b28">[Hou and Song 2009;</ref><ref type="bibr" target="#b29">Hou et al. 2013]</ref> to model word correlations like Quantum correlations of non-separable states.</p><p>The explicit term occurrence based approaches are insufficient to capture hidden semantics. The advent of machine learning techniques have opened up a door to learning semantic spaces based on topic modelling and word embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interference Topic Model</head><p>The analogy to Quantum interference is used in <ref type="bibr">[Sordoni et al. 2013a</ref>] for modeling interactions between topics. Topic modeling is used to discover hidden themes in text collections. A topic is defined as a probability distribution over a vocabulary and a document is a mixture of one or more such topics. Finally, every word in a document is supposed to come from one of the topics. The probability of a term w in a document model θ d with k topics is given as <ref type="bibr">[Sordoni et al. 2013a]</ref>:</p><formula xml:id="formula_58">p(w |θ d ) = k p(w |z = k, ϕ)p(z = k |θ d ) = k θ dk ϕ kw (<label>48</label></formula><formula xml:id="formula_59">)</formula><p>where w ∈ {1, ..., N } denotes a word from the vocabulary. z ∈ {1, ..., K } is the index for a topic. θ d denotes a document where θ d = (θ d 1 , ..., θ dk ) , θ di being the "topic proportions for the document" <ref type="bibr">[Sordoni et al. 2013a</ref>]. ϕ is a N × K matrix representing the distribution of topics over terms.</p><p>Consider the case of two topics: 'war' and 'oil'. The term 'Iraq' is present in both topics. Now if a document contains both topics, still the probability of term 'Iraq' in the document is less than the maximum of its probability in either of the topics. Mathematically speaking <ref type="bibr">[Sordoni et al. 2013a]</ref>,</p><formula xml:id="formula_60">p(w = Iraq|θ d ) = p(Iraq|war ) * p(war |θ d ) + p(Iraq|oil)p * (oil |θ d ) (49) p(Iraq|θ d ) ≤ max(p(Iraq|war ), p(Iraq|oil))</formula><p>However, the probability of the term 'Iraq' occurring in the document should be significantly more given it contains topic 'war' and 'oil'. Current topic models do not consider the interference or relation between two topics when generating a word. They assume the topics to be independent. To capture topic dependence via Quantum probabilities, <ref type="bibr">[Sordoni et al. 2013a</ref>] assumes a Hilbert space where each dimension corresponds to a word from the vocabulary. Then, each topic is a vector in this Hilbert space z k , which is a superposition of vectors corresponding to the terms. Thus we have:</p><formula xml:id="formula_61">|z k ⟩ = w z kw |e w ⟩ = w ϕ kw e iφ kw |e w ⟩ (50)</formula><p>where ϕ kw e iφ kw is the complex amplitude for the topic |z k ⟩ in state |e w ⟩ and | ϕ kw e iφ kw | 2 = p(w |z = k, ϕ). A document can be represented as a superposition of topic states, with the coefficients being the proportion of topic in the document.</p><formula xml:id="formula_62">|d⟩ = 1 Z d ( k θ dk |z k ⟩)<label>(51)</label></formula><p>where Z d is a normalization constant. The projection of a document vector onto a word vector is given as:</p><formula xml:id="formula_63">d w = ⟨e w |d⟩ ∝ k θ dk ϕ kw e iφ kw<label>(52)</label></formula><p>The probability of a term in the document is given by:</p><formula xml:id="formula_64">p(e + w e w ) = | ⟨e w |d⟩ | 2 ∝ | k θ dk ϕ kw e iφ kw | 2 (53) = k θ dk ϕ kw + 2 i &lt;j θ di θ d j ϕ iw ϕ jw cos φ iw -φ jw</formula><p>This equation represents the proposed interference-topic model. The first part of the expression on the right hand side corresponds to the classical topic model given in Equation <ref type="formula" target="#formula_58">48</ref>, and the second is "the interference term which boosts or penalizes the probability for term w in the final document model depending on the phase differences φ iw -φ jw " <ref type="bibr">[Sordoni et al. 2013a</ref>]. For a particular word, if a pair of topics are in the same phase then, φ iw -φ jw = 0 and cos(φ iw -φ jw ) = 1.</p><p>This increases the probability of seeing the word w in the document. For the phase difference of π 2 , the interference term vanishes and the classical topic model is recovered. In their experiment, <ref type="bibr">[Sordoni et al. 2013a</ref>] estimated the interference term using a similarity measure between the topic distributions, such as the Cosine similarity. The topic model helps in relevance ranking in IR by providing a better match for queries and documents, beyond the term level. This Quantum-,inspired topic model is applied to retrieval tasks like the TREC newswire corpora and performs better than the classical topic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Complex Numbers</head><p>QT in its most general formulation uses complex numbers in its representations and computations. Without the use of complex amplitudes, for example, the interference effects will be restricted to only positive and negative interference values (+1 and -1), while not utilizing the full range of possibilities in between. Therefore, it is imperative that Quantum models outside of Physics which are directly or indirectly making use of the superposition and interference phenomena use complex numbers in representation of state vectors, in order to maximally exploit the power of quantum probabilities.</p><p>However, it is difficult to get an intuition as to how to represent concepts, objects, terms, decisions, etc. using complex numbers.</p><p>[van Rijsbergen 2004] proposed using inverse document frequency (idf) of a term as the imaginary part and the term frequency (tf) as the real part of a complex number. In <ref type="bibr" target="#b113">[Zuccon et al. 2011]</ref>, this proposal was investigated and found to be performing poorly than the baseline Vector Space models. In <ref type="bibr" target="#b93">[Wittek et al. 2014]</ref>, different types of word semantics are combined using a complex Hilbert Space. The main idea is to represent distributional semantics, like the word co-occurrence information as real part and represent ontological information about words as the imaginary part of a complex valued vector. The real vectors are constructed using the technique of Random Indexing, where a word vector is constructed using the vectors that represent the contexts of the word. A document is then represented as a sum of its word vectors. Besides, using the technique of concept indexing, a document is also represented as a Bag of Concepts vector. Each word is mapped to one or more concepts from a medical ontology. These two representations are merged into a single complex vector. Thus, similarity between two documents can be calculated as the inner product of the two complex vectors which will reflect both the distributional and ontological similarity. This model is used in the IR task of TREC Medical Records Track and the retrieval effectiveness is found to be better than either the term-based only or concept-based only approaches in terms of the Mean Average Precision (MAP) and Precision@10 metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantum-inspired Neural Representation Models</head><p>In <ref type="bibr">[Li et al. 2018b</ref>], the challenge of emergent meaning and sentiment of a combination of words is addressed. They hypothesize that humans do not associate a single meaning or sentiment to a word. A word contributes to the meaning or the sentiment of a sentence depending upon the other words it is combined with. For example, the words 'Penguin' and 'Flies' (Verb) might be neutral in polarity individually, but the phrase 'Penguin Flies' is of negative polarity. Similar examples can be constructed for sentiment of sentences. This is compared to the Quantum interference phenomenon where two superposed quantum states interfere and the final outcome depends upon their relative phase. As such a word embedding model using complex numbers is introduced. Each word is represented by a complex vector. It comprises a real part that holds word co-occurrence information, and a complex phase that captures abstract combinatory information like the sentiment factor. A sentence is considered as a superposition of words and thus a sentence vector can be constructed as a density matrix. This density matrix is learnable from labelled data, along with a projection matrix, which is used to calculate the probabilities assigned by the sentence vector. For a sentiment classification task, the projection matrix is used to classify the sentiment of the sentence according to the trace rule of calculating probabilities. The proposed model outperformed some word-embedding based models.</p><p>Wang et al. <ref type="bibr" target="#b85">[Wang et al. 2019]</ref> proposed an end-to-end quantum-inspired neural framework for text classification.</p><p>In particular, words are represented as pure states in a complex-valued Hilbert space, while sentences as mixture of pure states (i.e., words). Hence a sentence is represented in a mixture density matrix. In this work, phases are not defined explicitly but learnt through a backpropagation algorithm. Having said that, the exploitation of complex values is pivotal to the formulation of quantum concepts. Then, a set of measures is applied to the mixture density matrix, resulting in a sequence of scalar values. Practically, the measurements are related to high semantic concepts. Finally, a softmax function normalises the output of measurements into a probability distribution before classifying the sentence.</p><p>Comprehensive experiments on six different datasets demonstrated the effectiveness of the proposed method against some neural models. This framework was extended in <ref type="bibr" target="#b42">[Li et al. 2019</ref>] for a question-answering task. The words are formulated as pure states in a complex-valued Hilbert space. Though, in contrast to <ref type="bibr" target="#b85">[Wang et al. 2019]</ref>, each word is represented in a pure density matrix while a sliding window is applied to the sentence, generating a local mixture density matrix for each local window. Both question and answer are represented by a sequence of mixture density matrices. Then, the same set of common measurements is applied to those density matrices in the sense that they share common semantic concepts.</p><p>A max-pooling function is performed over the measurement output components, resulting in a dense representation before the matching process through the Cosine similarity measurement. The proposed complex-valued network for matching achieved comparable performances to strong CNN and RNN baselines on two benchmarking question answering (QA) datasets.</p><p>In <ref type="bibr">[Zhang et al. 2018d</ref>], a quantum many-body wave function is used to model the semantic meaning of words within a local context, i.e., sentences, and a global context, i.e., corpus. In particular, each word is represented by different base states in the sense that each basis corresponds to a different word meaning. First, they model the word meaning within a sentence and corpus by the tensor product of basis states and then project the global tensor representation onto the Manuscript submitted to ACM word embeddings, the computation times for the complex embeddings in <ref type="bibr">[Li et al. 2018b</ref>] is reduced, with additional application to the TREC-10 Question Classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">User Interactions</head><p>3.2.1 Projection Models. The area of user interactions in IR has many sub-aspects, primarily -the cognitive level of interaction, understanding the user IN by reformulation, expansion of queries, and building a user profile based on historical interactions. Earlier, we mentioned about the work in <ref type="bibr">[Melucci 2005a,b]</ref>, which use multiple basis of a Hilbert space to model different user contexts. This work is further extended in <ref type="bibr" target="#b49">[Melucci 2008;</ref><ref type="bibr" target="#b51">Melucci and White 2007]</ref> to combine different user interaction and contextual features for Implicit Relevance Feedback (IRF). Their model uses interaction features like document display time, document saving, document bookmarking, webpage scrolling, webpage depth and document access frequency to construct a user interest profile. A basis vector represents each of these interaction features. The matching of documents against a user profile is done by projecting a document vector onto the subspace spanned by the basis vectors for the user profile. A large projection signifies high relevance of the document to the profile. The features described above are calculated for each document that the user has interacted with and a document-features correlation matrix is formed. Singular Value Decomposition (SVD) is performed to get the eigenvectors, which form the basis for a user profile.</p><p>In <ref type="bibr" target="#b21">[Frommholz et al. 2011;</ref><ref type="bibr">Piwowarski and Lalmas 2009a]</ref>, a general framework for query reformulation using Quantum probabilities is described. The queries are represented as density matrices in a term space and query reformulation updates the query density matrix, which can be used to detect change in user IN in a search session.</p><p>A Hilbert Space for user's perception of document relevance is constructed in <ref type="bibr">[Uprety et al. 2018</ref>]. It deals with the challenge of modeling multidimensional relevance of documents. In an extended Multidimensional User Relevance Model (MURM) <ref type="bibr" target="#b38">[Li et al. 2017;</ref><ref type="bibr" target="#b108">Zhang et al. 2014]</ref>, seven factors or dimensions of relevance are identified, which influence user's judgment of a document. They are Topicality, Interest, Novelty, Understandability, Scope, Habit and Reliability. The features defined for each of these seven dimensions in <ref type="bibr" target="#b38">[Li et al. 2017</ref>] are extracted from the retrieved documents of a query and fed into the LambdaMART [Burges 2010] Learning to Rank algorithm. Thus for each relevance dimension, a document has a relevance score. In other words, for a query one gets seven different ranking lists, one for each dimension. The scores obtained are converted into probabilities using max-min normalization. Representing user's relevance perception of a document with respect to each relevance dimension as a vector, and perception of non-relevance as its orthogonal vector, a document can be represented in a two dimensional vector space <ref type="bibr">[Uprety et al. 2018</ref>]. The two relevance and non-relevance vectors for a relevance dimension form an orthonormal basis of the vector space. Figure <ref type="figure">7a</ref> denotes one such vector for a user's perception of document relevance |U ⟩ d with respect to Topicality dimension of relevance. The projection of the document perception vector on the Topicality vector is proportional to the probability of relevance of the document with respect to the Topicality dimension. Relevance and non-relevance of the document with respect to another dimension is represented as another set of orthogonal vectors, which, in general form another basis in the same Hilbert Space. In Figure <ref type="figure">7b</ref>, we see that the projection of the document perception vector is different in the Reliability basis, suggesting that, while the document has a high relevance when considering the Topicality dimension, it is not so much relevant when considering the Reliability dimension.</p><p>The most popular interpretation of QT is that the state vector collapses upon measurement from a superposition to a definite state. When drawing an analogy, the user's cognitive state is generally considered as in a superposition of various Information Needs (IN) and on judging a document as relevant, it collapses to one particular IN. However, in practice, this may not always be the case. Even after judging documents, a user may still be in an ambiguous or Manuscript submitted to ACM Users are asked to judge documents on a -4 to 4 scale of relevance. For some query-document pairs, the users are asked to judge the same document for a second time. According to the standard collapse of the IN, after the judging a document as relevant, subsequent judgments will produce the same relevance result. However, it is found that in many cases, users change the relevance decisions. This will happen only when after the judging the document for the first time, the users were still uncertain about the document and their IN. The user's cognitive state was still superposed. This is especially the case where judgments on some documents are not trivial and difficult to make. The weak measurement model involves the Two State Vector Formalism (TSVF) of QT. In TSVF, the state of a system is not represented by a single vector |ψ ⟩ but rather by two vectors |ϕ⟩ and |ψ ⟩, where one vector represents the state of the system in the past (relative to a time t), and the other represents the state after time t. A weak measurement of an observable W on the system is given by:</p><formula xml:id="formula_65">w = ⟨ϕ | W |ψ ⟩ ⟨ϕ |ψ ⟩<label>(56)</label></formula><p>This type of Quantum measurement is applied in case of session search. A user's IN is represented by two vectors.</p><p>One contains the historical session information in terms of Implicit relevance feedback, and the other represents the current query, in terms of Pseudo Relevance Feedback. The document vectors, |d i ⟩, are calculated using word embedding techniques, and then the corresponding projectors P D i = |d i ⟩ ⟨d i | are constructed. The relevance probability of document d i using weak measurement is calculated as:</p><formula xml:id="formula_66">p = ϕ past d i ⟨d i |ϕ cur r ⟩ ϕ past ϕ cur r<label>(57)</label></formula><p>The experiment is conducted on the TREC Clueweb12 document collection and the QWM method gives a better performance than the Quantum Language Model and its variations, as well as some state-of-the-art classical IR models.</p><p>The TSVF is also used in <ref type="bibr" target="#b90">[Wang et al. 2017]</ref> to modify the query density matrix in QLM. A quantum state is denoted as ψ post ψ pr e . Here ψ pr e is a state evolving from the past to the present and ψ post is a state devolving from future to the present. The previous user query in the session is considered for the past state and the current query for which the documents are to be retrieved is considered as the future query. Then, separate projectors are constructed for the past and future queries and the density matrix ρ d for the document is estimated in the following manner:</p><formula xml:id="formula_67">ρ d = arg max( M pas t i=1 log tr (ρ d Π i ) + M f ut ur e j=1 log tr (ρ d Π j ))<label>(58)</label></formula><p>where M past and M f utur e are the number of projectors (made up of single terms or compound terms) in the past query and the future query respectively.</p><p>3.2.2 Feedback. The query drift problem presented in the previous subsection is approached using user's search history in <ref type="bibr" target="#b100">[Zhang et al. 2016]</ref>. A document is represented as a superposition of query vectors for current query and for a latent query defined by the user's query history.</p><formula xml:id="formula_68">|d⟩ = a d |q c ⟩ + b d |q h ⟩<label>(59)</label></formula><p>q h denotes the user IN that the user implicitly has in mind based on historical context, but has not been explicitly expressed into words. A document, in the superposition state of being relevant to both the current (q c ) and latent query (q h ), is then evaluated in terms of an expanded query. This is similar to the double slit experiment analogy with the two slits representing q c and q h and the detector screen representing the evaluation of this document in terms of the expanded query. Thus the document relevance with respect to the queries q c and q h interfere with each other. If where θ is the phase between the two paths d → q c → q e and d → q h → q e . We get interference between the two paths, because the actual path is superposed, d → (q c &amp;q h ) → q e . The first round retrieval is assumed to be using both the current and the latent query at the same time. This method of query expansion using user's previous interactions, is termed as the Quantum Query Expansion (QQE) approach for session search. It gives better results than the QFM discussed in the previous subsection, over the NDCG evaluation measure. <ref type="bibr" target="#b39">[Li et al. 2015]</ref> propose a Session-QLM (SQLM) to model the evolving nature of user's IN in a search session. The evolution is modelled using density matrix transformation. The density matrix is constructed using user interaction features like clicked and skipped documents, dwell time, click sequence, etc. User's historical queries in context is also used in <ref type="bibr" target="#b37">[Li et al. 2016</ref>] for a Contextual Quantum Language Model (CQLM). The density matrices are constructed to represent the language models for the current query and for the historical queries in a search session. They are then combined to give the CQLM.</p><formula xml:id="formula_69">ρ CQ LM = ξ × ρ c + (1 -ξ ) × ρ h<label>(61)</label></formula><p>where ξ ∈ [0, 1] combines the two language models.</p><p>The construction of ρ h is done by combining all the ρ h i of the previous queries in the session. The historical queries in the session which are similar to the current query are given more weight. Hence:</p><formula xml:id="formula_70">ρ h = n-1 i=1 γ i × ρ h i (62)</formula><p>where γ i is the similarity between current query q c and previous query q i . The similarity is calculated by "representing each query as a TF-IDF vector, derived from the concatenation of all of its result documents. " <ref type="bibr" target="#b37">[Li et al. 2016</ref>].</p><p>The CQLM, however, was not designed to capture the evolution of user IN. To address this issue, the same paper further proposed an Adaptive CQLM (ACQLM) to model the evolution of user IN. The basic idea is to decompose the current query into three -a common part, an added part and a removed part, relative to the previous queries in the session. For example, if q k = wxy, q k -1 = xyz, "then xy is the common part, z is the added part and w is the removed part. The common part indicates the user's underlying search topic/theme for the session. The removed and added parts reflect the change in IN" <ref type="bibr" target="#b37">[Li et al. 2016</ref>]. The ACQLM adjusts the QLM in such a way, as to assign a higher probability to the terms (or composite terms) of the common and added parts. Thus the ACQLM builds upon the CQLM by incorporating query change signals in a structured and intuitive way, moving the QLM into the right direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Context Effects.</head><p>A series of research has been carried out from the user cognitive aspect of IR, drawing parallels from QT and using the Quantum framework to model and explain some of the aspects. An early work <ref type="bibr">[Wang et al. 2010b</ref>] investigated the interference in relevance judgment of a topic caused by another topic. Consider the topics "Brave</p><p>Heart" (William Wallace's nickname and the name for his film biography) and "William Wallace", and a biographical article about William Wallace. Both topics are relevant to the article. Consider another topic about "William Wallace's wife". In a user study, it was found out that when the topics "Brave Heart" and "William Wallace" were displayed together for the article, 93% users chose to judge the article as relevant to "William Wallace" and only 14% chose it as being relevant to the topic "Brave Heart". However, when "Brave Heart" was displayed together with "William Wallace's wife", 89% of the users judged "Brave Heart" as relevant to the article and 5% judged "William Wallace's wife" to be relevant. There were experiments conducted with different topics and articles and such type of context effects were found, where the presence of one topic or document influences the relevance judgment of another topic or document.</p><p>In the first case, "William Wallace" is highly relevant to the article. It sets a high comparison baseline which affects the judgment for the topic "Brave Heart" and results in a low probability of relevance. However, it appears more relevant in comparison with "William Wallace's wife". For a Quantum probabilistic explanation of this result, we regard "William Wallace" and "William Wallace's Wife" as two different contexts for the topic "Brave Heart". Each context is described by a basis. So a document or topic d can be represented in the context basis as:</p><formula xml:id="formula_71">|d⟩ = a 1 |q 1 ⟩ + a 2 | q1 ⟩<label>(63)</label></formula><p>where | q1 ⟩ represents the absence of context q 1 . Representing a query q in the same basis as |q⟩ = b 1 |q 1 ⟩ + b 2 | q1 ⟩, we can calculate the relevance of the document d for query q as: p</p><formula xml:id="formula_72">(d |q) = | ⟨q|d⟩ | 2 (64) = (a 1 b 1 + a 2 b 2 ) * (a 1 b 1 + a 2 b 2 ) † = a 2 1 b 2 1 + a 2 2 b 2 2 + 2a 1 b 1 a 2 b 2 cos θ</formula><p>where the probability amplitudes are complex quantities, and θ represents the phase difference term. The third term is the interference term, which can be positive or negative depending upon the phase differences. For some contexts, the interference term is negative and the relevance of the same document for the query can be low, which explains why "Brave Heart" is judged less relevant when seen in the context of "William Wallace". There is a negative interference term that lowers the probability of relevance for the given query/article.</p><p>A follow-on work <ref type="bibr" target="#b86">[Wang et al. 2016</ref>] further explored the influence of context in document relevance judgment. It specifically investigates the presence of Order Effects in relevance judgment of documents. In the experiment, users are shown a pair of documents for a query and the relevance judgment by the user for a document is affected by the order, in which the document is presented. For example, for the query "Albert Einstein" users are shown documents about "Issac Newton" and "Theory of Relativity". The relevance probability of "Issac Newton" is lower when it is shown after "Theory of Relativity" (called a comparative context) than when it is shown first (non-comparative context). In simple terms, having seen a more relevant document first, user's perception of relevance for a particular document may be lower. This can be explained as an Order Effect due to incompatibility between the topics, as shown in Figure 8. The paper also tested the Quantum Question Order inequality [Wang and Busemeyer 2013], which is an inequality for testing incompatibility in decision making systems. One of the earliest works to investigate order effects in the different relevance dimensions is [Bruza and Chang 2014].</p><p>A user study was conducted, in which participants were asked questions about different pairs of relevance dimensions for a document, e.g. Credibility and Understandability, etc. It was found that the judgement of credibility, novelty, etc.</p><p>was different depending upon the order in which they were asked to judge.</p><p>Similar order effects using query log data have been investigated in <ref type="bibr">[Uprety and Song 2018]</ref>. The method of constructing a Hilbert space for multidimensional document relevance perception from <ref type="bibr">[Uprety et al. 2018</ref>] is used (discussed earlier in this subsection). It is assumed that a user may consider multiple relevance dimensions while judging a document, for example, topicality and novelty. The relevance perception vectors corresponding to different relevance dimensions are in general incompatible in the Hilbert space representation. Thus different orders of consideration of the relevance dimensions may lead to different final judgment of the document. To investigate such behaviour in query log data, a subset of queries are found, where the top two retrieved documents have similar scores of relevance in all the seven dimensions. Yet the first document in the ranked list is not judged relevant, but the second one is. A small set of such queries are indeed found and order effects arising out of different order of consideration of relevance dimensions is offered as a possible explanation for such queries. Figure <ref type="figure">9</ref> explains the order effect for two documents d 1 and d 2 (ranking order for a query), which have the exact same Hilbert space, yet only d 2 is clicked. For d 1 , if the user first considers Topicality and then Reliability to judge document d 1 , then the final probability of judgment obtained is 0.0399 (Figure <ref type="figure">9a</ref>). Whereas, for d 2 , if the order is reversed, the probability of final judgment obtained will be 0.3014 (Figure <ref type="figure">9b</ref>), much larger in this case. However, an important question is why the order is reversed in the user's mind for the next document. The authors argue that it could be due to a memory bias -the user can use the last relevance dimension considered for the previous document as the first dimension while judging the current document. Also, there is a possibility that such behaviour can be due to a variety of different reasons, or just random errors in the log data.</p><p>Nonetheless, a quantum cognitive explanation based on order effects is a possibility.</p><p>As we see that there is some evidence of incompatibility between different relevance dimensions, <ref type="bibr">[Uprety et al. 2019b</ref>] investigated the violation of Bell-type inequalities for multidimensional relevance judgment data. A violation of Bell-type inequalities would confirm the quantum nature of data. However, no such violation is found due to lacking probabilities of relevance available for joint judgment of a pair of documents in their dataset.</p><p>Order effect in risk and ambiguity is also investigated and observed in Information Foraging Theory in <ref type="bibr" target="#b94">[Wittek et al. 2016]</ref>. This paper identifies a theoretical limit to simultaneous consideration of risk and ambiguity in decision making using eye tracking data, analogous to the uncertainty principle.</p><p>Manuscript submitted to ACM In <ref type="bibr">[Uprety et al. 2019a</ref>], the phenomena of incompatibility and order effects between relevance dimensions has been studied through a novel protocol design inspired from the Stern-Gerlach experiment of Physics. For a query-document pair, two groups of users were asked three questions relating to Topicality (T), Understandability (U) and Reliability (R) of a document, in orders TUR and TRU respectively. A complex-valued Hilbert space for the user cognitive state is constructed using the data obtained from the experiment, which is used to construct operators corresponding to the T, U and R measurements/judgements. Interference and incompatibility is discussed using these operators. This is the first work where complex numbers are used to capture interactions between relevance dimensions such as incompatibility and interference. It is extended in <ref type="bibr" target="#b83">[Uprety et al. 2020]</ref> to test the violation of a Kolmogorovian probability axiom: 0 = δ = P(A ∨ B) -P(A) -P(B) + P(A ∧ B)</p><p>where the events A and B are the questions regarding Understandability and Reliability of a document. The conjunction and disjunction questions are asked through a specific experiment design and a violation of the above equality is observed in the data. Quantum model predicts a violation for all queries. This paper also compares quantum and Bayesian models for predicting multidimensional relevance probabilities. Quantum predictions are consistently closer to the experimental data, while predictions from the Bayesian model deviate significantly in some cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SUMMARY AND LIMITATIONS</head><p>van Rijsbergen's seminal work introduces us to similarities between the mathematical representation of microscopic particles in QT and information objects in IR. It does not delve into much depth over the distinct advantages of the quantum framework over traditional IR frameworks.</p><p>Early research inspired by van Rijsbergen's ideas implement QT-based ad-hoc IR models by considering information need space as Hilbert space and introducing ideas of superposition for ambiguous queries. These representations provide a good starting point in QR, but they generally fail to outperform the state-of-art methods in IR.</p><p>The Quantum Language Model (QLM) is a promising application and intends to solve a crucial problem in NLP and IR -of representing compound terms in relation to the individual terms. Superposition principle is made use of and a quantum algorithm to build a language model is applied. It performs better than baseline models like tf-idf and BM25.</p><p>The later quantum-inspired language models show marked improvement over the QLM but need to be applied on a wide variety of IR and NLP tasks and compared with the state-of-the-art baselines. The complex word embedding is another promising approach, however there is a lack of clarity as to why this methods performs better than some classical methods and what is the intuition behind the interference terms and complex phases.</p><p>The Quantum Probability Ranking Principle is an important milestone in quantum-inspired IR as it approaches and combines QT and IR from an axiomatic point of view. However, the problem of quantifying the interference term Table <ref type="table">1</ref>. Review Summary remains and document similarity approaches applied do not take the quantum advantage. One needs to devise a way to subscribe complex phases to documents and then calculate the interference terms.</p><p>The query fusion and query expansion approaches make use of superposition and interference phenomena, however it is difficult to get an intuitive explanation of how these two are coming into effect and providing the advantage over classical methods. The Contextual QLM (CQLM) and Adaptive-CQLM are promising applications of the QLM to incorporate user interactions, however they are outperformed by the state-of-art machine learning based methods.</p><p>The integration of the quantum framework to neural networks is promising and combines the representational complexity of neural networks with the probabilistic generalization provided by the quantum framework, especially when complex numbers are included. However, as we see in the results reported in this survey, the state-of-the-art neural networks outperform quantum-inspired models. A reason could be that the datasets used are mostly static, devoid of context, the human factor and its complexities, but it is not the case in real applications.</p><p>The cognitive experiments on order effects in document judgment provide a good insight into why quantum probability is useful in modeling human decision making. However, most of these experiments are only performed on small user collected samples and need to be conducted on real world search data. Also, they do not yet provide a way to make use of the order effect information to improve the effectiveness of IR systems.</p><p>We summarise the survey in Table <ref type="table">1</ref> with the papers categorised into the sub-areas of IR mentioned in Figure <ref type="figure" target="#fig_1">1</ref>. We also list papers which use quantum-inspired neural networks, encompassing all the other sub-areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FUTURE DIRECTIONS IN QUANTUM-INSPIRED IR</head><p>Quantum Theory was developed as a framework to explain the counter-intuitive behaviour of microscopic particles which could not be explained using traditional probability and logic models. Hence, the most important thing to consider Manuscript submitted to ACM while applying the quantum framework to IR or any other computational sciences, is the existence of such non-classical data (which violates classical logic, e.g. Boolean logic). There is substantial evidence in behavioural sciences that data obtained from human information interaction and decision-making can be quantum-like data. Phenomena like conjunction and disjunction fallacy, violation of law of total probability (LTP), similarity effects <ref type="bibr" target="#b77">[Tversky 1977]</ref>, etc. can be investigated in user behaviour in IR. Conjunction and disjunction fallacies can exist in relevance judgment of documents. Although the QPRP incorporates the interference term in document ranking, it does not explicitly occur due to the violation of LTP. In fact, LTP violation can be investigated in IR when users make decisions under ambiguity and the cognitive state can be modelled as a superposition of different states.</p><p>Hence, the presence of quantum-like data and quantum phenomena in IR can completely change our understanding of the fundamentals of IR. A strong candidate to start with is to rethink the concept of relevance and the interpretation of probability of relevance. In the Cranfield methodology of building IR collections, a common practice is to reject annotator disagreement as noise and fix one relevance label for a given document which has been judged by the majority of annotators. However, it is possible that both labels exist for the document for the same query, and the disagreement between annotators is due to their different contexts which leads to different semantic interpretations of the document.</p><p>Or, there can be ambiguity in the document content and meta-data (e.g. arising out of its lack of credibility, novelty, etc.) which can put annotators in two minds, leading to different relevance labels. Hence a document needs to be modelled as both relevant and non-relevant for a query. We see that QT has tools to model two mutually exclusive states of a system as a single state (Superposition). Future work can begin with constructing such contextual datasets <ref type="bibr" target="#b30">[Inel et al. 2014</ref>].</p><p>With such contextual data in hand, subspace generalization of vector spaces can be utilized to create more contextual and dynamic representations. Representing a document or a word with a subspace rather than a vector allows for representing its different aspects in the vectors which span the subspace. This can be instrumental in capturing meaning in the data in the same way as humans do (subject to multiple contexts, arising out of external factors or intrinsic cognitive biases). Integrating different Hilbert Spaces by using the tensor product is a useful technique to fuse different modes of information like text, images, audio, etc. as in multi-modal IR. It can also be useful in fusing different cognitive aspects of information (Polyrepresention) e.g., product reviews sentiment and brand credibility.</p><p>The presence of incompatibility in judgments can render many user models, which assume joint distributions between variables, as ineffective. For example, in <ref type="bibr" target="#b43">[Lin and He 2009]</ref>, a joint sentiment-topic model to detect sentiment and topics simultaneously from text is proposed. The joint probability of a word, topic and sentiment label assigned is written as p(w, z, l) = p(w |z, l)p(z, l) where w is a word, z is a topic of the document and l is the sentiment label of the document. If there is incompatibility between the sentiment and topic of a document, then the predictions based on this model would not match the user's decisions <ref type="bibr">[Bruza and Chang 2014]</ref>. This is something which can be captured using the quantum framework and quantum-inspired models will be better equipped to handle such cases.</p><p>This research can further benefit from a formal model of quantum-inspired neural networks with a theoretical basis and where the interference term and complex numbers naturally occur in the neural computations. We believe that best way forward in this field will be the integration of concepts and constructs from QT with the state-of-the-art machine learning models, e.g. neural networks. QT framework is best positioned to model human decisions under ambiguity and dynamic changes of context. Their fusion with QT can enhance their ability to model complex human behavioural data, building a platform for more human-centred Artificial Intelligence. It is known that the neural models suffer from the problem of generalisation. One way to tackle the problem is that multiple statistical hypotheses of a neural network can be preserved in the form of a superposition state in the middle layer and used by the model decision layer. Traditionally, a deep learning model is based on one hypothesis, thus limiting the model's generalisation ability. The output layer of</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>. The emerging Manuscript submitted to ACM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Brief overview of quantum-inspired IR field of Quantum Cognition [Busemeyer and Bruza 2012] studies such quantum-like phenomena in cognitive and</figDesc><graphic coords="3,73.44,95.04,428.39,185.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Double slit experiment setup mathematical framework even outside of Physics. The fundamental difference between the classical and quantum</figDesc><graphic coords="4,153.00,97.44,342.73,115.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2. 2 . 4 Fig. 4 .</head><label>244</label><figDesc>Fig. 3. A two dimensional Hilbert Space with initial state vector and its projection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Structure of the Quantum inspired IR survey</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Three dimensional Information Need (IN) space</figDesc><graphic coords="12,200.12,95.04,248.47,163.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>providing a list of documents which covers all possible topics (IN aspects) relevant to the user IN. It advocates a more diverse ranking of documents, to achieve a minimal redundancy. Thus redundant documents can be assumed to be destructively interfering (negative interference term) and the documents having exclusive information be positively interfering. The cos(θ ) part of the interference term is estimated as the Pearson's correlation between the term vectors of two documents. The term vectors are constructed using the BM25 scheme. Experiments show that the QPRP based ranking for subtopic retrieval performs better than a model based on Portfolio Theory<ref type="bibr" target="#b89">[Wang and Zhu 2009]</ref> (then state-of-the-art) for subtopic retrieval on the ClueWeb09-B collection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>Fig. 7. Modelling user's perception of relevance dimensions in Hilbert space superposed state and there may not have been an apparent change in the IN. The standard interpretation of state collapse may not accurately capture the evolution of IN. This challenge is investigated in [Wang et al. 2018] using a Quantum Weak Measurement (QWM) model. It is a generalization of the standard collapse model where the variance of measurement results is much larger. To test the weak measurement phenomena in user judgments, a study is carried out. Users are asked to judge documents on a -4 to 4 scale of relevance. For some query-document pairs, the users are</figDesc><graphic coords="27,124.75,95.04,141.37,92.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><figDesc>|q e ⟩ represents the vector for the expanded query and |d⟩ = a d |q c ⟩ + b d |q h ⟩, then the projection of document onto the expanded query vector is: d → q e = | ⟨q e |d⟩ | 2 (60) = |a d ⟨q e |q c ⟩ + b d ⟨q e |q h ⟩ | 2 = | ⟨q c |d⟩ ⟨q e |q c ⟩ + ⟨q h |d⟩ ⟨q e |q h ⟩ | 2 = | ⟨q c |d⟩ ⟨q e |q c ⟩ | 2 + | ⟨q h |d⟩ ⟨q e |q h ⟩ | 2 + 2 ⟨q c |d⟩ ⟨q e |q c ⟩ ⟨q h |d⟩ ⟨q e |q h ⟩ cos θ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. On viewing document about Theory of Relativity, the judgment of topic Newton is lower for the query Einstein</figDesc><graphic coords="30,150.76,95.04,171.36,104.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><figDesc>Fig. 9. Different order of consideration of dimensions leads to different final probability</figDesc><graphic coords="31,287.64,95.04,149.94,90.71" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Manuscript submitted to ACM</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Note that the current state-of-the-art BERT-based neural model for TREC-QA has achieved MAP and MRR of 0.943 and 0.974 respectively<ref type="bibr" target="#b23">[Garg et al. 2019</ref>].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The TANDA model mentioned above currently gives the best performance on WikiQA dataset (MAP and MRR of 0.92 and 0.933 respectively, as compared to 0.695 and 0.71 by[Zhang et al. 2018d]).</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>* This work is funded by the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs> under the <rs type="grantName">Marie Sklodowska-Curie</rs> grant agreement No <rs type="grantNumber">721321</rs>, and <rs type="funder">Natural Science Foundation of China</rs> (Grant No <rs type="grantNumber">U1636203</rs>). Corresponding author: <rs type="person">Dawei Song</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_dXwc6wE">
					<idno type="grant-number">721321</idno>
					<orgName type="grant-name">Marie Sklodowska-Curie</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
				<org type="funding" xml:id="_EPQDERD">
					<idno type="grant-number">U1636203</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>local one. This results in a high dimensional tensor, capturing interactions of words within a sentence and corpus. The high dimension resulted tensor representation is further decomposed in subspace base states, which finally processed by a CNN component for constructing the final representation.</p><p>Remark: The above works outperformed various existing neural models at the time when the papers were published.</p><p>However, more recent neural models, such as BERT based models <ref type="bibr" target="#b23">[Garg et al. 2019;</ref><ref type="bibr" target="#b66">Raffel et al. 2019</ref>] have achieved a largely improved performance on the same tasks. It is worth exploring the integration of quantum models with the new BERT architecture <ref type="bibr" target="#b16">[Devlin et al. 2019</ref>] in the future.</p><p>Readers interested in tensor networks for representation learning, with or without quantum-inspirations, can also refer to <ref type="bibr">[Zhang et al. 2019b</ref>] which introduces a Tensor Space Language model (TSLM) by building higher dimensional tensors using word vectors, leading to a generalisation of n-gram models.</p><p>In <ref type="bibr" target="#b34">[Jiang et al. 2020]</ref>, authors integrate quantum interference phenomena in neural networks with application to ad-hoc retrieval. Existing neural IR models are formulated in terms of classical probability. For example, if q i represent sub-units (e.q. words) of a query Q, then neural models first perform sub-unit level matching and then aggregate the scores obtained to calculate a final relevance score. Formulated in terms of probabilities, such aggregation follows the law of total probability:</p><p>The authors hypothesise that a quantum-like cognitive interference can occur such that the aggregation of relevance scores can happen non-linearly, due to negative contribution of certain query or document sub-units. Thus the above equation becomes similar to Equation <ref type="formula">1</ref>:</p><p>They proceed to model this interference term and incorporate into a neural architecture. Query and document states are represented as a superposition of their respective sub-unit states with the coefficients of document sub-unit states being the tf-idf values, and those of query sub-units being trainable parameters. A composite system is constructed by taking the tensor product of the query and document state vectors. Then, calculating relevance probability using the trace rule breaks down the probability into two parts -similarity matching as used in neural IR models and the interference term, which is determined by the interaction between different document features. The similarity matching is achieved using a query attention mechanism, and the interference is modelled as a n-gram window convolution network. The new model is tested on Robust04 and Clueweb09-cat-B collections. While it performs better than various existing neural ranking models and even a vanilla-BERT <ref type="bibr" target="#b46">[MacAvaney et al. 2019</ref>] (on P@20 metric on Robust04 dataset), it under-performs the current-state-of-the-art model <ref type="bibr" target="#b46">[MacAvaney et al. 2019</ref>] on both NDCG@20 and P@20 on the Robust04. On the other hand, on the Clueweb-09-cat-B dataset it beats existing neural IR models and also the state-of-the-art XLNet model <ref type="bibr" target="#b98">[Yang et al. 2019]</ref> in NDCG@20 and ERR@20 metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantum-inspired Classification</head><p>Classification algorithms inspired by Quantum detection theory <ref type="bibr" target="#b27">[Helstrom 1969]</ref>  training. The nature of reserving multi-hypothesis at the same time is like quantum superposition. This makes for some exciting research prospects in the future.</p><p>The authors are hopeful that this literature survey is able to provide a clear picture of the quantum-inspired IR field and set a road-map for researchers to take this field forward.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno>Caputo et al. 2011</idno>
		<title level="m">Area Sub-area References Representation and Ranking Projection Models</title>
		<imprint>
			<date type="published" when="2005">Melucci 2005b. 2017</date>
		</imprint>
	</monogr>
	<note>van Rijsbergen 2004 Piwowarski and Lalmas 2009a Piwowarski et al. 2008 Piwowarski et al. 2010a Piwowarski et al. 2010c Piwowarski et al. 2010b Frommholz et al. 2010] Quantum Language Models Sordoni et al. 2013b Xie et al. 2015 Zhang et al. 2018d Hou and Song 2009 Hou et al. 2013 Zhang et al. 2018b Zhang et al. 2018a Zhang et al. 2018d Blacoe et al. 2013],[Blacoe 2015 Li et al. 2018a] Quantum-inspired Ranking [Zuccon et al. 2009 Zuccon and Azzopardi 2010 Zhao et al. 2011 Zhang et al. 2011</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ir [</forename><surname>Multimodal</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010a]</date>
		</imprint>
	</monogr>
	<note>Kaliciak et al. 2011 Kaliciak et al. 2013 Gkoumas et al. 2018], [Zhang et al. 2018c Zhang et al. 2020] Quantum-inspired Representation</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">], [Tiwari and Melucci 2018] User Interactions Projection Models [Melucci and White</title>
		<idno>Buccio et al. 2018</idno>
		<imprint>
			<date type="published" when="2007">Wang et al. 2019. Li et al. 2019. 2007. Melucci 2008</date>
		</imprint>
	</monogr>
	<note>Aerts and Czachor 2004 Bruza and Cole 2005 Sordoni et al. 2013a Zuccon et al. 2011 Wittek et al. 2014 Li et al. 2018b Jaiswal et al. 2018 Piwowarski and Lalmas 2009a Frommholz et al. 2011 Uprety et al. 2018], [Wang et al. 2018], [Wang et al. 2017</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">[</forename><surname>Feedback</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<title level="m">Context Effects</title>
		<imprint>
			<date type="published" when="2015">2015. 2016. 2016. 2016. 2019</date>
		</imprint>
	</monogr>
	<note>Wang et al. 2010b Uprety and Song 2018 Uprety et al. 2019b Wittek et al. 2016 Uprety et al. 2019a Uprety et al. 2020] Quantum-inspired Neural Networks -[Zhang et al. 2018a Li et al. 2018b Jaiswal et al. 2018], [Zhang et al. 2018d Zhang et al. 2019a Zhang et al. 2020 Li et al. 2019 Zhang et al. 2019b Jiang et al. 2020</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quantum aspects of semantic analysis and symbolic artificial intelligence</title>
	</analytic>
	<monogr>
		<title level="j">Journal of Physics A: Mathematical and General</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multimodal fusion for multimedia analysis: a survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pradeep K Atrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdulmotaleb</forename><forename type="middle">El</forename><surname>Anwar Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><forename type="middle">S</forename><surname>Saddik</surname></persName>
		</author>
		<author>
			<persName><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="345" to="379" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards Quantum Language Models</title>
		<author>
			<persName><forename type="first">Ivano</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Tamburini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1840" to="1849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic Composition Inspired by Quantum Measurement</title>
		<author>
			<persName><forename type="first">William</forename><surname>Blacoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quantum Interaction</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="41" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Quantum-Theoretic Approach to Distributional Semantics</title>
		<author>
			<persName><forename type="first">William</forename><surname>Blacoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elham</forename><surname>Kashefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Niels Bohr</publisher>
			<date type="published" when="1937">2013. 1937. 1937</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="289" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quantum Logic of Semantic Space: An Exploratory Investigation of Context Effects in Practical Reasoning</title>
		<author>
			<persName><forename type="first">Pia</forename><surname>Borlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">J</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">We Will Show Them! Essays in Honour of Dov Gabbay</title>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vivien</forename><surname>Chang</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1926">2013. 2013. 1926. 1926. 2014. 2014. 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="339" to="362" />
		</imprint>
	</monogr>
	<note>Max Born Quantum mechanics of collision processes Zeit fur Phys Perceptions of document relevance Frontiers in Psychology Interactive Information Retrieval: An Introduction</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Binary Classification Model Inspired from Quantum Detection Theory</title>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Di Buccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prayag</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM SIGIR International Conference on Theory of Information Retrieval -ICTIR &apos;18</title>
		<meeting>the 2018 ACM SIGIR International Conference on Theory of Information Retrieval -ICTIR &apos;18</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><surname>Burges</surname></persName>
		</author>
		<title level="m">From RankNet to LambdaRank to LambdaMART: An Overview</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Explorations in context space: Words, sentences, discourse</title>
		<author>
			<persName><forename type="first">Curt</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kay</forename><surname>Livesay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discourse Processes</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="211" to="257" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Bruza</surname></persName>
		</author>
		<title level="m">Quantum Models of Cognition and Decision</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>st ed.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A quantum theoretical explanation for probability judgment errors</title>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><forename type="middle">M</forename><surname>Pothos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Query Algebra for Quantum Information Retrieval</title>
		<author>
			<persName><forename type="first">Annalina</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Italian Information Retrieval (IIR) Workshop</title>
		<meeting>the 2nd Italian Information Retrieval (IIR) Workshop<address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-01-27">2011. January 27-28, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><surname>Dirac</surname></persName>
		</author>
		<title level="m">The Principles of Quantum Mechanics (International Series of Monographs on Physics)</title>
		<imprint>
			<publisher>Clarendon Press</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Order effects: A study of the possible influence of presentation order on user judgments of document relevance</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Eisenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><surname>Barry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="293" to="300" />
			<date type="published" when="1988">1988. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Feynman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">B</forename><surname>Leighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Sands</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The New Millennium Edition: Quantum Mechanics (Feynman Lectures on Physics</title>
		<imprint>
			<publisher>Basic Books</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">III</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Supporting Polyrepresentation in a Quantum-inspired Geometrical Retrieval Framework</title>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Birger</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ingwersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Symposium on Information Interaction in Context (IIiX &apos;10</title>
		<meeting>the Third Symposium on Information Interaction in Context (IIiX &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Processing Queries in Session in a Quantum-Inspired IR Framework</title>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="751" to="754" />
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An Information Nutritional Label for Online Documents</title>
		<author>
			<persName><forename type="first">Norbert</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hanselowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>Jarvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabella</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="46" to="66" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection</title>
		<author>
			<persName><forename type="first">Siddhant</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thuy</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04118</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Investigating non-classical correlations between decision fused multi-modal documents</title>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Gkoumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Quantum Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="163" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Measures on the Closed Subspaces of a Hilbert Space</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gleason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Indiana University Mathematics Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="885" to="893" />
			<date type="published" when="1957">1957. 1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Griffiths</surname></persName>
		</author>
		<title level="m">Consistent Quantum Theory</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Quantum detection and estimation theory</title>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">W</forename><surname>Helstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Physics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="252" />
			<date type="published" when="1969-06-01">1969. 01 Jun 1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Characterizing Pure High-Order Entanglements in Lexical Semantic Spaces via Information Geometry</title>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">QI</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Manuscript submitted to</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mining Pure High-order Word Associations via Information Geometry for Information Retrieval</title>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Crowdtruth: Machine-human computation framework for harnessing disagreement in gathering annotated data</title>
		<author>
			<persName><forename type="first">Oana</forename><surname>Inel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Khamkham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Cristea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anca</forename><surname>Dumitrache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arne</forename><surname>Rutjes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jelle</forename><surname>Van Der Ploeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Romaszko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lora</forename><surname>Aroyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Semantic Web Conference</title>
		<meeting>International Semantic Web Conference</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-01">Jan Sips. 2014</date>
			<biblScope unit="page" from="486" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cognitive Perspectives of Information Retrieval Interaction: Elements of a Cognitive IR Theory</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ingwersen</surname></persName>
		</author>
		<idno type="DOI">10.1108/eb026960</idno>
		<ptr target="https://doi.org/10.1108/eb026960" />
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="3" to="50" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Quantum-like Generalization of Complex Word Embedding: A Lightweight Approach for Textual Classification</title>
		<author>
			<persName><forename type="first">Amit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaiswal</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Holdack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference</title>
		<meeting>the Conference<address><addrLine>Lernen, Wissen, Daten, Analysen; Mannheim, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-08-22">2018. 2018. August 22-24, 2018</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">User-oriented and cognitive models of information retrieval</title>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ingwersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reprint of article in Encyclopedia of Library and Information Science, Taylor &amp; Francis</title>
		<meeting><address><addrLine>Taylor &amp; Francis, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2012. 2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="5521" to="5534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Quantum Interference Inspired Neural Matching Model for Ad-hoc Retrieval</title>
		<author>
			<persName><forename type="first">Yongyu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research &amp; Development in Information Retrieval (SIGIR &apos;20)</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research &amp; Development in Information Retrieval (SIGIR &apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Combining visual and textual systems within the context of user feedback</title>
		<author>
			<persName><forename type="first">Leszek</forename><surname>Kaliciak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nirmalie</forename><surname>Wiratunga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="445" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Contextual image annotation via projection and quantum theory inspired measurement for integration of text and visual features</title>
		<author>
			<persName><forename type="first">Leszek</forename><surname>Kaliciak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Quantum Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="217" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An adaptive contextual quantum language model</title>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">456</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Understanding an enriched multidimensional user relevance model by analyzing query logs</title>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="2743" to="2754" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Modeling Multi-Query Retrieval Tasks Using Density Matrix Transformation</title>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;15)</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="871" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Quantum Language Model-based Query Expansion</title>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prayag</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM SIGIR International Conference on Theory of Information Retrieval (ICTIR &apos;18</title>
		<meeting>the 2018 ACM SIGIR International Conference on Theory of Information Retrieval (ICTIR &apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="183" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Quantum-Inspired Complex Word Embedding</title>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Third Workshop on Representation Learning for NLP, Rep4NLP@ACL 2018</title>
		<meeting>The Third Workshop on Representation Learning for NLP, Rep4NLP@ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-20">2018. July 20. 2018</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">CNM: An Interpretable Complex-valued Network for Matching</title>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4139" to="4148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Joint Sentiment/Topic Model for Sentiment Analysis</title>
		<author>
			<persName><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM &apos;09</title>
		<meeting>the 18th ACM Conference on Information and Knowledge Management (CIKM &apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Producing high-dimensional semantic spaces from lexical co-occurrence</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curt</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="203" to="208" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Iterative maximum-likelihood reconstruction in quantum homodyne tomography</title>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Lvovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optics B: Quantum and Semiclassical Optics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">556</biblScope>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">CEDR: Contextualized embeddings for document ranking</title>
		<author>
			<persName><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1101" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Can vector space bases model context</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2005-01">2005. 01 2005</date>
			<biblScope unit="volume">151</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Context Modeling and Discovery Using Vector Space Bases</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Information and Knowledge Management (CIKM &apos;05</title>
		<meeting>the 14th ACM International Conference on Information and Knowledge Management (CIKM &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="808" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A basis for information retrieval in context</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An Investigation of Quantum Interference in Information Retrieval</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Multidisciplinary Retrieval</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="136" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Utilizing a geometry of context for enhanced implicit feedback</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management -CIKM &apos;07</title>
		<meeting>the sixteenth ACM conference on Conference on information and knowledge management -CIKM &apos;07</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A Markov random field model for term dependencies</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">An Introduction to Neural Information Retrieval</title>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="1" to="117" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neural information retrieval: at the end of the early years</title>
		<author>
			<persName><forename type="first">Kezban</forename><surname>Dilek Onal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ismail</forename><surname>Sengor Altingovde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Mustafizur Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinar</forename><surname>Karagoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Braylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng-Lu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henna</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quinten</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Angert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Banner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><forename type="middle">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Lease</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval Journal</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="111" to="182" />
			<date type="published" when="2018-06-01">2018. 01 Jun 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Quantum mechanics as a theory of probability</title>
		<author>
			<persName><forename type="first">Itamar</forename><surname>Pitowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Physical theory and its interpretation</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="213" to="240" />
		</imprint>
	</monogr>
	<note>Manuscript submitted to</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">What Can Quantum Theory Bring to Information Retrieval</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM International Conference on Information and Knowledge Management (CIKM &apos;10)</title>
		<meeting>the 19th ACM International Conference on Information and Knowledge Management (CIKM &apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Filtering Documents with Subspaces</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yashar</forename><surname>Moshfeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="615" to="618" />
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">2009a. A Quantum-Based Model for Interactive Information Retrieval</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="224" to="231" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Structured Information Retrieval and Quantum Theory</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Symposium on Quantum Interaction (QI &apos;09)</title>
		<meeting>the 3rd International Symposium on Quantum Interaction (QI &apos;09)<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="289" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Exploring a Multidimensional Representation of Documents and Queries</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Adaptivity, Personalization and Fusion of Heterogeneous Information (RIAO &apos;10)</title>
		<meeting>Adaptivity, Personalization and Fusion of Heterogeneous Information (RIAO &apos;10)<address><addrLine>Paris, France, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Sound and Complete Relevance Assessment for XML Retrieval</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">pages</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A quantum probability explanation for violations of symmetry in similarity judgments</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Pothos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A quantum probability explanation for violations of &apos;rational&apos; decision theory</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><forename type="middle">M</forename><surname>Pothos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="2171" to="2178" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A quantum geometric model of similarity</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><forename type="middle">M</forename><surname>Pothos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="679" to="696" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The Probability Ranking Principle in IR</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="294" to="304" />
			<date type="published" when="1977">1977. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Interactive information retrieval</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Ruthven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="43" to="91" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms</title>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Renqiang Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinliang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Dynamic information retrieval: Theoretical framework and application</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Sloan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on the theory of Information Retrieval</title>
		<meeting>the 2015 International Conference on the theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">How Quantum Theory Is Developing the Field of Information Retrieval</title>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Frommholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S M Yasir</forename><surname>Arafat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Di Buccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Francisco Huertas-Rosero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><forename type="middle">M</forename><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Fall Symposium: Quantum Informatics for Cognitive, Social, and Semantic Processes</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Modeling Latent Topic Interactions Using Quantum Interference for Information Retrieval</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd ACM International Conference on Information &amp; Knowledge Management (CIKM &apos;13)</title>
		<meeting>the 22Nd ACM International Conference on Information &amp; Knowledge Management (CIKM &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1197" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Modeling Term Dependencies with Quantum Language Models for IR</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;13)</title>
		<meeting>the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="653" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Towards a cognitive theory of information retrieval</title>
		<author>
			<persName><forename type="first">Alistair</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Ennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="321" to="351" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Towards a Quantum-Inspired Framework for Binary Classification</title>
		<author>
			<persName><forename type="first">Prayag</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1815" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A Quantum Probability Account of Order Effects in Inference</title>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1518" to="1552" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Features of similarity</title>
		<author>
			<persName><forename type="first">Amos</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="327" to="352" />
			<date type="published" when="1977">1977. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Conditional expectation in an operator algebra</title>
		<author>
			<persName><forename type="first">Hisaharu</forename><surname>Umegaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IV. Entropy and information. Kodai Math. Sem. Rep</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="59" to="85" />
			<date type="published" when="1962">1962. 1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Modelling dynamic interactions between relevance dimensions</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Dehdashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Fell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval</title>
		<meeting>the 2019 ACM SIGIR International Conference on Theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Investigating Bell Inequalities for Multidimensional Relevance Judgments in Information Retrieval</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Gkoumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quantum Interaction</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="177" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Investigating order effects in multidimensional relevance judgment using query logs</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM SIGIR International Conference on Theory of Information Retrieval</title>
		<meeting>the 2018 ACM SIGIR International Conference on Theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="191" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Modeling Multidimensional User Relevance in IR Using Vector Spaces</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval (SIGIR &apos;18)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="993" to="996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Quantum-Like Structure in Multidimensional Relevance Judgements</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Uprety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prayag</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Dehdashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Fell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="728" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The geometry of information retrieval</title>
		<author>
			<persName><forename type="first">Cornelis</forename><surname>Joost Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">John von Neumann. 1955. Mathematical Foundations of Quantum Mechanics</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Semantic Hilbert space for text representation learning</title>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The World Wide Web Conference</title>
		<meeting>The World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3293" to="3299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Exploration of Quantum Interference in Document Relevance Judgement Discrepancy</title>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">144</biblScope>
			<date type="published" when="2016-04">2016. Apr 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Tensor Product of Correlated Textual and Visual Features: A Quantum Theory Inspired Image Retrieval Framework</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leszek</forename><surname>Kaliciak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-Fall 2010 Symposium on Quantum Informatics for Cognitive, Social, and Semantic Processes (QI 2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Explanation of relevance judgement discrepancy with quantum interference</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-Fall 2010 Symposium on Quantum Informatics for Cognitive, Social, and Semantic Processes (QI 2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Portfolio theory of information retrieval</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">A quasi-current representation for information needs inspired by Two-State Vector Formalism</title>
		<author>
			<persName><forename type="first">Panpan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">482</biblScope>
			<biblScope unit="page" from="627" to="637" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Modeling Relevance Judgement Inspired by Quantum Weak Measurement</title>
		<author>
			<persName><forename type="first">Panpan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="424" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A quantum question order model supported by empirical tests of an a priori and precise prediction</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="689" to="710" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Combining Word Semantics within Complex Hilbert Space for Information Retrieval</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Wittek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bevan</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sándor</forename><surname>Darányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quantum Interaction</title>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="160" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Risk and Ambiguity in Information Seeking: Eye Gaze Patterns Reveal Contextual Behavior in Dealing with Uncertainty</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Wittek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying-Hsang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sándor</forename><surname>Darányi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Gedeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ik</forename><forename type="middle">Soo</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Modeling Quantum Entanglements in Quantum Language Models</title>
		<author>
			<persName><forename type="first">Mengjiao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI&apos;15)</title>
		<meeting>Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1362" to="1368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">Grace</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Sloan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Dynamic Information Retrieval Modeling (Synthesis Lectures on Information Concepts, Retrieval, and S)</title>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Ranking short answer texts with attention-based neural matching model</title>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM international on conference on information and knowledge management</title>
		<meeting>the 25th ACM international on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5754" to="5764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">A generalized language model in tensor space</title>
		<author>
			<persName><forename type="first">Lipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xindian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuqin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7450" to="7458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A Quantum Query Expansion Approach for Session Search</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Melucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">2018a. End-to-end quantum-like language models with application to question answering</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiabin</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Thirty-Second AAAI Conference on Artificial Intelligence (AAAI&apos;18)</title>
		<meeting>Thirty-Second AAAI Conference on Artificial Intelligence (AAAI&apos;18)</meeting>
		<imprint>
			<biblScope unit="page" from="5666" to="5673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Investigating query-drift problem from a novel perspective of photon polarization</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on the Theory of Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="332" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A Quantum Many-body Wave Function Inspired Language Modeling Approach</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1303" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Quantum-Inspired Interactive Networks for Conversational Sentiment Analysis</title>
		<author>
			<persName><forename type="first">Yazhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuchi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panpan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="5436" to="5442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">2018b. Unsupervised Sentiment Analysis of Twitter Posts Using Density Matrix Representation</title>
		<author>
			<persName><forename type="first">Yazhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="316" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<author>
			<persName><forename type="first">Yazhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panpan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Quantum-like Multimodal Network Framework for Modeling Interaction Dynamics in Multiparty Conversational Sentiment Analysis</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">2018c. A quantum-inspired multimodal sentiment analysis framework</title>
		<author>
			<persName><forename type="first">Yazhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panpan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">752</biblScope>
			<biblScope unit="page" from="21" to="40" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Multidimensional Relevance Modeling via Psychometrics and Crowdsourcing</title>
		<author>
			<persName><forename type="first">Yinglong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacek</forename><surname>Gwizdka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval (SIGIR &apos;14</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval (SIGIR &apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="435" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">A Novel Re-ranking Approach Inspired by Quantum Measurement</title>
		<author>
			<persName><forename type="first">Xiaozhao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexian</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="721" to="724" />
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Query-drift Prevention for Robust Query Expansion</title>
		<author>
			<persName><forename type="first">Liron</forename><surname>Zighelnic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;08</title>
		<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="825" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Using the Quantum Probability Ranking Principle to Rank Interdependent Documents</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd European Conference on Advances in Information Retrieval (ECIR&apos;2010)</title>
		<meeting>the 32nd European Conference on Advances in Information Retrieval (ECIR&apos;2010)<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="357" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">The Quantum Probability Ranking Principle for Information Retrieval</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leif</forename><forename type="middle">A</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="232" to="240" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">On the use of Complex Numbers in Quantum Models for Information Retrieval</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval Theory</title>
		<meeting><address><addrLine>Berlin Heidelberg; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="346" to="350" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
