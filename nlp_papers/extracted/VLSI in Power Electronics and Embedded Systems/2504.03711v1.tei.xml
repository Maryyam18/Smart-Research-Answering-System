<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Encoder-Based</title>
				<funder ref="#_Brd5zxE">
					<orgName type="full">Hong Kong Research Grants Council</orgName>
					<orgName type="abbreviated">RGC</orgName>
				</funder>
				<funder>
					<orgName type="full">InnoHK, Hong Kong SAR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-03-28">28 Mar 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jing</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuchao</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
							<email>eezhiyao@ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Nettag</forename><surname>Deepcell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Progsg</forename><surname>Design2vec</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gnn</forename><surname>Circuit</surname></persName>
						</author>
						<author>
							<persName><surname>Gamora</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Foundation AI Models for VLSI Circuit Design and EDA WENJI FANG ‚Ä†</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology (HKUST)</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology (HKUST)</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">YAO LU</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science and Technology (HKUST)</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Science and Technology (HKUST)</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">YUCHAO WU</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science and Technology (HKUST)</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">ZHIYAO XIE *</orgName>
								<orgName type="institution" key="instit1">YUZHE MA</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science and Technology (Guangzhou)</orgName>
								<orgName type="institution" key="instit3">HKUST(GZ)</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Hong Kong University of Science and Technology (HKUST)</orgName>
								<address>
									<addrLine>Decoder-Based RTLLM VerilogEval CreativeEval RTL-repo VHDL-Eval ChipGPTV VerilogEval v2 Chip-Chat AutoChip VGen ChipNemo MG-Verilog VerilogCoder CraftRTL RTLSquad BetterV ChipGPT RTLRewriter LLM4DV AutoSVA2 AssertLLM ChIRAAG Verilog Reader UVLLM MEIC RTLFixer HLSPilot C2HLSC GPTAIG Chip SpecLLM DIVAS ChatEDA</addrLine>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Encoder-Based</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-03-28">28 Mar 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">ADC1A949645118B4163B3C52EC1F0026</idno>
					<idno type="arXiv">arXiv:2504.03711v1[cs.AR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-28T12:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Task-Specific AI for EDA Paradigm Feature Extraction ML Model Design Single-Stage Circuit Data Single EDA Task Label Collection ML Model Training (c) Type II: General Decoder-Based Circuit Foundation Model Paradigm LLM Decoder DeepGate DeepGate2 FGNN HOGA DeepGate3 PolarGate DeepSeq Circuit Encoder ‚Ñí ùíåùíÜùíö Mutation Prompt ùë∑ ùíéùíñùíï</term>
					<term>Single Circuit Variation</term>
					<term>Circuits Combining Gen Prompt ùë∑ ùíåùíÜùíö</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Artificial intelligence (AI)-driven electronic design automation (EDA) techniques have been extensively explored for VLSI circuit design applications. Most recently, foundation AI models for circuits have emerged as a new technology trend. Unlike traditional task-specific AI solutions, these new AI models are developed through two stages: 1) self-supervised pre-training on a large amount of unlabeled data to learn intrinsic circuit properties; and 2) efficient fine-tuning for specific downstream applications, such as early-stage design quality evaluation, circuit-related context generation, and functional verification. This new paradigm brings many advantages: model generalization, less reliance on labeled circuit data, efficient adaptation to new tasks, and unprecedented generative capability. In this paper, we propose referring to AI models developed with this new paradigm as circuit foundation models (CFMs). This paper provides a comprehensive survey of the latest progress in circuit foundation models, unprecedentedly covering over 130 relevant works. Over 90% of our introduced works were published in or after 2022, indicating that this emerging research trend has attracted wide attention in a short period. In this survey, we propose to categorize all existing circuit foundation models into two primary types: 1) encoder-based methods performing general circuit representation learning for predictive tasks; and 2) decoder-based methods leveraging large language models (LLMs) for generative tasks. For our introduced works, we cover their input modalities, model architecture, pre-training strategies, domain adaptation techniques, and downstream design applications. In addition, this paper discussed the unique properties of circuits from the data perspective. These circuit properties have motivated many works in this domain and differentiated them from general AI techniques. Finally, we shared our observed challenges and potential future research directions about developing foundation AI models for EDA methodologies.</p><p>CCS Concepts: ‚Ä¢ Hardware ‚Üí Very large scale integration design; ‚Ä¢ Computing methodologies ‚Üí Machine learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Integrated circuit (IC) is the foundation of our information society. Its complexity has been continuously growing, recently exceeding 100 billion transistors <ref type="bibr" target="#b0">[1]</ref>. Such increases in IC complexity have led to sky-rocketing IC design costs, which are estimated to surpass US$500 million for 3nm technology <ref type="bibr" target="#b1">[2]</ref>. These challenges result in a compelling need to improve IC design efficiency, possibly achieved by ground-breaking next-generation electronic design automation (EDA) techniques. Many EDA practitioners in both academia and industry have placed high hopes in new artificial intelligence (AI) or machine learning (ML) methods in IC design and EDA techniques, targeting more agile design for lower IC design costs, less human efforts, and shorter turnaround time.</p><p>AI for EDA/chip design. In recent years, AI for chip design, also named AI/ML for EDA or AI-assisted EDA <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, has been viewed as a highly promising technique, owing to its ability to reuse knowledge from prior circuit design data. Relevant AI-driven EDA techniques are also adopted in commercial EDA tools <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Various ML models can be trained to provide early predictions or optimizations for circuits, bypassing time-consuming downstream design and simulation steps. Learning from prior design solutions, ML models can perform circuit quality evaluations at early design stages and thus guide early design optimizations. Existing AI for EDA techniques have been extensively explored for almost all standard VLSI design stages (e.g., architecture stage, high-level synthesis (HLS) code, register-transfer level (RTL) code, gate-level netlist, post-placement layout, clock tree, and post-routing layout) and all primary circuit design objectives (e.g., timing, power, area, congestion, IR drop, signal integrity, and functionality).</p><p>Foundation AI for EDA/chip design: a new trend and our focus. Recently, general foundation AI models in natural language processing (NLP) and computer vision (CV) (e.g., BERT <ref type="bibr" target="#b6">[7]</ref>, CLIP <ref type="bibr" target="#b7">[8]</ref>, DALLE <ref type="bibr" target="#b8">[9]</ref>, and ChatGPT <ref type="bibr" target="#b9">[10]</ref>) have emerged and represent a significant leap in AI techniques. These foundation models, characterized by their large model scale and application scopes, have demonstrated an incredible ability to understand, predict, and generate content <ref type="bibr" target="#b10">[11]</ref>. In comparison with these foundation models in NLP and CV, previous AI applications in circuits lag far behind well-explored general natural languages and images. This has motivated the latest trend of exploring foundation AI models for EDA techniques and circuit design applications.</p><p>The trending works on foundation AI for EDA have demonstrated unprecedented ability in model generalization, few-shot learning, and generation tasks. These models typically leverage a two-stage paradigm of pre-training on large-scale datasets followed by fine-tuning for specific applications, significantly enhancing adaptability across various EDA tasks. Their great potential has attracted wide attention from the EDA community. Some representative works <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> are relatively highly cited since their publication, compared with average EDA publications. However, there is a lack of systematic definition, analysis, or survey on this series of latest works, leading to confusion when discussing many concepts in our communities (e.g., large circuit model vs. LLM-aided design vs. AI agents for EDA). In this survey paper, we will cover all representative works on foundation AI for EDA. We propose referring to this type of work as circuit foundation models (CFMs). Figure <ref type="figure">2</ref> illustrates the evolutionary tree of existing circuit foundation models, including both encoder-based and decoder-based paradigms. This paper also covers the potential and challenges of CFMs from our perspective.</p><p>Structure of Section 1. In this Introduction, we will first propose our own taxonomy of existing AI for EDA techniques in Section 1.1, categorizing all existing AI for EDA techniques into two major types. Then we will briefly introduce the already extensively studied Type I techniques (supervised AI for EDA) in Section 1.2 and elaborate on the emerging Type II techniques (foundation AI for EDA, the focus of our survey) in Section 1.3. After that, in Section 1.4, we will summarize all existing surveys that cover similar topics and elaborate on the contributions of this survey. In Section 1.5, we will introduce the overall structure of this whole survey paper.</p><p>1.1 Our Taxonomy of AI for EDA Techniques: Two Different Types In this survey, we propose to categorize existing AI for EDA techniques into two main types, as listed below. Figure <ref type="figure" target="#fig_0">1</ref> summarizes and compares all three paradigms of these two types of works.</p><p>‚Ä¢ Type I: Supervised Predictive AI Techniques for EDA. The mainstream paradigm of previous AI for EDA solutions adopts supervised predictive AI models. These supervised predictive models have been developed for various applications, including early-stage design quality prediction, fast design quality simulation, design space exploration, etc. Relevant works have been extensively studied and covered in existing surveys <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> and book <ref type="bibr" target="#b15">[16]</ref>.</p><p>‚Ä¢ Type II: Foundation AI Techniques for EDA (Circuit Foundation Model). This trending technique is the focus of this survey. The development of foundation AI solutions, according to our proposed definition, involves two phases: 1) Pre-training phase; 2) Finetuning phase. The first pre-training step, which is typically self-supervised on a large amount of unlabeled data, enables the AI model to learn more general circuit intrinsic patterns. The subsequent fine-tuning step can efficiently make the model adapt to specific EDA tasks. We propose to incorporate both paradigms into the scope of circuit foundation models:</p><p>-Encoder-based circuit foundation models. One primary paradigm performs circuit representation learning to support predictive tasks. They typically encode a circuit design into a general embedding (i.e., a vector with rich circuit information). This embedding will be the input to lightweight downstream models for various EDA applications.</p><p>-Decoder-based circuit foundation models. The other primary paradigm performs decoding tasks, thus supporting generative tasks. They typically adopt decoder-based large language models (LLMs) to help generate circuits, including design HLS or RTL code, design functionality descriptions, verification assertions, EDA tool scripts, etc.</p><p>1.2 Type I: Supervised Predictive AI Techniques for EDA (covered in prior surveys) Existing AI for EDA methods are mostly tailored to specific tasks, such as early prediction of various design quality metrics (e.g, timing <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>, area <ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>, power <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref>, IR drop <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref>, routability <ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref>, crosstalk <ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref>, and manufacturability <ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref>) or the reasoning of circuit functionalities <ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref> for verification applications. Additionally, tasks for circuit optimization (e.g., flow tuning <ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref><ref type="bibr" target="#b60">[61]</ref>, design space exploration <ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref>, design quality optimization <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b65">66]</ref>) also largely rely on the prediction of circuit quality to provide feedback. As Figure <ref type="figure" target="#fig_0">1</ref> (a) shows, these methods are typically developed by supervised training, which requires extensive label collection, model customization, and model development for every single task. Despite obvious effectiveness, this mainstream supervised paradigm has several inter-related general limitations:</p><p>(1) Difficulty to get sufficient labeled data. It is typically difficult to accumulate sufficient labeled training data: 1) Many coarse-grained prediction tasks do not support many labels. For example, to predict the layout area of a netlist, each circuit layout only provides one label (i.e., its layout area).</p><p>2) The label generation process is inherently highly timeconsuming. A dilemma is, most predictive AI models are trained to bypass the the slowest design/simulation steps. However, these slowest steps are exactly required to collect labels. (2) Time-consuming AI model development process. The development process of supervised task-specific solutions is tedious and time-consuming. The development steps include circuit collection, label generation, feature engineering, model architecture design, model training, and model testing. This whole process easily takes months of engineering efforts. (3) Lack of generalization across tasks. Since supervised task-specific models cannot be directly generalized to other tasks, it leads to an inefficient repetitive development of ML solutions. Moreover, from the methodology perspective, it implies that these supervised ML solutions only learned task-specific patterns, instead of understanding more general knowledge of target circuit designs. Due to the page limit and the large number of extensively explored type I works, we will not exhaustively cover all prior type I works. For a more comprehensive list of type I supervised predictive works, we refer our readers to prior surveys <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> and a book <ref type="bibr" target="#b15">[16]</ref> co-authored by many researchers in this domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Type II: Foundation AI Techniques for EDA (the focus of this paper)</head><p>This survey focuses on the emerging paradigms of foundation AI techniques for EDA. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref> (b) and (c), this type of technique leverages pre-trained foundation AI models for circuits (referred to as circuit foundation models), which can be efficiently fine-tuned using a small amount of task-specific labeled circuit data. Compared to traditional task-specific supervised AI for EDA solutions, this type II techniques offer significant advantages:</p><p>(1) Learning unlabeled circuit intrinsics. Circuit foundation models are typically pre-trained on a large amount of unlabeled data, enabling them to capture the underlying intrinsic information about circuits, without requiring expensive labeled datasets. (2) Efficient fine-tuning for solving EDA task. Well-pre-trained models require only a small amount of labeled data for fine-tuning. It significantly reduces the time and resources needed to solve each specific EDA task compared to training models from scratch. (3) Generalization across various tasks. General circuit intrinsics learned by foundation models can be adapted to multiple tasks, making the models versatile and reducing the need for repetitive task-specific model development. (4) Unprecedented generative capability for EDA tasks. Some circuit foundation models exhibit remarkable generative capabilities, unprecedentedly automating tasks such as circuit code generation, assertion generation for verification, and design flow script generation. These models go beyond existing predictive tasks, enabling innovative AI-driven solutions that enhance design productivity and streamline circuit development flow.</p><p>Encoder-based circuit foundation model. Figure <ref type="figure" target="#fig_0">1</ref> (b) demonstrates the paradigm of circuit encoders. Circuit encoders transform various circuit modalities (e.g., graphs or text formats) into generalized embeddings that contain rich intrinsic circuit properties. These encoders are typically pre-trained on circuit data. Due to the uniqueness of the circuit data compared with well-studied images or natural language, encoder models have to be specifically customized to handle circuit data. Research works primarily focus on two aspects: (1) in phase 1, developing specialized ML architectures and pre-training techniques to effectively capture circuit semantics, structural information, and physical attributes, and (2) in phase 2, leveraging pre-trained circuit encoders to support various predictive EDA tasks, including design quality evaluation and functional reasoning. In this survey, we systematically categorize existing circuit encoders according to their respective design stages and provide a comprehensive analysis of their supported downstream tasks.</p><p>Decoder-based circuit foundation model. Figure <ref type="figure" target="#fig_0">1</ref> (c) illustrates the paradigm of circuit decoders. Circuit decoders typically leverage LLMs as their backbone, which are typically extensively pre-trained on vast text datasets spanning multiple domains. Leveraging the powerful pre-trained LLMs, circuit decoders mainly focus on domain adaptation to circuit-related generative tasks, such as prompt engineering, fine-tuning, retrieval-augmented generation, etc. In this survey, we categorize existing decoder-based methods based on their application domains, covering key areas such as circuit code generation, verification, design flow automation, etc. For each category, we analyze representative benchmarks, model development techniques, and the latest advancements.</p><p>Key differences between encoder-and decoder-based models are summarized below:</p><p>(1) Circuit modality as input: Encoders primarily process graph-based circuit structures, such as netlists and control-data flow graphs, often leveraging graph learning models. Some recent works integrate multimodal learning, combining structural graphs with textual descriptions. In contrast, decoders focus on text-based formats like HDL code and natural language specifications, utilizing LLMs for interpretation and generation. (2) Circuit learning techniques: Encoders require customized pre-training and fine-tuning on circuit data. They are typically built from scratch using graph AI models. There is no standard architecture for circuit encoding, leading to diverse model designs and self-supervised learning techniques. In contrast, decoders typically rely on LLMs already extensively pretrained on vast text datasets. Relevant works rely on existing pre-trained LLMs in the public domain, including both open-sourced (e.g., Llama, Mistral, DeepSeek) and commercial (e.g., GPT-3.5, GPT-4o) LLMs. These works focus on adaptation to the circuit domain through prompt engineering, fine-tuning, and retrieval augmented generation (RAG). (3) Target downstream tasks: Encoders typically support predictive tasks such as design quality evaluation and functional reasoning, leveraging encoded circuit embeddings. Decoders are typically tailored for generative tasks, such as circuit code generation, verification automation, design flow generation, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Comparison of Existing Relevant Surveys and This Paper.</head><p>Table <ref type="table">1</ref> compares all existing survey papers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> about foundation AI models for circuit applications. Notably, almost all surveys <ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> focus only on decoder-based models (i.e., LLM for EDA). This trend reflects the rapid evolution of LLMs and their significant potential for generative EDA tasks, such as HDL code generation, verification, debugging, etc. Among these surveys on decoder-based LLMs for EDA, some surveys <ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref> try to provide comprehensive reviews on multiple relevant tasks, while some others <ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> focus on one specific topic, mostly about circuit security. The only exception is a special perspective paper <ref type="bibr" target="#b10">[11]</ref> co-authored by many EDA researchers. It advocates for an ambitious framework of multiple encoder-based foundation models aligned across design stages. This envisioned concept is named large circuit model (LCM) <ref type="bibr" target="#b10">[11]</ref>. Different from existing surveys, our survey paper incorporates both encoder-based and decoderbased circuit foundation models, analyzing their similarities and differences.</p><p>Surveys Design Design Design Design Design Design Encoder Decoder Time No. of CFM Generation Verification Debugging Security Optim. Flow -based -based Published Works Covered [70] ‚úì ‚úì 2023-10 15 [67] ‚úì ‚úì ‚úì ‚úì ‚úì 2023-12 22 [11] ‚úì ‚úì ‚úì ‚úì 2024-03 6 (Encoder) + 21 (Decoder) [71] ‚úì ‚úì ‚úì ‚úì 2024-04 14 [72] ‚úì ‚úì ‚úì ‚úì ‚úì 2024-05 32 [73] ‚úì ‚úì ‚úì ‚úì ‚úì 2024-06 24 [74] ‚úì ‚úì ‚úì ‚úì ‚úì 2024-10 29 [69] ‚úì ‚úì ‚úì ‚úì 2024-12 71 [68] ‚úì ‚úì ‚úì 2025-01 39 Ours ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì ‚úì 2025-03 21 (Encoder) + 111 (Decoder)</p><p>Table 1. Comparison of existing surveys on foundation models for chip design, covered in Section 1.4.</p><p>Table <ref type="table">1</ref> also reports the number of CFM-related works covered in each survey paper. We only count works in the scope of the circuit foundation model (i.e., pre-train and fine-tuned AI models targeting circuit design tasks). Partially due to the fast development in this emerging direction, most existing surveys only covered less than 40 related works. In comparison, our comprehensive survey unprecedentedly introduces the largest number of (i.e., over 130) relevant works, covering all key circuit design tasks listed in Table <ref type="table">1</ref>. We briefly introduce each existing survey and highlight the unique contributions of our study below.</p><p>Surveys on decoder models covering broad tasks. LLM4EDA <ref type="bibr" target="#b66">[67]</ref> is an early comprehensive review, covering various EDA tasks such as chatbot-based methods, circuit code and script generation, and circuit verification. However, since it was published in 2023 and this direction developed very fast, it only covered 22 works. Xu et al. <ref type="bibr" target="#b73">[74]</ref> summarize 29 early-stage studies on circuit code generation, debugging, verification, and physical implementation. While it provides insights into these areas, it lacks coverage of the latest developments and broader topics such as security, design optimization, and architecture design. Abdollahi et al. <ref type="bibr" target="#b68">[69]</ref> provide a more extensive survey, analyzing 71 studies on LLM-assisted circuit design, including applications in circuit generation, verification, and debugging. However, possibly due to their automated literature screening process, we observed several incorrect descriptions in this survey. For example, the survey <ref type="bibr" target="#b68">[69]</ref> incorrectly categorizes works of <ref type="bibr" target="#b74">[75]</ref><ref type="bibr" target="#b75">[76]</ref><ref type="bibr" target="#b76">[77]</ref> as LLM-aided design methodologies, while these works actually primarily focus on the acceleration of LLMs (i.e., designing hardware accelerators). A recent survey by Pan et al. <ref type="bibr" target="#b67">[68]</ref> reviews LLM applications in EDA. Despite its recency, it still only covers a limited number of works (39 works), primarily focusing on design generation and design flow automation. It lacks a broader discussion on design verification, security, architecture design, and analog tasks.</p><p>Surveys on decoder models covering a specific task. In addition to surveys targeting broad EDA applications, the other series of surveys <ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> focus specifically on circuit security topics with LLM-assisted techniques. Saha et al. <ref type="bibr" target="#b69">[70]</ref> pioneered the discussion of integrating LLMs into the SoC security verification paradigm in 2023. At the time, not many specialized LLM-based solutions had been customized for SoC security. Therefore this work <ref type="bibr" target="#b69">[70]</ref> primarily summarizes applying general LLM techniques in hardware security tasks. In 2024, three short surveys (all less than 7 pages) <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> cover LLM methods for hardware security, each covering 10 to 30 works.</p><p>A perspective paper on LCM. In 2024, a special perspective paper <ref type="bibr" target="#b10">[11]</ref> co-authored by many EDA researchers proposes and advocates an interesting and ambitious concept of large circuit model (LCM). This LCM can be viewed as an envisioned framework of multiple aligned encoderbased circuit foundation models, each devoted to one design stage. This paper also reviews both supervised task-specific AI solutions and foundation AI models for EDA (i.e., 6 encoders and 21 decoders). It identifies key challenges in developing large-scale circuit encoders and sets the stage for future advancements in encoder-based circuit foundation models.</p><p>The contributions of this survey, compared with prior surveys, can be summarized below:</p><p>(1) This survey proposes the concept of circuit foundation model. It incorporates both encoderbased circuit representation learning techniques and decoder-based LLM for EDA methods into a unified framework, enabling comparison between these two paradigms.</p><p>(2) This comprehensive survey systematically introduces over 130 works. All existing circuit foundation models cited in prior surveys <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> have been covered in this work. (3) The 21 encoder-based models span all standard design stages, including HLS, RTL, netlist, and layout stages, along with their supporting predictive EDA tasks. (4) The 111 decoders-based models cover all mainstream EDA applications, including VLSI circuit code processing (generation, optimization, verification, and debugging), hardware security, design flow automation, physical design, architecture design, and analog design. (5) Besides the in-depth analysis of these approaches, we highlight key advancements, challenges, and future research directions to further enhance circuit foundation models and their impact on modern VLSI design automation. This survey tries to cover all publications within the scope of the circuit foundation model, including journals, transactions, conference and workshop proceedings, thesis, and pre-prints. However, very short articles (e.g., late-breaking results, experiment reports) that are equal to or less than 3 pages may not be covered. For the same work with multiple versions and possibly different titles, we will avoid duplicated citations and tend to cite the latest version. When counting the publication date, we use the date when the earliest version gets released to the public.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Overall Structure of This Survey Paper</head><p>Figure <ref type="figure">3</ref> provides the overall structure of this paper.</p><p>‚Ä¢ In Section 2, we will summarize related preliminary knowledge, covering both standard VLSI circuit design flow (Section 2.1) and basic techniques of general foundation AI models, including LLM techniques (Section 2.2), self-supervised learning techniques (Section 2.3), multimodal learning techniques (Section 2.4). ‚Ä¢ In Section 3, we will introduce all our observed unique properties of circuit data. These properties have largely motivated many CFM works in this survey, and differentiate these works from general AI solutions in other domains (e.g., CV, NLP). ‚Ä¢ In Section 4, we will cover all existing encoder-based circuit foundation models, covering the HLS stage (Section 4.1), RTL stage (Section 4.2), netlist stage (Section 4.3) and layout stage (Section 4.4). The emerging and more advanced circuit encoder techniques will be covered in Section 4.5. ‚Ä¢ In Section 5, we will cover all existing decoder-based circuit foundation models, covering all application domains: RTL code generation (Section 5.1), HLS code generation (Section 5.2), design optimization (Section 5.3), hardware code verification (Section 5.4), hardware code debugging (Section 5.5), hardware design security (Section 5.6), design flow automation and layout design (Section 5.7), hardware architecture design (Section 5.8), and analog circuit design (Section 5.9). ‚Ä¢ In Section 6, we will analyze the challenges and opportunities of the circuit foundation models, based on our own research experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARY</head><p>Before covering specific CFM works, in this Section, we first summarize preliminary knowledge related to circuit foundation model, covering both standard VLSI circuit design flow in Section 2.1 and the basic techniques of foundation AI models, including LLM techniques in Section 2.2, self-supervised learning techniques in Section 2.3, multimodal learning techniques in Section 2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Standard VLSI Design Stage and Flow</head><p>A standard VLSI circuit design flow comprises several stages: specification definition, RTL design, logic synthesis, and physical design, as shown in the center of Figure <ref type="figure">3</ref>. At each stage, the design is represented in the corresponding format: specification, RTL code, netlist, and layout. In addition to these standard stages, high-level synthesis (HLS) is sometimes employed for more agile design or FPGA prototyping, based on HLS code in C/C++/SystemC. Verification and design quality analysis are carried out at various stages to ensure functional correctness and meet design quality constraints, respectively. Together, these stages transform the initial design specifications into a manufacturable and verified digital circuit layout. We introduce each design stage below. Specification definition. The design process begins with a clear natural language specification that outlines the expected functionality, as well as performance, power, and area (PPA) requirements for a target digital circuit. This specification serves as the blueprint for subsequent design steps.</p><p>HLS code design. The specification can be translated into an abstract design using high-level programming languages or description languages like C/C++ or SystemC. Designers develop algorithms that meet the functional requirements. The algorithms are described at a high level, focusing on functionality rather than hardware specifics.</p><p>RTL design. RTL design is the process of translating the high-level specification into a more detailed and implementable representation using hardware description languages (HDLs) such as Verilog or VHDL. These HDLs describe the behavior of digital circuits at the register-transfer level. The HDL code captures how data moves between registers (i.e., sequential registers) and how logic gates operate on that data within each clock cycle (i.e., combinational logic). Viewing each design as a finite-state machine, RTL defines the state transitions across clock cycles, ensuring that the circuit responds correctly to changes in input signals and synchronizes with the clock.</p><p>Logic synthesis. Logic synthesis converts high-level RTL designs into low-level, optimized gatelevel netlists. This process consists of three key steps: translation (i.e., elaboration), optimization, and technology mapping. First, the synthesis process begins by translating the RTL code into an intermediate representation, such as the AND-Inverter Graph (AIG) in synthesis tools like ABC <ref type="bibr" target="#b77">[78]</ref>. The synthesis tool then optimizes the logic based on constraints like delay and logic depth. Finally, technology mapping is performed, where the optimized logic is mapped to specific gates from a technology library provided by semiconductor foundries. This library contains various gate types, each with unique characteristics. The final output is a gate-level netlist, which represents the circuit in terms of logic gates and their interconnections.</p><p>Physical design. Physical design translates the gate-level netlist into a manufacturable physical layout. This process includes several key steps: floor planning, placement, clock tree synthesis (CTS), and routing. The first step, floor planning, involves arranging the major functional blocks of the chip in a way that optimizes performance while minimizing area. Designers determine the approximate locations of various components. Following floor planning, placement positions individual gates and components within the predefined floorplan, aiming to minimize wire length and ensure efficient placement. CTS follows placement, where the clock distribution network is designed to ensure the proper synchronization of all clock signals across the chip. Finally, routing connects the placed components using metal layers to form the required electrical connections.</p><p>During routing, considerations such as signal integrity, minimization of crosstalk, and adherence to design rules are essential to ensure the layout is functionally correct and manufacturable.</p><p>Verification. Verification ensures the design meets specifications <ref type="bibr" target="#b78">[79]</ref> and includes functional and physical verification. Functional verification checks if the design meets its specifications, using testbench simulations to model real-world conditions. Formal verification applies mathematical techniques, with equivalence checking to ensure consistency between design representations (e.g., RTL and gate-level). Physical verification ensures the layout complies with manufacturing constraints using design rule checking (DRC) and layout versus schematic (LVS) to detect and correct violations for manufacturability.</p><p>Analysis. Analysis evaluates the design against performance metrics to ensure it meets specifications. Static timing analysis (STA) verifies that timing constraints are met, ensuring signals propagate within required time limits. Power analysis estimates both dynamic (switching activity) and static (leakage currents) power consumption. Signal integrity analysis checks for issues like crosstalk, noise, and electromagnetic interference. Additionally, thermal analysis assesses heat generation and dissipation to ensure proper thermal management and reliable operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">LLM Techniques in AI Foundation Models</head><p>The evolution of LLMs marks a pivotal advancement in artificial intelligence, particularly in NLP. Before delving into their applications in circuit design, it's essential to understand their techniques. Below, we introduce the brief evolution history of LLM and the key techniques employed in the morden advanced LLM models. This foundational understanding highlights the transformative potential of LLMs across various domains, including circuit design.</p><p>A brief history of LLM. LLMs have evolved from early rule-based approaches to modern deep learning-driven foundation models, significantly advancing natural language processing (NLP). These advancements have enabled models like BERT and GPT to capture complex semantic and contextual nuances, leading to breakthroughs in various language-related tasks. Below, we summarize the key evolutionary stages of LLM development.</p><p>(1) Rule-based method: The earliest NLP systems relied on manually crafted linguistic rules and statistical models <ref type="bibr" target="#b79">[80]</ref>. These approaches defined explicit syntactic and semantic rules for processing text but were limited in scalability and adaptability. While rule-based methods could handle predefined patterns effectively, they struggled with the complexity and variability of natural language, making them unsuitable for large-scale applications. (2) ML solution by manual feature engineering: The introduction of statistical machine learning improved NLP by enabling data-driven language modeling. Early machine learning solutions required extensive manual feature engineering, where domain experts designed handcrafted features such as n-grams, part-of-speech tags, and dependency structures. Traditional models, including Hidden Markov Models (HMMs) and Support Vector Machines (SVMs), demonstrated better adaptability than rule-based methods but still relied on humandesigned representations, limiting their generalization capabilities. (3) Task-specific deep learning: The emergence of deep learning revolutionized NLP by replacing manual feature engineering with automatic representation learning. Models like Word2Vec <ref type="bibr" target="#b80">[81]</ref> and GloVe <ref type="bibr" target="#b81">[82]</ref> introduced word embeddings, representing words in continuous vector spaces to capture semantic relationships. Recurrent Neural Networks (RNNs) <ref type="bibr" target="#b82">[83]</ref> and Long Short-Term Memory Networks (LSTMs) <ref type="bibr" target="#b83">[84]</ref> further improved sequence modeling by capturing contextual dependencies in text. However, these models faced challenges with long-range dependencies and computational efficiency due to their sequential nature.</p><p>(4) General transformer-based foundation model: The introduction of the Transformer architecture marked a paradigm shift in NLP. Transformers utilize self-attention mechanisms to process entire sequences in parallel, capturing global dependencies efficiently. Encoderbased models like BERT excel in understanding context through bidirectional masked language modeling, while decoder-based models like GPT specialize in generative tasks using autoregressive token prediction. These foundation models are pre-trained on massive datasets and fine-tuned for various downstream applications, eliminating the need for task-specific model development. Their success has extended beyond NLP, inspiring new research directions in domains such as circuit design, where they are increasingly being used for tasks such as RTL code generation, verification, and design optimization.</p><p>Key techniques in decoder-only LLMs. Modern decoder-only LLMs, such as GPT, leverage a range of advanced techniques to enhance their performance and adaptability across various tasks. Below, we summarize five key techniques used in state-of-the-art decoder-based language models. (1) Auto-regressive generation: Decoder-only LLMs follow an auto-regressive approach, where they generate text sequentially, predicting one token at a time based on previously generated tokens. This autoregressive process allows models to produce coherent and contextually relevant text, making them highly effective for generative tasks such as text completion, summarization, and code generation. (2) Prompt engineering: Prompt engineering involves carefully crafting input text (prompts) to guide LLMs toward producing desired outputs. Since decoder-based models lack inherent task-specific fine-tuning for every possible use case, effective prompting helps steer model behavior without requiring additional training. Techniques such as zero-shot prompting (providing a task description), few-shot prompting (including examples), and chain-of-thought prompting (explicit reasoning steps) have been widely explored to enhance model performance across different applications. (3) Supervised fine-tuning (SFT): SFT refines pre-trained LLMs on specific datasets with labeled examples, enabling better adaptation to specialized tasks. By providing high-quality training examples, SFT improves accuracy and reliability in domain-specific applications, such as HDL code generation, circuit verification, and design optimization. Many domain-adapted LLMs, including those for EDA tasks, leverage SFT to improve performance on structured data and technical domains. (4) Retrieval-augmented generation (RAG): RAG enhances LLMs by incorporating external knowledge sources during inference. Instead of relying solely on pre-trained knowledge, the model retrieves relevant documents or contextual information from databases, augmenting its response with up-to-date and factual content. This technique is particularly useful for knowledge-intensive applications, such as circuit debugging and design flow optimization, where dynamic information retrieval improves response accuracy and relevance.</p><p>(5) Reinforcement learning from human feedback (RLHF): RLHF refines LLM behavior using human preferences to optimize response quality. In this approach, human annotators rank model outputs, and reinforcement learning algorithms adjust the model's reward function to align responses with human expectations. RLHF has been instrumental in making LLMs more aligned with human intent, improving coherence, factual correctness, and ethical considerations in generated outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Self-Supervised Learning Techniques in AI Foundation Model</head><p>In the development of AI foundation models, a variety of machine learning techniques are employed to enable these models to generalize across a wide range of tasks. These techniques are categorized into two primary phases: self-supervised learning for pre-training and supervised fine-tuning for downstream tasks.</p><p>Self-supervised learning is a powerful technique that allows models to learn from unlabeled data by generating labels from the data itself, often using auxiliary tasks. This phase helps the model understand general representations that can later be fine-tuned for specific tasks. We demonstrate the representative self-supervised learning techniques below.</p><p>‚Ä¢ Contrastive learning. This method learns representations by comparing similar (positive) and dissimilar (negative) pairs. For example, in image processing, positive pairs may be different augmentations of the same image, while negative pairs come from different classes. This method helps models generate useful embeddings for downstream tasks like retrieval or classification. It has been successful in computer vision and natural language processing (e.g., SimCLR <ref type="bibr" target="#b84">[85]</ref>, CLIP <ref type="bibr" target="#b7">[8]</ref>, MoCo <ref type="bibr" target="#b85">[86]</ref>). ‚Ä¢ Mask-reconstruction. This method involves randomly masking parts of the input and training the model to predict the missing information. This forces the model to learn context from the surrounding data, improving its ability to understand structure and relationships.</p><p>In NLP, BERT <ref type="bibr" target="#b6">[7]</ref> predicts masked words in sentences, while in vision tasks, Masked Autoencoders (MAE) <ref type="bibr" target="#b86">[87]</ref> show how masking portions of an image can lead to effective representation learning, aiding tasks like classification or segmentation. ‚Ä¢ Auto-regressive. The auto-regressive method involves predicting the next element in a sequence, given the previous elements. In natural language processing, models like GPT <ref type="bibr" target="#b87">[88]</ref> generate coherent text by predicting the next word based on the preceding context. In vision tasks, pixel-based auto-regressive models predict pixel values given prior pixels, such as in PixelCNN <ref type="bibr" target="#b88">[89]</ref>. The strength of auto-regressive models lies in their ability to learn complex dependencies within sequential or spatial data, allowing them to generate high-quality outputs for tasks like text generation, image synthesis, and beyond.</p><p>After pre-training with self-supervised methods, foundation AI models are fine-tuned on labeled data to adapt to specific tasks. This fine-tuning process enhances their performance across various applications, such as in the domain of NLP and CV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Multimodal Learning Techniques in AI Foundation Model</head><p>Multimodal learning techniques are essential for AI foundation models, as they enable the integration and processing of multiple data modalities such as text, images, and video. We summarize the key multimodal learning techniques into two categories: multimodal encoders for representation learning and multimodal decoders for generation.</p><p>Multimodal encoders for representation learning focus on learning joint representations across multiple modalities, allowing the model to extract and relate information effectively. Notable examples include CLIP <ref type="bibr" target="#b7">[8]</ref>, which aligns visual and textual representations to enable zero-shot learning for tasks like image classification and retrieval. ALBEF <ref type="bibr" target="#b89">[90]</ref> builds upon CLIP by aligning text and image representations and then performing multimodal fusion, improving performance in multimodal reasoning tasks such as visual question answering. These techniques lay the foundation for multimodal circuit representation learning, where textual descriptions (e.g., HDL code), structural graphs (e.g., netlists), and layout images can be effectively integrated for comprehensive circuit analysis and optimization.</p><p>Multimodal decoders for generation utilize one modality as input to generate content in another modality, such as describing images with text or synthesizing images and videos from textual descriptions. The BLIP family <ref type="bibr" target="#b90">[91,</ref><ref type="bibr" target="#b91">92]</ref> bridges image understanding and text generation by introducing a connector that adapts image embeddings for frozen LLMs, enabling accurate textual descriptions of images. LLaVA <ref type="bibr" target="#b92">[93]</ref> enhances image understanding by fine-tuning LLMs with visualtext instruction pairs, improving the model's ability to process and describe images. Extending this approach to video, Video-LLaVA <ref type="bibr" target="#b93">[94]</ref> generates video content based on textual or image-based inputs. Beyond generating text from visual inputs, some models focus on the reverse task-creating visual content from textual descriptions. DALL‚Ä¢E <ref type="bibr" target="#b94">[95]</ref> pioneers this field by generating diverse and high-quality images from textual prompts, facilitating creative content synthesis. Parti <ref type="bibr" target="#b95">[96]</ref> further refines this capability, enabling the generation of high-resolution, contextually accurate images from detailed prompts. These advancements in multimodal generation highlight the potential of circuit foundation models, where similar approaches could be employed to generate circuit layouts from textual specifications, convert hardware design schematics into structured descriptions, or facilitate design debugging by linking textual analysis with circuit visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">UNIQUE CIRCUIT DATA PROPERTIES</head><p>In this section, we will summarize the unique properties of circuits, especially from the data perspective. We will compare the circuit data with other common data formats, such as general images or natural languages. Understanding these unique properties of circuits is important, since they largely motivate many circuit foundation models and thus differentiate these CFM from general AI solutions in other domains like CV or NLP.</p><p>Equivalence across design stages. In the standard digital IC design flow, which includes specification, HLS code, RTL, netlist, and layout, ensuring equivalence across these stages is crucial for maintaining the integrity of the design. Each design stage refines the design from an abstract specification into a more detailed representation, but the underlying functionality and performance must remain consistent. This concept of equivalence has led to the use of circuit equivalent transformations as a data augmentation technique, allowing for the generation of multiple, functionally equivalent representations of a circuit. Furthermore, it has inspired crossdesign-stage alignment in circuit foundation models, enabling these models to capture and align information across different stages of the design flow. This alignment enhances the model's ability to transfer knowledge between stages and improves cross-stage consistency.</p><p>Multimodal circuit format. As shown in Figure <ref type="figure">4</ref>, circuit data inherently can be represented in multiple formats and modalities, each capturing different aspects of the circuit, including:</p><p>‚Ä¢ Text. This modality includes hardware description languages (HDLs) such as Verilog and VHDL, along with high-level specifications in natural language. Text-based representations define circuit functionality, behavioral constraints, and design requirements, emphasizing semantic information of circuits. ‚Ä¢ Graph. Circuit structures are naturally represented as graphs, where nodes correspond to components (e.g., logic gates, registers, functional blocks) and edges capture connectivity (e.g., data flow, control dependencies). Graph-based formats, including control-data flow graphs and gate-connected graphs, preserve the topological relationships, which are crucial for structural reasoning in EDA tasks. ‚Ä¢ Image. The physical layout of circuits, particularly at the post-synthesis stage, can be represented in two-dimensional visual formats, similar to the format of images. These 'images' capture geometric features, including component placement and interconnect routing, which are critical for the physical design process and manufacturability. Each of these modalities provides a unique perspective of the circuit, and fusing them enables a comprehensive understanding of the design, facilitating advancing foundation AI techniques for circuits.</p><p>Multiple objectives. The ultimate target objectives in circuit design are PPA (i.e., power, performance, and area) and functionality. PPA metrics are crucial for optimizing the overall design, ensuring that the circuit meets the required performance standards while minimizing power</p><p>reg [1:0] R1,R2,R3; reg [2:0] R4; wire [2:0] W1,W2; ... assign W1 = R0 + R1; ... always @(posedge clk) R4 &lt;= W2; Verilog Code (b) RTL (HLS) Code Text Control-Data Flow Graph R1 [0:2] R2 [0:2] ADD C1 [0:2] MUL MUX XOR C2 [0] ‚Ä¶ (c) Netlist Gate Connected Graph ‚Ä¶ + Real SPEF (d) Layout Graph w. Physical Features Layout Image Logic Synthesis Specification (a) Specification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural Language Text</head><p>The module is designed to handle division operations and provides a negative output when the division operation results in a negative quotient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logic Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Physical Design</head><p>Fig. <ref type="figure">4</ref>. VLSI design stages and corresponding modalities.</p><p>consumption and chip area. Functionality metric targets fulfilling the intended specifications, guaranteeing that the circuit behaves correctly under various conditions. Achieving both PPA optimization and functional correctness is essential for delivering robust and efficient hardware.</p><p>Parallel execution of hardware. Hardware circuits inherently operate with parallelism, clearly distinguishing them from the sequential execution of software code. In combinational logic, multiple logic operations are computed simultaneously, enabling high-speed parallel data processing. Meanwhile, sequential elements, such as registers and flip-flops, update synchronously at each clock cycle, ensuring efficient and coordinated circuit state transition. This fundamental parallelism plays a crucial role in defining circuit behavior, making it essential for accurately capturing circuit intrinsic properties in AI-driven design automation.</p><p>Circuit data availability. AI-driven EDA solutions depend on access to high-quality, diverse, and representative circuit data for both model development and evaluation. However, the scarcity of open circuit datasets remains a significant technical bottleneck. This challenge primarily arises from the semiconductor industry's reluctance to share proprietary circuit designs, which are considered valuable commercial IP. The absence of publicly available datasets hampers AI-driven EDA advancements, as collecting labeled data is both time-consuming and resource-intensive. Moreover, the limited diversity of open-source circuit designs restricts model generalization and performance.</p><p>As circuit foundation models gain traction in agile IC design, data availability becomes even more critical, particularly in the context of scaling laws for circuit foundation models, as observed in several existing works <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b97">98]</ref>. These laws suggest that model performance improves with larger datasets, making the shortage of diverse and extensive circuit data a fundamental limitation in training highly capable models. Addressing this challenge is crucial for unlocking the full potential of AI-driven EDA solutions.</p><p>Circuit reusability. Reusability is a key factor in practical circuit development, as companies often rely on pre-designed IP blocks rather than building circuits from scratch. This inherent reusability presents an opportunity for circuit foundation models to exploit semantic similarities across designs, enhancing performance on downstream tasks. By leveraging patterns and shared features within circuit datasets, these models can improve efficiency and adaptability in various EDA applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FOUNDATION MODEL AS A CIRCUIT ENCODER</head><p>In this section, we will cover all encoder-based circuit foundation models. The circuit encoder paradigm consists of two major stages: (1) It first pre-trains AI models to encode circuits into generalized embedding vectors that capture rich intrinsic properties of circuits. These embeddings provide a flexible representation that can further be fine-tuned with task-specific supervision. <ref type="bibr" target="#b1">(2)</ref> The fine-tuning process enables the embeddings to support various predictive downstream tasks, such as early-stage design quality prediction and functional reasoning, thus supporting design space exploration. The goal is to predict specific outcomes based on given circuit data. Existing works mainly focus on exploring the pre-training techniques that capture the structural, semantic, and physical aspects of circuits. As summarized in Figure <ref type="figure" target="#fig_4">5</ref>, we categorize the existing circuit encoder pre-training techniques into four types, each focusing on different aspects of learning circuit representations:</p><p>‚Ä¢ Self-supervised contrastive learning in Figure <ref type="figure" target="#fig_4">5</ref> (a). This technique minimizes the distance between embeddings of similar circuits while maximizing the distance between embeddings of dissimilar circuits based on the circuits' functionality. This process pre-trains the model to differentiate between functionally equivalent and non-equivalent circuits. In this way, the pre-trained model learns meaningful representations that reflect the intrinsic functional properties of the circuit designs. ‚Ä¢ Self-supervised mask-reconstruction in Figure <ref type="figure" target="#fig_9">5 (b)</ref>. In this technique, parts of the circuit representation are masked, and the model is pre-trained to reconstruct the masked missing parts. This process pre-trains the model to learn robust, complete representations of circuits, capturing both the structural and functional aspects. The pre-training task typically involves masking graph nodes or textual tokens of a circuit and using the remaining circuit information to predict the missing parts. ‚Ä¢ Supervised circuit pre-training tasks in Figure <ref type="figure" target="#fig_9">5 (c</ref>). In addition to self-supervised pretraining techniques, certain approaches incorporate task-related supervision to pre-train circuit encoders. Unlike direct target-task supervision in supervised methods, these pretraining tasks provide generalizable guidance to help the model learn circuit properties from labeled data. For example, predicting the truth-table distance between circuit pairs pre-trains the model to capture functional properties, which can then be leveraged for functional tasks such as SAT solving and logic synthesis. ‚Ä¢ Multimodal circuit fusion in Figure <ref type="figure" target="#fig_9">5 (d)</ref>. This technique integrates multiple modalities of circuit data, such as textual, structural, and physical information, to create richer, more comprehensive representations. The model is pre-trained to fuse these different modalities, enabling it to capture a broader range of circuit characteristics. In this way, the model supports complex tasks that require information from different modalities. In the following subsections, we summarize existing circuit encoders based on their target circuit design stages, including HLS stage (Section 4.1), RTL stage (Section 4.2), netlist stage (Section 4.3) and layout stage (Section 4.4). A detailed comparison and summary of these circuit encoders are provided in Table <ref type="table">2</ref> and <ref type="table">Table 3</ref>, respectively. Section 4.5 will cover the emerging and more advanced circuit encoder techniques. For each stage, we first summarize the employed circuit dataset, including detailed statistics and data collection process, then detail the proposed encoding techniques, including circuit preprocessing, ML model architecture, and pre-training techniques, and finally discuss the supported downstream tasks with evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Circuit Encoder for HLS</head><p>In the context of HLS, the circuit encoder plays a pivotal role in representing and optimizing the design space for HLS circuits. HLS involves the transformation of high-level programming languages (e.g., C/C++) into hardware description languages (e.g., Verilog), with the goal of improving the design, performance, and power efficiency of hardware systems. Efficient exploration of this design space is critical, and HLS encoders are explored to learn meaningful representations of the circuit designs, enabling better optimization and decision-making. As shown in Figure <ref type="figure">6</ref> (a), two notable methods in this domain are HARP <ref type="bibr" target="#b98">[99]</ref> and ProgSG <ref type="bibr" target="#b99">[100]</ref>, both pre-train HLS encoders with self-supervised learning, improving the exploration of the HLS design space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Dataset for HLS circuits.</head><p>Target Stage Method Modality Pre-Training Downstream Task Graph Text Self-Supervised Supervised Design Quality Functionality HLS HARP [99]</p><formula xml:id="formula_0">‚úì ‚úì ‚úì ProgSG [100] ‚úì ‚úì ‚úì ‚úì RTL Design2Vec [101] ‚úì ‚úì ‚úì ‚úì SNS v2 [25] ‚úì ‚úì CircuitEncoder [102] ‚úì ‚úì ‚úì CircuitFusion [97] ‚úì ‚úì ‚úì ‚úì Netlist DeepGate [103] ‚úì ‚úì ‚úì DeepGate2 [104] ‚úì ‚úì ‚úì DeepGate3/4 [98, 105] ‚úì ‚úì ‚úì GAMORA [54] ‚úì ‚úì ‚úì HOGA [106] ‚úì ‚úì ‚úì ‚úì PolarGate [107] ‚úì ‚úì ‚úì DeepSeq [108, 109] ‚úì ‚úì ‚úì FGNN [110, 111] ‚úì ‚úì ‚úì CircuitEncoder [102] ‚úì ‚úì ‚úì MGVGA [112] ‚úì ‚úì ‚úì ‚úì ‚úì NetTAG [113] ‚úì ‚úì ‚úì ‚úì ‚úì DeepCell [114] ‚úì ‚úì ‚úì Layout Circuit GNN [115] ‚úì ‚úì ‚úì TAG [116] ‚úì ‚úì ‚úì LLM-HD [117] ‚úì ‚úì ‚úì</formula><p>Table 2. Comparison of modality, pre-training techniques, and supported downstream tasks for existing encoder-based circuit foundation models, as covered in Section 4.</p><p>The HLS dataset <ref type="bibr" target="#b117">[118]</ref> used in these works consists of 42 unique kernels, each with multiple optimization pragmas generated by the AMD/Xilinx HLS tool, resulting in over 10,000 design configurations. The HLS designs serve both text and graph modalities. In the text modality, the data consists of C/C++ code, averaging 1,286 tokens per program. In the graph modality, the programs are converted into the control-data flow graphs (CDFG), with an average of 354 nodes and 1,246 edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Encoding techniques for HLS circuits.</head><p>Both HARP <ref type="bibr" target="#b98">[99]</ref> and ProgSG <ref type="bibr" target="#b99">[100]</ref> employ self-supervised learning techniques to pre-train HLS encoders. HARP <ref type="bibr" target="#b98">[99]</ref> focuses on encoding the graph format of HLS CDFG, while ProgSG <ref type="bibr" target="#b99">[100]</ref> extends this by adding textual input for richer multimodal circuit representation learning. We detail the HLS encoding techniques below.</p><p>Self-supervised HLS graph encoder with masked pragma reconstruction. HARP <ref type="bibr" target="#b98">[99]</ref> focuses on HLS control-data flow hierarchical graphs for representing circuit designs. Specifically, HARP <ref type="bibr" target="#b98">[99]</ref> utilizes a hierarchical graph representation of HLS designs, incorporating both highlevel and low-level views, where the high-level view combines C/C++ code and LLVM intermediate representation (IR) to capture the program's structure and semantics, and the low-level view focuses on LLVM IR to capture detailed implementation details. This dual-level representation helps mitigate long-range dependencies within the program. The model employs a GNN to encode this hierarchical graph into circuit embeddings. During pre-training, it applies a self-supervised learning technique called masked pragma reconstruction, with paradigm demonstrated in Figure <ref type="figure" target="#fig_4">5</ref> (b). In this approach, certain pragmas (compiler directives) are masked, and the GNN model is trained to predict these masked pragmas based on the surrounding node embeddings in the graph. This enables the model to learn the specific effects of each pragma, enhancing its performance and improving its ability to transfer knowledge across tasks.</p><p>Self-supervised HLS encoder enhanced via HLS graph-text mulimodal fusion. ProgSG [100] builds upon HARP <ref type="bibr" target="#b98">[99]</ref> by integrating multimodal learning to improve HLS encoding. It combines two modalities: CDFG hierarchical graph used in HARP <ref type="bibr" target="#b98">[99]</ref> and HLS C/C++ source code text, allowing the model to capture both structural and semantic aspects of the design. ProgSG <ref type="bibr" target="#b99">[100]</ref> uses a GNN for graph encoding and an LLM for text encoding. It introduces a node-token message passing mechanism for multimodal fusion, where information is exchanged through block nodes and tokens from the high-level view before being propagated to normal nodes and tokens via GNN and transformer layers. To address the scarcity of labeled designs, ProgSG <ref type="bibr" target="#b99">[100]</ref> employs a self-supervised pre-training technique based on compiler-generated data flow analysis tasks. This static analysis task predicts the relationship between two nodes in a CDFG, such as reachability and data dependencies, enabling the model to learn how data moves through the program. This pre-training improves the model's ability to generalize, boosting its performance in downstream tasks such as design space exploration and design optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Downstream tasks for HLS encoders.</head><p>The two methods, HARP <ref type="bibr" target="#b98">[99]</ref> and ProgSG <ref type="bibr" target="#b99">[100]</ref>, support downstream tasks that predict various HLS design quality metrics, including latency (in cycle counts), block RAM utilization, digital signal processor utilization, flip-flop utilization, and lookup-table utilization. These metrics are critical for evaluating the performance and efficiency of HLS designs. The models are assessed using the regression metric root mean square error (RMSE), which measures the accuracy of the design performance predictions.</p><p>In addition to performance prediction, these HLS encoders are further used for design space exploration, a task aimed at finding the optimal design for a given kernel. This process involves exploring various design configurations to identify the best-performing design in terms of resource utilization and latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Circuit Encoder for RTL Stage</head><p>In the RTL stage of VLSI design, the RTL encoder can capture both the semantics and structure of RTL circuits. As illustrated in Figure <ref type="figure">6 (b)</ref>, which shows the timeline of existing RTL encoders, four notable methods have emerged in this domain: Design2Vec <ref type="bibr" target="#b100">[101]</ref> utilizes supervised pretraining tasks for functional verification tasks. In contrast, SNS v2 <ref type="bibr" target="#b24">[25]</ref>, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref>, and CircuitFusion <ref type="bibr" target="#b96">[97]</ref> employ self-supervised learning techniques for design quality prediction tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Dataset for RTL circuits.</head><p>The RTL designs are used in both text and graph modalities: the text modality directly adopts the HDL code (e.g., Verilog), while the graph modality converts the RTL code into a CDFG based on the abstract syntax tree. For functional verification tasks, Design2Vec <ref type="bibr" target="#b100">[101]</ref> employs three designs, including two RISC-V CPUs and one TPU. For each design, the authors generated random tests and sampled each test parameter uniformly. They used a testbench to randomly sample input test stimuli and a Verilog RTL simulator to obtain ground-truth labels of whether a cover point was covered by that test, resulting 4118 cover points in total. As for design quality evaluation tasks, SNS v2 <ref type="bibr" target="#b24">[25]</ref> and CircuitFusion <ref type="bibr" target="#b96">[97]</ref> collect various types of RTL designs from various open-sourced benchmarks, including ITC'99 <ref type="bibr" target="#b118">[119]</ref>, OpenCores <ref type="bibr" target="#b119">[120]</ref>, Chipyard <ref type="bibr" target="#b120">[121]</ref>, VexRiscv <ref type="bibr" target="#b121">[122]</ref>, XiangShan <ref type="bibr" target="#b122">[123]</ref>, and other open-sourced designs. The RTL designs are synthesized using logic synthesis tools such as Synopsys Design Compiler, and the design quality metrics (i.e., PPA values) are obtained from the post-synthesis netlists. In the latest work CircuitFusion <ref type="bibr" target="#b96">[97]</ref>, the dataset scale includes up to 500K nodes for the circuit graph and up to 20M tokens for Verilog code text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Encoding techniques for RTL.</head><p>As shown in Figure <ref type="figure">6</ref> (b), in the supervised encoding branch, Design2Vec <ref type="bibr" target="#b100">[101]</ref> pioneers RTL encoding by learning functional semantics through pre-training supervisions for verification tasks. In the self-supervised learning branch, SNS v2 <ref type="bibr" target="#b24">[25]</ref> proposes to leverage functional contrastive learning on RTL graphs to capture RTL circuit representations, while CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> enhances this by introducing cross-stage alignment with netlist stage, incorporating implementation details from netlists. CircuitFusion <ref type="bibr" target="#b96">[97]</ref> further improves by integrating code text and functional summaries with the RTL graph for multimodal fusion, and adds additional self-supervised techniques to learn RTL circuits at multiple modalities and granularities. We detail the key techniques for RTL encoders below.</p><p>Supervised RTL semantic encoder with functional supervisions. Design2Vec <ref type="bibr" target="#b100">[101]</ref> learns semantic representations of RTL circuits for functional verification. The input to Design2Vec <ref type="bibr" target="#b100">[101]</ref> includes the hardware design represented as a CDFG derived from the RTL Verilog code, along with the corresponding source code text. The CDFG captures both the control and data flow aspects of the design, providing a comprehensive view of the hardware's functionality. Design2Vec <ref type="bibr" target="#b100">[101]</ref> employs a GNN to process the RTL CDFG, with each node augmented by RTL code text embeddings obtained from an LSTM for multimodal fusion. To capture the sequence dependency of circuit functionality, an additional LSTM is used to generate final node embeddings. During pre-training, Design2Vec <ref type="bibr" target="#b100">[101]</ref> uses a supervised learning pre-training task that predicts the coverage of specific points in the design when simulated on test inputs. This task requires the model to integrate both the structural and functional aspects of the hardware design, effectively learning the interactions between control and data flow.</p><p>Self-supervised RTL encoder with contrastive learning. Although the supervised pretraining task is designed to learn the circuit functionality, it cannot be generalized to other functionunrelated tasks. The other three RTL encoders (i.e., SNS v2 <ref type="bibr" target="#b24">[25]</ref>, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref>, and Circuit-Fusion <ref type="bibr" target="#b96">[97]</ref>) employ self-supervised learning techniques that learn a generalized circuit embedding. The pioneering work SNS v2 <ref type="bibr" target="#b24">[25]</ref> first introduces self-supervised contrastive learning to learn generalized circuit embeddings. The input to the SNS v2 <ref type="bibr" target="#b24">[25]</ref> model is the graph format of HDL code based on the abstract syntax tree. It proposes a hierarchical graph format for RTL designs, where the low-level graph consists of subgraphs sampled from registers, and the high-level graph represents register dependency. The model uses a two-level hierarchical GNN architecture. The low level processes small subgraphs, capturing local structural and functional features, while the high level aggregates these embeddings to predict quality metrics such as power, area, and timing for the entire design. For pre-training, SNS v2 <ref type="bibr" target="#b24">[25]</ref> employs a contrastive learning approach to pre-train the subgraph GNN on unlabeled hardware designs. The model learns to create functionally equivalent circuit representations, where similar embeddings are assigned to functionally equivalent circuits, despite differences in their representation. This self-supervised learning task enables the model to understand circuit equivalence. After pre-training, the model is fine-tuned using labeled datasets and adapted to new domains, allowing it to predict design quality metrics for various RTL circuits.</p><p>Self-supervised RTL encoder enhanced with cross-stage alignment. Following SNS v2 <ref type="bibr" target="#b24">[25]</ref>, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> also converts circuit RTL code into a graph-based representation using the abstract syntax tree. The model processes the graph using a graph transformer, which allows it to learn from the structural relationships of RTL designs. For pre-training, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> employs graph contrastive learning on RTL designs, similar to SNS v2 <ref type="bibr" target="#b24">[25]</ref>. In addition, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> introduces multi-stage contrastive learning, which involves learning embeddings both within the same design stage (intra-stage) and across different stages (inter-stage) between RTL and netlist designs. This technique helps align the embeddings from different design stages into a shared latent space, improving the model's ability to transfer learning between different stages and enhancing its generalization across the hardware design process.</p><p>Self-supervised RTL encoder enhanced with multimodal fusion. Another recent work CircuitFusion <ref type="bibr" target="#b96">[97]</ref> proposes self-supervised learning and advances the RTL encoder by fusing multiple modalities of RTL designs to enhance chip design workflows. Specifically, it processes three input modalities: HDL code, representing circuit functionality in textual form (e.g., Verilog); graph format, capturing the circuit's structure through an abstract syntax tree; and functionality summary, a high-level textual abstraction of the design's function. The model uses unimodal encoders for each modality, including graph, code, and summary encoders, followed by a multimodal fusion encoder with a cross-attention mechanism to combine the outputs into a unified latent space. During pre-training, CircuitFusion <ref type="bibr" target="#b96">[97]</ref> utilizes several self-supervised tasks: (1) Intra-modal learning, including contrastive learning and masked graph modeling to capture the internal structure of each modality, (2) Cross-modal alignment, where contrastive learning aligns the different modalities in a shared space, (3) Multimodal fusion, which involves tasks like masked summary modeling and mixup-embedding matching to combine structural and semantic information from all modalities, and (4) Implementation-aware alignment, which aligns RTL and netlist representations to ensure the design's functionality maps accurately to its physical implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Downstream tasks for RTL encoders.</head><p>The RTL stage is crucial for implementing the functionality of the specification and serves as the foundation for design quality optimization, such as PPA. The primary downstream tasks for RTL encoders focus on functional verification and early-stage PPA prediction. For functional verification, the Design2Vec <ref type="bibr" target="#b100">[101]</ref> model uses the semantic representations learned through pretraining tasks to predict whether a given test covers specific portions of the design and to generate test vectors. The model is evaluated based on its ability to predict coverage and detect bugs in hardware designs. By improving test generation and bug detection efficiency, the model enhances the overall verification process. For design quality prediction, SNS v2 <ref type="bibr" target="#b24">[25]</ref>, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref>, and CircuitFusion <ref type="bibr" target="#b96">[97]</ref> all focus on predicting key synthesis results, including area, power consumption, and timing for hardware designs. These models are evaluated using performance metrics such as the correlation coefficient (R) and Mean Absolute Percentage Error (MAPE), providing insights into the accuracy of design quality predictions and contributing to early-stage optimization for PPA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Circuit Encoder for Netlist Stage</head><p>The netlist stage is one of the most actively explored stages in circuit encoders, with circuit encoding playing a critical role in extracting meaningful representations from the structural and functional properties of logic circuits. In recent years, several methods have been developed that apply graph learning techniques (e.g., GNNs and Graph Transformers), to improve netlist analysis. As shown in Figure <ref type="figure">7</ref> (a), the timeline for netlist encoders includes both supervised methods, such as the DeepGate Family <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b102">[103]</ref><ref type="bibr" target="#b103">[104]</ref><ref type="bibr" target="#b104">[105]</ref>, HOGA <ref type="bibr" target="#b105">[106]</ref>, PolarGate <ref type="bibr" target="#b106">[107]</ref>, and DeepSeq <ref type="bibr" target="#b107">[108,</ref><ref type="bibr" target="#b108">109]</ref>, as well as self-supervised methods like FGNN <ref type="bibr" target="#b109">[110,</ref><ref type="bibr" target="#b110">111]</ref>, CircuitEncoder <ref type="bibr" target="#b101">[102]</ref>, NetTAG <ref type="bibr" target="#b112">[113]</ref>, and DeepCell <ref type="bibr" target="#b113">[114]</ref>. These encoders have evolved from encoding simple AND-Inverter Graphs (AIGs) of netlists to more complex post-synthesis netlists involving various types of gates. For downstream tasks, these netlist encoders support a wide range of applications. These include functional reasoning and verification tasks, such as arithmetic block identification, SAT solving, and logic synthesis, as well as netlist-stage design quality evaluation tasks like timing, power, and area estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Dataset for circuit netlists.</head><p>Most of the netlist encoders <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b102">[103]</ref><ref type="bibr" target="#b103">[104]</ref><ref type="bibr" target="#b104">[105]</ref><ref type="bibr" target="#b105">[106]</ref><ref type="bibr" target="#b106">[107]</ref><ref type="bibr" target="#b107">[108]</ref><ref type="bibr" target="#b108">[109]</ref><ref type="bibr" target="#b109">[110]</ref><ref type="bibr" target="#b110">[111]</ref> target the And-Inverter Graph (AIG) format of the netlist, which is an intermediate representation commonly used in logic synthesis and verification. Recently, works <ref type="bibr" target="#b112">[113,</ref><ref type="bibr" target="#b113">114]</ref> have expanded their scope beyond basic AIG gates to handle more complex post-synthesis netlists, which include various standard cells. For AIG datasets, the encoders gather data from various benchmarks like OpenABC-D <ref type="bibr" target="#b123">[124]</ref>, ITC'99 <ref type="bibr" target="#b118">[119]</ref>, IWLS <ref type="bibr" target="#b124">[125]</ref>, OpenCores <ref type="bibr" target="#b119">[120]</ref>, EPFL <ref type="bibr" target="#b125">[126]</ref>, GAMORA <ref type="bibr" target="#b53">[54]</ref>, arithmetic modules <ref type="bibr" target="#b109">[110]</ref>, Chipyard <ref type="bibr" target="#b120">[121]</ref>, and</p><p>LGSynth-93 <ref type="bibr" target="#b126">[127]</ref>. RTL designs from these benchmarks are typically converted into AIG formats using the ABC open-source logic synthesis tool. These encoders primarily focus on combinational logic within AIGs, with DeepSeq [109] also considering sequential registers in its encoding process. As for the post-synthesis netlist datasets, they are obtained from RTL benchmarks like ITC'99 <ref type="bibr" target="#b118">[119]</ref>, IWLS <ref type="bibr" target="#b124">[125]</ref>, OpenCores <ref type="bibr" target="#b119">[120]</ref>, EPFL <ref type="bibr" target="#b125">[126]</ref>, Chipyard <ref type="bibr" target="#b120">[121]</ref> and VexRiscv <ref type="bibr" target="#b121">[122]</ref>. Logic synthesis is conducted using technology libraries to generate the post-synthesis netlists. NetTAG <ref type="bibr" target="#b112">[113]</ref> processes both combinational and sequential netlist gates, while DeepCell <ref type="bibr" target="#b113">[114]</ref> focuses on the combinational aspects. This expansion enables the models to handle a wider range of netlist formats and to predict design quality more accurately at post-synthesis stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Encoding techniques for netlist.</head><p>As shown in Figure <ref type="figure">7</ref> (a), we categorize the encoding methods into supervised pre-training tasks and self-supervised learning methods. In the supervised encoding branch, DeepGate family <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b102">[103]</ref><ref type="bibr" target="#b103">[104]</ref><ref type="bibr" target="#b104">[105]</ref> pioneers AIG encoding for netlists, learning functional semantics for logic synthesis and verification tasks. They have improved scalability with advanced supervision, better graph learning models, and optimized memory consumption. Other methods, like HOGA <ref type="bibr" target="#b105">[106]</ref> and PolarGate <ref type="bibr" target="#b106">[107]</ref>, refine AIG encoding with customized GNN architectures and message-passing mechanisms to capture both structural and functional properties. DeepSeq <ref type="bibr" target="#b107">[108,</ref><ref type="bibr" target="#b108">109]</ref> extends the DeepGate Family to handle sequential circuits, improving the model's ability to process more complex circuit behaviors. In the self-supervised learning branch, FGNN <ref type="bibr" target="#b109">[110,</ref><ref type="bibr" target="#b110">111]</ref> first introduces functional contrastive learning to solve the arithmetic block identification problem. CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> enhances this with cross-stage alignment, incorporating RTL-stage information to improve netlist encoding. NetTAG <ref type="bibr" target="#b112">[113]</ref> and DeepCell <ref type="bibr" target="#b113">[114]</ref> push the boundaries of AIG encoding by advancing it to handle more complex post-synthesis netlists, allowing for the processing of designs with various</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Stage</head><p>Method Technique Downstream Task Pre-train objective HLS HARP <ref type="bibr" target="#b98">[99]</ref> Masked pragma reconstruction HLS design space exploration ProgSG <ref type="bibr" target="#b99">[100]</ref> Data flow analysis tasks for graph and node HLS design space exploration Design2Vec <ref type="bibr" target="#b100">[101]</ref> Testing cover point prediction Verification coverage prediction and test generation SNS v2 <ref type="bibr" target="#b24">[25]</ref> Functional contrastive learning Post-synthesis PPA prediction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RTL</head><p>CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> Intra-stage functional contrastive learning Cross-stage functional contrastive alignment Post-synthesis PPA prediction CircuitFusion <ref type="bibr" target="#b96">[97]</ref> Masked gate reconstruction Functional contrastive for graph/ summary Modality fusion Cross-design-stage alignment Post-synthesis PPA prediction DeepGate <ref type="bibr" target="#b102">[103]</ref> Signal probability prediction Signal probability prediction on large AIGs DeepGate2 <ref type="bibr" target="#b103">[104]</ref> Truth-table supervisions on node Logic synthesis and SAT solving DeepGate3/4 <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b104">105]</ref> Truth-table supervisions on node and graph SAT solving GAMORA <ref type="bibr" target="#b53">[54]</ref> Task-specific supervisions Logic functional reasoning HOGA <ref type="bibr" target="#b105">[106]</ref> Task-specific supervisions Logic synthesis QoR prediction, functional reasoning Netlist PolarGate [107] Truth-table supervisions Signal probability and truth-table distance prediction DeepSeq [108, 109] Truth-table supervisions on node Toggle rate prediction for power analysis FGNN [110, 111] Functional contrastive learning Gate function reasoning CircuitEncoder [102] Intra-stage functional contrastive learning Cross-stage functional contrastive alignment Register function reasoning MGVGA [112] Masked gate reconstruction QoR prediction, logic equivalence identification NetTAG [113] Logic expression contrastive Masked gate reconstruction Netlist graph contrastive learning Netlist graph size prediction Post-layout PPA prediction Gate/Register function prediction DeepCell <ref type="bibr" target="#b113">[114]</ref> Masked circuit modeling Functional ECO</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Layout</head><p>Circuit GNN <ref type="bibr" target="#b114">[115]</ref> Task-specific supervisions Congestion and wirelength prediction TAG <ref type="bibr" target="#b115">[116]</ref> Layout instance distance prediction Wirelength, and net parasitic capacitance prediction LLM-HD <ref type="bibr" target="#b116">[117]</ref> Masked language modeling Hotspot detection</p><p>Table 3. Summary of the pre-training techniques and supported downstream tasks of circuit encoders, covered in Section 4.</p><p>standard cells and more intricate gate structures, thus improving the prediction and optimization of hardware designs in post-synthesis stages. Supervised AIG encoder with functional supervision. The DeepGate family <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b102">[103]</ref><ref type="bibr" target="#b103">[104]</ref><ref type="bibr" target="#b104">[105]</ref>] is one of the pioneers in netlist encoders. They handle circuit AIGs using customized graph learning models, which are pre-trained using supervised pre-training tasks. These works primarily focus on functional-related tasks, such as training on pairwise truth table differences between sampled logic gates. The DeepGate family continuously improves model performance and scalability, with DeepGate3 <ref type="bibr" target="#b97">[98]</ref> introducing a graph transformer to capture global circuit relationships, and DeepGate4 <ref type="bibr" target="#b104">[105]</ref> optimizing the model by eliminating redundant computations.</p><p>Specifically, DeepGate <ref type="bibr" target="#b102">[103]</ref> employs a GNN architecture specifically tailored for AIG graphs, incorporating an attention mechanism and recurrent layers to aggregate information across the graph. Each node's embedding is computed based on its gate type and its relationships with neighboring nodes. The recurrent GNN is designed to capture the functional behavior of the circuit by using both forward and reversed propagation layers, simulating the logic behavior. Signal probability (the probability of a node being in logic '1') is used as the supervision task, with signal probabilities derived from random logic simulations. These simulations are run on the circuits to obtain accurate probability values, allowing the model to learn functional behavior more effectively.</p><p>DeepGate2 <ref type="bibr" target="#b103">[104]</ref> enhances the functionality-awareness encoding by introducing the Hamming distance between the truth tables of logic gates as supervision. The model uses a one-round GNN architecture, which processes both functional and structural embeddings for each gate. Unlike the multi-round GNN used in the original DeepGate, this one-round architecture efficiently propagates embeddings in a single pass. The functional embeddings represent the logic behavior of gates, incorporating the pairwise truth table difference as a supervisory signal, while structural embeddings capture the topology of the circuit. A self-attention mechanism is used to aggregate information across different gates, enabling the model to focus more on controlling fan-in gates. During pre-training, a functionality-aware loss is proposed, which aligns gate embeddings with their functional equivalence. This loss minimizes the distance between embeddings corresponding to gates that perform similar logical operations, thereby improving the model's ability to recognize functionally equivalent gates.</p><p>DeepGate3 <ref type="bibr" target="#b97">[98]</ref> improves upon DeepGate2 <ref type="bibr" target="#b103">[104]</ref> by enhancing both performance and scalability with a graph transformer model. It uses DeepGate2 <ref type="bibr" target="#b103">[104]</ref> as the AIG node tokenizer and refines the node embeddings with a graph transformer to capture long-range dependencies within the graph.</p><p>For generating graph-level embeddings, another graph transformer is used for pooling. During pre-training, in addition to the gate-level supervisions used in DeepGate2, graph-level tasks are introduced. These tasks involve using fan-in cones to segment circuits into smaller subgraphs and predict intrinsic features such as the size and depth of these subgraphs, further improving the model's ability to understand circuit structures at a broader level.</p><p>DeepGate4 <ref type="bibr" target="#b104">[105]</ref> further improves the scalability and efficiency challenges of large-scale circuit AIG representation learning by integrating a GAT-based sparse transformer. By leveraging graph sparsity, the model reduces the time and memory complexity of the transformer, making it suitable for processing large circuits. The architecture also incorporates structural encodings for gates, such as level and out-degree, to enhance the learning of circuit properties. The circuit graph is partitioned into smaller cones based on logic levels, which are then processed by the sparse transformer. This approach significantly improves both accuracy and computational efficiency, particularly for large-scale circuit designs, outperforming previous methods in terms of scalability and overall performance.</p><p>Supervised AIG encoder enhanced with GNN architecture. In addition to DeepGate family, other works (i.e., GAMORA <ref type="bibr" target="#b53">[54]</ref>, HOGA <ref type="bibr" target="#b105">[106]</ref> and PolarGate <ref type="bibr" target="#b106">[107]</ref>) explore to customize the GNN architecture and message-passing mechanism to enhance the scalability and performance of AIG encoding, combining with supervised pre-training tasks. In GAMORA <ref type="bibr" target="#b53">[54]</ref>, netlist AIGs are transformed into a graph representation and processed using a GNN. During pre-training, the GNN is trained with multiple functionally driven tasks, which jointly reason about Boolean function aggregation and structural topology. This enables efficient symbolic reasoning for largescale Boolean networks. Specifically, GAMORA <ref type="bibr" target="#b53">[54]</ref>'s model is designed to recognize fundamental functional components within circuits, including identifying adder root and leaf nodes and detecting XOR and MAJ functions. The multi-task learning framework enhances the model's ability to generalize across various functional tasks, leveraging shared representations to improve both accuracy and scalability in processing large AIG-based netlists.</p><p>In HOGA <ref type="bibr" target="#b105">[106]</ref>, hop-wise features are precomputed for each design to capture interactions over multiple hops before training. This step is done independently of the graph structure, enabling scalability for distributed training. The AIG format of circuits is processed using a customized GNN with a hop-wise aggregation scheme, which precomputes features based on multiple hops. It also employs gated self-attention to adaptively learn high-order circuit structures. This approach avoids recursive aggregation, which can be computationally expensive for large circuits. The model is then trained using task-specific labels, allowing it to be adapted for downstream tasks.</p><p>In PolarGate <ref type="bibr" target="#b106">[107]</ref>, each node in the netlist AIGs represents two logical states: low level (0) and high level <ref type="bibr" target="#b0">(1)</ref>, which are fundamental for Boolean logic tasks. The model employs a GNN with a novel functionality-aware message passing mechanism that aggregates information from neighboring nodes while distinguishing between AND and NOT gates through specialized operators. To achieve this, PolarGate <ref type="bibr" target="#b106">[107]</ref> introduces an ambipolar embedding space, where each node is mapped to both a positive and a negative embedding to represent the two logical states. It also uses differentiable logical operators, such as OPAND and OPNOT, that are designed to be differentiable and compatible with embedding propagation in the AIG structure. Additionally, the message passing strategy is modified to adhere to Boolean logical behavior, ensuring more accurate functional representation of the circuit. These innovations enable PolarGate <ref type="bibr" target="#b106">[107]</ref> to effectively capture the logical operations of circuits and improve the model's ability to process and learn from netlist-based designs.</p><p>Supervised AIG encoder enhanced for sequential circuits. Beyond focusing on the combinational logics of AIGs, DeepSeq <ref type="bibr" target="#b108">[109]</ref> explores capturing the sequential behavior of AIGs. DeepSeq <ref type="bibr" target="#b108">[109]</ref> further advances this by using a directed acyclic GNN, which is optimized for sequential netlists. It incorporates a customized propagation scheme that avoids recursive propagation and handles cyclic sequential netlists in a single forward pass. The architecture separates learning into three distinct embedding spaces: structure embedding for circuit connectivity, function embedding for logic computations, and sequential embedding for capturing the temporal behavior between consecutive clock cycles. During pre-training, DeepSeq <ref type="bibr" target="#b108">[109]</ref> uses multiple functional pre-training supervisions, including transition probability prediction to model sequential behavior, logic probability prediction to capture logic functionality, and pairwise truth-table difference to identify functional similarities among logic gates. These techniques enable DeepSeq <ref type="bibr" target="#b108">[109]</ref> to effectively learn both the functional and sequential aspects of sequential AIG circuits.</p><p>Self-supervised AIG encoder with contrastive learning. In addition to customized supervised pre-training tasks based on circuit properties, another key approach for netlist encoders is leveraging self-supervised learning techniques to learn from unlabeled circuit data and capture the intrinsic information of the circuit. FGNN <ref type="bibr" target="#b109">[110,</ref><ref type="bibr" target="#b110">111]</ref> is a pioneer in adopting self-supervised contrastive learning for AIG netlist encoding. It uses a customized GNN to encode AIGs into embeddings, integrating a contrastive learning framework to enhance circuit functionality learning. The GNN architecture incorporates two types of learnable message aggregators: an ANG aggregator for AND gates and an INV aggregator for inverters. Asynchronous message passing is employed to efficiently propagate information through the graph while preserving functionality semantics. During pre-training, the model uses a contrastive learning scheme to learn circuit embeddings that reflect the Boolean functionality of the circuits. This scheme ensures that the embeddings of functionally equivalent circuits are close in the embedding space. Additionally, a new loss function is introduced to effectively capture the relative functional distance between circuits, taking into account input order invariance and circuits with different input widths, further improving the model's ability to represent the circuits' functionality.</p><p>Self-supervised netlist encoders with cross-stage alignment. Recent advancements in self-supervised learning for netlist encoders have introduced cross-design-stage alignment to enhance model awareness of different abstraction levels in circuit design. CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> and MGVGA <ref type="bibr" target="#b111">[112]</ref> both propose novel alignment strategies to bridge the high-level abstract semantics of RTL with the low-level implementation details of netlists, enabling more robust circuit representation learning. CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> represents both RTL and netlist circuits as graph-based structures and processes them using a GNN. To learn circuit intrinsics, the model employs graph contrastive learning within each design stage, differentiating functionally similar and dissimilar circuit graphs. Additionally, it introduces intra-stage contrastive learning between RTL and netlist stages, effectively aligning representations across design stages. This cross-stage awareness significantly improves the encoder's adaptability for downstream tasks following fine-tuning. Similarly, MGVGA <ref type="bibr" target="#b111">[112]</ref> proposes the concept of RTL-netlist alignment by integrating LLM-based processing for RTL descriptions and GNN-based encoding for AIG netlists. During pre-training, it introduces masked gate modeling, a technique that masks gates in the latent space while preserving logical equivalence, ensuring functional consistency throughout the representation learning process. Furthermore, a cross-modal learning strategy is implemented, where Verilog-based functional constraints guide AIG-based representation learning, reinforcing the structural-functionality alignment. These cross-stage alignment techniques enhance the capability of netlist encoders, improving their generalization across multiple circuit design stages and boosting performance in downstream EDA applications.</p><p>Self-supervised post-synthesis netlist encoder with multimodal fusion. While many existing netlist encoders focus on simpler AND-Inverter gates, they struggle with more complex post-synthesis netlists that involve various gates from standard liberty cells. To address this challenge, two recent works have advanced netlist encoding by incorporating multimodal fusion (i.e., NetTAG <ref type="bibr" target="#b112">[113]</ref>) or AIG-netlist alignment (i.e., DeepCell <ref type="bibr" target="#b113">[114]</ref>) to unprecedentedly handle the complexities of post-synthesis netlists.</p><p>As shown in Figure <ref type="figure" target="#fig_7">8</ref>, in NetTAG <ref type="bibr" target="#b112">[113]</ref>, post-synthesis netlists are represented as text-attributed graphs, where each node corresponds to a gate and is associated with attributes that include both functional symbolic logic expressions and physical characteristics (such as area, power, and delay). The model employs a two-stage multimodal hybrid architecture: first, an LLM-based text encoder processes the textual attributes of the gates to generate semantic-rich embeddings. Then, a graph transformer refines these embeddings by capturing the global circuit structure through graph-based attention mechanisms. During pre-training, the model utilizes four key self-supervised objectives. Expression contrastive learning enhances the LLM's understanding of Boolean logic by contrasting symbolic expressions. Masked gate reconstruction is a graph-based task where certain gates are masked, and the model predicts the gate type, encouraging it to capture structural roles. Netlist graph contrastive learning aims to group similar netlists together while separating dissimilar ones, improving the model's ability to recognize functional equivalence in different netlist structures. Finally, cross-stage contrastive alignment aligns netlist embeddings with RTL and layout embeddings, combining functional and physical information to improve performance across various design stages. These self-supervised tasks enable NetTAG <ref type="bibr" target="#b112">[113]</ref> to learn both the functional and structural aspects of post-synthesis netlists, significantly enhancing its ability to predict design qualities and optimize circuits across different stages of the design process.</p><p>Self-supervised post-synthesis netlist encoder with AIG-netlist alignment. DeepCell <ref type="bibr" target="#b113">[114]</ref> proposes multiview representation learning to simultaneously capture structural and functional information from both post-synthesis netlists and AIGs. The model uses two separate encoders: the PM Encoder, which is a GNN designed to capture the features of standard cells from the post-synthesis netlists, integrating both structural and functional embeddings through specialized aggregators, and the AIG Encoder, which is a pre-trained AIG encoder based on DeepGate2 <ref type="bibr" target="#b103">[104]</ref> that generates gate-level embeddings to provide additional structural information. During pre-training, DeepCell <ref type="bibr" target="#b113">[114]</ref> employs a self-supervised mask circuit modeling task, where a subset of the cell embeddings is masked, and the model reconstructs these embeddings using the information from the AIG encoder. This approach refines the post-synthesis netlist representations by integrating insights from both the local circuit view (i.e., netlist) and the global gate-level view (i.e., AIG), enhancing the overall quality of the circuit representation and improving downstream tasks such as design quality prediction and functional verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Downstream tasks for netlist encoders.</head><p>Netlist encoders support a wide range of downstream tasks, including functional reasoning and verification tasks, as well as netlist-stage design quality evaluation tasks such as timing, power, and area estimation. In functional reasoning and verification, key tasks ensure circuit functional correctness. Logic probability prediction estimates the likelihood that a gate outputs a logic '1', evaluated by Mean Absolute Error (MAE). Equivalence class identification groups functionally equivalent gates, with performance assessed by classification accuracy. SAT solving checks Boolean satisfiability, evaluated by solving time and satisfiability accuracy. Arithmetic function block identification identifies components like adders, assessed using classification metrics. Finally, functional ECO identifies mismatches post-synthesis, with evaluation based on error reduction and change cost. In design quality prediction, tasks focus on estimating key metrics like power, area, and delay. Logic synthesis QoR prediction uses MAPE to predict power, area, and delay after synthesis. Power evaluation estimates power based on toggle rate, evaluated by MAE and accuracy. Post-layout PPA prediction estimates power, performance, and area after layout, using MAPE to compare predicted versus actual results. These tasks enhance circuit optimization and validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Circuit Encoder for Layout Stage</head><p>In the layout stage of hardware design, circuit encoders process either the netlist or the GDSII format of circuit layouts. As shown in Figure <ref type="figure">7</ref> (b), the timeline for layout encoders includes both supervised methods such as Circuit GNN <ref type="bibr" target="#b114">[115]</ref> which handles layout topology and geometry, and self-supervised methods like TAG <ref type="bibr" target="#b115">[116]</ref>, which employs text-graph multimodal encoding, and LLM-HD <ref type="bibr" target="#b116">[117]</ref> which treats layout GDSII data as text. These methods focus on effectively capturing the physical and structural properties of layout designs to improve design quality prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Dataset for layout circuits.</head><p>The datasets used in Circuit GNN <ref type="bibr" target="#b114">[115]</ref> come from the ISPD2011 benchmark <ref type="bibr" target="#b127">[128]</ref> for congestion prediction (12 designs) and the DAC2012 dataset <ref type="bibr" target="#b128">[129]</ref> for net wirelength prediction (7 designs). These are preprocessed into a Circuit Graph that combines topological and geometrical information. TAG <ref type="bibr" target="#b115">[116]</ref> uses 447 industrial AMS circuits in sub-10nm technology. The data is processed with StarRC extraction tools to obtain placement coordinates and create spatial and text embeddings by annotating the netlists with instance names and device types. For LLM-HD <ref type="bibr" target="#b116">[117]</ref>, the ICCAD 2012 <ref type="bibr" target="#b129">[130]</ref> and ICCAD 2020 <ref type="bibr" target="#b130">[131]</ref> benchmarks are used for layout hotspot detection, with GDSII layouts. The ICCAD 2012 dataset <ref type="bibr" target="#b129">[130]</ref> focuses on metal layer hotspots, and ICCAD 2020 <ref type="bibr" target="#b130">[131]</ref> on via-layer patterns. The data is processed directly from GDSII to preserve spatial and geometric features, using semantic and hierarchical encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Encoding techniques for layout.</head><p>Figure <ref type="figure">7</ref> (b) illustrates the categories of layout encoders. In the supervised branch, Circuit GNN <ref type="bibr" target="#b114">[115]</ref> customizes the GNN architecture to capture both the topology and geometry of the circuit layout. In the self-supervised branch, TAG <ref type="bibr" target="#b115">[116]</ref> proposes text-graph multimodal learning, while LLM-HD <ref type="bibr" target="#b116">[117]</ref> focuses on leveraging LLMs for textual layout encoding. These approaches enable the models to effectively learn and represent the topology, geometry, and physical property of circuit layouts for downstream tasks.</p><p>Supervised layout encoder with customized GNN architecture. In Circuit GNN <ref type="bibr" target="#b114">[115]</ref>, the input modalities consist of topological data (from the netlist) and geometrical data (from the layout). These modalities are represented in a circuit graph, where cells and nets are the vertices, and topo-edges and geom-edges connect them. The model is built upon a GNN, which processes the heterogeneous circuit graph. The GNN utilizes message-passing to propagate information across both topological and geometrical edges. Topological information is passed through topo-edges, while geometrical information is transmitted via geom-edges. These messages are then fused to update the representations of cells and nets. During pre-training, the integration of topological and geometrical information is achieved through the message-passing paradigm, with topo-geom message-passing ensuring both types of data contribute to the final learned representation. Taskspecific supervisions are employed to train the model.</p><p>Self-supervised layout encoder with text-graph multimodal fusion. TAG <ref type="bibr" target="#b115">[116]</ref> framework employs three primary modalities: (1) Text embedding, where the instance names and device/subcircuit types from the circuit netlists are used as text inputs, processed using fastText to generate word embeddings, (2) Graph format, where the circuit is represented as a heterogeneous hierarchical graph encoding devices (nodes) and their connections (edges), including device types (e.g., NMOS, PMOS, capacitors) and hierarchical relationships between sub-circuits, and (3) Self-attention, where a multi-head self-attention layer is applied to the embeddings to capture global dependencies between instances within sub-circuits. The model architecture combines a GNN with self-attention to process both graph and text embeddings. GNN layers aggregate node information, while the self-attention mechanism ensures a global view of the circuit by considering the entire sub-circuit during training. During pre-training, the model is trained in an unsupervised manner with a focus on predicting the relative layout distance between instances within a sub-circuit. This distance prediction task is framed as a regression problem, where the embeddings are trained to predict the normalized relative distance between instances in manual layouts.</p><p>Self-supervised layout encoder with text semantic encoding. In LLM-HD <ref type="bibr" target="#b116">[117]</ref>, the input modalities of this layout encoder include GDSII layout data and its semantic encoding. The GDSII data is transformed into a sequential format to make it suitable for processing by a language model. The key components include polygon shapes and spatial relationships between them, encoded as sequential tokens. The model architecture employs a BERT-based transformer specifically designed for layout patterns, utilizing multi-head self-attention to capture relationships between layout features both locally and globally. The architecture consists of an embedding layer, followed by LLM-HD <ref type="bibr" target="#b116">[117]</ref> layers, and concludes with a classification layer. During pre-training, the model uses masked language modeling, an unsupervised task where portions of the input data are randomly masked, and the model predicts the masked portions. This pre-training enables the model to learn representations of layout patterns, before fine-tuning for specific tasks such as hotspot detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Downstream tasks for layout encoders.</head><p>Circuit GNN <ref type="bibr" target="#b114">[115]</ref> supports both congestion prediction and net wirelength prediction tasks. For congestion, it predicts routing congestion during both the logic synthesis and placement stages, evaluated using correlations and classification metrics like precision, recall, and F1-score. TAG <ref type="bibr" target="#b115">[116]</ref> handles three layout-stage tasks: layout matching prediction (binary classification of layout constraints, evaluated by accuracy, TPR, FPR, PPV, and F1-score), wirelength estimation (HPWL evaluated with R2, MAE, and sMAPE), and net parasitic capacitance prediction (evaluated using R2 and MAE). LLM-HD <ref type="bibr" target="#b116">[117]</ref> focuses on hotspot detection, a binary classification task identifying layout areas prone to manufacturing defects.  ML model architecture customized for circuits. To effectively capture the unique structural and functional properties of circuit data, various customized architectures have been developed, particularly in graph-based learning models. These architectures integrate specialized messagepassing mechanisms to enhance the representation of circuit structures. For instance, GAMORA <ref type="bibr" target="#b53">[54]</ref> and PolarGate <ref type="bibr" target="#b106">[107]</ref> introduce customized GNN-based message passing tailored for AIGs, enabling the model to efficiently capture both Boolean functionality and structural connectivity.</p><p>Pre-training tasks customized for circuits. Pre-training tasks for circuit encoders can be divided into supervised and self-supervised methods, with each method specifically designed to capture the unique properties of circuit data. In supervised learning, for example, DeepGate2 <ref type="bibr" target="#b103">[104]</ref> uses truth table supervision to train encoders by comparing the pairwise differences between truth tables of logic gates, thereby capturing the functional behavior of the circuit. This approach helps the encoder learn how different gates function in the context of their logic operations. On the other hand, for example, SNS v2 <ref type="bibr" target="#b24">[25]</ref> introduces self-supervised learning for RTL encoders with functional contrastive learning. The model learns to cluster functionally similar circuits and separate dissimilar ones in the latent space. Another notable self-supervised pre-training task is masked circuit reconstruction, such as used in NetTAG <ref type="bibr" target="#b112">[113]</ref>, where specific gates in a circuit's netlist are masked, and the model learns to predict the missing gates based on the surrounding context. These pre-training tasks are vital for learning generalized representations that can be fine-tuned for various downstream tasks, such as design space exploration and functional verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Trend 2: circuit multimodal fusion.</head><p>Circuit design involves multiple modalities, including hardware description languages, graphical representations, and functional summaries, each capturing different aspects of the circuit. Recent works in circuit foundation models have focused on integrating these modalities through multimodal fusion techniques, enabling models to leverage both structural and semantic information for more robust representation learning. Two primary approaches have emerged in this area: hybrid ML model architecture that combines different encoders for various modalities and crossattention-based fusion with self-supervised learning. The timeline of multimodal fused encoders is demonstrated in Figure <ref type="figure" target="#fig_8">9 (a)</ref>.</p><p>Multimodal fusion by hybrid models. Hybrid models integrate distinct encoding architectures tailored to specific circuit modalities. For example, ProgSG <ref type="bibr" target="#b99">[100]</ref> and Design2Vec <ref type="bibr" target="#b100">[101]</ref> focus on HLS and RTL-stage circuits, respectively, where the source code contains rich semantic information. These models employ LLMs to encode textual descriptions while using GNNs to capture structural information from control-data flow graphs. This dual-modality approach ensures that both functional intent and circuit topology are preserved in the learned representations. At the netlist and layout stages, where the netlist code provides limited functional information, NetTAG <ref type="bibr" target="#b112">[113]</ref> and TAG <ref type="bibr" target="#b115">[116]</ref> adopt a similar hybrid approach but with modifications suited for lower-level representations. NetTAG <ref type="bibr" target="#b112">[113]</ref> extracts detailed symbolic logic expressions for each gate, encoding them using an LLM, while a GNN captures the circuit's global structural dependencies. TAG <ref type="bibr" target="#b115">[116]</ref> follows a similar strategy, leveraging textual attributes alongside graph-based structural encodings to improve netlist representation.</p><p>Multimodal fusion by cross attention. In addition to hybrid models, cross-attention-based fusion has been proposed as an alternative strategy for multimodal integration. CircuitFusion <ref type="bibr" target="#b96">[97]</ref>, designed for RTL-stage encoding, processes three primary modalities-HDL code, functional summaries, and structural graphs-in parallel. Each modality is first encoded independently, after which an additional multimodal fusion encoder with cross-attention mechanisms aligns and integrates the learned representations. The cross-attention mechanism ensures that the fused representation retains complementary information from all modalities while mitigating redundancy. CircuitFusion <ref type="bibr" target="#b96">[97]</ref> further enhances representation learning through self-supervised tasks such as masked summary modeling and embedding mixup, reinforcing the alignment between modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">Trend 3: cross-design-stage alignment.</head><p>Cross-design-stage alignment has become a promising direction in circuit foundation models, enabling representations learned at earlier design stages (e.g., RTL) to be aligned with their corresponding lower-level implementations (e.g., netlist, layout). This alignment enhances generalizability, allowing models to better capture the functional and physical characteristics of circuits throughout the design process. Two primary approaches have been explored for achieving crossstage alignment: contrastive learning-based alignment and mask-reconstruction-based alignment. The timeline of cross-stage aligned encoders is demonstrated in Figure <ref type="figure" target="#fig_8">9 (b)</ref>.</p><p>Cross-stage alignment via contrastive learning. Contrastive learning-based alignment has been effectively used for bridging different design stages by learning stage-invariant circuit representations. CircuitEncoder <ref type="bibr" target="#b101">[102]</ref> and CircuitFusion <ref type="bibr" target="#b96">[97]</ref> focus on RTL-to-netlist alignment by integrating structural and functional representations through self-supervised contrastive learning. These models enforce similarity constraints between functionally equivalent circuits across design stages, ensuring that embeddings capture both high-level design intent and low-level implementation details. NetTAG <ref type="bibr" target="#b112">[113]</ref> extends this approach beyond RTL and netlist, incorporating layout information to enable RTL-netlist-layout alignment. By leveraging cross-modal contrastive learning, NetTAG <ref type="bibr" target="#b112">[113]</ref> aligns representations across all three design stages, facilitating more accurate early-stage predictions of post-layout circuit characteristics.</p><p>Cross-stage alignment via mask-reconstruction. Mask-reconstruction-based alignment, on the other hand, focuses on recovering masked portions of a circuit while maintaining logical and structural consistency across design stages. MGVGA <ref type="bibr" target="#b111">[112]</ref> is designed for RTL-to-AIG alignment, where it employs Masked Gate Modeling to selectively mask gate-level details in AIG representations while preserving functional equivalence. This ensures that the learned embeddings retain both RTL-level semantics and AIG-level logic properties. DeepCell <ref type="bibr" target="#b113">[114]</ref> also employs this technique for AIG-to-netlist alignment, incorporating a self-supervised masking strategy to reconstruct standard cell representations from their lower-level gate descriptions. This approach enhances the model's ability to understand structural variations while preserving functional equivalence across abstraction levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FOUNDATION MODEL AS A CIRCUIT DECODER</head><p>Another major paradigm of circuit foundation models is circuit decoders, which leverage LLMs for the automated generation of circuit-related content. These models facilitate the creation of RTL code (e.g., Verilog or VHDL), HLS code (e.g., SystemC or C++), design scripts (e.g., Tcl or Python), design descriptions, etc. As summarized in Figure <ref type="figure" target="#fig_1">10</ref>, this section provides a comprehensive overview of Foundation model as circuit decoder RTL code generation (Section 5.1) DAVE <ref type="bibr" target="#b131">[132]</ref>, ChipGPT <ref type="bibr" target="#b132">[133]</ref>, VerilogEval <ref type="bibr" target="#b13">[14]</ref>, GPT4AIGChip <ref type="bibr" target="#b133">[134]</ref>, Chip-Chat <ref type="bibr" target="#b134">[135]</ref>, AutoChip <ref type="bibr" target="#b135">[136]</ref>, RTLLM <ref type="bibr" target="#b11">[12]</ref>, VeriGen <ref type="bibr" target="#b136">[137]</ref>, RapidGPT <ref type="bibr" target="#b137">[138]</ref>, CodeV <ref type="bibr" target="#b138">[139]</ref>,</p><p>AutoVCoder <ref type="bibr" target="#b139">[140]</ref>, BetterV <ref type="bibr" target="#b140">[141]</ref>, ChipNemo <ref type="bibr" target="#b12">[13]</ref>, Chang et al. <ref type="bibr" target="#b141">[142]</ref>, OriGen <ref type="bibr" target="#b142">[143]</ref>, VerilogCoder <ref type="bibr" target="#b143">[144]</ref>, Thakur et al. <ref type="bibr" target="#b14">[15]</ref>, RTLCoder <ref type="bibr" target="#b144">[145]</ref>, MG-Verilog <ref type="bibr" target="#b145">[146]</ref> CreativeEval <ref type="bibr" target="#b146">[147]</ref>, VHDL-Eval <ref type="bibr" target="#b147">[148]</ref>, Chang et al. <ref type="bibr" target="#b148">[149]</ref>,</p><p>OPL4GPT <ref type="bibr" target="#b149">[150]</ref>, RTLSquad <ref type="bibr" target="#b150">[151]</ref>, MAGE <ref type="bibr" target="#b151">[152]</ref>, RTL-repo <ref type="bibr" target="#b152">[153]</ref>, OpenLLM-RTL <ref type="bibr" target="#b153">[154]</ref>, Sun et al. <ref type="bibr" target="#b154">[155]</ref>,</p><p>DeepRTL <ref type="bibr" target="#b155">[156]</ref>, CraftRTL <ref type="bibr" target="#b156">[157]</ref>, <ref type="bibr" target="#b157">[158]</ref><ref type="bibr" target="#b158">[159]</ref><ref type="bibr" target="#b159">[160]</ref><ref type="bibr" target="#b160">[161]</ref><ref type="bibr" target="#b161">[162]</ref><ref type="bibr" target="#b162">[163]</ref><ref type="bibr" target="#b163">[164]</ref><ref type="bibr" target="#b164">[165]</ref><ref type="bibr" target="#b165">[166]</ref> HLS code generation (Section 5.2)</p><p>HLSPilot <ref type="bibr" target="#b166">[167]</ref>, C2HLSC <ref type="bibr" target="#b167">[168]</ref>, SynthAI <ref type="bibr" target="#b168">[169]</ref>, Liao et al. <ref type="bibr" target="#b169">[170]</ref>, Gai et al. <ref type="bibr" target="#b170">[171]</ref> Design optimization (Section 5.3)</p><p>BetterV <ref type="bibr" target="#b140">[141]</ref>, ChipGPT <ref type="bibr" target="#b132">[133]</ref>, RTLRewriter <ref type="bibr" target="#b171">[172]</ref>, Martine et al. <ref type="bibr" target="#b172">[173]</ref>, Xu et al. <ref type="bibr" target="#b173">[174]</ref>, Thorat et al. <ref type="bibr" target="#b174">[175]</ref>,</p><p>Sandal et al. <ref type="bibr" target="#b160">[161]</ref>, DeLorenzo et al. <ref type="bibr" target="#b161">[162]</ref> Hardware verification (Section 5.4)</p><p>ChipNeMo <ref type="bibr" target="#b12">[13]</ref>, RTLFixer <ref type="bibr" target="#b175">[176]</ref>, AutoSVA <ref type="bibr" target="#b176">[177]</ref>, NSPG <ref type="bibr" target="#b177">[178]</ref>, DIVAS <ref type="bibr" target="#b178">[179]</ref>, SimEval <ref type="bibr" target="#b179">[180]</ref>, AssertLLM <ref type="bibr" target="#b180">[181]</ref>, ChIRAAG <ref type="bibr" target="#b181">[182]</ref>, UVLLM <ref type="bibr" target="#b182">[183]</ref>, LLM4DV <ref type="bibr" target="#b183">[184]</ref>, VerilogReader <ref type="bibr" target="#b184">[185]</ref>, FVEval <ref type="bibr" target="#b185">[186]</ref>, OpenLLM-RTL <ref type="bibr" target="#b153">[154]</ref>, AssertionBench <ref type="bibr" target="#b186">[187]</ref>, <ref type="bibr" target="#b187">[188]</ref><ref type="bibr" target="#b188">[189]</ref><ref type="bibr" target="#b189">[190]</ref><ref type="bibr" target="#b190">[191]</ref><ref type="bibr" target="#b191">[192]</ref><ref type="bibr" target="#b192">[193]</ref><ref type="bibr" target="#b193">[194]</ref><ref type="bibr" target="#b194">[195]</ref><ref type="bibr" target="#b195">[196]</ref><ref type="bibr" target="#b196">[197]</ref><ref type="bibr" target="#b197">[198]</ref> Circuit code debugging (Section 5.5) MEIC <ref type="bibr" target="#b198">[199]</ref>, RTLFixer <ref type="bibr" target="#b175">[176]</ref>, VeriAssist <ref type="bibr" target="#b190">[191]</ref>, HDLdebugger <ref type="bibr" target="#b199">[200]</ref>, Chrysalis <ref type="bibr" target="#b200">[201]</ref>, Llm4sechw <ref type="bibr" target="#b201">[202]</ref>, <ref type="bibr" target="#b178">[179,</ref><ref type="bibr" target="#b202">203,</ref><ref type="bibr" target="#b203">204]</ref> Hardware security (Section 5.6) DIVAS <ref type="bibr" target="#b178">[179]</ref>, Saha et al. <ref type="bibr" target="#b204">[205]</ref>, Self-HWDebug <ref type="bibr" target="#b205">[206]</ref>, Ahmad <ref type="bibr" target="#b206">[207]</ref>, AutoSVA2 <ref type="bibr" target="#b207">[208]</ref>, ChIAAG <ref type="bibr" target="#b181">[182]</ref>, Latibari et al. <ref type="bibr" target="#b208">[209]</ref>, Netlist Whisperer <ref type="bibr" target="#b209">[210]</ref>, SCAR <ref type="bibr" target="#b210">[211]</ref>,</p><p>Kande et al. <ref type="bibr" target="#b187">[188]</ref>, Pearce et al. <ref type="bibr" target="#b211">[212]</ref>, <ref type="bibr">[70-73, 178, 193, 213-215]</ref> Design flow &amp; Layout (Section 5.7)</p><p>ChatEDA <ref type="bibr" target="#b215">[216]</ref>, SmartonAI <ref type="bibr" target="#b216">[217]</ref>, LLSM <ref type="bibr" target="#b217">[218]</ref>, MetRex <ref type="bibr" target="#b218">[219]</ref>, DRC-Coder <ref type="bibr" target="#b219">[220]</ref>, ChipAlign <ref type="bibr" target="#b220">[221]</ref>, FabGPT <ref type="bibr" target="#b221">[222]</ref>, Chen et al. <ref type="bibr" target="#b222">[223]</ref>, Ho et al. <ref type="bibr" target="#b223">[224]</ref> Architecture design (Section 5.8)</p><p>AIGChip <ref type="bibr" target="#b133">[134]</ref>, ChatEDA <ref type="bibr" target="#b215">[216]</ref>, SpecLLM <ref type="bibr" target="#b224">[225]</ref>, <ref type="bibr" target="#b216">[217,</ref><ref type="bibr" target="#b225">[226]</ref><ref type="bibr" target="#b226">[227]</ref><ref type="bibr" target="#b227">[228]</ref> Analog design (Section 5.9)</p><p>LADAC <ref type="bibr" target="#b228">[229]</ref>, AnalogCoder <ref type="bibr" target="#b229">[230]</ref>, FLAG <ref type="bibr" target="#b230">[231]</ref>, ADO-LLM <ref type="bibr" target="#b231">[232]</ref>, LaMAGIC <ref type="bibr" target="#b232">[233]</ref>, Artisan <ref type="bibr" target="#b233">[234]</ref>, LEDRO <ref type="bibr" target="#b234">[235]</ref>, AnalogXpert <ref type="bibr" target="#b235">[236]</ref>, AnalogGenie <ref type="bibr" target="#b236">[237]</ref> Fig. <ref type="figure" target="#fig_1">10</ref>. Research tree of foundation models as circuit decoder, covered in Section 5.</p><p>LLM-assisted circuit design techniques, categorizing them into 7 main directions according to their applications in generative EDA tasks:</p><p>(1) LLM-assisted hardware code generation and optimization. This category explores the application of LLMs in generating hardware code across different abstraction levels, such as RTL and HLS code. We will discuss the use of LLMs for RTL code generation in Section 5.1 and HLS code generation in Section 5.2. Additionally, we will examine efforts in producing optimized hardware in Section 5.3. Some works in this optimization category overlap with the hardware code generation.</p><p>(2) LLM-assisted hardware code verification and debugging. Beyond code generation, LLMs are employed to verify the correctness of hardware code (HLS or RTL) and to fix potential bugs. Section 5.4 will cover the role of LLMs in hardware code verification, while Section 5.5 will focus on hardware debugging techniques. (3) LLM for hardware security. Works on hardware security focus on security-oriented design, debugging, and verification. We will delve into these topics in Section 5.6, highlighting the unique challenges in security as distinct from general verification and debugging. ( <ref type="formula">4</ref>) LLM for design flow automation and layouts. Section 5.7 explores the application of LLMs in automating the design flow based on natural-language instructions, as well as enhancing circuit layout processing for improved manufacturability. ( <ref type="formula">5</ref>) LLM for hardware architecture design. Section 5.8 addresses the application of LLMs at a higher level of abstraction, focusing on design architecture and specifications. This includes applications for memory design and AI accelerators. ( <ref type="formula">6</ref>) LLM for analog circuit design. Beyond the scope of digital VLSI design, LLM-assisted analog circuit design is another important direction. In Section 5.9, we will explore how LLMs can benefit analog circuit design, highlighting the significance of this area in the broader context of hardware development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">LLM for RTL Code Generation</head><p>RTL design is a crucial step in the whole VLSI design process. This process defines the expected behavior of circuits with hardware description languages (HDLs) like Verilog and VHDL. However, RTL design remains a manual, time-consuming, tedious, and error-prone task. Recently, leveraging LLMs for RTL generation offers a promising automated solution. Specifically, LLM solutions can directly generate expected design RTL in HDL code, typically based on design descriptions in natural language as LLM input. Such RTL code generation is the most extensively explored application of LLM-assisted EDA techniques. The existing works contribute primarily in two ways: 1) new benchmarks evaluating LLM performance, covered in Section 5.1.1 and listed in Table <ref type="table">4</ref>; and 2) new LLM solutions on RTL code generation, covered in Section 5.1.2 and listed in Table <ref type="table">5</ref> and Figure <ref type="figure" target="#fig_1">12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">RTL code generation benchmarks.</head><p>As LLMs become popular for RTL design generation, benchmarks become crucial for assessing the accuracy, efficiency, and reliability of LLM-based solutions for circuits. We summarize all benchmarks on RTL generation in Table <ref type="table">4</ref>, among which RTLLM <ref type="bibr" target="#b11">[12]</ref> and VerilogEval <ref type="bibr" target="#b13">[14]</ref> are two pioneering and most widely-adopted benchmarks for evaluating RTL code generation. Figure <ref type="figure" target="#fig_10">11</ref> illustrates the evaluation process of the RTL code generation benchmarks. A typical benchmark <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref> will provide dozens of design cases, each corresponding to one small circuit design or component. For each case, the benchmark will provide three types of files: 1) design descriptions as the LLM input, 2) test benches to verify the correctness of LLM-generated HDL code, and 3) the correct HDL code (i.e., reference model), typically handcrafted by designers, as a reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmarks for RTL Code Generation Benchmarks</head><p>Open-sourced link Date RTLLM <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b153">154]</ref> ‚úì <ref type="url" target="https://github.com/hkust-zhiyao/rtllm">https://github.com/hkust-zhiyao/rtllm</ref> 2023-10 VerilogEval <ref type="bibr" target="#b13">[14]</ref> ‚úì <ref type="url" target="https://github.com/NVlabs/verilog-eval">https://github.com/NVlabs/verilog-eval</ref> 2023-12 VerilogEval v2 <ref type="bibr" target="#b164">[165]</ref> 2024-08 CreativeEval <ref type="bibr" target="#b146">[147]</ref> ‚úì <ref type="url" target="https://github.com/matthewdelorenzo/creativeval">https://github.com/matthewdelorenzo/creativeval</ref> 2024-04 RTL-repo <ref type="bibr" target="#b152">[153]</ref> ‚úì <ref type="url" target="https://github.com/AUCOHL/RTL-Repo">https://github.com/AUCOHL/RTL-Repo</ref> 2024-05 VHDL-Eval <ref type="bibr" target="#b147">[148]</ref> 2024-06 ChatGPTV <ref type="bibr" target="#b148">[149]</ref> ‚úì <ref type="url" target="https://github.com/aichipdesign/chipgptv">https://github.com/aichipdesign/chipgptv</ref> 2024-11</p><p>Table <ref type="table">4</ref>. Collection of benchmarks on LLMs for RTL generation in Section 5.1. VerilogEval <ref type="bibr" target="#b13">[14]</ref> and its second version <ref type="bibr" target="#b164">[165]</ref> share the same open-source link.</p><p>RTLLM <ref type="bibr" target="#b11">[12]</ref> is one of the first benchmarks on design RTL generation based on natural language descriptions. It introduces a comprehensive evaluation framework with three progressive goals: syntax correctness, functionality correctness, and design quality (i.e., PPA metrics). The benchmark includes 30 diverse designs, ranging from simple arithmetic circuits to complex systems like a RISC CPU, and provides automated evaluation pipelines with natural language descriptions, testbenches, and human-crafted reference designs. RTLLM also adopts a self-planning prompt engineering technique, which significantly improves the performance of GPT-3.5 <ref type="bibr" target="#b87">[88]</ref> by decomposing the RTL generation task into planning and code generation steps. The latest version (i.e., RTLLM 2.0) is available in OpenLLM-RTL <ref type="bibr" target="#b153">[154]</ref> and expands the benchmark to 50 designs.</p><p>VerilogEval <ref type="bibr" target="#b13">[14]</ref> is the other pioneering benchmark on RTL generation based on natural language descriptions. It comprises 156 problems sourced from HDLBits, covering a wide range of topics from combinational circuits to finite state machines. VerilogEval offers two types of problem descriptions: machine-generated (using LLMs) and human-curated, ensuring clarity and reducing ambiguity. The benchmark provides an automated testing environment using the ICARUS Verilog simulator and employs the pass@k metric to evaluate functional correctness. Additionally, VerilogEval explores supervised fine-tuning (SFT) with a synthetic dataset of 8,502 problem-code pairs, demonstrating that fine-tuning can enhance LLM performance, especially for models not originally trained on Verilog. Based on VerilogEval <ref type="bibr" target="#b13">[14]</ref>, VerilogEval v2 <ref type="bibr" target="#b164">[165]</ref> evaluates the performance of new models and enhances the infrastructure and further discusses the importance of prompt engineering for RTL generation task.</p><p>In addition to the widely adopted RTLLM and VerilogEval benchmarks, there are several other benchmarks that assess LLMs in RTL code generation. CreativeEval <ref type="bibr" target="#b146">[147]</ref> evaluates LLM creativity in Verilog generation based on fluency, flexibility, originality, and elaboration, finding GPT-3.5 to be the most creative among tested models. RTL-Repo <ref type="bibr" target="#b152">[153]</ref>  Benchmark workflow comprises three steps: 1) LLMs generate RTL code from specifications, 2) The code is input into a synthesis tool to identify syntax errors, and 3) A simulation process checks for mismatches against predefined reference models or test case golden results.</p><p>Table <ref type="table">5</ref>. Works on LLMs for RTL generation. In the 'Works' column, denotation '*' refers to works on security, while '(Opt)' means the work focuses on design optimization. Though VerilogEval <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b164">165]</ref> is a benchmark (in Table <ref type="table">4</ref>), it also proposes SFT with problem-pair pairs, while the training dataset is not open-sourced. DeLorenzo et al. <ref type="bibr" target="#b161">[162]</ref> introduce an RTL generation framework that integrates the MCTS sampling process, which we classify as a form of prompt engineering since it solely alters the inference process, without necessitating fine-tuning. Some works provide code through GitHub but don't provide open-source models or training datasets. We classify them as SFTs with private data.</p><p>evaluate LLMs on 'long-range dependency handling' ability through several metrics. However, the dataset lacks corresponding functional specifications, preventing it from being considered a standard benchmark. VHDL-Eval <ref type="bibr" target="#b147">[148]</ref> addresses the lack of VHDL-specific benchmarks, offering 202 problems with self-verifying testbenches to evaluate functional correctness through zero-shot generation and fine-tuning. ChatGPTV <ref type="bibr" target="#b148">[149]</ref> introduces a multi-modal benchmark for Verilog synthesis, incorporating visual inputs to improve LLM performance in handling spatial circuit complexity, showing significant accuracy gains over text-only approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">RTL code generation techniques.</head><p>RTL code generation is the most extensively explored application of LLM-assisted EDA techniques. Given the growing body of work in this area, we categorize existing approaches into four distinct strategies. Table <ref type="table">5</ref> and Figure <ref type="figure" target="#fig_1">12</ref> list the comparison and timeline of all related works, respectively. the next token based on the preceding context, which aids LLMs in grasping code syntax, but is limited in understanding required functional specifications. Consequently, this UFT approach is typically less effective and thus less adopted. Finally, LLMs trained on open datasets with instruction-code pairs (these methods also involve Supervised Fine-Tuning, denoted as 'SFT') utilize pairs of design specifications and RTL code to train the LLMs, and the dataset is open-sourced. This last strategy is both effective and benefits the community with open-source datasets.</p><p>Figure <ref type="figure" target="#fig_1">14</ref> compares the performance of various models on VerilogEval-Human <ref type="bibr" target="#b13">[14]</ref> and RTLLM <ref type="bibr" target="#b11">[12]</ref> over time, including both general-purpose coding LLMs (e.g., DeepSeek-Coder, CodeLlama) and RTL-specific coding LLMs (e.g., RTL-Coder <ref type="bibr" target="#b144">[145]</ref>, BetterV <ref type="bibr" target="#b140">[141]</ref>). This comparison highlights the advancements in Verilog code generation, illustrating how domain-specific fine-tuning and architectural modifications enhance the effectiveness of LLMs in hardware design automation.</p><p>Strategy 1: Prompt engineering. Prompt engineering is one of the earliest strategies used for RTL generation due to its simplicity and effectiveness in applying LLMs to circuit design, including commercial LLMs. While recent efforts have focused on developing new fine-tuned LLMs for RTL generation, research about prompt engineering continues to evolve. Prompt engineering <ref type="bibr" target="#b239">[240]</ref> mainly focuses on designing and optimizing input prompts to effectively communicate with LLMs and elicit desired design generations. The advantage of this methodology is the elimination of the requirement for fine-tuning and adaptability across different LLMs. Tons of works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b132">133,</ref><ref type="bibr" target="#b134">135,</ref><ref type="bibr" target="#b135">136,</ref><ref type="bibr" target="#b137">138,</ref><ref type="bibr" target="#b157">158,</ref><ref type="bibr" target="#b158">159,</ref><ref type="bibr" target="#b237">238]</ref> have explored applying and customizing advanced prompt engineering techniques for RTL code generation by LLMs, as demonstrated in Figure <ref type="figure" target="#fig_1">13</ref>.</p><p>Chip-Chat <ref type="bibr" target="#b134">[135]</ref>, as a pioneering work, investigates the use of conversational LLMs, such as OpenAI's ChatGPT, in translating natural language specifications into HDLs for circuit design. Through a case study, the authors explore the collaborative design of an 8-bit accumulator-based microprocessor with GPT-4. The methodology involves breaking down the design into subtasks managed through conversation threads, where GPT-4 generates Verilog code guided by a human engineer who verifies and refines the output. The study finds that while LLMs can produce highquality code and act as effective design assistants, they require human oversight for specification corrections and struggle with verification tasks. This research highlights the potential of LLMs to enhance productivity in circuit design when used as a complement to human expertise.</p><p>(Claude3-Haiku) as a "teacher" to improve the quality of open-source RTL datasets. To address the scarcity of high-quality Verilog data, CodeV <ref type="bibr" target="#b138">[139]</ref> leverages the observation that LLMs excel at summarizing Verilog code, rather than generating it from scratch. The system operates by first collecting and filtering a large corpus of high-quality Verilog modules from open-source repositories. These modules are then fed into GPT-3.5, which generates multi-level summaries-detailed functional descriptions and higher-level problem statements-for each module. These description-code pairs form a high-quality dataset used to fine-tune base LLMs (CodeLlama, DeepSeekCoder, and CodeQwen), resulting in the CodeV series of models.</p><p>DeepRTL <ref type="bibr" target="#b155">[156]</ref> introduces a unified representation model to enhance both understanding and generation of Verilog code. The model addresses limitations in previous approaches, which focus primarily on Verilog code generation, neglecting the critical task of understanding. DeepRTL <ref type="bibr" target="#b155">[156]</ref> is fine-tuned on a comprehensive dataset that aligns Verilog code with multi-level natural language descriptions, covering line, block, and module levels with both detailed and high-level functional descriptions. The dataset includes both open-source and proprietary Verilog code, annotated using a CoT approach with GPT-4 and verified by human experts. The authors introduce a novel benchmark for Verilog understanding and propose using semantic evaluation metrics like embedding similarity and GPT score, which capture semantic coherence more effectively than traditional methods like BLEU and ROUGE. Additionally, the paper employs curriculum learning, allowing the model to incrementally build knowledge from simpler to more complex tasks, enhancing its performance in both understanding and generation of Verilog code.</p><p>Strategy 3: LLMs trained on open datasets with code only. In the initial phase of finetuning LLMs for RTL design generation, early efforts primarily relied on unsupervised data sourced from platforms like GitHub and other open-source code repositories. The key benefit of using unsupervised datasets is their ease of training and the large volume of existing unlabeled data, eliminating the need for labor-intensive labeling tasks. However, the limited label alignment of these datasets limits their effectiveness in training LLMs for RTL generation. These techniques mainly enable LLMs to understand language patterns, structures, and semantics by processing vast amounts of text data. LLMs are tasked to predict the next token given the previous context <ref type="bibr" target="#b87">[88]</ref>.</p><p>For example, VGen <ref type="bibr" target="#b14">[15]</ref>, as the pioneering work, first evaluates the ability of unsupervised LLMs to generate Verilog code, a critical aspect of circuit design. The authors fine-tune several pre-trained LLMs on a large dataset of Verilog code collected from GitHub and textbooks, creating the largest training corpus for this purpose. They develop an evaluation framework that includes test benches for assessing both the syntactic and functional correctness of the generated code across various problem scenarios. Wang et al. <ref type="bibr" target="#b162">[163]</ref> explores the use of LLMs for automatically generating Verilog code from natural language specifications. It introduces a novel approach that employs reinforcement learning with golden code feedback, specifically using proximal policy optimization and a reward function based on the similarity of abstract syntax trees between generated and reference code. This method enhances the semantic evaluation of the generated code and addresses the limitations of existing open-source models, which often lack performance compared to commercial alternatives. The authors present their model, VeriSeek, which has 6.7 billion parameters and achieves state-of-the-art results.</p><p>Strategy 4: LLMs trained on open datasets with instruction-code pairs. This process, known as 'instruction fine-tuning' or 'supervised fine-tuning' <ref type="bibr" target="#b241">[242]</ref>, adjusts the model to follow specific instructions or prompts more effectively. Different from adopting in-house private datasets in strategy 2, this strategy tries to provide open-source datasets to benefit the community. To address the scarcity of high-quality training data, RTLCoder <ref type="bibr" target="#b144">[145]</ref> introduces an automated dataset generation workflow. As illustrated in Figure15, the dataset generation workflow follows a threestep process, establishing a foundational paradigm for dataset creation. Its generated dataset enables  <ref type="bibr" target="#b144">[145]</ref>. Following works (like AutoVCoder <ref type="bibr" target="#b139">[140]</ref>, Origen <ref type="bibr" target="#b142">[143]</ref>) also adopts similar methodologies for dataset generation. The dataset generation consists of three steps. The first two steps are designed to generate diverse instructions (design specifications) and the final step is to generate high-quality reference code for the next fine-tuning step.</p><p>a fine-tuned LLM coder that outperforms GPT-3.5 <ref type="bibr" target="#b87">[88]</ref> and achieves performance comparable to GPT-4 <ref type="bibr" target="#b87">[88]</ref>. This pioneering work provides the first open-source RTL LLM coder with instruction fine-tuning. Similar to the paradigm introduced by RTLCoder, CraftRTL <ref type="bibr" target="#b156">[157]</ref> further analyzes existing LLM's performance on Verilog, identifying two key weaknesses: poor handling of nontextual representations (like Karnaugh maps and waveforms) and inconsistent performance due to minor coding errors. Targeting these weaknesses, CraftRTL creates a "correct-by-construction" synthetic dataset that includes Karnaugh maps, finite state machines, and waveform representations.</p><p>They develop an automated framework for generating detailed error reports that identify common minor mistakes in code completions, which are then used to create a targeted code repair dataset by injecting errors into correct open-source code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">LLMs for HLS Code Generation</head><p>Similar to RTL code generation, several works have explored LLM-based HLS code generation to improve automation and efficiency when designing hardware with high-level programming languages. As summarized in Table <ref type="table">6</ref>, existing solutions primarily rely on prompt engineering without fine-tuning the models. Additionally, many works are open-sourced. Notably, HLSPilot <ref type="bibr" target="#b166">[167]</ref> and Liao et al. <ref type="bibr" target="#b169">[170]</ref> introduce new benchmarks for evaluating HLS code generation performance. For example, SynthAI <ref type="bibr" target="#b168">[169]</ref> introduces a multi-agent generative AI framework for modular HLS design, integrating ReAct agents, CoT prompting, RAG, and web search capabilities to enhance decision-making. By systematically planning and executing modular designs, SynthAI improves design quality and scalability. HLSPilot <ref type="bibr" target="#b166">[167]</ref> focuses on hybrid CPU-FPGA architectures, proposing a three-stage approach: C/C++ to HLS translation, design space exploration, and LLM-based profiling. It integrates C-to-HLS optimization strategies to generate complex circuit designs, employs a DSE tool for pragma parameter tuning, and leverages LLMs for performance profiling to identify bottlenecks and optimize HLS designs. Liao et al. <ref type="bibr" target="#b169">[170]</ref> investigate the translation of natural language specifications or C code into RTL, evaluating the capability of LLMs to automate hardware design. C2HLSC <ref type="bibr" target="#b167">[168]</ref> explores fully automated C-to-HLS transformation, refactoring generic C code into an HLS-compatible format while supporting hierarchical designs and pragma generation for optimizing area and throughput. These works collectively highlight the potential of LLMs in improving HLS design automation, enabling more efficient translation from high-level code to synthesizable hardware descriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">LLMs for Design Optimizations</head><p>During circuit code generation using LLMs, besides functional correctness focused by Section 5.1 and 5.2, design quality metrics such as power, performance, and area (PPA) are also critical for ensuring </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">LLM for Hardware Code Verification</head><p>In addition to circuit code generation, verifying the functional correctness of circuit designs is a critical yet highly labor-intensive task that heavily relies on human engineers. To address this challenge, LLM-based solutions have been explored to automate hardware verification. Table <ref type="table" target="#tab_7">8</ref> summarizes existing works in this direction. Current LLM-based verification approaches focus on two primary directions: 1) Assertion generation with LLMs. These approaches leverage LLMs to generate assertions based on design specifications or RTL code <ref type="bibr" target="#b176">[177,</ref><ref type="bibr" target="#b177">178,</ref><ref type="bibr" target="#b180">181,</ref><ref type="bibr" target="#b181">182,</ref><ref type="bibr" target="#b187">[188]</ref><ref type="bibr" target="#b188">[189]</ref><ref type="bibr" target="#b189">[190]</ref><ref type="bibr" target="#b190">[191]</ref>. The generated assertions are then used to validate whether the design under test (DUT) complies with its specifications, with either formal verification tools (e.g., Cadence JasperGold) for static formal property verification or simulation tools (e.g., Synopsys VCS) for dynamic verification on test benches. 2) Test bench generation with LLMs. LLMs are also employed to generate test stimuli, enhancing the simulation-based verification process <ref type="bibr">[183-185, 191, 195]</ref>. The comparison of these explorations is listed in Table <ref type="table" target="#tab_7">8</ref>, with the timeline demonstrated in Figure <ref type="figure" target="#fig_12">16</ref>, almost all existing explorations directly employ prompt engineering due to the lack of high-quality verification data for fine-tuning. Some of these verification efforts focus specifically on security verification, which will be further discussed in Section 5.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Assertion generation with LLMs.</head><p>We categorize existing works on assertion generation into two main types: assertion generation benchmarks and assertion generation techniques. The former focuses on evaluating the effectiveness of LLMs in generating functionally correct assertions, while the latter explores various methodologies to improve the accuracy and reliability of LLM-generated assertions. We detail these two categories below.</p><p>Benchmarking LLM-aided assertion generation. Similar to RTL code generation, benchmarking is crucial for evaluating the quality of LLM-generated assertions. The evaluation process involves three key aspects: syntax correctness, functional correctness, and overall assertion quality. Syntax correctness can be verified using RTL code compilers, while functional correctness can be validated through simulation-based verification or formal property checking based on the golden RTL implementations. However, assessing assertion quality remains an open challenge, as it depends on multiple factors, such as completeness and relevance to the design specification.</p><p>Currently, key assertion generation benchmarks include AssertionBench <ref type="bibr" target="#b186">[187]</ref>, AssertEval <ref type="bibr" target="#b153">[154]</ref>, and FVEval <ref type="bibr" target="#b185">[186]</ref>, all of which use Cadence JasperGold for formal property verification of generated assertions against golden RTL implementations. Specifically, AssertionBench <ref type="bibr" target="#b186">[187]</ref> consists of 100 Verilog hardware designs from OpenCores <ref type="bibr" target="#b119">[120]</ref>, with formally verified assertions derived from GOLDMINE <ref type="bibr" target="#b242">[243]</ref> and HARM <ref type="bibr" target="#b243">[244]</ref> tools. The evaluation metrics include syntax correctness and LLM for RTL Verification Method New New Open Open Prompt Link Date Model Dataset Model Benchmark Engineering AutoSVA2 [177] ‚úì 2023-09 NL2SVA [189] ‚úì 2023-09 LLM4DV [184] ‚úì ‚úì <ref type="url" target="https://github.com/ZixiBenZhang/ml4dv">https://github.com/ZixiBenZhang/ml4dv</ref> 2023-10 ChIRAAG [182] ‚úì 2024-01 AssertLLM [181] ‚úì ‚úì ‚úì <ref type="url" target="https://github.com/hkust-zhiyao/AssertLLM">https://github.com/hkust-zhiyao/AssertLLM</ref> 2024-02 Xiao et al. <ref type="bibr" target="#b193">[194]</ref> ‚úì 2024-03 Blocklove et al. <ref type="bibr" target="#b195">[196]</ref> ‚úì 2024-04 Liu et al. <ref type="bibr" target="#b189">[190]</ref> ‚úì ‚úì 2024-04 Huang et al. <ref type="bibr" target="#b190">[191]</ref> ‚úì 2024-05 Bhandari et al. <ref type="bibr" target="#b194">[195]</ref> ‚úì ‚úì 2024-06 VerilogReader <ref type="bibr">[</ref> functional correctness. AssertEval <ref type="bibr" target="#b153">[154]</ref> from OpenLLM-RTL <ref type="bibr" target="#b153">[154]</ref> includes 17 OpenCores <ref type="bibr" target="#b119">[120]</ref> designs, each accompanied by a natural language specification and golden RTL implementation. It evaluates assertions based on syntax correctness, functional correctness, and COI (cone-of-influence) coverage. FVEval <ref type="bibr" target="#b185">[186]</ref> assesses assertions in three scenarios: (1) NL2SVA-Human, generating assertions from human-written specifications and real-world testbenches; (2) NL2SVA-Machine, translating formal logic from synthetic natural language descriptions to SystemVerilog assertions; and (3) Design2SVA, directly generating assertions from RTL designs. It evaluates various LLMs (e.g., GPT-4o, Gemini, LLaMA3) based on syntax correctness, full functional correctness, and partial correctness (assertions that are logically related but not fully equivalent to the reference). Generate design assertions with LLMs. LLMs automate hardware verification by leveraging natural language specifications and RTL code to produce SystemVerilog Assertions (SVA). These techniques can be categorized based on their input types: (1) Natural language specifications alone (e.g., ChIRAAG <ref type="bibr" target="#b181">[182]</ref>, AssertLLM <ref type="bibr" target="#b180">[181]</ref>). ( <ref type="formula">2</ref>) RTL code alone (e.g., AutoSVA2 <ref type="bibr" target="#b176">[177]</ref>). (3) Both specification and RTL code (e.g., NL2SVA <ref type="bibr" target="#b188">[189]</ref>). Due to the scarcity of high-quality assertion datasets, most works employ prompt engineering rather than fine-tuning LLMs. Evaluation methods typically rely on formal property verification (FPV) using tools like Cadence JasperGold, ensuring that generated assertions maintain logical correctness. Some works, such as ChIRAAG <ref type="bibr" target="#b181">[182]</ref>, also incorporate simulation-based validation using Synopsys VCS with test benches.</p><p>For example, AutoSVA2 <ref type="bibr" target="#b176">[177]</ref> prompts GPT-4 with RTL code and a refined rule-based system to generate valid SVAs, validated through FPV. NL2SVA <ref type="bibr" target="#b188">[189]</ref> employs few-shot prompting with both RTL and natural language descriptions to guide assertion generation, also evaluated via FPV. ChIRAAG <ref type="bibr" target="#b181">[182]</ref> relies solely on natural language specifications, using prompt engineering for assertion synthesis, with validation conducted through simulation. AssertLLM <ref type="bibr" target="#b180">[181]</ref> processes entire specification documents, utilizing a three-phase approach where different LLMs handle specification extraction, waveform analysis, and assertion generation, with verification performed through FPV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Test bench generation with LLMs.</head><p>In addition to assertion generation, recent advancements in LLM-based verification have introduced automated test bench generation <ref type="bibr">[183-185, 191, 195]</ref>, significantly reducing the manual effort involved in verifying RTL designs. These approaches aim to enhance coverage metrics, including code coverage and functional coverage, by generating high-quality test benches for simulation.</p><p>Existing explorations also fall into these main categories: (1) Test bench generation for code coverage. This type focuses on measuring how thoroughly the RTL code is exercised during simulation. This includes metrics such as statement coverage, branch coverage, toggle coverage, and FSM state coverage. Achieving high code coverage ensures that most structural elements of the design have been tested but does not guarantee full functional correctness. (2) Test bench generation for functional coverage. This type ensures that all intended design behaviors are tested according to the specification. Functional coverage is often defined using assertions and covergroups, verifying that different functional scenarios, corner cases, and expected behaviors are exercised. Unlike code coverage, functional coverage validates the correctness of the design beyond just its structural execution. We detail the two categories below.</p><p>Test bench generation for code coverage. VerilogReader <ref type="bibr" target="#b184">[185]</ref> integrates LLMs into coveragedirected test generation, focusing on achieving code coverage closure by generating test stimuli that target uncovered RTL lines and branches. It takes as input a Verilog design under test (DUT), natural language descriptions, and code coverage reports from simulations. The output consists of automatically generated test stimuli designed to improve code coverage in RTL verification. To generate test inputs effectively, VerilogReader employs prompt engineering with a Prompt Generator that structures LLM interactions in two stages: first, understanding the DUT and its current coverage status, and second, generating test inputs in a structured JSON format. Additionally, it includes a Coverage Explainer, which transforms raw simulator coverage reports into an LLMreadable format, and a DUT Explainer, which enhances LLM comprehension of Verilog code by providing natural language descriptions and test guidance.</p><p>Test bench generation for functional coverage. Most existing explorations <ref type="bibr" target="#b182">[183,</ref><ref type="bibr" target="#b183">184,</ref><ref type="bibr" target="#b190">191,</ref><ref type="bibr" target="#b194">195</ref>] focus on functional coverage, as LLMs more excel in understanding RTL functionality and specifications rather than analyzing RTL code structure, which is required for code coverage. For example, VeriAssist <ref type="bibr" target="#b190">[191]</ref> takes the design specification as input and generates initial RTL code along with corresponding test cases. It employs a self-verification process, where the generated RTL is simulated with test cases while considering timing constraints. This is followed by a self-correction mechanism, where the LLM refines the RTL design based on simulation feedback, addressing compilation and functional errors. By mimicking a human-in-the-loop design approach, VeriAssist <ref type="bibr" target="#b190">[191]</ref> improves the accuracy and correctness of both RTL code and test benches. Another work UVLLM <ref type="bibr" target="#b182">[183]</ref> integrates LLMs with Universal Verification Methodology (UVM) to automate test case generation and RTL code repair. The framework consists of four steps: pre-processing, where linters and LLMs eliminate syntax errors; UVM processing, which generates and runs test cases within a UVM testbench; post-processing, which analyzes simulation logs to identify errors; and repair, where LLMs generate RTL patches based on detected issues. While UVLLM is open-sourced and showcases LLMs' potential in verification automation, challenges remain, including the need for extensive training data and the high computational cost of large-scale LLM inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">LLM for Hardware Code Debugging</head><p>Debugging in hardware design involves identifying and fixing both syntax and functional errors in circuit implementations. Traditionally, engineers conduct this process of fixing bugs manually, making it a tedious and labor-intensive task. Recent advancements in LLMs automate hardware debugging, reducing human intervention and improving efficiency. Existing research explores LLMassisted debugging for both RTL and HLS code, offering new methodologies for error detection, root cause analysis, and automated patch generation, as detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">LLM for RTL code debugging.</head><p>implementations to benchmark LLM performance in syntax correction. HDLDebugger <ref type="bibr" target="#b199">[200]</ref>, developed around the same time, similarly employs RAG to retrieve relevant debugging information from documentation and code databases. Additionally, it incorporates a self-guided fine-tuning process to improve LLM-based debugging accuracy. The framework also includes a novel data generation module that synthetically creates pairs of buggy and corrected HDL code using a reverse engineering approach. Both methods significantly enhance LLM capabilities in syntax debugging by integrating retrieval-based contextual learning and structured reasoning techniques.</p><p>Functional debugging. Compared with syntax debugging, functional debugging is significantly more challenging as it requires deep reasoning about circuit functionality and identifying the root cause of errors. Recent works <ref type="bibr" target="#b143">[144,</ref><ref type="bibr" target="#b182">183,</ref><ref type="bibr" target="#b190">191,</ref><ref type="bibr" target="#b198">199,</ref><ref type="bibr" target="#b203">204]</ref> have explored LLM-based approaches to address functional RTL debugging. VeriAssist <ref type="bibr" target="#b190">[191]</ref> enhances pre-trained LLMs with self-verification and self-correction techniques. The framework generates test cases alongside RTL code and simulates the generated design to detect functional errors. If discrepancies are identified, self-correction mechanisms iteratively refine the RTL code based on simulation feedback, improving debugging accuracy. MEIC <ref type="bibr" target="#b198">[199]</ref> proposes an LLM-based iterative debugging framework and introduces a new debugging benchmark based on RTLLM-v1.0 <ref type="bibr" target="#b11">[12]</ref>, an RTL generation dataset containing 15 source designs. By introducing 178 buggy variations of these designs, MEIC categorizes errors into syntax and functional bugs, providing a structured evaluation dataset for LLM-based debugging research. Qayyum et al. <ref type="bibr" target="#b203">[204]</ref> integrate RAG into functional debugging by retrieving relevant RTL specifications and comparing them with the RTL implementation. This enables LLMs to detect inconsistencies and suggest fixes based on the intended circuit behavior, significantly improving debugging accuracy through formal specification guidance.</p><p>Beyond direct RTL code analysis, some works incorporate auxiliary sources such as abstract syntax tree (AST) and waveform analysis to enhance functional debugging. UVLLM <ref type="bibr" target="#b182">[183]</ref> introduces an LLM-based unified verification methodology, leveraging AST representations to improve error localization and code corrections. Similarly, VerilogCoder <ref type="bibr" target="#b143">[144]</ref> employs a rewriting mechanism that enhances debugging accuracy. This process integrates information from EDA tools, such as ASTs and waveform tracing tools, to refine LLM-driven RTL debugging. By combining LLM reasoning with structured program analysis, these methods offer improved robustness in identifying and correcting functional design errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">LLM for HLS debugging.</head><p>Compared to RTL and HLS generation tasks, significantly fewer works focus on debugging at the HLS level. One of the pioneering efforts in this direction is Chrysalis <ref type="bibr" target="#b200">[201]</ref>, a benchmark designed for training and evaluating LLMs' capability to identify functional bugs in HLS code. Unlike syntax errors that can be easily detected by compilers, many functional bugs at the HLS level require deeper semantic analysis and program reasoning. Chrysalis provides a structured dataset that allows LLMs to learn patterns of common HLS-specific issues and evaluate their debugging performance in terms of both syntax correctness and functional accuracy. This benchmark sets the foundation for future research in LLM-assisted HLS debugging by offering a standardized dataset for evaluating model capabilities in detecting and resolving high-level synthesis errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">LLMs for Hardware Security</head><p>Besides functional verification and debugging, a growing number of research explore the use of LLMs for hardware security verification and threat detection. Recent works <ref type="bibr">[70-73, 179, 188, 193, 205-207, 213, 214]</ref> integrate LLMs into automated security analysis, detection of vulnerabilities, and protection of hardware designs. As summarized in ‚úì 2023-11 SecRT-LLM <ref type="bibr" target="#b204">[205]</ref> ‚úì ‚úì 2024-05 Self-HWDebug <ref type="bibr" target="#b205">[206]</ref> ‚úì 2024-05 Qayyum et al. <ref type="bibr" target="#b203">[204]</ref> 2024-06</p><p>Table <ref type="table" target="#tab_8">10</ref>. Existing explorations in LLMs for security, covered in Section 5.6.</p><p>LLM-based research in hardware security can be divided into two primary directions. Protective hardware security focuses on using LLMs to detect vulnerabilities, generate security patches, and implement secure-by-design methodologies at the RTL and gate levels. These approaches aim to proactively mitigate security risks through automated analysis and verification techniques. Offensive hardware security, in contrast, explores how LLMs can facilitate attack strategies and identify potential hardware exploits. Together, these two research directions contribute to the development of more resilient defense mechanisms by providing insights into adversarial techniques and enabling the design of effective countermeasures. Below, we introduce representative works about both directions in detail.</p><p>LLM-aided protective hardware security. Research on LLM-assisted protective hardware security can be categorized into two key areas: security bug detection through security assertion generation and security bug fixing, which involves identifying and debugging vulnerabilities. These approaches highlight the potential of LLMs in automating security analysis, enhancing verification processes, and mitigating hardware vulnerabilities.</p><p>In security bug identification, LLMs have been explored to automate the detection of hardware vulnerabilities and generate security assertions. For instance, Kande et al. <ref type="bibr" target="#b187">[188]</ref> demonstrate the potential of LLMs in generating hardware security assertions, a task that traditionally requires significant expertise. Similar to the functional assertion generation process, their framework employs LLM to generate security assertions based on security specifications and evaluates LLM performance using a benchmark suite of real-world designs and corresponding golden reference security assertions, analyzing the impact of prompt detail on accuracy. DIVAS <ref type="bibr" target="#b178">[179]</ref> introduces an LLM-powered framework that automates SoC security analysis and policy-based protection. The system maps vulnerabilities to Common Weakness Enumerations (CWEs), generates verifiable SVAs, and implements security policies through security modules or wrappers. Evaluated on open-source benchmarks, DIVAS demonstrates effectiveness in automating SoC security analysis, policy enforcement, and vulnerability detection using the DiSPEL tool. Similarly, SecRL-LLM <ref type="bibr" target="#b204">[205]</ref> propose a database containing 10,000 vulnerable finite state machine designs incorporating 16 security weaknesses. They further develop an LLM-based framework, integrating in-context learning and fidelity-check mechanisms to enhance both vulnerability insertion and detection in hardware designs.</p><p>Beyond vulnerability detection, some works also explore security bug fixing by leveraging LLMs for automated debugging and countermeasure implementation. Pearce et al. <ref type="bibr" target="#b211">[212]</ref> conducted one of the earliest studies in this area, prompting LLMs to automatically repair software security vulnerabilities as early as 2021, prior to the emergence of today's more powerful models. Their work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLM for Design Flow Automation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Open Link Date ChatEDA <ref type="bibr" target="#b215">[216]</ref> ‚úì <ref type="url" target="https://github.com/wuhy68/ChatEDAv1">https://github.com/wuhy68/ChatEDAv1</ref> 2023-08 RAG-EDA <ref type="bibr" target="#b227">[228]</ref> ‚úì <ref type="url" target="https://github.com/lesliepy99/RAG-EDA">https://github.com/lesliepy99/RAG-EDA</ref> 2024-07 ChipAlign <ref type="bibr" target="#b220">[221]</ref> 2024-12</p><p>LLM for Layout Design Method Open Link Date Ho et al. <ref type="bibr" target="#b223">[224]</ref> 2024-05 FabGPT <ref type="bibr" target="#b221">[222]</ref> 2024-07 Chen et al. <ref type="bibr" target="#b222">[223]</ref> 2024-08 DRC-Coder <ref type="bibr" target="#b219">[220]</ref> 2024-11</p><p>Table 11. Explorations on LLMs for design flow automation and layout design, covered in Section 5.7.</p><p>presents a comprehensive empirical evaluation of multiple commercial and open-source LLMs, including OpenAI Codex, AI21's Jurassic models, Polycoder, and gpt2-csrc, assessing their ability to generate secure and functional patches for synthetic, handcrafted, and real-world security bugs. Recently, Self-HWDebug <ref type="bibr" target="#b205">[206]</ref> introduces a framework leveraging LLMs to generate debugging instructions for security issues. By defining a set of CWEs and corresponding mitigation strategies, the framework enhances LLM prompt effectiveness, enabling automated security debugging and vulnerability resolution. In the domain of side-channel attack (SCA) mitigation, Netlist Whisperer <ref type="bibr" target="#b209">[210]</ref> and SCAR <ref type="bibr" target="#b210">[211]</ref> propose LLM-driven solutions to enhance security at the hardware level. Netlist Whisperer <ref type="bibr" target="#b209">[210]</ref> adopts a two-phase, pre-silicon LLM-based approach: first, a GPT-3 model identifies power leakage-inducing nets in a circuit, and then a second GPT-3 model generates an SCA-resistant netlist, eliminating the need for traditional power trace collection. SCAR <ref type="bibr" target="#b210">[211]</ref> focuses on cryptographic accelerators, utilizing control-data flow graphs to identify and localize SCA vulnerabilities. It then employs a deep-learning explainer to analyze the vulnerabilities and leverages an LLM to automatically generate and insert security patches into the RTL code. LLM-aided offensive hardware security. Besides protective solutions, research also explores how LLMs can be leveraged to execute security threats, such as automated hardware trojan insertion. For example, Kokolakis et al. <ref type="bibr" target="#b212">[213]</ref> propose an LLM-based framework for automating hardware trojan insertion and evaluating its impact on a modern RISC-V microarchitecture. Their method begins with a filtering process to identify suitable modules for Trojan insertion. The RTL code of selected modules is provided to the LLM, which assists in implanting hardware trojans by modifying the design. While this approach demonstrates the feasibility of hardware trojan insertion using fine-tuned LLMs, further research is needed for more complex attack scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">LLM for Design Flow Automation and Layout Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.1">LLM for design flow automation.</head><p>LLMs have also been explored for automating design flow processes, primarily in two key areas: design flow script synthesis <ref type="bibr" target="#b215">[216]</ref> and chip-related question-answering (QA) <ref type="bibr" target="#b220">[221,</ref><ref type="bibr" target="#b227">228]</ref>. These applications aim to reduce human effort in configuring and optimizing EDA toolchains while improving accessibility to chip design knowledge. We compare existing works in Table <ref type="table">11</ref>.</p><p>For design flow script synthesis, ChatEDA <ref type="bibr" target="#b215">[216]</ref> is a pioneering work that leverages LLMs for automating EDA design flow execution. The framework decomposes user requests into structured sub-tasks, generates EDA scripts, and autonomously executes them using EDA tools. To enhance the model's understanding of EDA workflows, instruction tuning techniques are applied. Additionally, ChatEDA introduces a benchmark suite comprising 50 tasks that include simple flow calls, complex multi-step flow executions, and parameter-tuning scenarios. The evaluation process assesses both the correctness and executability of the generated scripts using real EDA tools, followed by manual scoring to ensure logical coherence and practical usability.</p><p>For chip-related question-answering, RAG-EDA <ref type="bibr" target="#b227">[228]</ref> presents a customized RAG framework for EDA tool documentation QA. The framework processes EDA tool documentation and user queries, employing hybrid information retrieval methods that combine lexical search (i.e., TF-IDF, BM25) and semantic retrieval (i.e., vector embeddings). A contrastive learning-based reranker is trained to filter relevant documents, improving retrieval accuracy. The LLM is then fine-tuned through a two-stage approach: (1) domain knowledge pretraining using EDA textbooks and (2) instruction tuning with QA datasets. The evaluation metrics include retrieval recall (recall@k) for the retriever and reranker, and BLEU, ROUGE-L, and UniEval scores to assess the accuracy and factual consistency of generated answers. Additionally, ChipAlign <ref type="bibr" target="#b220">[221]</ref> extends LLM capabilities for chip-related QA tasks by addressing the challenge of aligning domain-adapted large language models for chip design with strong instruction-following abilities. It proposes a training-free model merging approach that combines a domain-specific chip LLM with a general instruction-aligned LLM. Instead of retraining on instruction-following data, ChipAlign employs a novel geodesic interpolation technique in the weight space to produce a merged model that maintains chip design expertise while significantly improving instruction alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.2">LLM for layout design.</head><p>Some recent works employ foundation models for circuit layouts to enhance the physical design process and manufacturability, as demonstrated in Table <ref type="table">11</ref>. Since circuit layouts are typically represented in the format like images, these works typically integrate vision models with LLMs to better understand and process circuit layouts.</p><p>For instance, FabGPT <ref type="bibr" target="#b221">[222]</ref> introduces a large multimodal model designed for wafer defect knowledge querying in semiconductor fabrication. It processes Scanning Electron Microscope (SEM) images of wafers alongside textual metadata extracted using Optical Character Recognition (OCR) and predefined label sets. By fusing visual and textual information, the model enhances defect detection and knowledge retrieval. A pre-trained multimodal encoder captures critical wafer defect features, while a prediction module identifies defect types. Additionally, the model incorporates a Q&amp;A system with a modulation module that aligns visual and textual representations to improve interpretability in querying fabrication processes. Ho et al. <ref type="bibr" target="#b223">[224]</ref> propose an LLM-based optimization framework for standard cell layout design, incrementally generating clustering constraints to enhance PPA and routability. Their study assesses existing LLMs' understanding of SPICE netlists, clustering constraints, and physical layout descriptions. Leveraging ReAct prompting, the model iteratively refines clustering decisions, improving standard cell layout optimization. Chen et al. <ref type="bibr" target="#b222">[223]</ref> integrate reinforcement learning (RL) for OPC recipe optimization with a multi-modal LLM-backed agent system for recipe summarization. The RL component fine-tunes OPC parameters such as edge placement error (EPE) measurement points and polygon fragmentation to improve lithography accuracy. Meanwhile, the LLM-based agent extracts features, summarizes results, and generates structured OPC recipes, enhancing automation in semiconductor manufacturing. DRC-Coder <ref type="bibr" target="#b219">[220]</ref> presents a multi-agent framework for automating design rule checking (DRC) code generation using LLMs and vision-language models. It mimics human DRC coding by decomposing tasks into interpretation and coding, assigning two specialized LLM agents to reduce hallucinations and enhance reasoning accuracy. The framework also integrates domain-specific functions, including foundry rule analysis, layout design rule violation (DRV) analysis, and automated debugging loops to refine DRC rule generation. By incorporating vision models, DRC-Coder can interpret design rule illustrations and layout structures, ensuring accurate and executable DRC scripts.</p><p>LLM for Architecture Design Method Open Link Date Yan et al. <ref type="bibr" target="#b225">[226]</ref> 2023-06 Liang et al. <ref type="bibr" target="#b226">[227]</ref> 2023-07 GPTAIGChip <ref type="bibr" target="#b133">[134]</ref> 2023-09 SpecLLM <ref type="bibr" target="#b224">[225]</ref> ‚úì <ref type="url" target="https://github.com/hkust-zhiyao/SpecLLM">https://github.com/hkust-zhiyao/SpecLLM</ref> 2024-01</p><p>Table <ref type="table">12</ref>. Explorations in LLM-aided architecture design, covered in Section 5.8</p><p>LLM for Analog Circuit Design Method Open Link Date LADAC <ref type="bibr" target="#b228">[229]</ref> 2023-12 AnalogCoder <ref type="bibr" target="#b229">[230]</ref> ‚úì <ref type="url" target="https://github.com/anonyanalog/AnalogCoder">https://github.com/anonyanalog/AnalogCoder</ref> 2024-05 FLAG <ref type="bibr" target="#b230">[231]</ref> 2024-05 ADO-LLM <ref type="bibr" target="#b231">[232]</ref> 2024-06 LaMAGIC <ref type="bibr" target="#b232">[233]</ref> 2024-07 Artisan <ref type="bibr" target="#b233">[234]</ref> 2024-11 LEDRO <ref type="bibr" target="#b234">[235]</ref> 2024-11 AnalogXpert <ref type="bibr" target="#b235">[236]</ref> 2024-12 AnalogGenie <ref type="bibr" target="#b236">[237]</ref> ‚úì <ref type="url" target="https://github.com/xz-group/AnalogGenie">https://github.com/xz-group/AnalogGenie</ref> 2025-01</p><p>Table <ref type="table">13</ref>. Works on LLMs for analog circuit design, covered in Section 5.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">LLMs for Hardware Architecture Design</head><p>For hardware architecture design, LLMs have been explored in two primary areas: circuit architecture design <ref type="bibr" target="#b133">[134,</ref><ref type="bibr" target="#b225">226,</ref><ref type="bibr" target="#b226">227]</ref> and specification document processing <ref type="bibr" target="#b224">[225]</ref>. The comparison and timeline of these works are shown in Table <ref type="table">12</ref>. These works aim to leverage LLMs to enhance automation, reduce design complexity, and improve efficiency in architectural decision-making.</p><p>In circuit architecture design, GPT4AIGChip <ref type="bibr" target="#b133">[134]</ref> proposes an automated prompt-generation pipeline using in-context learning to guide LLMs in generating high-quality AI accelerator designs. This approach enables the structured decomposition of hardware design tasks, improving the consistency and efficiency of generated architectures. LCDA <ref type="bibr" target="#b225">[226]</ref> applies LLMs to accelerate the software-hardware co-design process, particularly for compute-in-memory architectures in AI accelerators. It addresses the cold-start problem in traditional co-design approaches by leveraging LLMs to guide design space exploration, significantly reducing the search time. QGAS <ref type="bibr" target="#b226">[227]</ref> extends the application of LLMs to quantum computing, using GPT-4 to iteratively design variational quantum algorithm ansatz architectures and translate the architecture into quantum assembly language code.</p><p>For specification document processing, SpecLLM <ref type="bibr" target="#b224">[225]</ref> tackles the inefficiencies and errorprone nature of developing architecture specifications in architecture design. It explores the use of LLMs to automate both the generation of specifications and the review of existing documentation. To structure the problem, the authors categorize architecture specifications into three levels, covering different degrees of design abstraction. They also introduce a dataset of 46 documents to evaluate the effectiveness of their approach. By leveraging LLMs, SpecLLM enhances both efficiency and accuracy in specification drafting and validation, demonstrating the potential for further automation in this critical aspect of hardware design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">LLMs for Analog Circuit Design.</head><p>While most research on LLMs for hardware design has focused on digital VLSI circuits, recent studies have started exploring LLM's potential in analog circuit design. Unlike digital design, which follows well-defined logic rules, analog circuits typically require tuning and optimization based on human expertise, making LLM-assisted automation more challenging. A summary of existing works is provided in Table <ref type="table">13</ref>. These studies introduced LLM-powered frameworks targeting different analog circuit types, such as power converters and amplifiers, focusing on knowledge-based reasoning, topology synthesis, and circuit optimization. These approaches aim to enhance the efficiency of analog design, addressing its inherent complexities.</p><p>LADAC <ref type="bibr" target="#b228">[229]</ref> introduces an LLM-driven decision-making agent for analog design, incorporating a knowledge library and interactive tools to assist in transistor sizing and simulation. Analog-Coder <ref type="bibr" target="#b229">[230]</ref> employs a training-free LLM approach for Python-based circuit generation, integrating prompt engineering and feedback mechanisms to refine designs. ADO-LLM <ref type="bibr" target="#b231">[232]</ref> combines Bayesian Optimization with LLMs to improve circuit design efficiency, leveraging Gaussian Process models for systematic design space exploration and in-context learning for guided optimization. LaMAGIC <ref type="bibr" target="#b232">[233]</ref> fine-tunes LLMs for analog topology generation, particularly for power converters, developing structured input-output representations that enhance circuit synthesis accuracy. Artisan <ref type="bibr" target="#b233">[234]</ref> focuses on operational amplifier (opamp) design, integrating topology selection and parameter tuning while employing Tree-of-Thought (ToT) and Chain-of-Thought (CoT) reasoning to improve structured decision-making. LEDRO <ref type="bibr" target="#b234">[235]</ref> enhances analog circuit sizing by using LLMs to refine design search regions, improving the efficiency of existing optimization methods. AnalogXpert <ref type="bibr" target="#b235">[236]</ref> streamlines analog circuit topology synthesis by incorporating a subcircuit library for design space reduction and using CoT prompting and iterative proofreading for better design accuracy. AnalogGenie <ref type="bibr" target="#b236">[237]</ref> introduces a generative AI framework that utilizes a large dataset of over 3,000 analog circuit topologies. It employs a GPT-based model for sequential pin connection prediction, offering a scalable and flexible approach to analog circuit generation. These works collectively demonstrate the growing potential of LLMs in automating complex aspects of analog design, paving the way for more efficient and scalable circuit synthesis methodologies.</p><p>6 CHALLENGES, DISCUSSION, AND POTENTIAL DIRECTIONS Despite the significant advancements in circuit foundation models, several challenges remain in terms of model performance, scalability, data availability, and the integration of predictive circuit encoders and generative circuit decoders. Moreover, these challenges are closely interrelated, often affecting and amplifying one another. We believe addressing these challenges is crucial to further enhancing the effectiveness and applicability of foundation AI models in EDA. In this section, we discuss our observed challenges and potential research directions to further improve the effectiveness and applicability of foundation AI models in EDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Challenge 1: Circuit Foundation Model Generalization and Scalability</head><p>The development of circuit foundation models presents several challenges regarding generalization, performance, and scalability. If we can address these challenges, circuit foundation models can effectively support a wider range of design tasks while maintaining computational efficiency.</p><p>Towards more generalized circuit embeddings from circuit encoders. One of the key challenges is designing circuit encoders that generate generalized embeddings capable of capturing both the semantic and structural intrinsic properties of circuits. These embeddings should effectively support largely different downstream tasks. For instance, design quality evaluation relies heavily on structural characteristics, while functional reasoning and verification require a deep understanding of circuit semantics. This requires innovations in ML model architectures, self-supervised learning techniques tailored for circuits, multimodal fusion strategies, and cross-design-stage alignment. The integration of graph-based encoders with text-based LLMs has shown promise in capturing both structural and semantic information, as seen in works like CircuitFusion <ref type="bibr" target="#b96">[97]</ref>, NetTAG <ref type="bibr" target="#b112">[113]</ref>,</p><p>and ProgSG <ref type="bibr" target="#b99">[100]</ref>. However, further advancements are needed to enhance representation learning across different abstraction levels while ensuring alignment between circuit modalities.</p><p>Towards reducing hallucinations of circuit decoders. Decoder-based models, particularly those leveraging LLMs, are prone to generating hallucinated or syntactically incorrect HDL code. Unlike natural language, circuit descriptions have strict syntax and correctness constraints, requiring verification and refinement mechanisms to ensure reliability. Approaches such as reinforcement learning with human feedback (RLHF), constraint-aware decoding, and post-generation validation can help mitigate hallucinations and improve the practicality of decoder-based circuit models.</p><p>Towards more scalable circuit foundation models. Scalability remains a critical challenge, particularly for large-scale circuit designs. Current models struggle with handling industrial-scale designs due to the complexity and size of modern VLSI circuits. Divide-and-conquer strategies, such as hierarchical modeling, circuit partitioning <ref type="bibr" target="#b171">[172]</ref>, and subgraph-based processing <ref type="bibr" target="#b96">[97]</ref>, offer potential solutions to improve scalability. By segmenting circuits into smaller, more manageable sub-circuits and processing them independently, models can maintain computational efficiency without sacrificing accuracy. Techniques such as progressive training, adaptive resolution encoding, and distributed processing can further enhance the scalability of circuit foundation models, enabling their deployment in large-scale EDA workflows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Challenge 2: Circuit Data Avaliability</head><p>The effectiveness of circuit foundation models heavily depends on access to large and diverse datasets for pre-training and fine-tuning. While efforts such as OpenABC-D <ref type="bibr" target="#b123">[124]</ref>, CircuitNet <ref type="bibr" target="#b244">[245]</ref>, and DeepCircuitX <ref type="bibr" target="#b245">[246]</ref> have contributed by collecting open-source circuit designs, obtaining a sufficiently large and labeled dataset remains a challenge. Privacy concerns, proprietary design restrictions, and the high cost of generating high-quality annotated data further limit dataset availability. Overcoming these barriers may require advancements in synthetic dataset generation or novel circuit data augmentation techniques.</p><p>Towards generating synthetic circuit datasets. One emerging approach to overcoming data scarcity is the generation of unlimited synthetic circuit datasets, which can be created using graphbased or text-based methods, as explored in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b246">247,</ref><ref type="bibr" target="#b247">248]</ref>. Graph-based approaches can generate large-scale circuit graphs with diverse topologies but often lack meaningful semantics, making it difficult to ensure functional correctness. On the other hand, text-based synthesis methods, such as automated HDL code generation, can produce realistic functional modules but typically lack scalability and diversity in structural variations. Bridging the gap between these two approaches by incorporating both functional correctness and large-scale diversity remains an open research challenge.</p><p>Towards more advanced circuit data augmentation. Data augmentation techniques have been widely explored in machine learning to improve model generalization. In the circuit domain, functionally equivalent transformations, such as logic optimization from the logic synthesis tools, have been used to create diverse training samples <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b109">110,</ref><ref type="bibr" target="#b112">113]</ref>. However, existing augmentation strategies primarily focus on structural transformations while maintaining functional equivalence. Future advancements could explore more sophisticated augmentation techniques, such as e-graph rewriting for RTL designs <ref type="bibr" target="#b248">[249]</ref> and netlists <ref type="bibr" target="#b249">[250]</ref> for broader design space exploration. These techniques can further enhance the robustness of circuit foundation models, ensuring they learn richer representations while preserving key design constraints such as timing, power, and area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Challenge 3: Bridging the Gap Between Circuit Encoder and Decoder</head><p>While circuit encoders and decoders have been developed separately to support predictive and generative tasks, unifying these two paradigms presents an opportunity to create a more powerful circuit foundation model. By integrating learned embeddings from circuit encoders into decoderbased generative models, and leveraging synthetic circuit generation from decoders to enhance circuit foundation model pre-training, the capabilities of both sides can be significantly improved.</p><p>Towards leveraging encoder embeddings for decoder generation. Current circuit decoders, often based on pre-trained LLMs, generate circuit contexts without explicitly considering circuit embeddings learned by encoders. By leveraging circuit encoders to generate structured, functionally meaningful embeddings, decoders can refine their generation process to ensure greater correctness and design feasibility. One potential approach is integrating decoder-based circuit text generation with graph embeddings learned from circuit encoders, allowing decoders to generate RTL, netlist, or layout designs that align with realistic circuit representations.</p><p>Towards leveraging decoder generated circuits for enhancing circuit foundation models. Generating synthetic circuits at different abstraction levels (e.g., RTL, netlist, layout) not only improves data availability but also provides a valuable resource for pre-training both encoders and decoders. By training foundation models on synthetically generated yet functionally diverse circuits, models can capture richer design patterns and structural relationships. Additionally, synthetic circuits can be used to fine-tune models for specific design tasks, enhancing their generalization across unseen circuit designs. Future research could explore hybrid approaches that combine rulebased generation, reinforcement learning, and generative models to create high-quality synthetic datasets that support both encoder and decoder training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this survey, we provide a systematic review of the latest progress in circuit foundation models, categorizing them into encoder-based and decoder-based approaches. Encoders aim to learn generalized circuit embeddings through self-supervised pre-training techniques, supporting predictive tasks such as design quality estimation and functional verification. Decoders, primarily built upon pre-trained LLMs, focus on generative tasks such as HDL code generation and verification automation. As AI techniques continue to transform the EDA landscape, circuit foundation models hold the potential to significantly reduce design effort, accelerate the chip design process, and improve design quality. Future potential research may target enhancing scalability, generalization, and efficiency, ultimately driving AI-powered innovation in modern VLSI design.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Different paradigms of AI for EDA techniques. (a) Type I: Supervised Predictive AI Techniques for EDA. This type of work has been extensively studied. (b) &amp; (c) Type II: Foundation AI Techniques for EDA (i.e., Circuit Foundation Models). This type of work includes two paradigms, named encoder-based and decoder-based circuit models. Both paradigms develop the foundation AI model through two stages: self-supervised pre-training and fine-tuning. Our survey will focus on the emerging type II methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 (</head><label>1</label><figDesc>Figure 1(b) &amp; (c) summarize two different paradigms of foundation AI models for circuits.We propose to incorporate both paradigms into the scope of circuit foundation models:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>‚Ä¢‚Ä¢ Section 4 . 5 :‚Ä¢ Section 5 . 1 - 5 . 3 :‚Ä¢ Section 5 . 4 &amp; 5 . 5 :‚Ä¢ Section 5 . 7 :‚Ä¢ Section 5 . 8 :‚Ä¢ Section 5 . 9 :Fig. 3 .</head><label>45515354555758593</label><figDesc>Fig.3. Overview of this survey paper. Section 2 provides the background of VLSI circuit design and foundation AI model techniques. Section 3 discusses the unique properties of circuit data that motivate AI-driven solutions. Section 4 and Section 5 comprehensively review existing circuit encoders and decoders, respectively. Finally, Section 6 explores key challenges and future directions in circuit foundation models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>‚Ä¢Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Summary of pre-training techniques used in circuit encoders, covered in Section 4. Representative pretraining techniques include (a) self-supervised contrastive learning, (b) self-supervised mask-reconstruction, (c) circuit-related supervisions, and (d) multimodal circuit fusion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>25 +Fig. 6 .</head><label>256</label><figDesc>Fig. 6. Timeline for HLS (Section 4.1) and RTL (Section 4.2) encoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>CircuitEncoder ASP-DAC' 25 ‚Ä¢Fig. 7 .</head><label>257</label><figDesc>Fig. 7. Timeline for netlist (Section 4.3) and layout (Section 4.4) encoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Multimodal pre-training techniques used in NetTAG [113], including representative self-supervised learning methods such as contrastive learning, mask-reconstruction, and cross-design-stage alignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Timeline for multimodal fused and cross-stage aligned encoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>4. 5</head><label>5</label><figDesc>Summary of Trending Techniques for Advancing Circuit Encoders4.5.1 Trend 1: Customized ML model architecture and pre-training tasks for circuits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Illustration of the benchmark on LLMs for RTL generation, recent works are covered in Section 5.1.Benchmark workflow comprises three steps: 1) LLMs generate RTL code from specifications, 2) The code is input into a synthesis tool to identify syntax errors, and 3) A simulation process checks for mismatches against predefined reference models or test case golden results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 15 .</head><label>15</label><figDesc>Fig.<ref type="bibr" target="#b14">15</ref>. Data generation flow of RTLCoder<ref type="bibr" target="#b144">[145]</ref>. Following works (like AutoVCoder<ref type="bibr" target="#b139">[140]</ref>, Origen<ref type="bibr" target="#b142">[143]</ref>) also adopts similar methodologies for dataset generation. The dataset generation consists of three steps. The first two steps are designed to generate diverse instructions (design specifications) and the final step is to generate high-quality reference code for the next fine-tuning step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Timeline of RTL verification (Section 5.4) and debugging works (Section 5.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Explorations in LLM-aided RTL code verification (Section 5.4).</figDesc><table><row><cell>185]</cell><cell></cell><cell></cell><cell>‚úì</cell><cell cols="2">github.com/magicYang1573/llm-hardware-test-generation 2024-06</cell></row><row><cell>FVEval [186]</cell><cell>‚úì</cell><cell>‚úì</cell><cell>‚úì</cell><cell>https://github.com/NVlabs/FVEval</cell><cell>2024-10</cell></row><row><cell>UVLLM [183]</cell><cell>‚úì</cell><cell></cell><cell>‚úì</cell><cell>https://github.com/amyuch/UVLLM</cell><cell>2024-11</cell></row><row><cell>AssertionBench [187]</cell><cell></cell><cell>‚úì</cell><cell>‚úì</cell><cell></cell><cell>2025-02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 ,</head><label>10</label><figDesc>most of these approaches rely on prompt engineering to enhance security verification and threat detection.</figDesc><table><row><cell></cell><cell></cell><cell>LLM for Hardware Security</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">New Model Dataset Model Dataset Benchmark Engineering New Open Open Open Prompt</cell><cell>Date</cell></row><row><cell>Pearce et al. [212]</cell><cell></cell><cell>‚úì</cell><cell>‚úì</cell><cell>2021-12</cell></row><row><cell>Baleegh et al. [203]</cell><cell></cell><cell></cell><cell>‚úì</cell><cell>2023-02</cell></row><row><cell>Kande et al. [188]</cell><cell></cell><cell>‚úì</cell><cell>‚úì</cell><cell>2023-06</cell></row><row><cell>DIVAS [179]</cell><cell></cell><cell></cell><cell>‚úì</cell><cell>2023-08</cell></row><row><cell>NSPG [178]</cell><cell>‚úì</cell><cell>‚úì</cell><cell></cell><cell>2023-08</cell></row><row><cell>SCAR [211]</cell><cell></cell><cell></cell><cell>‚úì</cell><cell>2023-10</cell></row><row><cell>Netlist Whisperer [210]</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Wenji Fang, Jing Wang, Yao Lu, Shang Liu, Yuchao Wu, Yuzhe Ma, and Zhiyao Xie</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">ACKNOWLEDGMENTS</head><p>This work is supported by <rs type="funder">Hong Kong Research Grants Council (RGC) CRF</rs> Grant <rs type="grantNumber">C6003-24Y</rs> and <rs type="projectName">ACCESS -AI Chip Center for Emerging Smart Systems</rs>, sponsored by <rs type="funder">InnoHK, Hong Kong SAR</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Brd5zxE">
					<idno type="grant-number">C6003-24Y</idno>
					<orgName type="project" subtype="full">ACCESS -AI Chip Center for Emerging Smart Systems</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt Engineering</head><p>Fine-tuned DAVE Nov. 2020 Fig. <ref type="figure">12</ref>. Timeline of works on RTL generation, covered in Section 5.1. The timeline also includes the works of generation for design optimization (e.g., BetterV <ref type="bibr" target="#b140">[141]</ref>). Recent works (e.g., Origen <ref type="bibr" target="#b142">[143]</ref> and Verilog-Coder <ref type="bibr" target="#b143">[144]</ref>) show a trend of utilizing feedback from EDA tools to improve generation quality.</p><p>(1) Prompt engineering. This approach designs specific prompts to guide LLMs in generating RTL outputs. The effectiveness of the generated code largely hinges on the quality of these prompts, which often requires iterative refinements and experimental trial-and-error.</p><p>Well-crafted prompts can lead to correct and even high-quality RTL code.</p><p>(2) LLMs trained on private datasets with instruction-code pairs. This approach fine-tunes LLMs (based on already pre-trained LLMs) using proprietary data, such as industrial inhouse circuit designs. It tailors models to an organization's needs, enhancing performance but requires significant resources and access to high-quality private data. <ref type="bibr" target="#b2">(3)</ref> LLMs trained on open datasets with code only. This approach uses open-source codebases to fine-tune LLMs, eliminating the need for labor-intensive, high-quality datasets that require manual annotation. Such unsupervised fine-tuning process can help LLMs capture inherent structures of RTL code but is less effective for instruction-following tasks. (4) LLMs trained on open datasets with instruction-code pairs. Fine-tunes models on pairs of design specifications and RTL implementations, helping them translate specifications into code. This requires a large number of high-quality pairs, which can be challenging to obtain but is quite effective in boosting LLMs' ability on hardware code generation tasks.</p><p>The first strategy, prompt engineering, primarily leverages commercial LLMs via API calls. In contrast, the other three strategies focus on customizing local LLMs by fine-tuning pre-trained models, mostly from open-source communities. Each strategy has its own advantages and drawbacks. Commercial models (e.g., GPT) reduce the substantial costs of training and deploying LLMs but may raise security and intellectual property concerns. On the other hand, fine-tuning local open-sourced LLMs (e.g., Llama, DeepSeek) can address these security and IP issues but requires significant resources and limits the model size. Smaller-scale customized LLMs tend to be less general compared with large commercial solutions.</p><p>The four distinct strategies for RTL generation using LLMs present unique advantages and challenges. Prompt engineering focuses on crafting precise prompts to guide LLMs in generating RTL code, which usually involves iterative refinement with EDA tools. In contrast, LLMs trained on private datasets ('Supervised Fine-Tuning', denoted as 'SFT' in Table <ref type="table">5</ref>) enhance model performance by fine-tuning them with proprietary data tailored to specific organizational needs. However, this method demands computational resources for fine-tuning, and the private circuit dataset is not open-sourced to facilitate the advancement of the community. Alternatively, LLMs trained on open datasets with code only ('Unsupervised Fine-Tuning', denoted as 'UFT' in Table <ref type="table">5</ref>) leverage open-source codebases for unsupervised fine-tuning, reducing the need for labor-intensive dataset preparation. However, this approach is less effective for RTL generation, which requires strict adherence to specific instructions including design descriptions. The UFT trains LLMs to predict The design specification will be combined with manually designed structure analysis and design principles (in VerilogCoder <ref type="bibr" target="#b143">[144]</ref>), and then the LLMs will take the prompt to generate corresponding RTL code. Most early works (RTLLM <ref type="bibr" target="#b11">[12]</ref>, AutoVCoder <ref type="bibr" target="#b139">[140]</ref>) on RTL generation stop at this step. The more recent works incorporate the feedback from EDA tools into the design flow, for example, utilizing the error information and mismatch log to prompt LLMs for rewriting. Recently, VerilogCoder <ref type="bibr" target="#b143">[144]</ref> presents a novel framework utilizing multiple AI agents to automate Verilog code generation and correction. It introduces a task and circuit relation graph for structured task decomposition, ensuring the inclusion of essential signal and state transition details. The system incorporates an AST-based waveform tracing tool for debugging, allowing agents to identify and correct functional errors. Using the ReAct <ref type="bibr" target="#b240">[241]</ref> technique, agents iteratively interact with Verilog tools, including syntax checkers and simulators, to refine the code. This methodology significantly enhances the automation of circuit design.</p><p>Strategy 2: LLMs trained on private dataset with instruction-code pairs. Aside from prompt engineering for circuit design generation, another powerful technique is fine-tuning. Finetuning can be categorized into unsupervised fine-tuning and supervised fine-tuning. Here we focus on models that utilize supervised fine-tuning on private datasets. Many solutions in this domain are developed by industrial companies or in collaboration with industrial organizations. As a result, the models or datasets are often not open-sourced. DAVE <ref type="bibr" target="#b131">[132]</ref> presents a pioneering custom dataset generation process that employs a template-based approach to create instruction-code pairs. They frame the Verilog generation task as a machine translation problem, fine-tuning a GPT-2 model to produce Verilog code from English descriptions. The training dataset generation process utilizes "Task/Result metastructure" that outlines the type of digital design task and relevant details, together with templates representing various scenarios such as combinational assignments and registers. The generated dataset is not open-sourced but includes diverse task instances to aid in fine-tuning the model. AutoVCoder <ref type="bibr" target="#b139">[140]</ref> is a framework designed to improve the accuracy of LLMs in generating Verilog code. It addresses the challenges of low syntactic and functional correctness in LLM-generated RTL code by employing three key techniques: a high-quality hardware dataset generation method, a two-round LLM fine-tuning process, and a domain-specific RAG mechanism. The framework uses a code scorer to filter a large dataset of Verilog code from GitHub and generates a synthetic dataset using GPT-3.5. The two-round fine-tuning leverages these datasets, and the RAG module is designed to enhance the process by providing relevant context during code generation. OriGen <ref type="bibr" target="#b142">[143]</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLM for Design Optimization Works</head><p>Open Link Date Martine et al. <ref type="bibr" target="#b172">[173]</ref> 2023-07 Sandal et al. <ref type="bibr" target="#b160">[161]</ref> 2024-01 BetterV <ref type="bibr" target="#b140">[141]</ref> 2024-02 DeLorenzo et al. <ref type="bibr" target="#b161">[162]</ref> 2024-02 RTLRewriter <ref type="bibr" target="#b171">[172]</ref> ‚úì <ref type="url" target="https://github.com/yaoxufeng/RTLRewriter-Bench">https://github.com/yaoxufeng/RTLRewriter-Bench</ref> 2024-09 Xu et al. <ref type="bibr" target="#b173">[174]</ref> 2024-10</p><p>Table <ref type="table">7</ref>. Collection of works on design optimization, covered in Section 5.3.</p><p>efficiency and practicality. Recent advancements have explored optimizing LLM-generated circuits, focusing on both RTL code optimization and HLS code optimization to enhance hardware performance. A detailed comparison of existing works in this domain is provided in Table <ref type="table">7</ref>. RTL code optimization. RTL code optimization leverages LLMs to refine hardware designs for better efficiency, focusing on improving PPA metrics. For example, ChipGPT <ref type="bibr" target="#b132">[133]</ref> employs an enumerative search strategy, generating multiple design variations and selecting the one with the best PPA. BetterV <ref type="bibr" target="#b140">[141]</ref> fine-tunes LLMs on domain-specific Verilog datasets, applying instructtuning and generative discriminators to improve Verilog code quality and optimize synthesis outcomes. However, current evaluations in BetterV primarily assess design quality based on AIG node reduction during synthesis, without directly considering final PPA metrics. RTLRewriter <ref type="bibr" target="#b171">[172]</ref> introduces a framework for RTL code rewriting, breaking down large circuits into smaller segments to enhance synthesis efficiency and leveraging multi-modal program analysis to incorporate visual and textual information. Its benchmark demonstrates superior performance compared to traditional RTL compilers such as Yosys and E-graph. Additionally, the work by Mart√≠nez et al. <ref type="bibr" target="#b172">[173]</ref> focuses on identifying key computational patterns like GEMM, convolution, and FFT within hardware code using LLM-based prompting techniques. Their method reduces false positives by employing a two-phase prompting approach, first interpreting the code and then verifying algorithm presence, highlighting the importance of prompt engineering for optimizing LLM-driven hardware design.</p><p>HLS code optimization. Besides RTL code optimization, optimizing HLS code, particularly pragma optimization, is a crucial task in high-level synthesis. Xu et al. <ref type="bibr" target="#b173">[174]</ref> propose RALAD (Retrieve Augmented Large Language Model Aided Design), a framework leveraging LLMs and RAG to optimize HLS programs without requiring computationally expensive fine-tuning. HLS allows circuit design using high-level languages like C/C++, but manual optimization remains highly expertise-driven. RALAD mitigates this challenge by embedding user code and a knowledge base (e.g., FPGA textbooks), retrieving relevant code snippets via a top-k search, generating prompts that incorporate user instructions and retrieved snippets, and using an LLM like CodeLlama to produce optimized code. The study also explores the impact of manual annotations to further refine optimization quality, demonstrating the framework's effectiveness in automating HLS code improvements. Fix Syntax Fix Functionality Fig. <ref type="figure">17</ref>. Overview of the LLM-based flow for RTL debugging, recent works are covered in Section 5.5. This approach includes two input methods for LLM solutions: the first method assigns debugging tasks directly to the LLM without supplementary information, while the second method enhances the debugging process by incorporating error information from EDA tools. This error log can be input directly into the LLM or used to query a pre-defined debugging database (RAG). Additionally, some approaches utilize AST or waveform tracing tools to more effectively identify problematic code segments. ‚úì 2024-03 VeriAssist <ref type="bibr" target="#b190">[191]</ref> 2024-05 MEIC <ref type="bibr" target="#b198">[199]</ref> 2024-05 Qayyum et al. <ref type="bibr" target="#b203">[204]</ref> 2024-06 VerilogCoder <ref type="bibr" target="#b143">[144]</ref> ‚úì 2024-08 UVLLM <ref type="bibr" target="#b182">[183]</ref> ‚úì ‚úì <ref type="url" target="https://github.com/amyuch/UVLLM">https://github.com/amyuch/UVLLM</ref> 2024-11</p><p>Table <ref type="table">9</ref>. Explorations in LLM-aided RTL code debugging (Section 5.5).</p><p>RTL debugging focuses on resolving errors identified during the verification process. Unlike verification, which primarily detects inconsistencies, debugging involves both locating and correcting these issues to ensure functional correctness. For example, representative debugging works <ref type="bibr" target="#b175">[176,</ref><ref type="bibr" target="#b190">191,</ref><ref type="bibr" target="#b198">199]</ref> leverage LLMs for both bug detection and bug fixing, emphasizing the automated correction of RTL errors. The debugging process typically consists of two key steps: (1) identifying the bug by pinpointing the exact error location within the RTL code and (2) fixing the bug by generating corrected RTL logic. While verification highlights potential failures, debugging requires deeper reasoning to determine the root cause of errors and propose appropriate fixes. Table <ref type="table">9</ref> and Figure <ref type="figure">16</ref> demonstrate the comparison and timeline of these explorations, respectively.</p><p>RTL bugs are broadly categorized into syntax bugs and functional bugs <ref type="bibr" target="#b198">[199]</ref>. Syntax bugs, such as missing semicolons or incorrect module instantiations, can be directly flagged by compilers (i.e., synthesis tools). Functional bugs, on the other hand, require executing test cases or formal verification to identify behavioral mismatches. Based on this classification, we categorize existing works in LLM-assisted RTL debugging into syntax debugging and functional debugging. Since functional debugging involves more complex reasoning and deeper analysis of design behavior, tools capable of addressing both syntax and functional errors are classified as functional debuggers.</p><p>Syntax debugging. RTLFixer <ref type="bibr" target="#b175">[176]</ref> and HDLDebugger <ref type="bibr" target="#b199">[200]</ref> are among the pioneering works to explore LLM-assisted RTL syntax debugging. Both works leverage the RAG technique to improve debugging accuracy by transforming syntax-buggy RTL code into syntax-correct RTL designs. RTLFixer <ref type="bibr" target="#b175">[176]</ref> integrates RAG and ReAct prompting, creating an autonomous debugging agent that retrieves expert guidance and applies iterative reasoning to correct syntax errors effectively. It also introduces VerilogEval-Syntax, a debugging dataset consisting of 212 erroneous Verilog</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NVIDIA Blackwell Platform: Advancing Generative AI and Accelerated Computing</title>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hot Chips Symposium (HCS)</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">As chip design costs skyrocket, 3nm process node is in jeopardy</title>
		<author>
			<persName><surname>Ibs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Machine learning for electronic design automation: A survey</title>
		<author>
			<persName><forename type="first">Guyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoyang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juejian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanfan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengrui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MLCAD: A survey of research in machine learning for CAD keynote paper</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hussam</forename><surname>Amrouch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marilyn</forename><surname>David Z Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J√∂rg</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><surname>Henkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">AI-driven design applications</title>
		<author>
			<persName><forename type="middle">Dso</forename><surname>Synopsys</surname></persName>
		</author>
		<author>
			<persName><surname>Ai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Cadence Cerebrus intelligent chip explorer</title>
		<author>
			<persName><surname>Cadence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Hierarchical text-conditional image generation with clip latents</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Casey</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Josh</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lama</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilge</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florencia</forename><surname>Leoni Aleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janko</forename><surname>Altenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Altman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">Shyamal Anadkat, et al. GPT-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Large circuit models: opportunities and challenges</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhufei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ru</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadaf</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingquan</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<publisher>Springer Science China Information Sciences</publisher>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">RTLLM: An open-source benchmark for design rtl generation with large language model</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teodor-Dumitru</forename><surname>Ene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathaniel</forename><surname>Pinckney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongjian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonah</forename><surname>Alben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Himyanshu</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanmitra</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ismet</forename><surname>Bayraktaroglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.00176</idno>
		<title level="m">Domain-Adapted LLMs for Chip Design</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathaniel</forename><surname>Pinckney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Verilogeval</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.07544</idno>
		<title level="m">Evaluating large language models for verilog code generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Benchmarking large language models for automated verilog rtl code generation</title>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenxing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<title level="m">Machine Learning Applications in Electronic Design Automation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Annotating slack directly on your verilog: Fine-grained rtl timing evaluation for early optimization</title>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Restructure-tolerant timing prediction via multimodal fusion</title>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A timing engine inspired graph neural network model for pre-routing slack prediction</title>
		<author>
			<persName><forename type="first">Zizheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Machine learning-based pre-routing timing prediction with reduced pessimism</title>
		<author>
			<persName><forename type="first">Erick</forename><surname>Carvajal Barboza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishchal</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using machine learning to predict path-based slack from graph-based timing analysis</title>
		<author>
			<persName><forename type="first">Uday</forename><surname>Andrew B Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Mallappa</surname></persName>
		</author>
		<author>
			<persName><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Design (ICCD)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pre-placement net length and timing estimation by customized graph neural network</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongjian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">MasterRTL: A pre-synthesis PPA estimation framework for any RTL design</title>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ceyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Wu</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transferable pre-synthesis PPA estimation for RTL designs with data augmentation techniques</title>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ceyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Wu</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast, robust and transferable prediction for hardware logic synthesis</title>
		<author>
			<persName><forename type="first">Ceyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pragya</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Wu</forename><surname>Wills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How good is your Verilog RTL code? A quick answer from machine learning</title>
		<author>
			<persName><forename type="first">Prianka</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakash</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Autopower: Automated few-shot architecture-level power modeling by power group decoupling</title>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Firepower: Towards a foundation with generalizable knowledge for architecture-level power modeling</title>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Powpredict: Cross-stage power prediction with circuit-transformation-aware learning</title>
		<author>
			<persName><forename type="first">Yufan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zizheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xun</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuomin</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runsheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ru</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Panda: Architecture-level power evaluation by unifying analytical and machine learning solutions</title>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanglei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Aided Design (ICCAD)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">APOLLO: An automated power modeling framework for runtime power introspection in high-volume commercial microprocessors</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Knebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kumaraguru</forename><surname>Palaniswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanrui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shidhartha</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PRIMAL: Power inference using machine learning</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiru</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Simmani: Runtime power modeling for arbitrary RTL with automatic signal selection</title>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanoviƒá</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">DEEP: Developing extremely efficient runtime on-chip power meters</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">GRANNITE: Graph neural network inference for transferable power estimation</title>
		<author>
			<persName><forename type="first">Yanqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PowerNet: Transferable dynamic IR drop estimation via maximum convolutional neural network</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santosh</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">IncPIRD: Fast learning-based prediction of incremental IR drop</title>
		<author>
			<persName><forename type="first">Chia-Tung</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">B</forename><surname>Kahng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">IR drop prediction with maximum convolutional neural network</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">533</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">MAVIREC: Ml-aided vectored ir-drop estimation and classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vidya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqing</forename><surname>Chhabria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><forename type="middle">S</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><surname>Sapatnekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Machine-learning-based dynamic IR drop prediction for ECO</title>
		<author>
			<persName><forename type="first">Yen-Chun</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yan</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Mo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric Jia-Wei</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">RouteNet: Routability prediction for mixed-size designs using convolutional neural network</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Hung</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guan-Qi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Shao-Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Global placement with deep learning-enabled explicit routability optimization</title>
		<author>
			<persName><forename type="first">Siting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyu</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Lay-net: Grafting netlist knowledge on layout-based congestion prediction</title>
		<author>
			<persName><forename type="first">Su</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lancheng</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">PROS: A plug-in for routability optimization applied in the state-of-the-art commercial EDA tool using deep learning</title>
		<author>
			<persName><forename type="first">Jingsong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-H</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangeline Fy</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automatic routability predictor development using neural architecture search</title>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tunhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiyi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongjian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joydeep</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Fallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Towards collaborative intelligence: Routability estimation based on decentralized private data</title>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minxue</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tunhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Routability-driven macro placement with embedded cnn-based prediction model</title>
		<author>
			<persName><forename type="first">Yu-Hung</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guan-Qi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao-Chun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Shao-Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Routing-free crosstalk prediction</title>
		<author>
			<persName><forename type="first">Rongjian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwook</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishnavi</forename><surname>Chauha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gi-Joon</forename><surname>Nam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Exact and efficient crosstalk estimation</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sachin</surname></persName>
		</author>
		<author>
			<persName><surname>Sapatnekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Si for free: machine learning of interconnect coupling delay and transition effects</title>
		<author>
			<persName><forename type="first">Mulong</forename><surname>Andrew B Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><surname>Nath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on System Level Interconnect Prediction (SLIP)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Layout hotspot detection with feature tensor generation and deep biased learning</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangeline Fy</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Hotspot detection via attention-based deep layout metric learning</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Hao Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Lithography hotspot detection: From shallow to deep learning</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangeline Fy</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International System-on-Chip Conference (SOCC)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Gamora: Graph learning based symbolic reasoning for large-scale boolean networks</title>
		<author>
			<persName><forename type="first">Nan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Gnn-re: Graph neural networks for reverse engineering of gate-level netlists</title>
		<author>
			<persName><forename type="first">Lilas</forename><surname>Alrahis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhrajit</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johann</forename><surname>Knechtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satwik</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hani</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baker</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Al-Qutayri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ozgur</forename><surname>Sinanoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Reignn: State register identification using graph neural networks for circuit reverse engineering</title>
		<author>
			<persName><forename type="first">Kaixin</forename><surname>Subhajit Dutta Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierluigi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Nuzzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Graph learning-based arithmetic block identification</title>
		<author>
			<persName><forename type="first">Zhuolun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">High performance graph convolutional networks with applications in testability analysis</title>
		<author>
			<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harbinder</forename><surname>Sikka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC))</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">FIST: A feature-importance sampling and tree-based method for automatic design flow parameter tuning</title>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guan-Qi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Hung</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><surname>Shao-Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erick</forename><forename type="middle">Carvajal</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Barboza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Flowtune: End-to-end automatic logic optimization exploration via domain-specific multiarmed bandit</title>
		<author>
			<persName><forename type="first">Walter</forename><surname>Lau Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Emmanuel</forename><surname>Gaillardon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxi</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Flowtuner: A multi-stage eda flow tuner exploiting parameter knowledge transfer</title>
		<author>
			<persName><forename type="first">Rongjian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwook</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lakshmi</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Lvov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gi-Joon</forename><surname>Nam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Boom-explorer: Risc-v boom microarchitecture design space exploration framework</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin Df</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">On learning-based methods for design-space exploration with high-level synthesis</title>
		<author>
			<persName><forename type="first">Hung-Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><forename type="middle">P</forename><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">High-level synthesis design space exploration: Past, present, and future</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Carrion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Schafer</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">RL-sizer: VLSI gate sizing for timing optimization using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Yi-Chen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishal</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung</forename><forename type="middle">Kyu</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Rl-ccd: Concurrent clock and data optimization using attention-based self-supervised reinforcement learning</title>
		<author>
			<persName><forename type="first">Yi-Chen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ting</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudipto</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishal</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung</forename><forename type="middle">Kyu</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">Ruizhe</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingbo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiong</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhentao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui-Ling</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianye</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.12224</idno>
		<title level="m">Llm4eda: Emerging progress in large language models for electronic design automation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A survey of research in large language models for electronic design automation</title>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanglei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Hardware design and verification with large language models: A scoping review, challenges, and open issues</title>
		<author>
			<persName><forename type="first">Meisam</forename><surname>Abdollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyedeh</forename><surname>Faegheh Yeganli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amir Baharloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Baniasadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
			<publisher>MDPI Electronics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Llm for soc security: A paradigm shift</title>
		<author>
			<persName><forename type="first">Dipayan</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shams</forename><surname>Tarek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katayoon</forename><surname>Yahyaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujan</forename><forename type="middle">Kumar</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Tehranipoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farimah</forename><surname>Farahmandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Llms for hardware security: Boon or bane?</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Kande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudev</forename><surname>Gohil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Delorenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeyavijayan</forename><surname>Rajendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI Test Symposium (VTS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Llms and the future of chip design: Unveiling security risks and building trust</title>
		<author>
			<persName><forename type="first">Zeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilas</forename><surname>Alrahis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Likhitha</forename><surname>Mankali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johann</forename><surname>Knechtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ozgur</forename><surname>Sinanoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Society Annual Symposium on VLSI (ISVLSI)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Navigating soc security landscape on llm-guided paths</title>
		<author>
			<persName><forename type="first">Sudipta</forename><surname>Paria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aritra</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swarup</forename><surname>Bhunia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Great Lakes Symposium on VLSI (GLSVLSI)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Kangwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruidi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuorui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Li Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Schlichtmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.18582</idno>
		<title level="m">Llm-aided efficient hardware design automation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Software-hardware co-design for fast and scalable training of deep learning recommendation models</title>
		<author>
			<persName><forename type="first">Dheevatsa</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ozdal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jade</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongsoo</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Lcm: Llm-focused hybrid spm-cache architecture with cache management for multi-core ai accelerators</title>
		<author>
			<persName><forename type="first">Chengtao</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongchun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akash</forename><surname>Poptani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Supercomputing (ICS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Neupims: Npu-pim heterogeneous acceleration for batched llm inferencing</title>
		<author>
			<persName><forename type="first">Guseul</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangyeop</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehong</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunmin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanghyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyungkyu</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gwangsun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divya</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongse</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Abc: An academic industrial-strength verification tool</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Mishchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Aided Verification (CAV)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Logic synthesis and verification algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><surname>Somenzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Ldc-1: a transportable, knowledge-based natural language processor for office environments</title>
		<author>
			<persName><forename type="first">Bruce</forename><forename type="middle">W</forename><surname>Ballard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>Lusth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><forename type="middle">L</forename><surname>Tinkham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Recurrent neural network based language model</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Karafiat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukavs</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Honza Cernocky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition</title>
		<author>
			<persName><surname>Sak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.1128</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Masked autoencoders are scalable vision learners</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Doll√°r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Lasse Espeholt, Oriol Vinyals, Alex Graves, and Koray Kavukcuoglu. Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Align before fuse: Vision and language representation learning with momentum distillation</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramprasaath</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhilesh</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Visual instruction tuning</title>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Video-llava: Learning united visual representation by alignment before projection</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Munan</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.10122</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Scaling autoregressive models for content-rich text-to-image generation</title>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Yu Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Baid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burcu</forename><surname>Karagol Ayan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.10789</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Circuitfusion: multimodal circuit representation learning for agile chip design</title>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadaf</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.11095</idno>
		<title level="m">Deepgate3: towards scalable circuit representation learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Robust gnn-based representation learning for hls</title>
		<author>
			<persName><forename type="first">Atefeh</forename><surname>Sohrabizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Cross-modality program representation learning for electronic design automation with high-level synthesis</title>
		<author>
			<persName><forename type="first">Zongyue</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atefeh</forename><surname>Sohrabizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Machine Learning for CAD (MLCAD)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Learning semantic representations to verify hardware designs</title>
		<author>
			<persName><forename type="first">Shobha</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><forename type="middle">Joe</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">A self-supervised, pre-trained, and cross-stage-aligned circuit encoder provides a foundation for various design tasks</title>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">DeepGate: Learning neural representations of logic gates</title>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadaf</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naixing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">DeepGate2: Functionality-aware circuit representation learning</title>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadaf</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui-Ling</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhufei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Deepgate4: Efficient and effective representation learning for circuit design at scale</title>
		<author>
			<persName><forename type="first">Ziyang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Less is more: Hop-wise graph attention for scalable and generalizable learning on circuits</title>
		<author>
			<persName><forename type="first">Chenhui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gokce</forename><surname>Sarar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiru</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Polargate: Breaking the functionality representation bottleneck of and-inverter graph neural network</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Deepseq: Deep sequential circuit learning</title>
		<author>
			<persName><forename type="first">Sadaf</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Deepseq2: Enhanced sequential circuit learning with disentangled representations</title>
		<author>
			<persName><forename type="first">Sadaf</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Functionality matters in netlist representation learning</title>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuolun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Fgnn2: A powerful pre-training framework for learning the logic functionality of circuits</title>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuolun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Circuit representation learning with masked gatemodeling and verilog-aigalignment</title>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haisheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Nettag: A multimodal rtl-and-layoutaligned netlist foundation model via text-attributed graph</title>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Deepcell: Multiview representation learning for post-mapping netlists</title>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhufei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.06816</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Versatile multi-stage graph neural network for circuit representation</title>
		<author>
			<persName><forename type="first">Shuwen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingxueff</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianye</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Tag: Learning circuit spatial embedding from layouts</title>
		<author>
			<persName><forename type="first">Keren</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">F</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Hsuan</forename><surname>Kokai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Llm-hd: Layout language model for hotspot detection with gds semantic encoding</title>
		<author>
			<persName><forename type="first">Yuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Towards a comprehensive benchmark for high-level synthesis targeted to fpgas</title>
		<author>
			<persName><forename type="first">Yunsheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atefeh</forename><surname>Sohrabizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongyue</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">RT-level ITC&apos;99 benchmarks and first ATPG results</title>
		<author>
			<persName><forename type="first">Fulvio</forename><surname>Corno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Sonza Reorda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Squillero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Design and Test of Computers</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m">OpenCores: The reference community for Free and Open Source gateware IP cores</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">Chipyard: Integrated design, simulation, and implementation framework for custom SoCs</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abraham</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Grubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Pemberton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>IEEE Micro</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<author>
			<persName><surname>Vexriscv</surname></persName>
		</author>
		<author>
			<persName><surname>Vexriscv</surname></persName>
		</author>
		<title level="m">FPGA friendly 32 bit RISC-V CPU implementation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Towards developing high performance risc-v processors using agile methodology</title>
		<author>
			<persName><forename type="first">Yinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guokai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingrui</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianruo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuojun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chowdhury</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.11292</idno>
		<title level="m">Openabc-d: A large-scale dataset for machine learning guided integrated circuit synthesis</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">IWLS 2005 benchmarks</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Albrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Logic and Synthesis (IWLS)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">The epfl combinational benchmark suite</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Amar√∫</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Emmanuel</forename><surname>Gaillardon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Logic and Synthesis (IWLS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Lgsynth93 benchmark set: Version 4.0. Mentor Graphics</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Mcelvain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-05">May, 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">The ispd-2011 routability-driven placement contest and benchmark suite</title>
		<author>
			<persName><forename type="first">Natarajan</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cliff</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gi-Joon</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarrod</forename><forename type="middle">A</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Physical Design (ISPD)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">The dac 2012 routability-driven placement contest and benchmark suite</title>
		<author>
			<persName><forename type="first">Natarajan</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cliff</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoguang</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Iccad-2012 cad contest in fuzzy pattern matching for physical verification and benchmark suite</title>
		<author>
			<persName><forename type="first">Andres</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Iccad-2020 cad contest in routing with cell movement</title>
		<author>
			<persName><forename type="first">Kai-Shun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Jen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao-Chun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guan-Chuen</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Dave: Deriving automatically verilog from english</title>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Machine Learning for CAD (MLCAD)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<author>
			<persName><forename type="first">Kaiyan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haimeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhe</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Chipgpt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14019</idno>
		<title level="m">How far are we from natural language hardware design</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">AIGChip: Towards next-generation AI accelerator design automation via large language models</title>
		<author>
			<persName><forename type="first">Yonggan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongzhi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sixu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaojian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyan</forename><surname>Celine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design (ICCAD)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Blocklove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13243</idno>
		<title level="m">Chip-chat: Challenges and opportunities in conversational hardware design</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Autochip: Automating hdl generation using llm feedback</title>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Blocklove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.04887</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Verigen: A large language model for verilog code generation</title>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Eda-aware rtl generation with large language models</title>
		<author>
			<persName><forename type="first">Humza</forename><surname>Mubashir Ul Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Emmanuel</forename><surname>Sami</surname></persName>
		</author>
		<author>
			<persName><surname>Gaillardon</surname></persName>
		</author>
		<author>
			<persName><surname>Valerio Tenace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.04485</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Codev: Empowering llms for verilog generation through multi-level summarization</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengwei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyuan</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.10424</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Autovcoder: A systematic framework for automated verilog code generation using llms</title>
		<author>
			<persName><forename type="first">Mingzhe</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieru</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenchao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Design (ICCD)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<author>
			<persName><forename type="first">Zehua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui-Ling</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Betterv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03375</idno>
		<title level="m">Controlled verilog generation with discriminative guidance</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Data is all you need: Finetuning llms for chip design via an automated design-data augmentation framework</title>
		<author>
			<persName><forename type="first">Kaiyan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dantong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cangyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.11202</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Origen: Enhancing rtl code generation with code-to-code augmentation and self-reflection</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kexing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youwei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.16237</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Verilogcoder: Autonomous verilog coding agents with graph-based planning and abstract syntax tree (ast)-based waveform tracing tool</title>
		<author>
			<persName><forename type="first">Chia-Tung</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.08927</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Rtlcoder: Fully open-source and efficient llm-assisted rtl code generation technique</title>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<title level="m" type="main">Mg-verilog: Multi-grained dataset towards enhanced llm-assisted verilog generation</title>
		<author>
			<persName><forename type="first">Yongan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongzhi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonggan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyan</forename><surname>Celine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2407.01910</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Creativeval: Evaluating creativity of llm-based hardware code generation</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Delorenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudev</forename><surname>Gohil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeyavijayan</forename><surname>Rajendran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.08806</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Vhdl-eval: A framework for evaluating large language models in vhdl code generation</title>
		<author>
			<persName><forename type="first">Prashanth</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luyao</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ambrogio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Mackin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorva</forename><surname>Nitsure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Beymer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Degan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LLM Aided Design Workshop</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Natural language is not enough: Benchmarking multi-modal generative ai for verilog generation</title>
		<author>
			<persName><forename type="first">Kaiyan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haobo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cangyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhe</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.08473</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Opl4gpt: An application space exploration of optimal programming language for hardware design by llm</title>
		<author>
			<persName><forename type="first">Kimia</forename><surname>Tasnia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sazadur</forename><surname>Rahman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<author>
			<persName><forename type="first">Bowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Rtlsquad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.05470</idno>
		<title level="m">Multi-agent based interpretable rtl design</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hejia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongming</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jishen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><surname>Mage</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.07822</idno>
		<title level="m">A multi-agent engine for automated rtl code generation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Allam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Shalan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.17378</idno>
		<title level="m">Rtl-repo: A benchmark for evaluating llms on large-scale rtl design projects</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Openllm-rtl: Open dataset and benchmark for llm-aided design rtl generation</title>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">Classification-based automatic hdl code generation using llms</title>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Li Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xunzhao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Schlichtmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.18326</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">Deeprtl: Bridging verilog understanding and generation with a unified representation model</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeju</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.15832</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Craftrtl: High-quality synthetic data generation for verilog code models with correct-by-construction non-textual representations and targeted code repair</title>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Da</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.12993</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Generating secure hardware using chatgpt resistant to cwes</title>
		<author>
			<persName><forename type="first">Madhav</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Sadhukhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debdeep</forename><surname>Mukhopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<title level="m" type="main">Rome was not built in a single step: Hierarchical prompting for llm-based chip design</title>
		<author>
			<persName><forename type="first">Andre</forename><surname>Nakkab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><surname>Garg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.18276</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Chain-of-descriptions: Improving code llms for vhdl code generation and summarization</title>
		<author>
			<persName><forename type="first">Prashanth</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorva</forename><surname>Nitsure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Mackin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luyao</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ambrogio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Haran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viresh</forename><surname>Paruthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Elzein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Coops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Beymer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Machine Learning for CAD (MLCAD)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main">Zero-shot rtl code generation with attention sink augmented large language models</title>
		<author>
			<persName><forename type="first">Selim</forename><surname>Sandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ismail</forename><surname>Akturk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.08683</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title level="m" type="main">Make every move count: Llm-based high-quality rtl code generation using mcts</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Delorenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Basak Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudev</forename><surname>Gohil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeyavijayan</forename><surname>Rajendran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.03289</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<title level="m" type="main">Large language model for verilog generation with golden code feedback</title>
		<author>
			<persName><forename type="first">Ning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingkun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Guan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.18271</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<author>
			<persName><forename type="first">Emil</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maoyang</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T Hui</forename><surname>Teo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.07039</idno>
		<title level="m">From english to asic: Hardware implementation with large language model</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<title level="m" type="main">Revisiting verilogeval: Newer llms, in-context learning, and specification-to-rtl tasks</title>
		<author>
			<persName><forename type="first">Nathaniel</forename><surname>Pinckney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Batten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Khailany</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.11053</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<title level="m" type="main">Lintllm: An open-source verilog linting framework based on large language models</title>
		<author>
			<persName><forename type="first">Zhigang</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huadong</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.10815</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<author>
			<persName><forename type="first">Chenwei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Hlspilot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.06810</idno>
		<title level="m">Llm-based high-level synthesis</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<author>
			<persName><forename type="first">Luca</forename><surname>Collini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.00214</idno>
		<title level="m">C2hlsc: Leveraging large language models to bridge the software-tohardware design gap</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title level="m" type="main">Synthai: A multi agent generative ai framework for automated modular hls design generation</title>
		<author>
			<persName><forename type="first">Arash</forename><surname>Seyed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Sheikholeslam</surname></persName>
		</author>
		<author>
			<persName><surname>Ivanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.16072</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Are llms any good for high-level synthesis</title>
		<author>
			<persName><forename type="first">Yuchao</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tosiron</forename><surname>Adegbija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Lysecky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.10428</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Exploring code language models for automated hls-based hardware generation: Benchmark, infrastructure and analysis</title>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhican</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanru</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxiang</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<monogr>
		<author>
			<persName><forename type="first">Xufeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingzhao</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Rtlrewriter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.11414</idno>
		<title level="m">Methodologies for large models aided rtl code optimization</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Code detection for hardware acceleration using large language models</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Antonio Mart√≠nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregorio</forename><surname>Bernab√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos√©</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garc√≠a</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Optimizing high-level synthesis designs with retrieval-augmented large language models</title>
		<author>
			<persName><forename type="first">Haocheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sitao</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LLM Aided Design Workshop</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<monogr>
		<title level="m" type="main">Advanced large language model (llm)-driven verilog development: Enhancing power, performance, and area optimization in code synthesis</title>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaotian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongwu</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiwen</forename><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.01022</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title level="m" type="main">Rtlfixer: Automatically fixing rtl syntax errors with large language models</title>
		<author>
			<persName><forename type="first">Yunda</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.16543</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b176">
	<monogr>
		<title level="m" type="main">Using LLMs to facilitate formal verification of RTL</title>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Orenes-Vera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wentzlaff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.09437</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Unlocking hardware security assurance: The potential of llms</title>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amisha</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Arunachalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avik</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Henrique</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafail</forename><surname>Psiakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiorgos</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanad</forename><surname>Basu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.11042</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b178">
	<monogr>
		<title level="m" type="main">Divas: An llm-based end-to-end framework for soc security analysis and policy-based protection</title>
		<author>
			<persName><forename type="first">Sudipta</forename><surname>Paria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aritra</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swarup</forename><surname>Bhunia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.06932</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Simeval: Investigating the similarity obstacle in llm-based hardware code generation</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Akyash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mardani</forename><surname>Hadi</surname></persName>
		</author>
		<author>
			<persName><surname>Kamali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">AssertLLM: Generating and evaluating hardware verification assertions from design specifications via multi-LLMs</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<author>
			<persName><forename type="first">Bhabesh</forename><surname>Mali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Maddala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sweeya</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vatsal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandan</forename><surname>Karfa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><surname>Chiraag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.00093</idno>
		<title level="m">Chatgpt informed rapid and automated assertion generation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">Uvllm: An automated universal rtl verification framework using llms</title>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingrong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Shan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.16238</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">Llm4dv: Using large language models for hardware test stimuli generation</title>
		<author>
			<persName><forename type="first">Zixi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Chadwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Mcnally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiren</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mullins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.04535</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<author>
			<persName><forename type="first">Ruiyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><surname>Verilogreader</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.04373</idno>
		<title level="m">Llm-aided hardware test generation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Fveval: Understanding language model capabilities in formal verification of digital hardware</title>
		<author>
			<persName><forename type="first">Minwoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghaith</forename><surname>Bany Hamad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Suhaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.23299</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">Assertionbench: A benchmark to evaluate large-language models for assertion generation</title>
		<author>
			<persName><forename type="first">Vaishnavi</forename><surname>Pulavarthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deeksha</forename><surname>Nandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Soham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debjit</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.18627</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">(security) assertions by large language models</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Kande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeyavijayan</forename><surname>Rajendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Towards improving verification productivity with circuitaware translation of natural language to systemverilog assertions</title>
		<author>
			<persName><forename type="first">Chuyue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Trippel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Deep Learning-aided Verification (DAV)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Domain-adapted llms for vlsi design and verification: A case study on formal verification</title>
		<author>
			<persName><forename type="first">Mingjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minwoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghaith</forename><surname>Bany Hamad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Suhaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI Test Symposium (VTS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title level="m" type="main">Towards llm-powered verilog rtl assistant: Self-verification and self-correction</title>
		<author>
			<persName><forename type="first">Hanxian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jishen</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.00115</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Kande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeyavijayan</forename><surname>Rajendran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.14027</idno>
		<title level="m">Llm-assisted generation of hardware assertions</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b192">
	<monogr>
		<title level="m" type="main">Fixing hardware security bugs with large language models</title>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.01215</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Llm-based processor verification: A case study for neuronnorphic processor</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huadong</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weixia</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<title level="m" type="main">Llm-aided testbench generation and bug detection for finite-state machines</title>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Bhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johann</forename><surname>Knechtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.17132</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b195">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Blocklove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.02326</idno>
		<title level="m">Evaluating llms for hardware design and test</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youshu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingkun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2503.04057</idno>
		<title level="m">Insights from rights and wrongs: A large language model for solving assertion failures in rtl design</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<title level="m" type="main">Are llms ready for practical adoption for assertion generation</title>
		<author>
			<persName><forename type="first">Vaishnavi</forename><surname>Pulavarthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deeksha</forename><surname>Nandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Soham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debjit</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.20633</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.06840</idno>
		<title level="m">Meic: Re-thinking rtl debug automation using llms</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<author>
			<persName><forename type="first">Xufeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsz</forename><surname>Ho Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Hdldebugger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.11671</idno>
		<title level="m">Streamlining hdl debugging with large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Invited paper: Software/hardware co-design for llm and its application for design verification</title>
		<author>
			<persName><forename type="first">Lily</forename><surname>Jiaxin Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanchen</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deming</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">Llm4sechw: Leveraging domain-specific large language model for hardware debugging</title>
		<author>
			<persName><forename type="first">Weimin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaichen</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Hardware Oriented Security and Trust Symposium (AsianHOST)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
	<note>Raj Gautam Dutta, Xiaolong Guo, and Gang Qu</note>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">On hardware security bug code fixes by prompting large language models</title>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">From bugs to fixes: Hdl bug identification and patching using llms and rag</title>
		<author>
			<persName><forename type="first">Khushboo</forename><surname>Qayyum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sallar</forename><surname>Ahmadi-Pour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandan</forename><surname>Kumar Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rolf</forename><surname>Drechsler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LLM Aided Design Workshop</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Empowering hardware security with llm: The development of a vulnerable hardware database</title>
		<author>
			<persName><forename type="first">Dipayan</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katayoon</forename><surname>Yahyaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujan</forename><forename type="middle">Kumar</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Tehranipoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farimah</forename><surname>Farahmandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Hardware Oriented Security and Trust (HOST)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<monogr>
		<title level="m" type="main">Self-hwdebug: Automation of llm self-instructing for hardware security verification</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Akyash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mardani</forename><surname>Hadi</surname></persName>
		</author>
		<author>
			<persName><surname>Kamali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.12347</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">On hardware security bug code fixes by prompting large language models</title>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailja</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title level="m" type="main">From rtl to sva: Llm-assisted generation of formal verification testbenches</title>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Orenes-Vera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wentzlaff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.09437</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Automated hardware logic obfuscation framework using gpt</title>
		<author>
			<persName><forename type="first">Banafsheh</forename><surname>Saber Latibari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujan</forename><surname>Ghimire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alam</forename><surname>Muhtasim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najmeh</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Nazari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houman</forename><surname>Immanuel Gubbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avesta</forename><surname>Homayoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soheil</forename><surname>Sasan</surname></persName>
		</author>
		<author>
			<persName><surname>Salehi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dallas Circuits and Systems Conference (DCAS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Netlist whisperer: Ai and nlp fight circuit leakage</title>
		<author>
			<persName><forename type="first">Madhav</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Sadhukhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debdeep</forename><surname>Mukhopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Attacks and Solutions in Hardware Security (ASHES)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Scar: Power side-channel analysis at rtl level</title>
		<author>
			<persName><forename type="first">Amisha</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navnil</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafail</forename><surname>Psiakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Henrique</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debjit</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanad</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration Systems (TVLSI)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Examining zero-shot vulnerability repair with large language models</title>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2339" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Harnessing the power of general-purpose llms in hardware trojan design</title>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Kokolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Athanasios</forename><surname>Moschos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelos</forename><forename type="middle">D</forename><surname>Keromytis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Applied Cryptography and Network Security (ACNS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Socurellm: An llmdriven approach for large-scale system-on-chip security verification and policy generation</title>
		<author>
			<persName><forename type="first">Shams</forename><surname>Tarek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipayan</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujan</forename><forename type="middle">Kumar</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Tehranipoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farimah</forename><surname>Farahmandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<monogr>
		<title level="m" type="main">Hw-v2w-map: Hardware vulnerability to weakness mapping framework for root cause analysis with gpt-assisted mitigation suggestion</title>
		<author>
			<persName><forename type="first">Yu-Zheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muntasir</forename><surname>Mamun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alam</forename><surname>Muhtasim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyu</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Banafsheh</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Saber Latibari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najmeh</forename><surname>Immanuel Gubbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Nazari Bavarsad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avesta</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName><surname>Sasan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.13530</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Chateda: A large language model powered autonomous agent for eda</title>
		<author>
			<persName><forename type="first">Zhuolun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xufeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haisheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Machine Learning for CAD (MLCAD)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<monogr>
		<title level="m" type="main">New interaction paradigm for complex eda software leveraging gpt</title>
		<author>
			<persName><forename type="first">Boyu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyu</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yidong</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.14740</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Llsm: Llm-enhanced logic synthesis model with eda-guided cot prompting, hybrid embedding and aig-tailored acceleration</title>
		<author>
			<persName><forename type="first">Shan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancai</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Metrex: A benchmark for verilog code metric reasoning using llms</title>
		<author>
			<persName><forename type="first">Manar</forename><surname>Abdelatty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingxiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherief</forename><surname>Reda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<monogr>
		<title level="m" type="main">Drc-coder: Automated drc checker code generation using llm autonomous agent</title>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chia-Tung</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.05311</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<author>
			<persName><forename type="first">Chenhui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Chipalign</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.19819</idno>
		<title level="m">Instruction alignment in large language models for chip design via geodesic interpolation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b221">
	<monogr>
		<title level="m" type="main">Fabgpt: An efficient large multimodal model for complex wafer defect knowledge queries</title>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xudong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhuo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.10810</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Intelligent opc engineer assistant for semiconductor manufacturing</title>
		<author>
			<persName><forename type="first">Guojin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Bei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Large language model (llm) for standard cell layout design optimization</title>
		<author>
			<persName><forename type="first">Chia-Tung</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxing</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LLM Aided Design Workshop</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<title level="m" type="main">SpecLLM: Exploring generation and review of vlsi design specification with large language model</title>
		<author>
			<persName><forename type="first">Mengming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.13266</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<title level="m" type="main">On the viability of using LLMs for SW/HW co-design: An example in designing CiM DNN accelerators</title>
		<author>
			<persName><forename type="first">Zheyu</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobo</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Sharon</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06923</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<title level="m" type="main">Unleashing the potential of LLMs for quantum computing: A study in quantum architecture design</title>
		<author>
			<persName><forename type="first">Zhiding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinglei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.08191</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b227">
	<monogr>
		<title level="m" type="main">Customized retrieval augmented generation and benchmarking for eda tool documentation qa</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuolun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tairu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.15353</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">Ladac: Large language model-driven auto-designer for analog circuits</title>
		<author>
			<persName><forename type="first">Chengjie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Authorea Preprints</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<monogr>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Souradip</forename><surname>Poddar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengkang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><surname>Analogcoder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.14918</idno>
		<title level="m">Analog circuit design via training-free code generation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Flag: Formula-llm-based auto-generator for baseband hardware</title>
		<author>
			<persName><forename type="first">Yunwei</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">You</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaosi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohu</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Circuits and Systems (ISCAS)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<monogr>
		<title level="m" type="main">Ado-llm: Analog design bayesian optimization with in-context learning of large language models</title>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.18770</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title level="m" type="main">Lamagic: Language-model-based topology generation for analog integrated circuits</title>
		<author>
			<persName><forename type="first">Chen-Chia</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoze</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.18269</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Artisan: Automated operational amplifier design via domain-specific large language model</title>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangli</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<monogr>
		<title level="m" type="main">Ledro: Llm-enhanced design space reduction and optimization for analog circuits</title>
		<author>
			<persName><forename type="first">Dimple</forename><surname>Vijay Kochar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanrui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anantha</forename><surname>Chandrakasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.12930</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b235">
	<monogr>
		<title level="m" type="main">Analogxpert: Automating analog topology synthesis by incorporating circuit design expertise into large language models</title>
		<author>
			<persName><forename type="first">Haoyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runsheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.19824</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Analoggenie: A generative engine for automatic discovery of analog circuit topologies</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weidong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<monogr>
		<title level="m" type="main">A deep learning framework for verilog autocompletion towards design and verification automation</title>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Dehaerne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bappaditya</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandip</forename><surname>Halder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><forename type="middle">De</forename><surname>Gendt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.13840</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b238">
	<monogr>
		<title level="m" type="main">Vrank: Enhancing verilog code generation from large language models via self-consistency</title>
		<author>
			<persName><forename type="first">Zhuorui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruidi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ing-Chao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><forename type="middle">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Schlichtmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.00028</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">Prompt programming for large language models: Beyond the few-shot paradigm</title>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the Conference on Human Factors in Computing Systems (CHI EA)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">React: Synergizing reasoning and acting in language models</title>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<author>
			<persName><forename type="first">Nisan</forename><surname>Daniel M Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><surname>Irving</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08593</idno>
		<title level="m">Fine-tuning language models from human preferences</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">Goldmine: Automatic assertion generation using data mining and static analysis</title>
		<author>
			<persName><forename type="first">Shobha</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tcheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Tuohy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design, Automation and Test in Europe Conference and Exhibition (DATE)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">Harm: a hint-based assertion miner</title>
		<author>
			<persName><forename type="first">Samuele</forename><surname>Germiniani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graziano</forename><surname>Pravadelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">Circuitnet: An open-source dataset for machine learning in vlsi cad applications with improved domain-specific evaluation metric and learning strategies</title>
		<author>
			<persName><forename type="first">Zhuomin</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runsheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ru</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<author>
			<persName><forename type="first">Zeju</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zedong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.18297</idno>
		<title level="m">A comprehensive repository-level dataset for rtl code understanding, generation, and ppa analysis</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<title level="a" type="main">Towards big data in ai for eda research: Generation of new pseudo-circuits at rtl stage</title>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">Syncircuit: Automated generation of new synthetic rtl circuits can enable big data in circuits</title>
		<author>
			<persName><forename type="first">Shang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenji</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">Combining power and arithmetic optimization via datapath rewriting</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Coward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theo</forename><surname>Drane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>Morini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Constantinides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Computer Arithmetic (ARITH)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">E-syn: E-graph rewriting with technology-aware cost functions for logic synthesis</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongce</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference (DAC)</title>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
