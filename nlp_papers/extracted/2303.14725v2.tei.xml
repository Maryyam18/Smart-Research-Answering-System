<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Natural Language Reasoning, A Survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-05-13">13 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fei</forename><surname>Yu</surname></persName>
							<email>feiyu1@link.cuhk.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Hongbo</forename><surname>Zhang</surname></persName>
							<email>hongboz183@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Prayag</forename><surname>Tiwari</surname></persName>
							<email>prayag.tiwari@ieee.org</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">PRAYAG TIWARI</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Halmstad University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">BENYOU WANG *</orgName>
								<orgName type="institution" key="instit2">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">https://github.com</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shenzhen Shenzhen</settlement>
									<country>FreedomIntelligence ReasoningNLP China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Halmstad University</orgName>
								<address>
									<settlement>Halmstad</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Benyou Wang</orgName>
								<orgName type="institution" key="instit2">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shenzhen Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Natural Language Reasoning, A Survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-13">13 May 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">D4E64AD0D5C6BC8EA1338AD826409476</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2303.14725v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-01T10:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This survey paper proposes a clearer view of natural language reasoning in the field of Natural Language Processing (NLP), both conceptually and practically. Conceptually, we provide a distinct definition for natural language reasoning in NLP, based on both philosophy and NLP scenarios, discuss what types of tasks require reasoning, and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on natural language reasoning in NLP, mainly covering classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. The paper also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in natural language reasoning research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic techniques and mathematical reasoning 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACM Reference Format: Fei Yu, Hongbo Zhang, Prayag Tiwari, and Benyou Wang. 2023. Natural Language Reasoning, A Survey. 1, 1 (May 2023), 36 pages. <ref type="url" target="https://doi.org/10.1145/nnnnnnn.nnnnnnn">https://doi.org/10.1145/nnnnnnn.nnnnnnn</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Natural Language Processing (NLP) has shown significant advancements in recent years, particularly with the introduction of transformers and pre-trained language models (PLMs). However, their abilities <ref type="foot" target="#foot_0">2</ref> <ref type="foot" target="#foot_1">2</ref> to perform natural language reasoning (NLR) are still far from satisfactory. Reasoning, the process of making inferences based on existing knowledge, is a fundamental aspect of human intelligence and is essential for complex tasks such as decision-making. Building an artificial intelligence system capable of reasoning is both the ultimate goal of the research community and the necessary way to improve the performance of complex applications. Compared to reason with formal language, reasoning with natural language expressions provides a more natural human-computer interaction interface and opens the door to research on defeasible reasoning, such as abduction and induction, which are incapable of formal-based symbolic methods.</p><p>PLMs such as BERT <ref type="bibr" target="#b34">[34]</ref> and GPT <ref type="bibr" target="#b116">[115]</ref> have been the essential components in NLP research since they occurred. Pre-trained on large-scale text corpora, PLMs are capable of natural language understanding. Recent progresses suggest that PLMs also have the potential to solve reasoning problems <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b142">141,</ref><ref type="bibr" target="#b146">145,</ref><ref type="bibr" target="#b159">158]</ref>. Specifically, PLMs can perform soft deductive reasoning over natural language statements <ref type="bibr" target="#b25">[25]</ref>, reason with implicit knowledge memorized in their parameters <ref type="bibr" target="#b146">[145]</ref>, and perform multi-step reasoning step-by-step just with a few demonstrations or instructions when the model size is large enough via chain-of-thought prompting <ref type="bibr" target="#b78">[77,</ref><ref type="bibr" target="#b159">158]</ref>. Recently, ChatGPT and GPT4 also made impressive reasoning capabilities to the community <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">16]</ref>.</p><p>However, while reasoning has attracted increasing attention recently <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b78">77,</ref><ref type="bibr" target="#b108">107,</ref><ref type="bibr" target="#b144">143,</ref><ref type="bibr" target="#b159">158]</ref>, there still lacks a distinct definition of reasoning and the term "reasoning" is sometimes of mistaken usage, which may affect the communication and development towards reasoning in the NLP community. For example, while it belongs to "commonsense reasoning", few people might deem that telling about a shared lived experiences <ref type="bibr" target="#b9">[10]</ref>, e.g. "name something that you might forget in a hotel room", is reasoning. Another example is that sometimes "natural language inference" is introduced as a task of natural language understanding <ref type="bibr" target="#b11">[12]</ref>, but other times of reasoning <ref type="bibr" target="#b25">[25]</ref>. By now, none all of the tasks named with "reasoning" are believed as reasoning (e.g. commonsense reasoning), and none all of the tasks named "without reasoning" are thought of as non-reasoning (e.g. natural language inference and multi-hop question answering). This raises a question: what reasoning is actually, and how can we identify reasoning tasks if their names are not much indicative? Although many researches <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b59">58,</ref><ref type="bibr" target="#b168">167,</ref><ref type="bibr" target="#b175">174]</ref> refer to a definition of reasoning from philosophy and logic, the definition cannot capture the reasoning in NLP well enough. For example, while reasoning is philosophically defined as "using evidence and logic to arrive at conclusions" <ref type="bibr" target="#b59">[58]</ref>, it fails to clarify whether implicit commonsense knowledge can be evidence and what types of conclusion are reasoning products, e.g. how about named-entity disambiguation?</p><p>To promote the research on reasoning in NLP, we make an attempt to propose a clearer view of NLP reasoning, both conceptually and practically. Conceptually, we propose a definition for NLP reasoning based on both philosophy and NLP scenarios, discuss what types of tasks require reasoning, and introduce a taxonomy of reasoning. Practically, we provide a comprehensive literature review on natural language reasoning in NLP based on our clarified definition, mainly covering classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. Reviewing papers of all sizes of PLMs, we capture general methodologies that can be applied to different model sizes: end-to-end reasoning, forward reasoning, and backward reasoning. Finally, we discuss some limitations and future directions of reasoning.</p><p>In addition to the definition of reasoning, there is an important point distinguishing this survey from the other surveys <ref type="bibr" target="#b59">[58,</ref><ref type="bibr" target="#b111">110,</ref><ref type="bibr" target="#b169">168]</ref>: we identify and view backward reasoning, another powerful paradigm for multi-step reasoning in addition to forward reasoning. While forward reasoning, such as chain-of-thought prompting, has been popular in LLMs recently, we argue that it is worth conducting more exploration of backward reasoning.</p><p>Backward reasoning is more efficient than forward reasoning both conceptually and empirically due to smaller search space <ref type="bibr" target="#b73">[72]</ref>, which is the potential to generalize to complex reasoning with longer steps.</p><p>In this article, we focus on the single-modality unstructured natural language text (without knowledge triples, tables and intermediate formal language) and natural language reasoning (rather than symbolic reasoning and mathematical reasoning) <ref type="foot" target="#foot_2">3</ref> <ref type="foot" target="#foot_3">3</ref> . Concretely, We conduct a review of related works that utilize transformer-based PLMs, with a deliberate exclusion of neuro-symbolic techniques. We sorted the collected papers and categorised the methodologies of natural language reasoning in NLP. We identify the progress and trend in recent years in this domain. The paper is organized into five sections (as shown in Figure <ref type="figure">1</ref>).</p><p>We collected more than two hundred papers related to reasoning or PLMs in recent years. We searched keywords such as inference, reasoning, infer, reason, multi-step, and multi-hop on the top conferences, including ACL, EMNLP, NAACL, ICML, ICLR, and NeurIPS, from 2019 to 2022. We also found some related works from the collected papers.</p><p>In conclusion, the main contributions of this survey are</p><p>(1) To our best knowledge, we are the first to provide a distinct definition for natural language reasoning in NLP and discuss to what degree some popular benchmarks are related to reasoning. (2) To our best knowledge, we are the first to conduct a comprehensive review on PLM-based natural language reasoning, covering diverse NLR benchmarks, and providing a comprehensive taxonomy of methodology. We also cover backward reasoning, which is neglected but has potential. (3) We introduce defeasible reasoning, which we believe is one of the most potential future directions, compare differences between deductive reasoning and defeasible reasoning, discuss how they can affect NLP solutions, and review current methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">WHAT IS NATURAL LANGUAGE REASONING</head><p>There still lacks a distinct definition of natural language reasoning in NLP, which affects the development and communication of NLR in the NLP community. To promote understanding, analysis and communication, we aim to suggest distinct definitions of terms and concepts for natural language reasoning in NLP. To realize this goal, we take a look into two relevant areas which have studied reasoning for a long time: philosophy and logic and transfer the relevant reasoning theory into NLP. First, we propose a definition for NLR in NLP that satisfies the concerns of the NLP community (Sec 2.1). Then, we provide categories of NLR and introduce how the differences between them can affect NLP solutions (Sec 2.2). Finally, we introduce the potentials, challenges, and requirements to achieve NLR (Sec 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definition</head><p>Reasoning in NLP has been focused on in recent years while philosophy has studied reasoning since thousand years ago, and logic is seen as the art of correct reasoning, which studies the concepts of inference, systematizes its categories, and develops principles of good reasoning, including formal logic and informal logic <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b64">63]</ref>. In this section, we first include reasoning theory from philosophy and logic and derive it into NLP reasoning. Then, we review some natural language reasoning topics in NLP. Finally, we propose a definition for reasoning in NLP, which combines the definition in philosophy and logic and the concerns of the NLP community. (Definition 2.3). The former two descriptions can tell us "what reasoning can do" and "what isn't reasoning", while the latter three provide us different definitions of "what is reasoning". However, the definition from logic (Definition 2.1) restricts reasoning to a subset within the coverage of formal logic. To reach a more generalized definition, we adopt the latter two definitions from philosophy, which are two different classes named theoretical reasoning and practical reasoning, respectively, as the basis for defining natural language reasoning in NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description 2.1 (task-based).</head><p>Reasoning is an essential mental activity when conducting conscious tasks with complex computations such as problem-solving, decision-making, persuasion, and explaining <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b72">71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description 2.2 (negation-based).</head><p>Reasoning is a dynamic process to get some knowledge without direct recourse to sense perceptions or immediate experience, which is opposed to sensation, perception and feeling <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b156">155]</ref>. Definition 2.1 (logic-based reasoning). Reasoning is to discover valid conclusions by applying logic <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b92">91,</ref><ref type="bibr" target="#b156">155]</ref>. Definition 2.2 (assertion-based reasoning / theoretical reasoning). Reasoning is to infer conclusions from a set of premises, consisting of one or more inference steps, where premises and conclusions are assertions that claim something is true or false about the world <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b124">123,</ref><ref type="bibr" target="#b156">155]</ref>. Definition 2.3 (action-based reasoning / practical reasoning). Practical reasoning is to infer actions from goals and knowledge, which is oriented to deciding whether an action is practically reasonable <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b156">155]</ref>.</p><p>2.1.2 Definition in NLP we suggest. According to Definition 2.2, Definition 2.3 and negation-based description 2.2, we can know "what is reasoning" and "what isn't reasoning" from the perspective of philosophy. There are also some descriptions towards the two questions in NLP. We compare and combine them in Table <ref type="table" target="#tab_0">1</ref>. We also review typical natural language reasoning datasets in NLP to observe and capture what the NLP community is concerned about.</p><p>From our observations, in NLP, natural language reasoning also combines multiple knowledge to derive conclusions. The unique characteristics are (1) knowledge sources and (2) conclusion types. Firstly, common knowledge sources are knowledge bases, context, and PLMs, where the former two can explicitly provide encyclopedic knowledge and contextual knowledge, while the last is implicit knowledge sources. Secondly, In addition to assertions and actions, it is also popular to infer relations, e.g. causes and effects, of events. We demonstrate examples of these three conclusion types in Table <ref type="table">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event</head><p>John was shot.</p><p>There are people around. Doctor can save life.</p><p>John will be sent to see a doctor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action</head><p>Marry is on the living room. Marry feels it hot. Remote control for air conditioner is in the bedroom.</p><p>go to the bedroom, take the remote control come back and turn on the air conditioner Table <ref type="table">2</ref>. Three types of conclusion in reasoning, where "assertion" and "event" assume something true or likely to be true in the world.</p><p>Correspondingly, we propose the definition of NLP reasoning in Definition 2.4 and suggest "what isn't reasoning in NLP" and "what NLP reasoning can do" in Description 2.3 and Description 2.4. It should be emphasized that conclusions are new (or unknown) assertions, events, or actions, which distinguishes reasoning from other knowledge-intensive tasks that may also require multiple knowledge. To better demonstrate the definition, we explain why some knowledge-intensive datasets are not reasoning in Table <ref type="table">3</ref>.</p><p>Definition 2.4 (NLP reasoning). Natural language reasoning is a process to integrate multiple knowledge (e.g. encyclopedic knowledge and commonsense knowledge) to derive some new conclusions about the (realistic or hypothetical) world. Knowledge can be from both explicit and implicit sources. Conclusions are assertions or events assumed to be true in the world, or practical actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description 2.3 (NLP negation-based)</head><p>. Natural language reasoning is to derive new assertions, events, or actions without direct recourse to models' memorization, knowledge base storage and the provided context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description 2.4 (NLP task-based).</head><p>Reasoning is an important method to arrive at the required answers or solutions. It is effective when what we need is neither provided by context nor memorized by models and stored by knowledge bases, but reachable by integrating available information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task</head><p>Why not reasoning CoNLL <ref type="bibr" target="#b55">[55]</ref> entity linking just align known entities without producing new assertions, events, or actions</p><p>CommonGen <ref type="bibr" target="#b86">[85]</ref> constrained text generation generate text but neither true assertions or events, nor actions Natural Questions <ref type="bibr" target="#b79">[78]</ref> open-domain QA the answer can be simply matched</p><p>Table 3. Examples to explain what is not reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Key Concepts.</head><p>We first introduce the key concepts: proposition and inference. Similarly, we derive the definitions from philosophy and logic to NLP. Then, we further clarify the definition of reasoning in NLP.</p><p>Definition of key concepts. In logic, the proposition is the basic operation unit in reasoning, and inference is a sub-process of a complete reasoning process. Concretely, while reasoning is performed with statements (as premises and conclusions), the real operation units are the semantics behind sentences, i.e. propositions <ref type="bibr" target="#b64">[63]</ref>.</p><p>Inference is a single step in reasoning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b124">123,</ref><ref type="bibr" target="#b156">155]</ref>, and each reasoning can be made of one or more inference steps (Definition 2.2. We put the two key concepts into NLP in Definition 2.5 and Definition 2.6. Definition 2.5 (NLP proposition). A proposition is the semantic meaning or information content of a statement rather than its superficial linguistic. Definition 2.6 (NLP inference). Inference is a single step that produces a single (intermediate) conclusion from some premises.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Categories of Inference</head><p>While knowledge has been well categorised in NLP (e.g. explicit world knowledge and implicit commonsense knowledge), we find that there is still a lack of reasonable taxonomy for inference. Therefore, we borrow the categories from philosophy and discuss the differences between classes to NLP and how they can affect the solutions.</p><p>Inference can be divided into (mainly) deductive, inductive and abductive <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b104">103]</ref>, or divided into monotonic and defeasible. Actually, the deduction is monotonic inference while induction and abduction are sub-classes of defeasible inference. Since "monotonic" and "defeasible" can capture the difference between deductive and non-deductive inference, we combine the two taxonomies into one: deductive inference and defeasible inference.</p><p>2.2.1 Deduction, Induction, and Abduction. According to Aristotle and Peirce, there are three major inferences: deduction, induction, and abduction <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b104">103]</ref>. This taxonomy is the most familiar one to the NLP community, adopted and studied by several works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b101">100,</ref><ref type="bibr" target="#b138">137,</ref><ref type="bibr" target="#b161">160,</ref><ref type="bibr" target="#b168">167,</ref><ref type="bibr" target="#b175">174]</ref>. The definitions are shown below (Table <ref type="table">4</ref> shows examples). Definition 2.7 (Deduction). A deductive inference is to infer valid knowledge (conclusion) from the given knowledge (premises). Definition 2.8 (Induction). An inductive inference is to infer probable knowledge, which describes a more general rule, extrapolated from the given knowledge. Definition 2.9 (Abduction). An abductive inference is to infer probable knowledge, as the best explanation (i.e. cause), for the given knowledge (i.e. phenomena).</p><p>Fact1: Aristotle is a human Rule: All human will die Fact2: Aristotle will die Deduction Abduction Induction (Fact1 + Rule → Fact2) (Fact1 + Rule ← Fact2) (Fact1 + Fact2 → Rule) Table <ref type="table">4</ref>. An simple example to show the difference between deduction, abduction and induction, where text in black is the given knowledge while text in red is the inferred knowledge. "Fact" denotes specific knowledge while "rule" denotes general principle.</p><p>However, among these three classes, researches on abduction and induction are much under-explored than deduction, while the widely studied deduction is only a very small set of human daily reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Deductive</head><p>Inference and Defeasible Inference. Our main goal is to promote research on non-deductive reasoning and highlight the differences and challenges. Therefore, we turn into monotonic inference and defeasible inference, which can better capture the features of deductive and non-deductive inference respectively. Key difference. The key difference between monotonic inference and defeasible inference from philosophy is that the former derives valid conclusions <ref type="foot" target="#foot_6">4</ref> while the latter only produces probable conclusions. Since the conclusions of deductive inference are truth-preserving that the future added knowledge will not affect their validity, thus the set of knowledge is incremental, i.e. monotonic. By contrast, the conclusions of non-deductive inference (e.g. induction and abduction) may be wrong, and the newly added knowledge may retract the conclusion, i.e. defeasible. For example, one may inductively infer "birds can fly" with the premises "parrots can fly" and "eagles can fly". However, when he or she discovers the new knowledge "ostrich cannot fly", the conclusion will be retracted.</p><p>Different characteristics. This difference towards conclusions between deductive inference and defeasible inference leads to many different characteristics, including inference relations between premises and conclusions, the quality of inference, and the requirement of knowledge. Concretely, there is only one inference relation between premises and each conclusion in deductive inference, i.e. support, and the inference is either valid or invalid. Therefore, we can derive a valid conclusion just with several supporting premises. By contrast, knowledge can strengthen, weaken and even rebut (the probability of) the conclusion in defeasible inference, and the quality of inference varies from weak to strong. Therefore, it is better to collect more comprehensive information to arrive at a more probable conclusion. We compare the characteristics of the deductive inference and defeasible inference in Table <ref type="table" target="#tab_2">5</ref>. Affects on NLP. These characteristics affect relevant knowledge acquisition, reasoning path structure, and the importance of interpretability in NLP. Firstly, while collecting the supporting knowledge toward the valid conclusion is enough for deductive reasoning, it is better to collect both supportive and opposing knowledge to compare the confidence of different conclusions for defeasible reasoning. Then, there has been increasing attention on reasoning path generation in NLP <ref type="bibr" target="#b127">[126,</ref><ref type="bibr" target="#b144">143,</ref><ref type="bibr" target="#b159">158]</ref>. However, due to more types of inference relation, the structure of reasoning paths for defeasible reasoning is more complex than deductive reasoning and thus becomes more challenging to generate. Finally, it is more important and sometimes even crucial for NLP models to perform interpretable defeasible reasoning. This is because people with different background knowledge can infer very different and even opposite conclusions by themselves, thus it is much more difficult to clarify the conclusion without explicit premises and reasoning procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deductive Inference Defeasible</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Potentials, Challenges, and Requirements of NLR</head><p>Potentials. Compared to reasoning with precise formal language, natural language provides a better humancomputer interaction interface. Besides, natural language opens a door to play with defeasible reasoning, where formal language fails.</p><p>Challenges. Firstly, natural language suffers from ambiguity and variety, since there are polysemy, synonymy and diverse structures. Therefore, while triples and formal languages are precise, statements and propositions are many-to-many in natural language, which poses a challenge on natural language understanding. Secondly, supervised data of inference is difficult to obtain, which may prevent it from large-scale training. Moreover, the step of reasoning is diverse at the instance level, i.e. different questions may require different inference steps to answer, and it is important to generalize to the unseen steps.</p><p>Requirements. Based on the definition (Definition 2.4), the key components in NLP to achieve reasoning are (1) (multiple) knowledge and (2) an algorithm capable of understanding and inference. Correspondingly, there are three stages: knowledge acquisition, knowledge understanding, and inference. Firstly, it requires collecting the relevant knowledge required for reasoning (knowledge acquisition). Then, the algorithm requires to capture propositions underlying the given knowledge (knowledge understanding). In addition to the general semantics, it should also capture the logical semantics such as negation, conjunction and disjunction. Subsequently, beginning from these propositions, the algorithm requires integrating some knowledge to infer a new conclusion with one or more steps to reach the final answer (inference). Though knowledge acquisition and understanding are also necessary for reasoning, the two topics are big enough to write another survey, thus we just focus on inference in this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WHY PLMS FOR NATURAL LANGUAGE REASONING 3.1 Introduction to PLMs</head><p>Pre-trained language models (PLMs) are based on transformer architecture <ref type="bibr" target="#b154">[153]</ref>, which is built with many attention modules and are pre-trained on massive amounts of text data via unsupervised learning techniques such as predicting masked tokens <ref type="bibr" target="#b34">[34]</ref> or generating the next tokens <ref type="bibr" target="#b116">[115]</ref>. Since BERT <ref type="bibr" target="#b34">[34]</ref> occurred, pretraining-thenfinetuning became a common paradigm, which transfers the general abilities of PLMs learned in the pretraining stage to downstream tasks with further task-specific finetuning. Since large language models have been found to be few-shot learners <ref type="bibr" target="#b15">[15]</ref>, in-context learning has become a new popular paradigm, which can predict a new sample with only a few demonstrations without finetuning parameters. Recently, the zero-shot prompting paradigm also becomes more popular in LLMs <ref type="bibr" target="#b78">[77]</ref>.</p><p>Types of PLMs. According to the architecture, PLMs can be divided into encoder-only (e.g. BERT <ref type="bibr" target="#b34">[34]</ref>), decoderonly (e.g. GPT <ref type="bibr" target="#b116">[115]</ref>) and encoder-decoder (e.g. T5 <ref type="bibr" target="#b117">[116]</ref>). According to the directivity, PLMs can be divided into bidirectional (encoder-only) and causal (decoder-only and encoder-decoder), while bidirectional PLMs are commonly used for discriminative tasks, causal PLMs can model general tasks but are more capable of generative tasks. According to the model size, there are medium-size PLMs and large language models, where LLMs are much larger than the former (e.g. 13B parameters).</p><p>Advantages of PLMs for NLR. We conclude with four advantages of PLMs for NLR.</p><p>• Ability of natural language understanding. Transformers represent words and sentences in a contextdependent manner as continuous vectors in a high-dimensional space dealing with ambiguity and uncertainty in nature. After large-scale pretraining, PLMs can learn a powerful understanding capability, which helps them to capture and understand knowledge mentioned in the text. • Ability to learn implicit knowledge into parameters. It has been found that PLMs can capture some implicit knowledge that is not explicitly mentioned, such as commonsense knowledge, into their parameters. This is important since it is impossible to explicitly enumerate and provide commonsense knowledge for reasoning. • Ability of in-context learning. LLMs such as GPT-3 exhibit the impressive ability to perform tasks only with some demonstrations without further fine-tuning, which is valuable to alleviate data sparsity problems. • Emergent abilities. Recently, it was found that LLMs have some emergent abilities that only occur when the model size is big enough <ref type="bibr" target="#b158">[157]</ref>, and LLMs can perform much more complex tasks as their size increases. Moreover, it has been demonstrated that performing multi-step reasoning in a few-shot or zero-shot manner is one of the emergent abilities <ref type="bibr" target="#b159">[158]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Empirical Development</head><p>Recent progresses also show the potential to leverage PLMs on natural language reasoning, which exhibits their learning and generalization abilities of reasoning skills with both explicit and implicit knowledge.</p><p>By finetuning on the specific dataset, <ref type="bibr" target="#b25">[25]</ref> first demonstrated that PLMs can perform deductive reasoning over explicitly provided natural language statements, which can zero-shot transfer to different domains. Moreover, <ref type="bibr" target="#b146">[145]</ref> showed that PLMs can combine memorized implicit taxonomic and world knowledge with explicitly provided knowledge for the deduction. In addition to deduction, PLMs can also learn to perform defeasible reasoning <ref type="bibr" target="#b123">[122,</ref><ref type="bibr" target="#b168">167,</ref><ref type="bibr" target="#b175">174]</ref>.</p><p>While LLMs with in-context learning were once thought to be incapable of multi-step reasoning, it has been found that their capabilities of reasoning can be unlocked by generating forward reasoning paths before the final answer <ref type="bibr" target="#b159">[158]</ref>, which is called Chain-of-Thought (CoT) prompting. With this prompting, the performance of many multi-step reasoning tasks in Big-Bench Hard can surpass the average human rater. Furthermore, LLMs can perform multi-step reasoning not only with few-shot exemplars, <ref type="bibr" target="#b78">[77]</ref> also found that they can automatically produce intermediate steps with a simple "Let's think step by step" prompting in a zero-shot manner. Surprisingly, LLMs can even learn from their self-generated reasoning paths <ref type="bibr" target="#b60">[59,</ref><ref type="bibr" target="#b179">178]</ref>. Moreover, GP4 outperformed a majority of people on several realistic examinations such as Uniform Bar Exam which also require some reasoning.</p><p>In addition, to forward reasoning paths, question decomposition, a backward reasoning method, is also effective in multi-hop question answering, which is beneficial to both medium-size PLMs <ref type="bibr" target="#b98">[97,</ref><ref type="bibr" target="#b103">102]</ref> and LLMs <ref type="bibr" target="#b103">[102,</ref><ref type="bibr" target="#b108">107]</ref>.</p><p>Moreover, while neural-based methods are blamed for black box prediction, <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b131">130]</ref> demonstrated that PLMs can produce faithful reasoning paths and make predictions based on them.</p><p>In conclusion, PLMs can learn to perform multi-step reasoning from supervised data or few-shot demonstrations. Their capabilities of natural language understanding, generalization, and leveraging implicit knowledge make them promising to deal with arbitrary natural language, commonsense knowledge and defeasible reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGIES OF NLR</head><p>In this section, we introduce three types of natural language reasoning approaches: end-to-end reasoning (Sec 4.1), forward reasoning, and backward reasoning. The overall taxonomy is shown as Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>The key difference among these three categories lies in the reasoning path. Concretely, "end-to-end reasoning" only predicts the final answers without any intermediate text, while the latter two approaches can produce reasoning paths, containing one or more steps with the intermediate conclusions, showing the process of (possibly multi-step) reasoning that links premises to the conclusion <ref type="foot" target="#foot_7">5</ref> .</p><p>Presenting the reasoning path for each prediction can improve the interpretability of a system. Especially, a strict reasoning path can also explicitly expose the supporting knowledge of each step. Moreover, producing reasoning paths has been demonstrated to be beneficial to the final performance of multi-step reasoning <ref type="bibr" target="#b78">[77,</ref><ref type="bibr" target="#b103">102,</ref><ref type="bibr" target="#b108">107,</ref><ref type="bibr" target="#b142">141,</ref><ref type="bibr" target="#b159">158]</ref>. There are two directions of reasoning.</p><p>Two Directions of reasoning. Multi-step reasoning can be performed by either forward <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b131">130,</ref><ref type="bibr" target="#b143">142,</ref><ref type="bibr" target="#b159">158]</ref> or backward <ref type="bibr" target="#b75">[74,</ref><ref type="bibr" target="#b84">83,</ref><ref type="bibr" target="#b98">97,</ref><ref type="bibr" target="#b108">107,</ref><ref type="bibr" target="#b144">143]</ref>. Forward reasoning is a bottom-up procedure, which starts from the existing knowledge and repeatedly makes inferences to obtain new knowledge until the problem is solved. The other, backward reasoning, is a top-down procedure, which starts from the problem and repeatedly breaks down into sub-problems until all of them can be solved by the existing knowledge. While backward reasoning targets the specified problems, forward reasoning can freely uncover new knowledge implicated by the existing knowledge without preassigned problems. Accordingly, the search space of forward reasoning is much larger than backward reasoning when solving a specific problem, facing the combinatorial explosion as the step of inference goes. When it comes to theorem proving, which is a verification problem, where the reasoning path is named "proof", forward reasoning and backward reasoning are often called "forward chaining" and "backward chaining" respectively.</p><p>We compare these three methods in Table <ref type="table">6</ref> and demonstrate an example in Figure <ref type="figure" target="#fig_6">6</ref>. The following subsections will further introduce and discuss the comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direction Pros Cons</head><p>End-to-End Reasoning -most efficient blackbox bad generalization Forward Reasoning bottom-up interpretability open-ended huge search space only effective in LLMs Backward Reasoning top-down interpretability efficient goal-specific Table 6. Comparison of end-to-end reasoning, forward reasoning, and backward reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">End-to-End Reasoning</head><p>End-to-end reasoning is a complete black-box prediction that only outputs the final answers without any explanation, intermediate conclusion, or reasoning path, whether it is a single-step or multi-step reasoning problem. There are mainly three kinds of models used to perform end-to-end reasoning: specialized models built upon medium-size PLMs, vanilla medium-size PLMs, and decoder-only LLMs. Besides, there is also some research on specialized pretraining methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Training specialized models.</head><p>To perform end-to-end reasoning, models need to aggregate multiple knowledge and reason over them. Correspondingly, there are specialized models improving the capability of multiple evidence aggregation <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b94">93,</ref><ref type="bibr" target="#b184">183,</ref><ref type="bibr" target="#b186">185]</ref> or reasoning <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b85">84,</ref><ref type="bibr" target="#b114">113,</ref><ref type="bibr" target="#b171">170,</ref><ref type="bibr" target="#b188">187]</ref>. Previous research often incorporated some task-specific inductive biases via architectural designs. For example, graph neural networks are popularly used to leverage edges (e.g. entity-entity relations) to promote information aggregation and integration between nodes (e.g. entity information) <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b114">113,</ref><ref type="bibr" target="#b171">170]</ref>. However, these designs only specialize in either specific tasks or datasets. By contrast, ReasonFormer <ref type="bibr" target="#b189">[188]</ref> proposed a variant architecture of transformer for general reasoning, with different modules responsible for different predefined fundamental reasoning capabilities. This kind of model can improve performance on specific tasks or datasets. Nevertheless, all of these designs rely heavily on handcrafts, introducing strong prior assumptions, which may hurt the generalization ability to other tasks. 4.1.2 Finetuning vanilla medium-size PLMs. Medium-size PLMs lack the ability to perform zero-shot reasoning such as theorem proving, argument completion, commonsense reasoning, and abduction without training <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b175">174,</ref><ref type="bibr" target="#b193">192]</ref>. Recently, it was found that transformers can be good soft deductive reasoners after in-domain training <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">25]</ref>. By contrast, it is more challenging to perform defeasible reasoning <ref type="bibr" target="#b123">[122,</ref><ref type="bibr" target="#b168">167,</ref><ref type="bibr" target="#b175">174]</ref>.</p><p>Deductive reasoning. Both bidirectional and causal PLMs have demonstrated learning ability for deductive reasoning. <ref type="bibr" target="#b25">[25]</ref> first found that BERT and RoBERTa (bidirectional PLMs) can perform theorem proving over synthetic natural language facts and rules after training. When it comes to causal PLMs, <ref type="bibr" target="#b5">[6]</ref> demonstrated that GPT2 can learn to reason over deductively valid arguments and is able to generalize from simple core schemes to some unseen composite schemes. However, there are two challenging problems in this paradigm: data sparsity and spurious correlations.</p><p>Due to data sparsity, many researchers resort to synthetic data, which is far away from the realistic setting <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b143">142]</ref>. Moreover, researchers demonstrated that training RoBERTa on synthetic data fails to generalize to linguistic variations on theorem proving and commonsense reasoning <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b193">192]</ref>, which indicates they learn less of the general logical structure underlying the linguistic variations. While training on high-quality data <ref type="bibr" target="#b49">[49]</ref> can alleviate the spurious correlation problem <ref type="bibr" target="#b49">[49]</ref>, such data is difficult to annotate on a large scale. Although automatic data collection can obtain large-scale examples, it is restricted to limit reasoning types dependent on the designed heuristic methods <ref type="bibr" target="#b10">[11]</ref>.</p><p>On the other hand, PLMs are found to learn spurious correlations on multi-hop reasoning, theorem proving and commonsense reasoning <ref type="bibr" target="#b97">[96,</ref><ref type="bibr" target="#b182">181,</ref><ref type="bibr" target="#b193">192]</ref>. In other words, finetuning on specific tasks and datasets may lead models to overfit to the specific spurious correlations underlying them. There are several researchers trying to reduce artifacts in the dataset such as by adding adversarial data <ref type="bibr" target="#b69">[68]</ref> and carefully constructing the new dataset <ref type="bibr" target="#b54">[54,</ref><ref type="bibr" target="#b152">151]</ref>. However, it is difficult to construct data without any artifact, and there may be some statistical features inherent in the problem which cannot avoid in principle <ref type="bibr" target="#b182">[181]</ref>. Another line to alleviate shortcuts is increasing attention on reasoning path generation, which may encourage models to perform actual reasoning (Sec 4.2).</p><p>Defeasible reasoning. The capability of defeasible reasoning seems to be more challenging for vanilla mediumsize PLMs to learn. Specifically, <ref type="bibr" target="#b123">[122]</ref> demonstrated that the performance of BART-large and T5-large on a defeasible reasoning task, i.e. generate a statement to update the strength of a probable conclusion, is far from satisfaction. There is a similar observation on inductive reasoning <ref type="bibr" target="#b168">[167]</ref>. Besides, it is hard to generalize the ability of abduction learned in a synthetic dataset to unseen domains <ref type="bibr" target="#b175">[174]</ref>  <ref type="foot" target="#foot_8">6</ref> . While data sparsity is also a challenge for defeasible reasoning, how to better enable PLMs capable of defeasible reasoning remains a problem.</p><p>4.1.3 Few-shot decoder-only LLMs. Few-shot prompting using decoder-only LLMs without finetuning can alleviate data sparsity and also prevents models from overfitting to specific tasks or datasets. However, there remains the question of whether models can be better capable of reasoning as the model size increases.</p><p>Although the performance on reasoning problems improves as the model size increases <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b123">122,</ref><ref type="bibr" target="#b168">167]</ref>, it is still unclear how much progress can be attributed to the improvement in reasoning capability. <ref type="bibr" target="#b28">[28]</ref> demonstrated that (deductive) reasoning problems are much more challenging that the scaling laws (of the Gopher family) work much slower than other tasks in BigBench and vanilla LLMs struggle with multi-step reasoning problems. <ref type="bibr" target="#b108">[107]</ref> found that while LLMs memorize more factual knowledge as the model size increases, it seems their ability to implicitly integrate knowledge for deduction does not improve.</p><p>Surprisingly, more reasoning capabilities of LLMs can be elicited by chain-of-thought prompting, as introduced in Sec 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Specialized pretraining.</head><p>To improve the reasoning capability of PLMs, there is some research on introducing inductive biases of reasoning when continual pretraining <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b70">69,</ref><ref type="bibr" target="#b106">105,</ref><ref type="bibr" target="#b132">131]</ref>. There are type-specific inductive biases <ref type="bibr" target="#b70">[69,</ref><ref type="bibr" target="#b106">105]</ref> and type-agnostic inductive biases <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b132">131]</ref>. For example, <ref type="bibr" target="#b33">[33]</ref> incorporated the general inductive bias of reasoning over multiple long evidence texts, while <ref type="bibr" target="#b70">[69]</ref> mainly designed for relational reasoning. Inductive biases are introduced with reasoning-related data and training strategies. For example, <ref type="bibr" target="#b132">[131]</ref> collected reasoningrelated text that involves logical inference keywords and let models to self-supervised predict these keywords. When the pretraining improves performance on multi-hop reasoning and logical reasoning problems, especially in the low-resource setting <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b70">69,</ref><ref type="bibr" target="#b132">131]</ref>, all of them worked on encoder-only PLMs, i.e. BERT and RoBERT.</p><p>Recently, <ref type="bibr" target="#b106">[105]</ref> proposed a new line that leverages programs such as SQL to pretrain PLMs with synthesized (program, execution result) pairs. The results are inspiring that PLMs, including medium-size, large-size, encoderonly and encoder-decoder, can attain significant improvement in multi-hop reasoning and logical reasoning.</p><p>However, it is important to ask whether it is still beneficial to incorporate inductive biases into LLMs, or whether simply increasing the model size and pretraining on more data is enough to improve reasoning capability. In other words, can LLMs learn reasoning well enough just by the current general pretraining? Maybe LLMs have already learned powerful reasoning capabilities that just need to be elicited via smart prompting such as CoT <ref type="bibr" target="#b159">[158]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Forward Reasoning</head><p>Forward reasoning repeatedly composes the existing knowledge to derive new knowledge until reaching the answers. There are two kinds of benefits to producing a forward reasoning path: trustworthiness <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b131">130]</ref> and performance improvement <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b142">141,</ref><ref type="bibr" target="#b159">158]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Trustworthiness.</head><p>Showing how multiple knowledge interacts and contribute to new conclusions can contribute to the system's interpretability. Furthermore, when the prediction is based on the reasoning procedure, it can alleviate the widespread shortcut problem. To exhibit the structure of reasoning, involving the required knowledge and their inference relation, reasoning paths are often represented as directed graphs or trees <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b63">62,</ref><ref type="bibr" target="#b93">92,</ref><ref type="bibr" target="#b127">126]</ref>. Typically, each node represents one piece of knowledge and the edge represents the inference relation between knowledge. For example, a single inference linking two premises to one conclusion can be represented as two nodes linking to their shared parent node.</p><p>Deductive reasoning. There is only one inference relation in deductive reasoning, i.e. support. To construct such an interpretable reasoning path, it needs to find the relevant knowledge as premises and infer the conclusions (inference). Since inference is to produce new knowledge with the given premises, it is usually implemented by vanilla generative PLMs <ref type="bibr" target="#b121">[120,</ref><ref type="bibr" target="#b131">130]</ref>. Instead of explicitly selecting or retrieving the required knowledge <ref type="bibr" target="#b127">[126]</ref>, some works put the context into the input and modelled both knowledge selection and inference as unified generation <ref type="bibr" target="#b143">[142,</ref><ref type="bibr" target="#b167">166]</ref>. However, it may generate hallucinations and invalid inferences. To alleviate this problem, <ref type="bibr" target="#b167">[166]</ref> leveraged an additional verifier to score the validity. In addition to just improving the validity of the knowledge node and inference relation edge, some researchers proposed performing faithful reasoning, which forces the prediction to rely on reasoning paths. This is mainly realized by designing decoupled modular frameworks to avoid shortcuts to irrelevant context <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b57">56,</ref><ref type="bibr" target="#b131">130]</ref>. For example, <ref type="bibr" target="#b27">[27]</ref> iteratively performed knowledge selection and inference alternately in a step-by-step manner, where each inference step only conditions the currently selected knowledge to infer the conclusion without seeing the question and the previous steps. Both supervised modular frameworks based on medium-size PLMs <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b131">130]</ref> and in-context learning modular frameworks based on LLMs <ref type="bibr" target="#b27">[27]</ref> have been explored to perform faithful reasoning. In addition to faithfulness, such step-decoupling behaviors also bring other effects. On the one hand, it is easier to provide supervised training data or in-context exemplars. The supervised framework can leverage one-step supervision <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b131">130]</ref> to train the system, which alleviates the data sparse problem in multi-step reasoning, while the in-context learning framework can demonstrate representative one-step examples that avoid the challenge of selecting the appropriate exemplars for multi-step reasoning <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28]</ref>. On the other hand, it brings error propagation. However, all of these works consider the simplest setting, where all the required knowledge is either explicitly provided in context or retrievable from knowledge bases.</p><p>Defeasible reasoning. There are more types of inference relations in defeasible reasoning, i.e. strengthen, weaken (the probability of the conclusion) and rebut. Since it is difficult to collect all the supporting premises, researches on this line mainly concern the label of inference relations between statements. In other words, there exists implicit reasoning, i.e. some premises are not explicitly provided. Similar to deductive reasoning, reasoning paths can be generated by one-shot generation <ref type="bibr" target="#b63">[62,</ref><ref type="bibr" target="#b93">92]</ref> or faithful modular framework <ref type="bibr" target="#b63">[62]</ref>. Different to deductive reasoning, it is more challenging to generate defeasible reasoning paths that even finetuned LLMs (T5-11B) find difficult.</p><p>However, there remains a problem with the evaluation of the constructed reasoning path. Specifically, there may be multiple reasoning paths for each problem, which poses challenges on data annotation <ref type="bibr" target="#b31">[31]</ref> and automatic evaluation <ref type="bibr" target="#b27">[27]</ref>. Annotating all possible reasoning paths for evaluation is impractical, especially for those longstep problems facing combinatorial explosion. And it is also challenging to automatically evaluate the validity of reasoning paths without annotated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Performance improvement.</head><p>Reasoning path can also be used to improve the answer performance on multistep deductive reasoning, including the in-domain performance of LLMs and the generalization ability of PLMs. For this purpose, it is not necessary to involve all the required knowledge in the reasoning path or keep the validity of inferences as what we are concerned about are the final results rather than reasoning paths.</p><p>Firstly, reasoning paths can improve the in-domain performance by providing enriching context <ref type="bibr" target="#b142">[141,</ref><ref type="bibr" target="#b159">158]</ref> or supervision signal <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b177">176]</ref>. Recently, <ref type="bibr" target="#b159">[158]</ref> demonstrated that the LLMs' performance of several reasoning tasks such as commonsense reasoning (both deductive and defeasible) can be significantly improved by generating a reasoning path before the final answers, which is called chain-of-thought prompting (CoT). Before this, while LLMs are successful in classical NLP tasks, they fail in reasoning, especially multi-step reasoning tasks. This finding boosted a series of research on this line <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr" target="#b78">77,</ref><ref type="bibr" target="#b95">94,</ref><ref type="bibr" target="#b136">135,</ref><ref type="bibr" target="#b137">136,</ref><ref type="bibr" target="#b142">141,</ref><ref type="bibr" target="#b157">156,</ref><ref type="bibr" target="#b172">171,</ref><ref type="bibr" target="#b177">176,</ref><ref type="bibr" target="#b185">184]</ref>. Especially, <ref type="bibr" target="#b78">[77]</ref> showed that even a simple zero-shot prompting "let's think step by step" can activate LLMs to perform commonsense reasoning and attained impressive performance. Furthermore, <ref type="bibr" target="#b157">[156]</ref> found that the final performance on commonsense reasoning can be greatly further improved by just voting the results on multiple reasoning paths. Besides, in addition to performing reasoning on downstream tasks via few-shot prompting without changing the parameters, supervised finetuning LLMs on CoT annotations can further improve their reasoning capability <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b177">176]</ref>. In addition to commonsense reasoning, the performance of classical logical reasoning and multi-step reasoning are also improved significantly by generating CoT <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b142">141]</ref>. However, classical logical reasoning is much more challenging than other typical tasks <ref type="bibr" target="#b28">[28]</ref>. Instead of one-shot CoT generation, <ref type="bibr" target="#b28">[28]</ref> proposed a more inspiring framework (SI) for theorem proving (a task of classical deductive reasoning) based on modules with different prompting, which outperforms 40x larger LLMs with CoT. Moreover, <ref type="bibr" target="#b60">[59,</ref><ref type="bibr" target="#b179">178]</ref> found that LLMs can self-improve their reasoning capabilities by finetuning their self-generated reasoning paths. However, such abilities are only effective in LLMs, i.e. the model scale should be large enough, which is also seen as an emergent ability of LLMs that can be elicited by few-shot <ref type="bibr" target="#b159">[158]</ref> and even zero-shot prompting <ref type="bibr" target="#b78">[77]</ref>. There are some researches transferring the CoT reasoning capability of LLMs to smaller models via knowledge distillation <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b95">94,</ref><ref type="bibr" target="#b137">136]</ref>.</p><p>Moreover, it can improve the generalization ability of PLMs. It has been observed that constructing the proof graph for the goal hypothesis can improve the zero-shot generalization ability of medium-size PLMs to the unseen step of reasoning <ref type="bibr" target="#b127">[126,</ref><ref type="bibr" target="#b129">128,</ref><ref type="bibr" target="#b143">142]</ref> and to unseen domain <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b143">142]</ref> on the theorem proving task, which is likely because it forces models to perform reasoning rather than exploit shortcuts. Also, turning one-shot construction into a stepwise procedure has a better generalization to the unseen steps of reasoning and to cross datasets <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b143">142]</ref>.</p><p>However, the search space of forward reasoning suffers from the combinatorial explosion as the number of reasoning steps increases. In addition to performing a single-step inference, planning is also very important to multi-step reasoning, especially to deep steps. It has been observed that while LLMs are capable of a single inference, they still struggle to plan on deep reasoning steps <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b136">135]</ref>. Yet this topic is under-explored with few researches <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b167">166]</ref>.</p><p>In addition to deductive reasoning, leveraging reasoning paths to improve performance on defeasible reasoning is still under-explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Backward Reasoning</head><p>Backward reasoning repeatedly breaks down problems into sub-problems and solves them until reaching the answers. Similar to forward reasoning, it can be used to produce trustworthy reasoning paths explicitly represented with knowledge and inference relations <ref type="bibr" target="#b57">[56,</ref><ref type="bibr" target="#b115">114,</ref><ref type="bibr" target="#b144">143]</ref> or improve the final performance without strict structures <ref type="bibr" target="#b73">[72,</ref><ref type="bibr" target="#b75">74,</ref><ref type="bibr" target="#b98">97]</ref>. It faces a smaller search space and thus is more efficient than forward reasoning. There are two popular backward reasoning methods: backward chaining and question decomposition. While the former is a proof-finding strategy, the latter is a general strategy available for general problems. Researches mentioned in this section are mainly about deductive reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Backward</head><p>Chaining. Backward chaining is the preferable approach for proof-finding by humans. Beginning from the goal, it repeatedly performs abductive reasoning to derive the potential premises as sub-goals until all the sub-goals can be proved or disproved by the existing knowledge. According to the source of the premises, or sub-goals, there are two kinds of abduction: predict part of premises (others are the existing knowledge) and predict all premises. The first one is to predict the unknown required premise for a conclusion with the existing knowledge, which can be realized by vanilla generative PLMs, either medium-size <ref type="bibr" target="#b57">[56]</ref> or large size <ref type="bibr" target="#b73">[72]</ref>. The other one is to predict all the premises from scratch without relying on the existing explicit knowledge, which can be realized by LLMs <ref type="bibr" target="#b144">[143]</ref>. While the former kind of abduction is easier to perform, the latter can solve the scenario where all the required premises do not exist in the knowledge base. Compared to forward chaining, backward chaining has a smaller search space and thus is more efficient <ref type="bibr" target="#b73">[72]</ref>. Moreover, <ref type="bibr" target="#b73">[72]</ref> proposed a backward chaining modular framework with LLMs as modules, which attains better performance than the existing forward chaining frameworks. Another direction is to perform forward chaining (deduction) and backward chaining (abduction) simultaneously <ref type="bibr" target="#b57">[56]</ref>. In addition to proof-finding, backward chaining can also be generalized to more general problems. For example, <ref type="bibr" target="#b144">[143]</ref> applied it to a multi-choice question-answering problem by combing the question and each answer choice into a verifiable hypothesis.</p><p>However, researches on this line are more under-explored than forward chaining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Question Decomposition.</head><p>Question decomposition is a backward reasoning method to improve performance on multi-hop questions that require integrating multiple pieces of knowledge and inferring over them to obtain the answers. It decomposes each question into several simpler sub-questions and answers these sub-questions to derive the final answers. In analogy to forward reasoning, solving a single-hop sub-question is to query a single piece of knowledge, and combining sub-answers to form the final answer is inference. And decomposing a question into sub-questions is an abductive step. In other words, while question decomposition introduces abduction steps, it removes the requirement of multi-step knowledge selection/retrieval. Multi-hop questions are difficult to answer because they have a long tail distribution and are challenging to find the relevant multiple pieces of knowledge. Especially, it might be very challenging to find the required knowledge for implicit multi-hop questions, whose superficial text and semantics can be very different to the required knowledge. By contrast, it is easier to query a piece of knowledge and answer each decomposed single-hop sub-question. For example, <ref type="bibr" target="#b103">[102]</ref> demonstrated that both medium-size PLMs and LLMs can significantly improve the performance on multi-hop questions with human-decomposed questions. It was also found effective in mathematical reasoning and symbolic reasoning <ref type="bibr" target="#b192">[191]</ref>. Besides, previous research has also shown that question decomposition is effective with both medium-size PLMs <ref type="bibr" target="#b191">[190]</ref> and LLMs <ref type="bibr" target="#b108">[107]</ref> on multi-hop questions. Research of this line has a longer history than LLM-only CoT methods.</p><p>Decomposition of explicit and implicit multi-hop question. According to the difficulty of decomposition, multihop questions can be divided into explicit multi-hop questions and implicit multi-hop questions. Explicit multi-hop questions are those which can be decomposed simply based on their superficial text (syntactical pattern). For example, the question "where was Obama's wife born?" can be decomposed into "who is Obama's wife?" and "where was #1 born?"<ref type="foot" target="#foot_10">foot_10</ref> based on the superficial text of the original question. Implicit multi-hop questions, however, are more difficult to decompose since their sub-questions are not syntactically consistent with the questions. For example, the question "can we directly live in the space?" needs to be decomposed into "what do we need to keep alive?" and "are there #1 in the space?", where the key predicate in the first sub-question "need" is not explicitly mentioned in the original question. While explicit multi-hop questions can be decomposed based on their superficial text and syntactical structures via extraction and editing <ref type="bibr" target="#b98">[97]</ref>, decomposing implicit multi-hop questions is much more difficult. A key challenge is that it lacks large-scale annotated data, which is labourintensive to obtain especially as the number of hops increases. StrategyQA <ref type="bibr" target="#b45">[45]</ref> is an implicit multi-hop question dataset annotated with sub-questions and the corresponding knowledge pieces, but its size is small (2.7k). To alleviate the data sparsity problem, there is some research on weak supervision data <ref type="bibr" target="#b105">[104,</ref><ref type="bibr" target="#b191">190]</ref>. Recently, in-context learning provides a new solution <ref type="bibr" target="#b103">[102,</ref><ref type="bibr" target="#b108">107]</ref> to this problem, which requires only a small set of demonstrations.</p><p>Framework with respect to sequential and tree structure. There are different structures of decomposition based on the dependencies among the parent question and sub-questions, involving sequential structure and tree structure. In a sequential structure, each sub-question is linearly dependent on the answer (e.g. a bridge entity) of the antecedent sub-question, and the answer of the last sub-question is the multi-hop question's answer. For example, the answer "Michelle" of the first sub-question "who is Obama's wife?" makes up of its subsequent sub-question "where was #1 born?" whose answer "1964" is also the final answer of the multi-hop question "where was Obama's wife born?". By contrast, in a tree structure, sub-questions are independent to each other with their answers equally contributing to the final answer. For example, the question "who can swim better, elephant or dolphin?" consists of "can elephant swim?" and "can dolphin swim?", and the final answer is derived by composing the corresponding sub-answer "elephant can't swim" and "dolphin can swim". There are three kinds of decomposition-based framework: module-based decomposition <ref type="bibr" target="#b98">[97]</ref>, decompose-then-recompose <ref type="bibr" target="#b103">[102,</ref><ref type="bibr" target="#b105">104]</ref>, and generate-then-answer <ref type="bibr" target="#b75">[74,</ref><ref type="bibr" target="#b108">107]</ref>. The first framework designs different modules responsible for different reasoning types, which separate and model sequential and tree structure independently <ref type="bibr" target="#b98">[97]</ref>. The decomposethen-recompose framework first decomposes the multi-hop question into all its comprised sub-questions and recomposes their sub-answers to derive the final answer <ref type="bibr" target="#b103">[102,</ref><ref type="bibr" target="#b105">104]</ref>. However, it ignores the dependencies among sub-questions (sequential structure). By contrast, the last one, generate-then-answer, is sequential in nature, which iteratively generates and answers a single-hop sub-question <ref type="bibr" target="#b75">[74,</ref><ref type="bibr" target="#b108">107]</ref>. It considers the question dependencies in sequential structure and is compatible with tree structure, but is less efficient than decompose-then-recompose since it can't solve sub-questions of tree structure in parallel.</p><p>However, it is still challenging to solve multi-hop questions with very long hops. Due to the combinatorial explosion, it becomes increasingly difficult to annotate decomposition supervision data and provide representative demonstrations for in-context learning. Also, there are likely to exist multiple decomposition paths when there are long hops, which also puts a challenge on planning. The following are the potential directions we suggest.</p><p>• Hierarchical decomposition. Instead of directly decomposing the multi-hop question into the simplest single-hop sub-questions, it might be easier for models to perform hierarchical decomposition, i.e. repeatedly decompose multi-hop questions into simpler multi-hop questions until there are only single-hop questions. Moreover, it is also more practical for researchers to annotate supervision data or select appropriate exemplars of in-context learning for layer-by-layer decomposition. • Knowledge-aware planning. When there exist multiple decomposition paths, it is critical to plan for a decomposition way to answerable sub-questions. For this purpose, it is important to be aware of what the existing knowledge there is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Summary</head><p>Reasoning requires models to integrate multiple knowledge and reason over them. Early research mostly improved reasoning performance via architectural designs and only constructed forward reasoning paths for interpretability or faithfulness. Specialized models were designed to improve evidence aggregation, reasoning capability or faithfulness, but they are constrained to specific tasks, datasets or reasoning types that hurt the generalization. Since transformers have been found to be soft deductive reasoners after in-domain finetuning, vanilla PLMs have been more popular to perform reasoning. However, data sparsity and spurious correlation problems make it difficult for medium-size PLMs to learn the general logical structure of diverse reasoning types. There are also some researches incorporating inductive biases via specialized pretraining, but it is unclear whether this is still worth as the model size and the number of pretraining data increases. Recently, it was found that an emergent ability comes as PLMs are large enough: generating a reasoning path before the final answer can significantly improve the multi-step reasoning performance, which boosts much research on this line. In addition to the forward reasoning direction, the other reasoning direction is backward, which is more efficient than forward reasoning due to the smaller search space. While forward reasoning can expose arbitrary new knowledge entailed by the existing knowledge, backward reasoning just targets at the specific goal or the problem solution. A typical approach of backward reasoning is question decomposition, which can improve performance on multi-hop questions for both medium-size PLMs and LLMs. While there is much research on deductive reasoning, defeasible reasoning is much more challenging for PLMs and is still under-explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">NLR BENCHMARKS</head><p>In this section, we review some typical and popular downstream benchmarks thought to require natural language reasoning and discuss to what extent they are actually related to reasoning. Although there might be more downstream benchmarks with respect to natural language reasoning, here we mainly focus on four of the most popular and familiar to the community: classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. We list the corresponding datasets and benchmarks and briefly introduce the development. Besides, we present some datasets collected from realistic examinations or explicitly designed to challenge LLMs, which we name "complex reasoning". In addition to well-known reasoning benchmarks, we also introduce some other tasks that require performing natural language reasoning. A figure of the taxonomy is shown in Fig <ref type="figure" target="#fig_7">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Classical Logical Reasoning</head><p>Some datasets explicitly target classical reasoning types in philosophy and logic, e.g. deduction, abduction and induction, following the definitions in the two areas. Thus, we call them "classical logical reasoning tasks". A key characteristic of this topic is that tasks are mostly artificial to study reasoning. There are both deductive reasoning and defeasible reasoning.</p><p>5.1.1 Deductive reasoning. Classical deductive reasoning tasks are defined formally based on formal logic, such as propositional logic and first-order logic. There are mainly three types of task: inference <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b101">100,</ref><ref type="bibr" target="#b161">160]</ref>, theorem proving <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b143">142]</ref> and reasoning path generation <ref type="bibr" target="#b101">[100]</ref>. The inference task is to reason the conclusion given the premises in a single step, while theorem proving is to predict whether the given proposition is true or false with the given knowledge bases, which usually requires multiple steps. Obviously, inference is the fundamental task that forms the basic capability of multi-step reasoning tasks such as theorem proving, while reasoning path generation is an interpretable task that can be complementary to multi-step reasoning. However, except FOLIO <ref type="bibr" target="#b49">[49]</ref>, all the existing explicit deductive reasoning datasets are synthesized. We list the classical deductive reasoning datasets in Table <ref type="table">7</ref>.</p><p>Dataset Size Data Source Task Remark bAbI-15 <ref type="bibr" target="#b161">[160]</ref> synthetic inference basic deduction RuleTaker † <ref type="bibr" target="#b25">[25]</ref>/ProofWriter † <ref type="bibr" target="#b143">[142]</ref> 500k synthetic theorem proving the first natural language theorem proving PARARULE-Plus <ref type="bibr" target="#b4">[5]</ref> 400k synthetic theorem proving addresses the depth imbalance issue on ParaRules AAC <ref type="bibr" target="#b5">[6]</ref> 710k synthetic inference based on 8 syllogistic argument schemes</p><p>LogicInference <ref type="bibr" target="#b101">[100]</ref> 200k synthetic inference reasoning path generation -</p><formula xml:id="formula_0">FOLIO [49]</formula><p>1.4k expert-written theorem proving more diverse patterns Table <ref type="table">7</ref>. Datasets of classical deductive reasoning, where bAbI-15 means "the 15-th task in bAbI tasks". † denotes there are ground reasoning paths.</p><p>Proof-finding and faithful reasoning. Since <ref type="bibr" target="#b25">[25]</ref> has proposed a theorem proving dataset and showed that vanilla medium-size PLMs can be soft theorem provers, a series of researches emerge on this task to study natural language reasoning, with both vanilla medium-size PLMs <ref type="bibr" target="#b127">[126,</ref><ref type="bibr" target="#b129">128,</ref><ref type="bibr" target="#b131">130,</ref><ref type="bibr" target="#b167">166,</ref><ref type="bibr" target="#b182">181]</ref> and LLMs <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b73">72,</ref><ref type="bibr" target="#b136">135,</ref><ref type="bibr" target="#b143">142]</ref>. However, while the performance of transformers on theorem proving is promising, <ref type="bibr" target="#b182">[181]</ref> found that there are some statistical features inherently existing in the problem, which may hinder models from generalization. In addition to just classifying the final label <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b182">181]</ref>, it has been demonstrated that producing proofs can bring better generalization ability to unseen proof depth and out-of-domain data <ref type="bibr" target="#b127">[126,</ref><ref type="bibr" target="#b143">142]</ref> and contribute to interpretability. There is several research on proof generation or proof-finding, either forward <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b131">130,</ref><ref type="bibr" target="#b143">142]</ref> or backward <ref type="bibr" target="#b73">[72,</ref><ref type="bibr" target="#b84">83,</ref><ref type="bibr" target="#b115">114]</ref>, where backward chaining is more efficient than forward chaining on proof-finding intrinsically <ref type="bibr" target="#b73">[72]</ref>. To alleviate the combinatorial explosion problem in the search space of the forward chaining, some researchers proposed planning <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b167">166]</ref>. Moreover, faithful reasoning is also an interesting topic in this problem, where the procedure of reasoning is strictly designed to guarantee that models actually perform reasoning to derive the answer rather than rely on shortcuts <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b131">130]</ref>. However, while the performance is promising, even approaching perfect sometimes, all research mentioned above is based on synthetic datasets. Moreover, recently, the new expert-written dataset FOLIO <ref type="bibr" target="#b49">[49]</ref> showed that when it comes to more diverse natural language, the performance degrades severely. By contrast, the entailment tree generation dataset EntailmentBank <ref type="bibr" target="#b31">[31]</ref> is often used to study the proof generation and faithful reasoning as with theorem proving <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b57">56,</ref><ref type="bibr" target="#b121">120,</ref><ref type="bibr" target="#b144">143,</ref><ref type="bibr" target="#b167">166]</ref>. The target hypotheses in this dataset are collected from realistic examinations and proofs are annotated by humans, which is a better alternative for studies on proof generation.</p><p>There are also some benchmarks to diagnose model's capabilities on logical semantics understanding <ref type="bibr" target="#b120">[119,</ref><ref type="bibr" target="#b128">127,</ref><ref type="bibr" target="#b130">129]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Defeasible reasoning.</head><p>Two typical defeasible reasoning types are abduction <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b175">174]</ref> and induction <ref type="bibr" target="#b161">[160,</ref><ref type="bibr" target="#b168">167]</ref>. There is also another type of defeasible reasoning <ref type="bibr" target="#b123">[122]</ref>. Datasets are shown in Table <ref type="table">8</ref>. Compared to classical deductive reasoning, researches on defeasible reasoning are still under-explored. Experiments suggested that there remains a large space to improve <ref type="bibr" target="#b168">[167]</ref>.</p><p>Inductive reasoning. Induction produces a more general principle from the given knowledge that can express or explains them. Early datasets require first inducing rules and then applying them to perform deduction, without inducing explicit rules <ref type="bibr" target="#b138">[137,</ref><ref type="bibr" target="#b161">160]</ref>. Recently, a new dataset DEER <ref type="bibr" target="#b168">[167]</ref> studies rule prediction, where the task is to induce natural language rules from natural language facts.</p><p>Abductive reasoning. Abduction is to predict the best explanation for the observations. According to the mode of the reversed reasoning, abduction can provide explanations that constitute premises of whether deductive reasoning <ref type="bibr" target="#b175">[174]</ref> or defeasible reasoning <ref type="bibr" target="#b6">[7]</ref>. Based on the explained objects (i.e. input), abduction may target a small set of premises <ref type="bibr" target="#b6">[7]</ref> or a knowledge corpus <ref type="bibr" target="#b175">[174]</ref>.</p><p>Others. In addition to abduction and induction, defeasibleNLI <ref type="bibr" target="#b123">[122]</ref> focuses on whether a premise can weaken or strengthen a probable conclusion. There are researches on defeasible inference graphs to improve both human reasoning <ref type="bibr" target="#b93">[92]</ref> and machine reasoning performance <ref type="bibr" target="#b94">[93]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Reasoning Size Source Task Remark bAbI-16 [160] induction -synthetic extraction induce-then-deduce CLUTRR [137] induction -synthetic extractive QA induce-then-deduce DEER [167] induction 1.2k Wikipedia generation rule prediction AbductionRules [174] abduction -synthetic generation abduce from knowledge database ART [7] abduction 17.8k ROCStories [98] 2-choice/generation abduce from two premises defeasibleNLI [122] others 43.8k other datasets classification/generation concern the change of strength</p><p>Table 8. Datasets of classical defeasible reasoning, where bAbI-16 means "the 16-th task in bAbI tasks".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Natural Language Inference</head><p>Natural language inference (NLI), also known as recognizing textual entailment (RTE), is a typical task in NLP. It is a 3-way classification task labelling as entailment, contradiction and neutral, to identify whether the given premise entails a hypothesis. An entailment is described as a conclusion that a person would typically infer from the premise or the implication described by the premise <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">29]</ref>. While NLI is regarded as a natural language understanding <ref type="bibr" target="#b11">[12]</ref> or natural language reasoning <ref type="bibr" target="#b25">[25]</ref> problem, we find it involves examples of both understanding and reasoning problems. Specifically, we identify there are mainly three types of premise-hypothesis entailment problems: paraphrasing, compound semantics understanding, and reasoning with implicit premises. For the first type, the hypothesis is a paraphrase of the premise. For the second type, the premise is a compound proposition entailing the hypothesis. For the last type, there need some unstated premises to link the provided premise to the hypothesis. We demonstrate samples from the popular dataset SNLI <ref type="bibr" target="#b11">[12]</ref> for each type respectively in Table <ref type="table">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Premise Hypothesis</head><p>Paraphrase Two doctors perform surgery on patient Doctors are performing surgery CSU Two women are embracing while holding to go packages Two women are holding packages (Two women are embracing)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reasoning</head><p>A soccer game with multiple males playing (Soccer is a sport) Some men are playing a sport Table <ref type="table">9</ref>. Examples from SNLI <ref type="bibr" target="#b11">[12]</ref> of three types of entailment, where CSU indicates "Compound Semantics Understanding". The blue-coloured sentence is the implicit premise, while the orange-coloured sentence is the other semantics of the premise.</p><p>There are several popular generic datasets listed in Table <ref type="table" target="#tab_6">10</ref>, where datasets with realistic hypotheses have few hypothesis-only biases than those with human-authored hypotheses. Concretely, it has been found that there are significant biases in human-authored hypotheses <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b162">161]</ref>, with which models can even predict the label without premise <ref type="bibr" target="#b107">[106,</ref><ref type="bibr" target="#b153">152,</ref><ref type="bibr" target="#b163">162]</ref>. Several datasets and benchmarks of NLI are just understanding problems, such as those presented specifically to probe and improve the model capabilities of paraphrase and compound semantics understanding <ref type="bibr" target="#b58">[57,</ref><ref type="bibr" target="#b128">127,</ref><ref type="bibr" target="#b165">164,</ref><ref type="bibr" target="#b166">165]</ref>. Also, datasets that are converted from other tasks into NLI-style are irrelevant to reasoning when they are not the reasoning problems originally <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b174">173]</ref>.</p><p>Interestingly, it was shown that crowdworkers sometimes annotated different labels to the same premisehypothesis pair <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">21]</ref>. We think this phenomenon can be attributed to the existence of defeasible reasoning, where people with different background knowledge can derive different conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Multi-Hop Question Answering</head><p>Multi-hop question answering (MHQA) studies answering the complex questions that require reasoning over evidence scattered in different contexts <ref type="foot" target="#foot_11">8</ref> , thus it is also called as multi-hop reading comprehension, where candidate contexts are either explicitly provided involving some distractors <ref type="bibr" target="#b54">[54,</ref><ref type="bibr" target="#b152">151,</ref><ref type="bibr" target="#b160">159,</ref><ref type="bibr" target="#b170">169]</ref> (distractor setting), or can be retrieved from external knowledge bases such as Wikipedia <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b110">109,</ref><ref type="bibr" target="#b170">169]</ref> and WorldTree <ref type="bibr" target="#b74">[73]</ref> (retrieval setting). The term "hop" here indicates the number of contexts required to reason rather than the number of inference steps, which describes the behaviour moving among different contexts.</p><p>Datasets &amp; Benchmarks. We list some typical datasets in Table <ref type="table" target="#tab_0">11</ref>. A key challenge on dataset construction is that it is very label-intensive to annotate large-scale multi-hop questions especially there is a combinatorial explosion as the number of hops increases. Many datasets are synthetic or semi-synthetic <ref type="bibr" target="#b54">[54,</ref><ref type="bibr" target="#b66">65,</ref><ref type="bibr" target="#b160">159,</ref><ref type="bibr" target="#b170">169]</ref>, where questions are mainly deductive, i.e. the answers are necessarily true with the given contexts. There are two types of rationale: supporting text set <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b74">73,</ref><ref type="bibr" target="#b152">151,</ref><ref type="bibr" target="#b170">169]</ref> and reasoning path including both forward <ref type="bibr" target="#b66">[65,</ref><ref type="bibr" target="#b68">67]</ref> and backward <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b152">151]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-hop question construction.</head><p>There are mainly two lines on multi-hop question construction: improve data quality and increase data number. Firstly, it has been found that there are artifacts in HotpotQA that can be leveraged to answer questions without performing multi-hop reasoning <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b69">68,</ref><ref type="bibr" target="#b97">96,</ref><ref type="bibr" target="#b151">150]</ref>. To deal with this problem, one way is to leverage adversarial data <ref type="bibr" target="#b54">[54]</ref>, another way is to construct new datasets of high-quality multi-hop questions with carefully designed data collection strategies <ref type="bibr" target="#b54">[54,</ref><ref type="bibr" target="#b152">151]</ref>. Secondly, as multi-hop questions are difficult to annotate, there are some researches on automatic data generation <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b102">101,</ref><ref type="bibr" target="#b176">175]</ref>.</p><p>Reasoning. After deriving the relevant contexts, it requires aggregating multiple pieces of evidence and reasoning over them. Firstly, there are some specialized models designed for better evidence aggregation <ref type="bibr" target="#b62">[61,</ref><ref type="bibr" target="#b186">185]</ref>. Secondly, reasoning is usually performed via end-to-end answering <ref type="bibr" target="#b62">[61,</ref><ref type="bibr" target="#b67">66,</ref><ref type="bibr" target="#b82">81,</ref><ref type="bibr" target="#b186">185,</ref><ref type="bibr" target="#b187">186]</ref> or backward Dataset Domain Size CS QS AT Rationale WikiHop [159] generic 51k Wikipedia synthetic option × MedHop [159] medicine 2.5k Medline synthetic option × HotpotQA [169] generic 112k Wikipedia semi-synthetic span yes/no sentences R4C [65] generic 4.6k Wikipedia semi-synthetic span yes/no triples BeerQA [109] generic 530 Wikipedia human-authored span yes/no × 2WikiMultiHopQA [54] generic 192k Wikipedia synthetic span sentences triples MuSiQue [151] generic 25k Wikipedia human-composed span paragraphs decomposition★ QASC [73]/eQASC † [67] science 9.9k WorldTree human-authored option sentences reasoning path [67]★ StrategyQA [45] generic 2.7k Wikipedia human-authored yes/no paragraphs decomposition★ Table <ref type="table" target="#tab_0">11</ref>. Datasets of multi-hop question answering. † indicates it annotates the rationale for this dataset. "CS" denotes "Context Source", "QS" denotes "Question Source", and "AT" denotes "Answer Type". In CS, the distractor setting is coloured blue, while the retrieval setting is coloured orange, and black means there are both. For rationale, ★ means "reasoning path", otherwise "supporting evidence set". "decomposition" indicates the ground annotations of decomposed sub-questions and the corresponding contexts.</p><p>decomposition <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b75">74,</ref><ref type="bibr" target="#b98">97,</ref><ref type="bibr" target="#b103">102,</ref><ref type="bibr" target="#b105">104,</ref><ref type="bibr" target="#b108">107]</ref>. In this topic, question decomposition (i.e. backward reasoning) is more popular than forward reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Commonsense Reasoning</head><p>Commonsense reasoning deals with implicit commonsense knowledge, where commonsense knowledge is necessarily required to solve the problem. Such knowledge may be obvious to people but non-trivial to machines since they are difficult to retrieve from the web due to reporting bias, e.g. "when people are hungry, they would like to eat something". However, although it is named as "commonsense reasoning", not all the datasets are reasoning as defined (Sec 2.1), such as querying shared living experiences <ref type="bibr" target="#b9">[10]</ref>, identifying pragmatic implications <ref type="bibr" target="#b134">[133]</ref>, and so on <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b86">85]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Datasets &amp; Benchmarks.</head><p>According to the conclusion type, there are mainly three types of reasoning problems in commonsense reasoning: "what" (i.e. assertions or events) "what if / why" (e.g. causal and temporal relations between events), and "how" (i.e. actions).</p><p>What. This type of problem is similar to multi-hop question answering, where the problems require combining multiple pieces of knowledge that some are from external knowledge sources. The key difference is that it requires some commonsense knowledge, which is not explicitly provided, in commonsense reasoning. In other words, the problems require integrating explicit knowledge, such as science <ref type="bibr" target="#b85">[84,</ref><ref type="bibr" target="#b96">95]</ref>, with some commonsense knowledge. We list some datasets in Table <ref type="table" target="#tab_0">12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Other Knowledge Knowledge Source Size Task Rationale</p><p>OpenBookQA <ref type="bibr" target="#b96">[95]</ref> science WorldTree 6k multi-choice QA science facts OpenCSR <ref type="bibr" target="#b85">[84]</ref> science WorldTree, ARC corpus 20k free-form QA × CREAK <ref type="bibr" target="#b100">[99]</ref> entity Wikipedia 13k claim verification explanation</p><p>Table 12. Datasets of "what" commonsense reasoning.</p><p>What if &amp; Why. This type of problem often reasons for causal and temporal relations between events. There are two causal relations: causes and effects, which can be seen as backward causal reasoning and forward causal reasoning respectively. Take the causality of events as an example, forward causal reasoning asks "what events are likely to happen next?", while backward causal reasoning asks "what may cause this event?" in a scenario described by the context, i.e. querying the plausible previous or subsequent events respectively. Besides, there are some problems that require considering another scenario in addition to the context, which can be seen as constrained causal reasoning. For example, TIMETRAVEL <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b112">111]</ref> is a counterfactual story rewriting dataset, where the original story is also given. See relevant datasets and benchmarks in Table <ref type="table" target="#tab_0">13</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Size Direction Context Source Task Remark ROCStories [98] 50k temporal human-authored 2-choice QA -SWAG [179] 113k temporal ActivityNet, LSMDC multi-choice QA -HellaSwag [180] 20k temporal ActivityNet, WikiHow multi-choice QA an upgraded SWAG COPA [121] 1k both human-authored 2-choice QA -Social-IQA [134] 38k both human-authored multi-choice QA social situations e-CARE † [37] 21k both human-authored 2-choice QA -WIQA [149] 40k forward ProPara [148] multi-choice QA about nature processes TIMETRAVEL [111] 29k forward ROCStories [98] generation counterfactual reasoning ART [7] 20k backward ROCStories [98] 2-choice/generation abductive commonsense reasoning TellMeWhy [79] 30k backward ROCStories [98] free-form QA each annotated 3 possible answers WikiWhy † [52] 9k backward human-edited Wikipedia free-form QA about Wikipedia entities / events</p><p>Table 13. Datasets of "what if" / "why" commonsense reasoning, where † denotes there annotates supporting facts or reasoning paths. For direction, "both" indicates there are both forward and backward causal reasoning.</p><p>How. This type of problem is mainly about "how to do it". It is more complex and also involves problem-solving and decision-making. See some in Table <ref type="table" target="#tab_0">14</ref>).</p><p>Dataset Size Context Source Option Source Task Remark WikiHow Goal-Step [182] 1489k WikiHow automatically generated multi-choice goals, steps, and temporal ordering PIQA [8] 21k human-authored human-authored 2-choice physical causal reasoning</p><p>Table 14. Datasets of "how" commonsense reasoning.</p><p>Others. Besides, some datasets involve multiple types of reasoning. We list some typical datasets in Table <ref type="table" target="#tab_2">15</ref>.</p><p>, Vol.</p><p>1, No. 1, Article . Publication date: May 2023. Natural Language Reasoning, A Survey • 25 Size Context Source Question Source Task Remark CSQA [144] CoS-E † [117]/ECQA † [1] 12k -semi-synthetic multi-choice QA ConceptNet concepts [138] explanation [1, 117], commonsense facts [1] CSQA2 [146] 14k -human-authored boolen QA data construction via gamification CosmosQA [60] 35k blog [17] human-authored multi-choice QA reading comprehension on blogs Moral Stories [38] 12k human-authored -classification/generation situated reasoning with social norms</p><p>Table 15. Datasets and benchmarks with multiple types of commonsense reasoning. † indicates it annotates the rationale for the dataset. 5.4.2 Reasoning. Since commonsense knowledge is essential to this topic, much research focused on commonsense knowledge [42, 64, 76, 82, 88, 118, 132, 138]. As for the reasoning system, there are mainly two types of methods: graph-based [40, 84, 170, 183] and vanilla PLMs [70, 76, 90, 112, 147, 176], where graph-based methods are designed to aggregate knowledge from commonsense knowledge bases while vanilla PLMs are used as implicit knowledge bases themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Complex Reasoning</head><p>There are some datasets collected from realistic examinations or tests, which may require domain-specific knowledge and multiple types of reasoning skills (Table <ref type="table" target="#tab_0">16</ref>).</p><p>Dataset Size Domain Source Task AR-LSAT [189] 2k law law school admission test multi-choice QA HEAD-QA [154] 6.7k healthcare specialized healthcare examination multi-choice QA AI2-ARC [24]/EntailmentBank † [31] 7.7k science grade-school standardized test multi-choice QA ReClor [177]/MetaLogic † [62] 6k generic standardized graduate admission examination RC + multi-choice QA LogiQA [89] 8k generic national civil servants examination of China RC + multi-choice QA ConTRoL [87] 8k generic competitive selection and recruitment test passage-level NLI</p><p>Table 16. Complex reasoning datasets with the realistic data from examinations or tests, where "RC" denotes "reading comprehension". † indicates "it annotates reasoning paths for some examples in this dataset".</p><p>To better diagnose the ability of LLMs, two few-shot prompting benchmarks called MMLU <ref type="bibr" target="#b50">[50]</ref> and Big-Bench <ref type="bibr" target="#b140">[139]</ref> are proposed, where tasks are much more challenging and even believed to be beyond the capabilities of current language models, in which some require to perform reasoning. Among tasks in Big-Bench, <ref type="bibr" target="#b142">[141]</ref> identified 23 challenging tasks, named as Big-Bench Hard (BBH), that LLMs failed to surpass the average humanrater, and many of them require to perform multi-step reasoning. However, when equipped with CoT prompting, GPT3 can outperform human performance on a major of these hard tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Others</head><p>In addition to the above-mentioned datasets and benchmarks, there are also some other tasks requiring natural language reasoning scattered in the NLP domain, involving dialog <ref type="bibr" target="#b126">[125]</ref>, reading comprehension <ref type="bibr" target="#b87">[86]</ref> and so on <ref type="bibr" target="#b48">[48]</ref>. Note that reasoning is an important method to arrive at the required answers or solutions, which is of more frequent usage in complex problems. In other words, reasoning can occur in many other domains to solve challenging problems that require multiple knowledge to derive conclusions. While there might be more reasoning tasks or datasets, we just list some of them in Table <ref type="table" target="#tab_0">17</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Size Reasoning Context Source Task ShARC <ref type="bibr" target="#b126">[125]</ref> 32k deductive government document conversation + boolean QA ROPES <ref type="bibr" target="#b87">[86]</ref> 14k deductive science textbook, Wikipedia RC + extractive QA ARC <ref type="bibr" target="#b48">[48]</ref> 2k abductive news comment 2-choice Table <ref type="table" target="#tab_0">17</ref>. Some other NLP benchmarks requiring natural language reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In this section, we propose some open questions, introduce some limitations, and suggest some future directions for reasoning. Among these, we also discuss the limitations of ChatGPT and GPT4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Open questions</head><p>We propose some open questions towards the reasoning capabilities of LLMs. There are many mysteries in their emergent reasoning capabilities.</p><p>• Why are CoT prompting effective?. Why can just produce reasoning paths, which can even be wrong, before the final answer bring such significant improvement? And why CoT prompting is only effective for LLMs? What happens to LLMs when prompting with CoT but fails at medium-size PLMs? • Where are these reasoning capabilities of LLMs from?. Why can LLMs emerge reasoning capabilities just as the model size increases? Where does the magic "Let's think step by step" come from? How can they learn these capabilities? While the mechanism of another LLMs magic, in-context-learning, has been studied <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b164">163]</ref>, it remains more mysterious about reasoning capabilities <ref type="bibr" target="#b109">[108]</ref>. • Do even larger models reason better?. If LLMs can emerge reasoning capabilities that can be elicited by prompts, whether they can learn competitive reasoning capabilities just as the model size increases? Or, whether it is still beneficial to build more datasets and design reasoning algorithms?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Limitations</head><p>We introduce both limitations of the current research and intrinsic in PLMs. Firstly, there are gaps in defeasible reasoning and reasoning path evaluation.</p><p>• Research gap on defeasible reasoning. While defeasible reasoning is widely used in our daily life, this topic is still under-explored in NLP. <ref type="bibr" target="#b3">[4]</ref> found that it is more challenging for ChatGPT to perform abductive reasoning and inductive reasoning than deduction, among which induction is the much more difficult one. • Lack of effective ways to evaluate reasoning paths. It is still challenging to automatically evaluate generated reasoning paths without ground truth. Evaluating reasoning paths might become increasingly important to build explainable and reliable AI systems, especially when more people contact and use ChatGPT-like products nowadays.</p><p>Secondly, there are also limitations intrinsic to PLMs.</p><p>• Soft deduction can produce invalid conclusions. Transformers can only predict conclusions with probability, irrespective of whether the conclusion of deductive reasoning is necessarily true in nature, which might prevent it from precise reasoning. This characteristic can result in a sub-optimal solution to deductive problems (including arithmetic reasoning and symbolic reasoning). For example, while ChatGPT is impressive on reasoning tasks, it still fails to achieve perfect performance on the simplest one-step deductive inference task <ref type="bibr" target="#b3">[4]</ref>.</p><p>• Biases on content. PLMs make their prediction based on context. While LLMs have made huge progress in reasoning, <ref type="bibr" target="#b32">[32]</ref> found that LLMs are biased by content like humans when performing deduction. For example, they perform worse in abstract or counterfactual situations than the realistic ones. Such biases will hinder them from actual reasoning and lead to wrong answers, degrading downstream performance. More severely, it might cause harmful societal influences due to some social biases such as gender, which also exist in GPT4 <ref type="bibr" target="#b16">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Future</head><p>We suggest some potential research directions at both the holistic and technical levels in the future. At the holistic level, firstly, reasoning should be generalized to more complex settings (longer steps and defeasible reasoning) and more diverse knowledge mediums (languages and modalities). Secondly, it should put more attention on interpretability and faithfulness. We introduce these directions as the following.</p><p>• Generalization to longer steps. The multi-step performance degrades as PLMs encounter samples that require more reasoning steps than those in training data or few-shot exemplars. Although there is research on decoupled one-step inference, which can alleviate the challenge of the OOD problem, it still struggles with planning. How to better generalize to longer steps is an important problem for complex reasoning tasks, which are also challenging to ChatGPT <ref type="bibr" target="#b3">[4]</ref>. • More researches on defeasible reasoning. PLMs are currently the most potential path to defeasible reasoning due to advantages we have introduced in Sec 3. According to philosophy, non-deductive reasoning is much more common than deductive reasoning in our daily lives and practical scenes. It is worth more effort to explore PLMs on defeasible reasoning since there lack of effective methods to deal with defeasible reasoning, while deductive reasoning can be solved by developed symbolic engines <ref type="foot" target="#foot_12">9</ref> , e.g. Prolog coding for first-order logic. Moreover, it might benefit scientific research a lot if AI can induce general rules from specific facts. • Reasoning over non-English languages. In addition to reason over English statements, it is also important to perform reasoning with other languages, which is much more challenging due to more severe data sparsity problems. • Reasoning with multi-modality. Other types of modalities can also contribute to reasoning, such as tables <ref type="bibr" target="#b22">[22]</ref> and images <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b81">80,</ref><ref type="bibr" target="#b141">140,</ref><ref type="bibr" target="#b173">172]</ref>. Recently, GPT4 can process images, which might push forward visual reasoning. • Interpretability and faithful reasoning. Transparent and reliable reasoning paths become increasingly important when it generalizes to longer steps and defeasible reasoning. Firstly, when there are many steps, it takes more time and effort for people to check the quality of reasoning. Therefore, unfaithful reasoning might introduce difficulty in people's judgement and decision-making. Secondly, when it comes to defeasible reasoning, exposing interpretable reasoning paths is much more important and sometimes necessary for people to be convinced. In this case, different people with different background knowledge can derive different and even opposed conclusions, thus it is crucial to illustrate the evidence collected to reason.</p><p>At the technical level, we suggest several directions to improve reasoning capabilities and performance of multi-step reasoning and defeasible reasoning as follows.</p><p>• More prompts to elicit reasoning capabilities from LLMs. Few-shot CoT and zero-shot CoT prompting are inspiring, and CoT annotations have been used to improve LLMs' reasoning capabilities <ref type="bibr" target="#b23">[23]</ref>. It is both interesting and important to find whether there are other prompts that can activate LLMs to perform reasoning or are beneficial to improving reasoning capabilities, especially on complex reasoning. • Self-improvement of LLMs. Data annotations for reasoning paths, especially for long-step and defeasible reasoning, are difficult to obtain. Interestingly, in our case studies, we found that ChatGPT can provide more comprehensive answers than the ground annotations in some existing datasets such as EntailmentBank <ref type="bibr" target="#b31">[31]</ref> and WikiWhy <ref type="bibr" target="#b52">[52]</ref>. Recent research have demonstrated that LLMs can learn from their self-generated reasoning paths to improve reasoning capabilities <ref type="bibr" target="#b60">[59,</ref><ref type="bibr" target="#b179">178]</ref>, which is the potential to alleviate the data challenge. • More exploration on backward reasoning. Backward reasoning can benefit both medium-size PLMs and LLMs, while CoT prompting only benefits LLMs. Moreover, it is more efficient than forward reasoning with a smaller search space, which can bring more benefits as the depth of reasoning increases. To solve more complex reasoning problems, it is worth conducting more exploration on this direction. • More researches on planning. Planning is important to perform longer-step reasoning since the search space will become bigger as the depth increases. • Exploration on self-correction. Since the conclusion of defeasible reasoning can be retracted by newly added evidence, it might be important for PLMs to self-correct their conclusions as the reasoning proceeds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2. 1 . 1 Fig. 1 .</head><label>111</label><figDesc>Fig. 1. Architecture of this survey.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Timeline of important works.</figDesc><graphic coords="5,98.72,104.61,414.51,54.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Reasoning process. The premises can be either explicit or implicit knowledge, e.g. PLMs' memory.</figDesc><graphic coords="7,193.35,212.61,225.29,132.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Further</head><figDesc>clarify the definition of NLP reasoning. We leverage these concepts to clarify the definition of NLP reasoning: what we mean by "integrate multiple information to derive new conclusions" is that (1) a single sentence conveying multiple semantics can provide multiple premises, (2) there must yield new semantics in inference and reasoning, i.e. conclusions are semantically different to all premises. We detail two examples to demonstrate this key idea (Fig 4) and illustrate the definition of reasoning in Fig 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Examples to show the key idea of "semantic difference", where check mark denotes reasoning while cross denotes not reasoning.</figDesc><graphic coords="7,103.23,463.85,405.48,139.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Taxonomy of natural language reasoning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. An example to demonstrate the reasoning procedure of end-to-end reasoning, forward reasoning, and backward reasoning. White colours the question, green colours the intermediate text, and orange colours the answer.</figDesc><graphic coords="13,98.72,104.61,414.57,199.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Natural language reasoning benchmarks in NLP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison and combination of descriptions about reasoning from philosophy and NLP.</figDesc><table><row><cell></cell><cell>What is Reasoning</cell><cell>What isn't Reasoning</cell></row><row><cell>Philosophy</cell><cell>infer a new assertion from a set of assertions infer an action from goals and knowledge</cell><cell>sensation, perception and feeling direct recourse to sense perceptions or immediate experience</cell></row><row><cell>NLP</cell><cell>more than understanding, slow thinking e.g. multi-hop QA, commonsense reasoning</cell><cell>memorize, look up, match information e.g. text summarization, style transfer</cell></row><row><cell>Combination</cell><cell cols="2">a dynamic process to integrate multiple knowledge to get new conclusions, rather than direct recourse to memorized or provided first-hand information</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .</head><label>5</label><figDesc>The characteristics of the deductive inference and defeasible inference.</figDesc><table><row><cell>Inference</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 10 .</head><label>10</label><figDesc>Datasets of NLI. "P" denotes "Premise" while "H" denotes "Hypothesis". † means that e-SNLI provides explanations for examples of SNLI.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Domain Size P Source H Source</cell><cell>Remark</cell></row><row><cell cols="2">SNLI [12]/e-SNLI † [18] generic</cell><cell cols="2">570k realistic</cell><cell cols="2">human-authored the first large-scale NLI dataset</cell></row><row><cell>MultiNLI [161]</cell><cell>generic</cell><cell cols="2">433k realistic</cell><cell cols="2">human-authored cover more styles and topics</cell></row><row><cell>XNLI [26]</cell><cell>generic</cell><cell cols="2">7.5k -</cell><cell>-</cell><cell>cross-lingual, based on MultiNLI</cell></row><row><cell>SciTail [75]</cell><cell>science</cell><cell>27k</cell><cell>realistic</cell><cell>realistic</cell><cell>the first NLI dataset with entirely realistic data</cell></row><row><cell>SciNLI [124]</cell><cell>science</cell><cell cols="2">107k realistic</cell><cell>realistic</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>• Fei Yu, Hongbo Zhang, Prayag Tiwari, and Benyou Wang</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In this survey, we refer to transformer-based pre-trained language models. , Vol. 1, No. 1, Article . Publication date: May 2023. Natural Language Reasoning, A Survey •</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>Although recently it is popular to solve mathematical reasoning problems such as math word problems using NLP methods, we do not cover them in this paper since mathematical reasoning is very different to natural language reasoning in nature as math is precise and formal.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>, Vol. 1, No. 1, Article . Publication date: May 2023. Natural Language Reasoning, A Survey • 5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>, Vol. 1, No. 1, Article . Publication date: May 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_6"><p>"Valid" means when the premises are true, the conclusion is impossible to be false.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_7"><p>There are also some researches on producing natural language explanations instead of reasoning procedure, but we just focus on reasoning paths in this survey</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_8"><p>By contrast, the ability of deduction learned in the synthetic dataset can be generalized to other domains<ref type="bibr" target="#b25">[25]</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p>, Vol. 1, No. 1, Article . Publication date: May 2023. Natural Language Reasoning, A Survey • 17</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_10"><p>"#1" denotes the answer of the first sub-question.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_11"><p>There are not only natural language reasoning questions, but also other types such as numerical comparison<ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b170">169]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_12"><p>Arithmetic reasoning and symbolic reasoning, which are popular recently, are also deductive and can be solved by calculator or code.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We appreciate the assistance from <rs type="person">Ridong HAN</rs> during the investigation and the suggestion from Zhihong CHEN on the figure demonstration in this survey.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Explanations for commonsenseqa: New dataset and models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mandowara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">August 1-6, 2021. 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3050" to="3065" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">What learning algorithm is in-context learning? investigations with linear models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Akyürek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno>CoRR, abs/2211.15661</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Dictionary of Philosophy</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Angeles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Barnes &amp; Noble Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wilie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<idno>CoRR, abs/2302.04023</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-step deductive reasoning over natural language: An empirical study on out-of-distribution generalisation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hartill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno>IJCLR-NeSy 2022</idno>
	</analytic>
	<monogr>
		<title level="m">The 2nd International Joint Conference on Learning and Reasoning and 16th International Workshop on Neural-Symbolic Learning and Reasoning</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Critical thinking for language models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Betz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWCS</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="63" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Abductive commonsense reasoning. In ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">PIQA: reasoning about physical commonsense in natural language</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">February 7-12, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="7432" to="7439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The Oxford Dictionary of Philosophy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Blackburn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Protoqa: A question answering dataset for prototypical common-sense reasoning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boratko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>O'gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1122" to="1136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Flexible generation of natural language deductions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bostrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-11">7-11 November, 2021. 2021</date>
			<biblScope unit="page" from="6266" to="6278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Pighin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Marton</surname></persName>
		</editor>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language</meeting>
		<imprint>
			<date type="published" when="2023-05">May 2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><surname>Processing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-09-17">2015. September 17-21, 2015. 2015</date>
			<publisher>The Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="632" to="642" />
			<pubPlace>Lisbon, Portugal</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E O E</forename><surname>Britannica</surname></persName>
		</author>
		<ptr target="https://www.britannica.com/topic/inference-reason" />
		<title level="m">inference. Encyclopedia Britannica</title>
		<imprint>
			<date type="published" when="2017-06-16">16 Jun. 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E O E</forename><surname>Britannica</surname></persName>
		</author>
		<ptr target="https://www.britannica.com/topic/reason" />
		<title level="m">reason. Encyclopedia Britannica</title>
		<imprint>
			<date type="published" when="2020-05-15">15 May. 2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. December 6-12, 2020, virtual, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno>CoRR, abs/2303.12712</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The icwsm 2009 spinn3r dataset</title>
		<author>
			<persName><forename type="first">K</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Annual Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>ICWSM 2009</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">e-snli: Natural language inference with natural language explanations</title>
		<author>
			<persName><forename type="first">O</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS; Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-03">2018. 2018. December 3-8, 2018. 2018</date>
			<biblScope unit="page" from="9560" to="9572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Figurative language in recognizing textual entailment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">August 1-6, 2021. 2021</date>
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
	<note>ACL/IJCNLP 2021 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Understanding dataset design choices for multi-hop reasoning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4026" to="4032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Uncertain natural language inference</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Chai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Schluter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">July 5-10, 2020. 2020</date>
			<biblScope unit="page" from="8772" to="8779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tabfact: A large-scale dataset for table-based fact verification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">April 26-30, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brahma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<idno>CoRR, abs/2210.11416</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Think you have solved question answering? try arc, the AI2 reasoning challenge</title>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<idno>CoRR, abs/1803.05457</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Transformers as soft reasoners over language</title>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3882" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">XNLI: evaluating cross-lingual sentence representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11-04">October 31 -November 4, 2018. 2018</date>
			<biblScope unit="page" from="2475" to="2485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Faithful reasoning using large language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<idno>CoRR, abs/2208.14271</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Selection-inference: Exploiting large language models for interpretable logical reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<idno>CoRR, abs/2205.09712</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Recognizing Textual Entailment: Models and Applications. Synthesis Lectures on Human Language Technologies</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Zanzotto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Why can GPT learn in-context? language models secretly perform gradient descent as meta-optimizers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<idno>CoRR, abs/2212.10559</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Explaining answers with entailment trees</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pipatanangkura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7358" to="7370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Language models show human-like content effects on reasoning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<idno>CoRR, abs/2207.07051</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reasonbert: Pre-trained to reason with distant supervision</title>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-11">7-11 November, 2021. 2021</date>
			<biblScope unit="page" from="6112" to="6127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Premise-based multimodal reasoning: Conditional inference on joint textual and visual clues</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">May 22-27, 2022. 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="932" to="946" />
		</imprint>
	</monogr>
	<note>ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning event graph knowledge for abductive reasoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5181" to="5190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">e-care: a new dataset for exploring explainable causal reasoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="432" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Moral stories: Situated reasoning about norms, intents, actions, and their consequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Emelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="698" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">CQG: A simple and effective controlled generation framework for multi-hop question generation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6896" to="6906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Scalable multi-hop relational reasoning for knowledge-aware question answering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1295" to="1309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Informal logic and the theory of reasoning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Finocchiaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informal Logic</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Social chemistry 101: Learning to reason about social and moral norms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="653" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Peirce&apos;s logic. The Internet Encyclopedia of Philosophy</title>
		<author>
			<persName><forename type="first">A.-V</forename><forename type="middle">P</forename><surname>Francesco</surname></persName>
		</author>
		<author>
			<persName><surname>Bellucci</surname></persName>
		</author>
		<ptr target="https://iep.utm.edu/peir-log/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Misinfo reaction frames: Reasoning about readers&apos; reactions to news headlines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roesner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3108" to="3127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="346" to="361" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Epistemology and cognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Goldman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>harvard university Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Critical thinking as argument analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Govier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Argumentation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="126" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The argument reasoning comprehension task: Identification and reconstruction of implicit warrants</title>
		<author>
			<persName><forename type="first">I</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1930" to="1940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Folio: Natural language reasoning with first-order logic</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riddell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zubova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burtell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sailor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kryscinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<idno>CoRR, abs/2209.00840</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Measuring massive multitask language understanding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">May 3-7, 2021. OpenReview.net, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title/>
		<ptr target="https://www.britannica.com/topic/logic" />
	</analytic>
	<monogr>
		<title level="j">J. J. Hintikka. logic. Encyclopedia Britannica</title>
		<imprint>
			<date type="published" when="2022-06-09">9 Jun. 2022, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Wikiwhy: Answering and explaining cause-and-effect questions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saxon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno>CoRR, abs/2210.12152</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Large language models are reasoning teachers</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<idno>CoRR, abs/2212.10071</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Constructing A multi-hop QA dataset for comprehensive evaluation of reasoning steps</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sugawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<publisher>International Committee on Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6609" to="6625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fürstenau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07-31">2011, 27-31 July 2011</date>
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
	<note>John McIntyre Conference Centre A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName><surname>Acl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">METGEN: A module-based entailment tree generation framework for answer explanation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Carpuat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Marneffe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">V M</forename><surname>Ruíz</surname></persName>
		</editor>
		<meeting><address><addrLine>Seattle, WA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">July 10-15, 2022. 2022</date>
			<biblScope unit="page" from="1887" to="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An analysis of natural language inference benchmarks through the lens of negation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kovatchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Webber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. November 16-20, 2020. 2020</date>
			<biblScope unit="page" from="9106" to="9118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Towards reasoning in large language models: A survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<idno>CoRR, abs/2212.10403</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Large language models can self-improve</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno>CoRR, abs/2210.11610</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Cosmos QA: machine reading comprehension with contextual commonsense reasoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2391" to="2401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Breadth first reasoning graph for multi-hop question answering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5810" to="5821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Metalogic: Logical reasoning explanations with fine-grained structure</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<idno>CoRR, abs/2210.12487</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">A concise introduction to logic</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Hurley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cengage Learning</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">(comet-) atomic 2020: On symbolic and neural commonsense knowledge graphs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021">February 2-9, 2021. 2021</date>
			<biblScope unit="page" from="6384" to="6392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">R4C: A benchmark for evaluating RC systems to get the right answer for the right reason</title>
		<author>
			<persName><forename type="first">N</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6740" to="6750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Summarize-then-answer: Generating concise explanations for multi-hop reading comprehension</title>
		<author>
			<persName><forename type="first">N</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6064" to="6080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Learning to explain: Datasets and models for identifying valid reasoning chains in multihop questionanswering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jhamtani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="137" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Avoiding reasoning shortcuts: Adversarial evaluation, training, and model development for multi-hop QA</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2726" to="2736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Merit: Meta-path guided contrastive learning for logical reasoning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">May 22-27, 2022. 2022</date>
			<biblScope unit="page" from="3496" to="3509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Maieutic prompting: Logically consistent reasoning with recursive explanations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno>CoRR, abs/2205.11822</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">LAMBADA: backward chaining for automated reasoning in natural language</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramachandran</surname></persName>
		</author>
		<idno>CoRR, abs/2212.13894</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">QASC: A dataset for question answering via sentence composition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guerquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8082" to="8090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Text modular networks: Learning to decompose tasks in the language of existing models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">June 6-11, 2021. 2021</date>
			<biblScope unit="page" from="1264" to="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Scitail: A textual entailment dataset from science question answering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mcilraith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018">February 2-7, 2018. 2018</date>
			<biblScope unit="page" from="5189" to="5197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Attention is (not) all you need for commonsense reasoning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4831" to="4836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
		<idno>CoRR, abs/2205.11916</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Tellmewhy: A dataset for answering why-questions in narratives</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">August 1-6, 2021. 2021</date>
			<biblScope unit="page" from="596" to="610" />
		</imprint>
	</monogr>
	<note>ACL/IJCNLP 2021 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">DVD: A diagnostic dataset for multi-step reasoning in video grounded dialogue</title>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beirami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Geramifard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">August 1-6, 2021. 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5651" to="5665" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Robustifying multi-hop QA through pseudo-evidentiality training</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6110" to="6119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">CYC: A large-scale investment in knowledge infrastructure</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Explainable multi-hop verbal reasoning through internal monologue</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1225" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Differentiable open-ended commonsense reasoning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4611" to="4625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Commongen: A constrained text generation challenge for generative commonsense reasoning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-20">16-20 November 2020. 2020</date>
			<biblScope unit="page" from="1823" to="1840" />
		</imprint>
	</monogr>
	<note>EMNLP 2020 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Reasoning over paragraph effects in situations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering, MRQA@EMNLP 2019</title>
		<meeting>the 2nd Workshop on Machine Reading for Question Answering, MRQA@EMNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11-04">November 4, 2019. 2019</date>
			<biblScope unit="page" from="58" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Natural language inference in context -investigating contextual reasoning over long texts</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021">February 2-9, 2021. 2021</date>
			<biblScope unit="page" from="13388" to="13396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Conceptnet-a practical commonsense reasoning tool-kit</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT technology journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="226" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Logiqa: A challenge dataset for machine reading comprehension with logical reasoning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Bessiere</surname></persName>
		</editor>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3622" to="3628" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Generated knowledge prompting for commonsense reasoning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3154" to="3169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">An essay concerning human understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Locke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1847">1847</date>
			<publisher>Kay &amp; Troutman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Could you give me a hint ? generating inference graphs for defeasible reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rajagopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">August 1-6, 2021. 2021</date>
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
	<note>ACL/IJCNLP 2021 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Think about it! improving defeasible reasoning by first modeling the question scenario</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rajagopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6291" to="6310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Teaching small language models to reason</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Magister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mallinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adámek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Malmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<idno>CoRR, abs/2212.08410</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? A new dataset for open book question answering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11-04">October 31 -November 4, 2018. 2018</date>
			<biblScope unit="page" from="2381" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Compositional questions do not necessitate multi-hop reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4249" to="4257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Multi-hop reading comprehension through question decomposition and rescoring</title>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6097" to="6109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Knight</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Rambow</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016">June 12-17, 2016. 2016</date>
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">CREAK: A dataset for commonsense reasoning over entity knowledge</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Onoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Datasets and Benchmarks</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Logicinference: A new dataset for teaching logical inference to seq2seq models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ontañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cvicek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fisher</surname></persName>
		</author>
		<idno>CoRR, abs/2203.15099</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Unsupervised multi-hop question answering by question generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5866" to="5880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Is a question decomposition unit all we need?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Baral</surname></persName>
		</author>
		<idno>CoRR, abs/2205.12538</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Reasoning and the logic of things: The Cambridge conferences lectures of 1898</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Peirce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Unsupervised question decomposition for question answering</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S H</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Webber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. November 16-20, 2020. 2020</date>
			<biblScope unit="page" from="8864" to="8880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Reasoning like program executors</title>
		<author>
			<persName><forename type="first">X</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ziyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno>CoRR, abs/2201.11473</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Hypothesis only baselines in natural language inference</title>
		<author>
			<persName><forename type="first">A</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, *SEM@NAACL-HLT 2018</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Nissim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Lenci</surname></persName>
		</editor>
		<meeting>the Seventh Joint Conference on Lexical and Computational Semantics, *SEM@NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">June 5-6, 2018. 2018</date>
			<biblScope unit="page" from="180" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Measuring and narrowing the compositionality gap in language models</title>
		<author>
			<persName><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<idno>CoRR, abs/2210.03350</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Why think step-by-step? reasoning emerges from the locality of experience</title>
		<author>
			<persName><forename type="first">B</forename><surname>Prystawski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<idno>CoRR, abs/2304.03843</idno>
		<imprint>
			<date type="published" when="2023-05">2023. May 2023</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Answering open-domain questions of varying reasoning steps from text</title>
		<author>
			<persName><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3599" to="3614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">Reasoning with language model prompting: A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<idno>CoRR, abs/2212.09597</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Counterfactual story reasoning and generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5042" to="5052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Back to the future: Unsupervised backprop-based decoding for counterfactual and abductive commonsense reasoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="794" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Dynamically fused graph network for multi-hop reasoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6140" to="6150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Interpretable proof generation via iterative backward reasoning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2968" to="2981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>OpenAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Explain yourself! leveraging language models for commonsense reasoning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4932" to="4942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Event2mind: Commonsense inference on events, intents, and reactions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</editor>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">July 15-20, 2018. 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="463" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">CONDAQA: A contrastive reading comprehension dataset for reasoning about negation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">December 7-11, 2022. 2022</date>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="8729" to="8755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Entailment tree explanations via iterative retrieval-generation reasoner</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Carpuat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Marneffe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">V M</forename><surname>Ruíz</surname></persName>
		</editor>
		<meeting><address><addrLine>Seattle, WA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">July 10-15, 2022. 2022</date>
			<biblScope unit="page" from="465" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Bejan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Gordon</surname></persName>
		</author>
		<idno>SS-11-06</idno>
	</analytic>
	<monogr>
		<title level="m">Logical Formalizations of Commonsense Reasoning, Papers from the 2011 AAAI Spring Symposium</title>
		<meeting><address><addrLine>Stanford, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2011">March 21-23, 2011. 2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Thinking like a skeptic: Defeasible inference in natural language</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-20">16-20 November 2020. 2020</date>
			<biblScope unit="page" from="4661" to="4675" />
		</imprint>
	</monogr>
	<note>EMNLP 2020 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">The dictionary of philosophy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Runes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Citadel Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Scinli: A corpus for natural language inference on scientific text</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sadat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Caragea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">May 22-27, 2022. 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7399" to="7409" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Interpretation of natural language rules in conversational machine reading</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saeidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S H</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sheldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11-04">October 31 -November 4, 2018. 2018</date>
			<biblScope unit="page" from="2087" to="2097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Prover: Proof generation for interpretable reasoning over rules</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="122" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Conjnli: Natural language inference over conjunctive sentences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Webber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. November 16-20, 2020. 2020</date>
			<biblScope unit="page" from="8240" to="8252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">multiprover: Generating multiple proofs for improved interpretability in rule reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3662" to="3677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">Robustlr: Evaluating robustness to logical perturbation in deductive reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<idno>CoRR, abs/2205.12598</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Fairr: Faithful and robust deductive reasoning over natural language</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1075" to="1093" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">APOLLO: A simple approach for adaptive pretraining of language models for logical reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<idno>CoRR, abs/2212.09282</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">ATOMIC: an atlas of machine commonsense for if-then reasoning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3027" to="3035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Social bias frames: Reasoning about social and power implications of language</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5477" to="5490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Social iqa: Commonsense reasoning about social interactions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4462" to="4472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">Language models are greedy reasoners: A systematic formal analysis of chain-of-thought</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<idno>CoRR, abs/2210.01240</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Distilling multi-step reasoning capabilities of large language models into smaller models via semantic decompositions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<idno>CoRR, abs/2212.00193</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">CLUTRR: A diagnostic benchmark for inductive reasoning from text</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sodhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4505" to="4514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</editor>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017">February 4-9, 2017. 2017</date>
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A M</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garriga-Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kluska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Kocurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Safaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tazarv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dsouza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rahane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stuhlmüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>La</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vuong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Norelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gholamidavoodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tabassum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kirubarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mullokandov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karakas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. CoRR, abs/2206.04615</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">A corpus for reasoning about natural language grounded in photographs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-02">July 28-August 2, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6418" to="6428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Challenging big-bench tasks and whether chain-of-thought can solve them</title>
		<author>
			<persName><forename type="first">M</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<idno>CoRR, abs/2210.09261</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Proofwriter: Generating implications, proofs, and abductive statements over natural language</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP (Findings), volume ACL/IJCNLP 2021 of Findings of ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3621" to="3634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Entailer: Answering questions with faithful and truthful chains of reasoning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<idno>CoRR, abs/2210.12217</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Commonsenseqa 2.0: Exposing the limits of AI through gamification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Vanschoren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Yeung</surname></persName>
		</editor>
		<meeting>the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021</meeting>
		<imprint>
			<date type="published" when="2021-12">December 2021, virtual, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Pre-training is (almost) all you need: An application to commonsense reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tamborrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pellicanò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Voitot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Naudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3878" to="3887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Reasoning about actions and state changes by injecting commonsense knowledge</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11-04">October 31 -November 4, 2018. 2018</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">reasoning over procedural text</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6075" to="6084" />
		</imprint>
	</monogr>
	<note>WIQA: A dataset for &quot;what if</note>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Is multihop QA in dire condition? measuring and reducing disconnected reasoning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8846" to="8863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Musique: Multihop questions via single-hop question composition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="539" to="554" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Performance impact caused by hidden bias of training data for recognizing textual entailment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tsuchiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hasida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Isahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mazo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Odijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tokunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">May 7-12, 2018. 2018</date>
		</imprint>
	</monogr>
	<note>LREC 2018 European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04">2017. December 4-9, 2017. 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">HEAD-QA: A healthcare dataset for complex reasoning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="960" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">What is reasoning? what is an argument?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Walton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="399" to="419" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno>CoRR, abs/2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<idno>CoRR, abs/2206.07682</idno>
		<title level="m">Emergent abilities of large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno>CoRR, abs/2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="287" to="302" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR (Poster)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Stent</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">June 1-6, 2018. 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Generating data to mitigate spurious correlations in natural language inference datasets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dasigi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">May 22-27, 2022. 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2660" to="2676" />
		</imprint>
	</monogr>
	<note>ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">An explanation of in-context learning as implicit bayesian inference</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event</title>
		<imprint>
			<date type="published" when="2022">April 25-29, 2022. OpenReview.net, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Can neural networks understand monotonicity reasoning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mineshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bekki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@ACL 2019</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Linzen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Chrupala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Belinkov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hupkes</surname></persName>
		</editor>
		<meeting>the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-01">August 1, 2019. 2019</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">HELP: A dataset for identifying shortcomings of neural models in monotonicity reasoning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mineshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bekki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics, *SEM@NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Shutova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Ku</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Evang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</editor>
		<meeting>the Eighth Joint Conference on Lexical and Computational Semantics, *SEM@NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 6-7, 2019. 2019</date>
			<biblScope unit="page" from="250" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title level="m" type="main">Generating natural language proofs with verifier-guided search</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<idno>CoRR, abs/2205.12443</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title level="m" type="main">Language models as inductive reasoners</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<idno>CoRR, abs/2212.10923</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Logical reasoning over natural language as knowledge representation: A survey</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno>CoRR, abs/2303.12023</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">QA-GNN: reasoning with language models and knowledge graphs for question answering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="535" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<title level="m" type="main">Complementary explanations for effective in-context learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pasunuru</surname></persName>
		</author>
		<idno>CoRR, abs/2211.13892</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Broaden the vision: Geo-diverse visual commonsense reasoning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-11">7-11 November, 2021. 2021</date>
			<biblScope unit="page" from="2115" to="2129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Docnli: A large-scale dataset for document-level natural language inference</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">August 1-6, 2021. 2021</date>
			<biblScope unit="page" from="4913" to="4922" />
		</imprint>
	</monogr>
	<note>ACL/IJCNLP 2021 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Abductionrules: Training transformers to explain unexpected inputs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bensemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Witbrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">May 22-27, 2022. 2022</date>
			<biblScope unit="page" from="218" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Low-resource generation of multi-hop reasoning questions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6729" to="6739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">ALERT: adapting language models to reasoning tasks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Golovneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Alkhamissy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<idno>CoRR, abs/2212.08286</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Reclor: A reading comprehension dataset requiring logical reasoning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Star: Bootstrapping reasoning with reasoning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<idno>CoRR, abs/2203.14465</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">SWAG: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11-04">October 31 -November 4, 2018. 2018</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Hellaswag: Can a machine really finish your sentence?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-02">July 28-August 2, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4791" to="4800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">On the paradox of learning to reason from data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Broeck</surname></persName>
		</author>
		<idno>CoRR, abs/2205.11502</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Reasoning about goals, steps, and temporal ordering with wikihow</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4630" to="4639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<title level="m" type="main">Greaselm: Graph reasoning enhanced language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>In ICLR. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Automatic chain of thought prompting in large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<idno>CoRR, abs/2210.03493</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">Transformer-xh: Multi-evidence reasoning with extra hop attention</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">SRLGRN: semantic role labeling graph reasoning network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kordjamshidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP (1)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8881" to="8891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">E3: entailment-driven extracting and editing for conversational machine reading</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-02">July 28-August 2, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2310" to="2320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main">Disentangling reasoning capabilities from language models with compositional reasoning transformers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<idno>CoRR, abs/2210.11265</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Analytical reasoning of text</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Carpuat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Marneffe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">V M</forename><surname>Ruíz</surname></persName>
		</editor>
		<meeting><address><addrLine>Seattle, WA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">July 10-15, 2022. 2022</date>
			<biblScope unit="page" from="2306" to="2319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<title level="m" type="main">Learning to decompose: Hypothetical question decomposition based on comparable texts</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<idno>CoRR, abs/2210.16865</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<monogr>
		<title level="m" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<idno>CoRR, abs/2205.10625</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">RICA: evaluating robust inference capabilities based on commonsense axioms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Yih</surname></persName>
		</editor>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-11">7-11 November, 2021. 2021</date>
			<biblScope unit="page" from="7560" to="7579" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
