<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Survey of Diffusion Models in Natural Language Processing</title>
				<funder ref="#_4savPmM">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-06-14">14 Jun 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hao</forename><surname>Zou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zae</forename><forename type="middle">Myung</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Dongyeop</forename><surname>Kang</surname></persName>
							<email>dongyeop@umn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Survey of Diffusion Models in Natural Language Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-06-14">14 Jun 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">10523A1266838C0BF25B1D1C34B3620E</idno>
					<idno type="arXiv">arXiv:2305.14671v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-01T11:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This survey paper provides a comprehensive review of the use of diffusion models in natural language processing (NLP). Diffusion models are a class of mathematical models that aim to capture the diffusion of information or signals across a network or manifold. In NLP, diffusion models have been used in a variety of applications, such as natural language generation, sentiment analysis, topic modeling, and machine translation. This paper discusses the different formulations of diffusion models used in NLP, their strengths and limitations, and their applications. We also perform a thorough comparison between diffusion models and alternative generative models, specifically highlighting the autoregressive (AR) models, while also examining how diverse architectures incorporate the Transformer in conjunction with diffusion models. Compared to AR models, diffusion models have significant advantages for parallel generation, text interpolation, token-level controls such as syntactic structures and semantic contents, and robustness. Exploring further permutations of integrating Transformers into diffusion models would be a valuable pursuit. Also, the development of multimodal diffusion models and large-scale diffusion language models with notable capabilities for few-shot learning would be important directions for the future advance of diffusion models in NLP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Diffusion models <ref type="bibr">(Sohl-Dickstein et al., 2015b;</ref><ref type="bibr" target="#b15">Ho et al., 2020;</ref><ref type="bibr" target="#b38">Song et al., 2020)</ref> have shown remarkable performance in image generation and attracted huge attention in the field of artificial intelligence. Researchers have also adopted the models to the field of natural language processing (NLP) and have just started to explore their generative capabilities in the domain (Fig. <ref type="figure" target="#fig_0">1</ref>). To date, diffusion models have been applied to a wide range of generative NLP tasks, such as unconditional text generation, controllable text generation, machine translation, and text simplification.</p><p>The main challenge in incorporating diffusion models into NLP is the discreteness of texts, which contrasts with the continuous space in which diffusion is modeled. To address this challenge, researchers have introduced modifications to the models, and we categorize them into two approaches:</p><p>• Discrete diffusion models built on categorical distributions. This method generalizes diffusion process to the discrete domain by corrupting and refining sentences at the token level. • Embedding diffusion models encode discrete texts into continuous space and perform Gaussian noising. As part of this method, additional embedding and rounding steps can be used in the forward and reverse processes, respectively, to convert tokens into embeddings.</p><p>In the following sections, we first introduce the general framework of vanilla diffusion models and the modified architecture for discrete state spaces in Section 2. In Section 3, we classify the surveyed architectures into two aforementioned approaches (discrete vs embedding diffusion models), using specific criteria that have been proposed. In Sec-tion 4, we conduct a detailed comparative analysis of diffusion models against other generative models in NLP domain. Based on empirical evidence, we highlight the advantages of diffusion models over autoregressive (AR) models, specifically in terms of parallel generation, text interpolation, token-level control, and robustness. In addition, we explore how various surveyed architectures have incorporated the Transformer with diffusion models for NLP. We highlight algorithms and techniques proposed for diffusion models in NLP in Section 5. Finally, we discuss potential future directions that are both timely and worthy of exploration in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">General Framework</head><p>Traditionally, diffusion models have focused on continuous state spaces, but recent advancements have expanded their application to discrete state spaces. Discrete diffusion models operate with discrete variables, such as text or categorical data, which present distinct characteristics and challenges.</p><p>A key distinction is the treatment of noise. Continuous diffusion models employ additive Gaussian noise, while discrete diffusion models introduce discrete perturbations or transformations to modify the discrete states. This enables exploration of different states and enhances sample diversity.</p><p>Transition probabilities also differ between continuous and discrete diffusion models. Continuous models utilize stochastic differential equations, whereas discrete models define transition probabilities using conditional distributions. These distributions capture dependencies between current and previous states, facilitating information propagation and guiding the diffusion process in discrete state spaces.</p><p>Diffusion Models Denoising diffusion probabilistic models (DDPMs) were initially introduced by <ref type="bibr">(Sohl-Dickstein et al., 2015a)</ref> and enhanced by <ref type="bibr" target="#b15">(Ho et al., 2020)</ref>. DDPMs employ a two-step process: adding Gaussian noise and performing a reverse process to restore the original data. <ref type="bibr" target="#b15">(Ho et al., 2020)</ref> developed DDPMs with an embedding function that maps discrete text to a continuous space, achieving comparable results to stateof-the-art generative models like generative adversarial networks (GANs). Subsequent works <ref type="bibr" target="#b38">(Song et al., 2020;</ref><ref type="bibr" target="#b8">Dhariwal and Nichol, 2021;</ref><ref type="bibr" target="#b27">Nichol and Dhariwal, 2021;</ref><ref type="bibr" target="#b34">Rombach et al., 2021)</ref> have further improved the quality and efficiency of DDPMs.</p><p>The forward process generates X t+1 by adding noise to X t , creating a dependency solely on X t . This categorizes the diffusion process as a Markov process, where the noise level is determined by the variance β t ∈ (0, 1) T t=1 . The expression for q(x t |x t-1 ) can be written as follows:</p><formula xml:id="formula_0">q(x t |x t-1 ) = N (x t ; 1 -β t • x t-1 ; β t I) (1)</formula><p>By applying the reparameterization approach to depict X t , where a t = 1β t , z t ∼ N (0, 1), t ≤ 0, the subsequent result can be obtained:</p><formula xml:id="formula_1">x t = √ α t x t-1 + √ 1 -α t Z t-1<label>(2)</label></formula><p>When computing q(x t |x 0 ), the joint probability distribution of (x 1:T |x 0 ) can be determined because it is established as a Markov chain:</p><formula xml:id="formula_2">q(x 1:T |x 0 ) = T t=1 q(x t |x t-1 )<label>(3)</label></formula><p>Then we can express x t at arbitrary time step t with reference to x 0 in a closed form, where ᾱt = α 1 α 2 ...α t :</p><formula xml:id="formula_3">q(x T |x 0 ) = N (x t ; √ ᾱt x 0 ; (1 -ᾱt )I) (4)</formula><p>For the reverse process, if we can determine the probability distribution of x t-1 based on the given condition of x t , i.e., if q(x t-1 |x t ) can be known, then we can iteratively sample random noise to generate an image or sentence. The challenge is to obtain q(x t-1 |x t ). To approximate it, we utilize p θ (x t-1 |x t ). Given that the added noise at each step is relatively small, we assume that p θ (x t-1 |x t ) follows a Gaussian distribution that can be modeled using a neural network. The reverse process can be expressed as follows:</p><formula xml:id="formula_4">p θ (x t-1 |x t ) = N (x t-1 ; µ(x t , t), θ (x t , t)) (5) p θ (x 0:T ) = p(x T ) T t=1 p θ (x t-1 |x t )<label>(6)</label></formula><p>Applying Bayes' rule, we can express q(x t-1 |x t , x 0 ) in terms of the known forward conditional probabilities q(x t |x t-1 , x 0 ), q(x t-1 |x 0 ), and q(x t |x 0 ). Our objective is to minimize the mean square error (MSE) loss between the KL divergence of the model p θ and the true distribution q. Diffusion models for discrete state spaces For scalar discrete random variables with K categories, where x t and x t-1 take values from 1 to K, the forward transition probabilities can be represented using matrices. Let</p><formula xml:id="formula_5">[Q t ] i,j = q(x t = j|x t-1 = i).</formula><p>We can denote the one-hot representation of x using a row vector, which can be expressed as follows:</p><formula xml:id="formula_6">q(x t |x t-1 ) = Cat(x t ; p = x t-1 Q t )<label>(7)</label></formula><p>In this context, Cat(x; p) represents a categorical distribution over the one-hot row vector x, where the probabilities are determined by the row vector p. The term x t-1 Q t corresponds to a row vectormatrix multiplication. An assumption is made that Q t is independently applied to each pixel of an image or token in a sequence, and that the distribution q factorizes over these higher dimensions as well. Therefore, we can express q(x t |x t-1 ) in terms of a single element. Starting from x 0 , we can derive the following t-step marginal and posterior at time t -1, where Qt = Q1Q2...Q t :</p><formula xml:id="formula_7">q(x t |x 0 ) = Cat(x t ; p = x 0 Qt ) (8) q(x t-1 |x t , x 0 ) = q(x t |x t-1 , x 0 )q(x t-1 |x 0 ) q(x t |x 0 )<label>(9)</label></formula><p>The Markov property of the forward process ensures that q(x t |x t-1 , x 0 ) can be simplified to q(x t |x t-1 ). Similarly, assuming the reverse process p θ (x t |x t-1 ) also exhibits a factorized structure, considering the conditional independence of the image or sequence elements, we can derive the KL divergence between q and p θ by aggregating the probabilities across all possible values of each random variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Survey of Diffusion Models in NLP</head><p>We present several studies on diffusion models in NLP by grouping them based on their methods for adapting the diffusion process to the textual domain. Specifically, we have two groups: Discrete Diffusion Models and Embedding Diffusion Models (Figure <ref type="figure" target="#fig_1">2</ref>). The former operates directly in the discrete input space, while the latter involves lifting discrete inputs into a continuous space.</p><p>For each category, we then categorize diffusion models into a multi-perspective taxonomy considering the following criteria: (1) the task they are applied to, (ii) schedule methods during the forward process and (iii) sampling methods used for the reverse process. We note that Reluency in "Schedule" column indicates a linguistic feature that measures the relevance of word w in one sentence d via tf-idf weights. Entropy is a measurement of the amount of information with entropy H in the word w to reflect the importance of that word. Table <ref type="table" target="#tab_0">1</ref> shows the categorization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discrete Diffusion Models</head><p>In the discrete diffusion process, the data is corrupted by switching between discrete values. Discrete diffusion models extend diffusion models to discrete state spaces by corrupting and refining the sentences at the token level.</p><p>Multinomial Diffusion <ref type="bibr" target="#b17">(Hoogeboom et al., 2021</ref>) introduces a diffusion-based generative model specifically designed for non-ordinal discrete data. It achieves this by diffusing the data to a uniform categorical distribution, effectively capturing the underlying structure while maintaining controlled randomness. The model's transition mechanism D3PMs <ref type="bibr">(Austin et al., 2021b)</ref> replaces Gaussian noise with Markov transition matrices to diffuse real-world data distribution. It incorporates various types of transition matrices, such as Gaussian kernels, nearest neighbors, and absorbing states, to extend corruption processes. Moreover, D3PMs <ref type="bibr">(Austin et al., 2021b)</ref> introduces a novel loss func-tion that combines the variational lower bound with an auxiliary cross-entropy loss. Unlike continuous diffusion, D3PMs <ref type="bibr">(Austin et al., 2021b)</ref> allows precise control over the data corruption and denoising process by selecting Q t in Equation <ref type="formula" target="#formula_6">7</ref>, going beyond the use of additive Gaussian noise.</p><p>Zero-Shot Diffusion <ref type="bibr" target="#b25">(Nachmani and Dovrat, 2021)</ref> utilizes an encoder-decoder architecture with time-based positional encoding for neural machine translation. It employs a transformer encoder to process the source-language sentence and a transformer decoder to handle the noisy target sentence. Notably, this work pioneers conditional text generation using a diffusion model.</p><p>Bit Diffusion <ref type="bibr">(Chen et al., 2023b)</ref> encodes discrete data as binary bits and trains a continuous diffusion model that treats these binary bits as real numbers. It firstly introduces the self-conditioning technique that greatly improves the sample quality and is widely applied to the following works <ref type="bibr" target="#b39">(Strudel et al., 2023;</ref><ref type="bibr" target="#b9">Dieleman et al., 2022;</ref><ref type="bibr" target="#b42">Yuan et al., 2022)</ref>.</p><p>SUNDAE <ref type="bibr">(Savinov et al., 2021)</ref> proposes stepunrolled text generation and is the first non-AR method to show strong results in both machine translation and unconditional text generation.</p><p>DiffusER <ref type="bibr" target="#b32">(Reid et al., 2023)</ref> employs a 2dimensional beam search and edit-based text generation. Instead of a pure end-to-end approach, the system divides the task into edit tagging and generation. It generates a sequence of edits to transform a random noise distribution into high-quality output.</p><p>DiffusionBERT <ref type="bibr" target="#b14">(He et al., 2022)</ref> combines diffusion models with Pre-trained Language Models (PLMs) <ref type="bibr" target="#b7">(Devlin et al., 2018;</ref><ref type="bibr" target="#b21">Lewis et al., 2019;</ref><ref type="bibr" target="#b31">Raffel et al., 2019;</ref><ref type="bibr">Brown et al., 2020;</ref><ref type="bibr" target="#b30">Qiu et al., 2020)</ref> by training BERT in reverse of a discrete diffusion process. It introduces a new noise schedule for the forward diffusion process and incorporates the time step into BERT <ref type="bibr" target="#b7">(Devlin et al., 2018)</ref>. By including the time step, DiffusionBERT captures lost temporal information during diffusion, enhancing the accuracy of the reverse process.</p><p>SSD-LM <ref type="bibr" target="#b13">(Han et al., 2022)</ref> stands out due to two key features. Firstly, it is semi-autoregressive, enabling iterative generation of text blocks and dynamic length adjustment during decoding. Secondly, it is simplex-based, directly applying diffusion on the natural vocabulary space instead of a learned latent space. This approach facilitates the incorporation of classifier guidance and mod-ular control without the need for modifications to existing classifiers.</p><p>Masked-Diffuse LM <ref type="bibr">(Chen et al., 2023a)</ref> employs strategic soft-masking, informed by linguistic features, to corrupt both discrete and continuous textual data. It iteratively denoises the data by predicting the categorical distribution. The gradual introduction of perturbations via soft-masking, following an easy-first-generation approach, enhances structural coherence, overall quality, and flexibility in text generation. This pioneering work utilizes linguistic features to effectively corrupt and recover input textual data, improving the generation process.</p><p>RDMs <ref type="bibr" target="#b45">(Zheng et al., 2023)</ref> introduces a novel reparameterization technique for discrete diffusion models. It employs a stochastic routing mechanism to decide between denoising or noisy resetting for each token. The router ensures uniform processing by assigning equal probabilities to all tokens. This reparameterization simplifies training and enables flexible sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Embedding Diffusion Models</head><p>Recent studies <ref type="bibr">(Li et al., 2022;</ref><ref type="bibr" target="#b11">Gong et al., 2022;</ref><ref type="bibr" target="#b39">Strudel et al., 2023)</ref> utilize diffusion processes to generate continuous representations (embeddings) for discrete tokens, known as embedding diffusion models.</p><p>Diffusion-LM (Li et al., 2022) constructs diffusion models on continuous word embedding space and incorporates auxiliary losses for joint learning of embedding and network parameters.</p><p>DiffuSeq <ref type="bibr" target="#b11">(Gong et al., 2022)</ref> focuses on sequence-to-sequence generation using encoderonly Transformers and partial noising to define the diffusion process and learn the denoising function.</p><p>SED <ref type="bibr" target="#b39">(Strudel et al., 2023)</ref> builds upon the modeling and objectives of Diffusion-LM, introducing a self-conditioning mechanism that enhances baseline performance. Notably, it demonstrates successful scalability to large text datasets like C4 <ref type="bibr" target="#b31">(Raffel et al., 2019)</ref>.</p><p>Difformer <ref type="bibr" target="#b10">(Gao et al., 2022)</ref> tackles challenges in applying continuous diffusion models to discrete text generation by addressing denoising objective collapse, imbalanced embedding scales, and inadequate noise during training. It introduces three crucial components: an anchor loss function, layer normalization for embeddings, and an increased noise factor to enhance the scale of added noise. CDCD (Dieleman et al., 2022) introduces a variance-exploding stochastic differential equations-based diffusion model tailored for text modeling and machine translation. It integrates time warping, an active learning strategy that dynamically adjusts the noise distribution during training to optimize efficiency.</p><p>SeqDiffuSeq <ref type="bibr" target="#b42">(Yuan et al., 2022)</ref> incorporates self-conditioning and introduces a method to learn token-level noise schedules for text generation. By leveraging appropriate noise schedules, it aims to enhance the quality of generated samples and likelihood modeling <ref type="bibr" target="#b18">(Kingma et al., 2021)</ref>. In contrast to DiffuSeq <ref type="bibr" target="#b11">(Gong et al., 2022)</ref>, SeqDiffuSeq <ref type="bibr" target="#b42">(Yuan et al., 2022)</ref> explores different model structures and investigates the impact of noise scheduling in sequence-to-sequence tasks.</p><p>DiffuSum <ref type="bibr" target="#b43">(Zhang et al., 2023)</ref> applies diffusion models to enhance extractive summarization. It generates summary sentence representations and extracts relevant sentences using representation matching. The model introduces a contrastive sentence encoding module that employs matching and multi-class contrastive losses to align and diversify representations. Significantly, DiffuSum represents the first known utilization of diffusion models in the field of extractive summarization.</p><p>GENIE <ref type="bibr" target="#b45">(Lin et al., 2023</ref>) is a large-scale diffusion-based language model consisting of an encoder and decoder. It enhances noise removal and paragraph-level coherence through continuous paragraph denoise (CPD) loss in pre-training. The CPD objective guides the diffusion-decoder to reconstruct a clean version of a corrupted text paragraph while preserving semantic and syntactic coherence.</p><p>DiNoiSer <ref type="bibr" target="#b41">(Ye et al., 2023)</ref> addresses small noise effects on "discrete" embeddings in a continuous space, improving diffusion models through noise manipulation in conditional sequence learning. It tackles the discreteness problem by excluding small-scale noises from diffused sequence learner training. For sampling, it introduces an effective method that consistently indicates large noise scales, enhancing the predictive capabilities by amplifying the influence of source conditions on predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discrete vs. Embedding Diffusion</head><p>In Table <ref type="table">2</ref>, we summarize the advantages of embedding diffusion models over discrete diffusion</p><p>Diffusion Process Classifier-based Controls Refinements Adaptation Discrete Diffusion token level Embedding Diffusion sequence level Table 2: Comparative Analysis of Discrete Diffusion Models and Embedding Diffusion Model. Refinements Adaptation column serves as an indicator of the system's ability to incorporate refinements from continuous diffusion in the image domain. models. • Diffusion Process: embedding diffusion models transform discrete inputs into a continuous space, enabling representation of multiple outcomes at intermediate timesteps, particularly crucial in capturing token-level uncertainty in language modeling. In contrast, denoising models operating in the discrete input space lack this ability and are confined to specific tokens. • Classifier-based Controls: embedding diffusion models can integrate classifier-based guidance, enhancing the quality of generated samples by leveraging additional information from a classifier to guide the sampling process. In contrast, discrete diffusion models lack this capability, thereby restricting their ability to generate high-quality samples. • Refinements Adaptation: Strudel et al. (2023) showed that discrete diffusion approaches do not reap the advantages derived from the advancements made in continuous diffusion methods within the domain of image processing. Conversely, embedding diffusion models exhibit the capacity to leverage these refinements, rendering them more advantageous and valuable in this context. 4 Diffusion vs. Other Generative Models 4.1 Comparison against Latent Variable Models Unlike variational autoencoders (VAEs) (Kingma and Welling, 2022; Rezende et al., 2014) or flowbased models <ref type="bibr" target="#b28">(Papamakarios et al., 2017;</ref><ref type="bibr" target="#b20">Kingma and Dhariwal, 2018)</ref>, diffusion models are learned using a fixed procedure with the latent variable having a high dimensionality (same as the original data). GANs <ref type="bibr" target="#b12">(Goodfellow et al., 2014)</ref> are known for potentially unstable training and less diverse generations due to their adversarial training nature. VAEs <ref type="bibr" target="#b19">(Kingma and Welling, 2022;</ref><ref type="bibr" target="#b33">Rezende et al., 2014)</ref> rely on a surrogate loss. Flow-based models require the construction of specialized architectures to construct reversible transforms.</p><p>As Dieleman et al. ( <ref type="formula">2022</ref>) notes, diffusion models have a distinct advantage over models like VAEs and GANs, which generate data in a single forward pass. Diffusion models instead focus on reconstructing a small amount of information that has been removed by the corruption process, making the task less challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison against Autoregressive Models</head><p>Autoregressive (AR) models currently dominate the field of language modeling. Also known as causal modeling or the next-token prediction task, AR modeling learns the joint distribution over a token sequence p(x 1 , x 2 , ..., x N ) by factorizing it into sequential conditionals p(x k |x 1 , ..., x k-1 ) and model them separately with shared parameters (see Figure <ref type="figure">3</ref>). This means that sampling always proceeds along the left-to-right direction of the sequence. However, in many cases, the ability to go back and refine the earlier parts of the sequence should be useful. In Figure <ref type="figure">3</ref>, we illustrate the fundamental distinctions between AR and diffusion models, and highlight the distinctive features of the diffusion architecture that endow it with the ability to refine the previous generations, which has potentials to advance the state-of-the-art in the field.</p><p>Additionally, <ref type="bibr" target="#b39">Strudel et al. (2023)</ref> reveals that, compared to AR models <ref type="bibr" target="#b3">(Bengio et al., 2003;</ref><ref type="bibr" target="#b40">Sutskever et al., 2011;</ref><ref type="bibr">Austin et al., 2021c;</ref><ref type="bibr" target="#b16">Hoffmann et al., 2022)</ref>, diffusion models can predict all tokens in a sequence at once, which increases interactions between tokens, potentially leading to more coherent samples. Similarly, <ref type="bibr">Savinov et al. (2021)</ref> and Li et al. ( <ref type="formula">2022</ref>) note that the fixed generation order (left-to-right) from AR models limits the model's flexibility in many controllable generation settings. For example, infilling task, which imposes lexical control on the right contexts, and the syntactic structure control task, which controls global properties involving both left and right contexts. More importantly, this prohibits the iterative refinement of complete text drafts from making them more self-consistent, which is a common task for human writers.</p><p>In Table <ref type="table" target="#tab_3">3</ref>, we summarize the empirical benefits of diffusion models over AR models. We categorize them into four aspects: parallel generation, sentence interpolation, token-level control, and robustness to input corruption.</p><p>• Parallel Generation: diffusion models exhibit a notable departure from the autoregressive nature of AR models. While AR models generate output tokens sequentially conditioned on preceding tokens, diffusion models adopt a parallel generation approach, enabling simultaneous generation of all output tokens. This characteristic enhances the speed and efficiency of text generation, rendering diffusion models particularly suitable for real-time applications.   In summary, diffusion models offer empirical advantages over AR models, encompassing parallel generation, text interpolation, and advanced tokenlevel controls. These characteristics underscore the potential of diffusion models in various text generation scenarios, emphasizing their efficiency, coherency, and flexibility. In addition to the advantages discussed in Table <ref type="table" target="#tab_3">3</ref>, we also identify two significant disadvantages of diffusion models compared to AR models in terms of training complexity and interpretability.</p><p>• Training Complexity: Diffusion models are more difficult to train than AR models due to their more complex architecture and optimiza-tion objective. In a diffusion model, the entire sequence is generated simultaneously through multiple rounds of diffusion steps, which involve applying a non-linear function to a set of latent variables to obtain the next generation of the sequence. This requires optimizing a complex objective function that includes both the data likelihood and the distance between the generated and ground-truth sequences. On the other hand, AR models generate sequences sequentially by conditioning each time step on the previous ones. This allows for a simpler optimization objective and faster convergence during training. • Model Interpretability: Diffusion models involve multiple non-linear transformations during the diffusion process, resulting in abstract representations in the latent space. These representations may not have a clear interpretation or meaning, and understanding how a specific output sequence is generated from the input can be challenging. This makes diffusion models less interpretable. In contrast, AR models generate sequences step by step, building on the previous steps. Each step is influenced by the preceding steps, making it easier to understand how the output sequence is generated based on the input. AR models are more interpretable</p><p>Architecture Training Corpus Parameter Size with Transformer Pre-trained Discrete Diffusion Models Multinomial Diffusion text8, enwik8 -12-layer Transformer D3PMs text8, LM1B, CIFAR-10 -12-layer Transformer Zero-shot Diffusion WMT14 (DE-EN, FR-EN) WMT19 (DE-FR) -12-layer Transformer SUNDAE WMT14 (EN-DE) C4 Python code dataset 63M encoder-decoder Transformer causality masking removed in the decoder DiffusionBERT LM1B 110M bert-base uncased is trained for reverse process SSD-LM OpenWebText 0.4B bi-directional Transformer encoder a timestep embedding added before the first Transformer block Bit Diffusion CIFAR-10, ImageNET MSCOCO 2017 -6-layer Transformer decoder DiffusER WMT'14 CNN/DailyMail, Yelp -6-layer Transformer to predict the edit operations 6-layer Transformer for generator Masked-Diffuse LM E2E 80M BERT to encode the input text Transformer to module the reverse process RDMs (Zheng et al., 2023) IWSLT14 (DE-EN) WMT14 (EN-DE) WMT16 (EN-RO) -Length prediction module on top of Transformer encoder Embedding Diffusion Models Diffusion-LM E2E, ROCStories 80M 12-layer Transformer DiffuSeq CCD, Quasar-T Newsela-Auto Wiki-Auto, QQP 91M 12-layer Transformer SED C4 135M &amp; 420M 12-layer Transformer CDCD MassiveText, C4 WMT2014, WMT2020 1.3B Mask-conditional Transformer Difformer IWSLT14, WMT14 WMT16, Gigaword -6-layer Transformer SeqDiffuSeq CCD, Quasar-T, Wiki-Auto QQP, IWSLT14 -12-layer Transformer DiffuSum CNN/DailyMail, XSum PubMed 13M 8-layer Transformer as encoder 12-layer Transformer as generator GENIE Gigaword, CNN/DailyMail XSum, CommonGen -6-layer Transformer as encoder 6-layer cross attention Transformer as denoising architecture DiNoiSer IWSLT14 (DE-EN) WMT14 (EN-DE, EN-RO) Wiki-Auto, QQP -12-layer Transformer</p><p>Table 4: Training Corpus and connection with Transformer for Discrete and Embedding Diffusion Models. Parameter column refers to the size of used Transformer architecture specifically. Pre-trained column indicates whether the system uses the pre-trained word embedding or not.</p><p>due to this sequential nature. These observations highlight the trade-offs associated with diffusion models, emphasizing the need to consider both their advantages and disadvantages in practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Transormers with diffusion models</head><p>Transformers architecture could be combined with diffusion models, as depicted in Figure <ref type="figure" target="#fig_4">4</ref>. Specifically, the Transformer models are used in the encoder-decoder layout to model the denoising function. During the reverse process, the input sequence x therefore only requires one forward computation. Furthermore, Table <ref type="table">4</ref> provides a comprehensive summary of the training corpus of surveyed systems, highlighting their associations with Transformers. This includes details such as the parameter size and the specific architectures employed by each system for modeling denoising functions, as well as their utilization of pre-trained representations from Transformers during the diffusion process. We hope that this summary can provide researchers with rapid insights into the interplay between Transformers and diffusion models in NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Algorithms &amp; Techniques</head><p>In this section, we highlight algorithms and techniques proposed for diffusion models in NLP. They are twofold: (1) adapting the models to discrete variables and (2) improving sampling procedures. Figure <ref type="figure" target="#fig_5">5</ref> depicts the algorithms proposed from the surveyed papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Adapting Discrete Variables</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Diffusion Steps</head><p>To optimize the objective function, DDPM <ref type="bibr" target="#b15">(Ho et al., 2020)</ref> utilizes the property that the noise added at each time step in the diffusion process is Gaussian noise; hence the concrete expressions of the objective can be derived. However, the Gaussian distribution here is mainly for continuous domains such as image generations. Hence, D3PM <ref type="bibr">(Austin et al., 2021a)</ref> proposed a new method for adding noises for discrete variables. D3PM defined a series of transition matrices that transformed the discrete tokens into [MASK] based on pre-defined probabilities at different time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Objective Functions</head><p>Predicting initial inputs directly Traditionally, for the approximations of the mean values of each time step, DDPM <ref type="bibr" target="#b15">(Ho et al., 2020)</ref> predicts the noise at each time step directly, however, Diffusion-LM <ref type="bibr">(Li et al., 2022)</ref> found that the model might fail to generate the initial input x 0 that commits to a single word as the denoising steps cannot ensure that x 0 lies precisely on the embedding of a word. To solve this problem, Diffusion-LM <ref type="bibr">(Li et al., 2022)</ref> predicts the initial input x 0 directly in their objective functions.</p><p>Partial noising and conditional denoising Dif-fuSeq <ref type="bibr" target="#b11">(Gong et al., 2022)</ref> connects the conditional text c and the target text x, and adds noise only to the target text x in forward process while denoising only x in the denoising process. In contrast to Diffusion-LM's approach (Li et al., 2022) of classifier-guided diffusion, DiffuSeq <ref type="bibr" target="#b11">(Gong et al., 2022)</ref> employs a method of classifier-free diffusion that is directed by spatial points. Thus, the system is capable of producing conditional generations in the absence of external classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Sampling from Latent Space</head><p>Asymmetric Time Intervals Time step plays a critical role in diffusion models. During typical reverse diffusion, symmetric time intervals are often used for both state transition and time reduction, resulting in shared t for f (x t , t). However, <ref type="bibr">Chen et al. (2023b)</ref> shows experimentally that when taking a larger step, using asymmetric time intervals with f (x t , t ′ ), implemented via a simple manipulation of time scheduling at generation, can lead to improved sample quality.</p><p>Self-Conditioning When estimating the data sample by the denoising network f at a time step, conditioning the network directly on its previously estimated samples (as opposed to discarding them) can provide better sample quality <ref type="bibr">(Chen et al., 2023b)</ref>.</p><p>Time Warping Dieleman et al. ( <ref type="formula">2022</ref>) introduces time warping, an active learning strategy that automatically adapts the distribution of noise levels sampled during training to maximize efficiency. The method alters the relative weighting of the noise levels corresponding to different time steps t. To sample t non-uniformly in practice, the inverse transform sampling can be used: first generate uniform samples u ∈ [0, 1] and then warp them using the inverse cumulative distribution function (CDF) of the distribution which corresponds to the desired weighting: t = F -(u). This time warping procedure is equivalent to time reweighting in expectation, but more statistically efficient. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Challenges &amp; Future Directions</head><p>In this section, we advance potential lines of inquiry that are both contemporarily significant and intellectually deserving of investigation (Figure <ref type="figure" target="#fig_6">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">General Challenges</head><p>Latent Space Restriction Diffusion models impose a restriction on the latent space representations, as the dimensions of latent vectors and inputs must be the same. This constraint limits the representational power of the latent vector.</p><p>Computational Cost The convergence of diffusion models requires a large number of iterations, which can lead to significant computational costs, especially when dealing with large datasets.</p><p>Sensitivity Diffusion models can be very sensitive to the choice of hyperparameters, such as diffusion coefficient, time step size, number of diffusion steps, etc., which can lead to suboptimal performance or even failure to converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependence on diffusion process assumptions</head><p>Diffusion models rely on the assumption that information diffuses smoothly and uniformly across the data, which may not always hold in practice. Given perfect mathematical formulation, the diffusion process itself might not be intuitive enough. For instance, optimizing from a totally noisy distribution is quite different to human mind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limited interpretability and explainabilities</head><p>The black-box nature of diffusion models makes it challenging to understand how they make decisions, limiting their interpretability. For instance, the latent vectors learned from diffusion models do not have any linguistic or structural explainabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">NLP-Specific Challenges</head><p>Token Rounding Errors The learned embeddings through embedding diffusion models define a mapping from discrete text to the continuous x 0 . We now describe the inverse process of rounding a predicted x 0 back to discrete text. Rounding is achieved by choosing the most probable word for each position. However, empirically, the model fails to generate x 0 that commits to a single word <ref type="bibr">(Li et al., 2022)</ref>.</p><p>High Perplexity As stated in <ref type="bibr">Li et al. (2022)</ref>; <ref type="bibr" target="#b24">Lovelace et al. (2022)</ref>, the perplexity from diffusion models lags behind AR models. However, measuring perplexity with a pretrained AR model such as GPT-2 may bias the metric towards AR models. Besides, previous studies have demonstrated that generating text with low perplexity does not necessarily imply high quality, but rather suggests degenerate behavior. <ref type="bibr" target="#b26">(Nadeem et al., 2020;</ref><ref type="bibr" target="#b44">Zhang et al., 2021)</ref>. Hence, better metrics which have a stronger correlation with human judgements of quality are needed. For this factor, <ref type="bibr" target="#b29">Pillutla et al. (2021)</ref> proposed MAUVE Score, a metric for openended text generation that compares the distribution of generated text with that of reference text using divergence frontiers, to better correlate with human judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Potential Future Directions</head><p>More Advanced Ways to connect Transformers How to better combine the spatiality of Transformer and temporality of Diffusion is a tricky question since the ideologies for Transformer and Diffusion are from totally different perspectives. Common architectures from our surveyed paper make The time step t included in the neural net through a Transformer sinusoidal position embedding in each block. And currently people just diffuse the whole sequence of the sentences, diffusion process on single token might be interesting to try on. More variations of injecting Transformers into Diffusion might be needed to explore and deeper analysis is needed with strong foundations.</p><p>Large Scaled Diffusion Language Models with impressive few-shot learning capabilities Giant language modeling has made significant strides in recent years and has become a dominant area of research in artificial intelligence. With advances in deep learning and natural language processing, large language models like GPT-3 have shown impressive abilities in tasks such as language translation, text generation, question-answering, and even programming. Currently only SED <ref type="bibr" target="#b39">(Strudel et al., 2023)</ref> has studied the scaling issues for diffusion models in NLP, the enormous potential of Large-Scale Diffusion Language Modeling in few-shot learning warrants further exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multimodal Diffusion Modeling</head><p>In recent years, there has been a growing interest in developing visual language models (VLMs), which are deep learning models that can understand the relationship between images and natural language. The amazing few-shot performance of VLMs shows great potential to transform how machines interact with the visual world and language, such as Vision-Language Pre-training (ViLBERT) model from Facebook AI Research (FAIR) and the Georgia Institute of Technology, and Flamingo from DeepMind. However, current VLMs are all based on Transformers, the incorporation of Diffusion Models presents vast potential for exploration and discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This survey paper extensively discusses the formulations, strengths, limitations, and applications of diffusion models in NLP. We conduct a comprehensive comparison between diffusion models and alternative generative models, focusing on autoregressive (AR) models. Additionally, we explore the integration of the Transformer architecture with diffusion models across various architectures.</p><p>Our findings demonstrate the significant advantages of diffusion models over AR models. They excel in parallel generation, enabling faster and more efficient text generation. Diffusion models also demonstrate superior performance in sentence interpolation, token-level controls, and robustness to input corruption. Further research on integrating Transformers into diffusion models and developing multimodal and large-scale diffusion language models for few-shot learning is crucial.</p><p>In summary, this survey paper provides a comprehensive overview of diffusion models in NLP, highlighting their benefits, comparative analysis with AR models, and avenues for future research. We hope it can contribute to the understanding and advancement of diffusion models in the field of NLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The selection of diffusion models included in this paper may introduce a bias based on our knowledge and availability of resources. This could potentially exclude relevant diffusion models that were not considered or well-known at the time of the survey. It is crucial to acknowledge that the selection of specific models and the exclusion of others can impact the comprehensiveness and generalizability of the findings. Another limitation pertains to the understanding and interpretation of the inner workings and decision-making processes of the surveyed diffusion models. Diffusion models in NLP, particularly those employing deep learning techniques, are often regarded as black-box models with limited interpretability. The lack of interpretability can impede the trust and acceptance of diffusion models in practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>Diffusion models in NLP may be influenced by biases present in the training data, highlighting the need to consider the ethical implications of deploying biased models in real-world applications. Furthermore, the impact of diffusion models in NLP extends to shaping public opinion, influencing decision-making processes, and affecting social dynamics. Therefore, we prioritize responsible use and communication of the findings in this paper, avoiding sensationalism, misrepresentation, or overgeneralization of the capabilities and limitations of diffusion models in NLP to ensure a well-rounded understanding among the public.</p><p>Table <ref type="table" target="#tab_0">1</ref>: To classify existing models, we consider three criteria: the task, the denoising condition, and the underlying approach (architecture). Additionally, we list the data sets and evaluation metrics on which the surveyed models are applied. We use the following abbreviations in the architecture column: D3PM (Discrete Denoising Diffusion Probabilistic Models), SUNDAE (Step-unrolled Denoising Autoencoders for Text Generation), DiffusionBERT (Improving Generative Masked Language Models with Diffusion Models), SSD-LM (Semi-autoregressive Simplexbased Diffusion Language Model for Text Generation and Modular Control), Bit Diffusion (Generating Discrete Data using Diffusion Models with Self-Conditioning), DiffusER (Discrete Diffusion via Edit-based Reconstruction), SED (Self-conditioned Embedding Diffusion for Text Generation), CDCD (Continuous diffusion for categorical data)</p><p>paper Tasks Denoising Condition Architecture Datasets Discrete Diffusion Modes ? char-level text and image generation unconditional D3PMs text8, LM1B, CIFAR-10 ? unconditional text generation and unsupervised spell-checking unconditional Multinomial Diffusion text8, enwik8 ? machine translation and unconditional text generation unconditional SUNDAE WMT'14, C4, a dataset of Python code ? unconditional text generation unconditional DiffusionBERT LM1B ? unconditional text generation and sentiment controlled text generation unconditional SSD-LM OpenWebText ? categorical image generations and image captioning unconditional Bit Diffusion CIFAR-10, ImageNET; MSCOCO 2017 ? machine translation, summarization, and style transfer unconditional DiffusER WMT'14, CNN/DailyMail, Yelp Embedding Diffusion Modes ? controllable text generation unconditional, classifier guidance Diffusion-LM E2E, ROCStories ? sequence to sequence text generation classifier-free conditional DiffuSeq CCD, Quasar-T, Newsela-Auto and Wiki-Auto, QQP ? prompt completion and infilling, machine translation classifier-free conditional CDCD MassiveText, C4, WMT2014, WMT2020 ? machine translation and text summarization classifier-free conditional Difformer IWSLT14, WMT14, WMT16, Gigaword ? sequenceto-sequence text generation classifier-free conditional SeqDiffuSeq CCD, Quasar-T, Wiki-Auto, QQP, IWSLT14 ? conditional and unconditional text generation unconditional, classifier-free guidance SED C4</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The yearly number of both published and preprinted papers on diffusion models for NLP. For year 2023, the blue bar shows the number collected until the end of April 2023, and the dashed gray bar shows the estimated number for the whole year.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The structures for Discrete Diffusion Models and Embedding Diffusion Models. In Discrete Diffusion Models, the tokens are categorized into categorical values. The figure shows how each token represents a prescribed action to be taken. On the other hand, the Embedding Diffusion Models method involves encoding the entire input sequence into embeddings, followed by applying the diffusion process.</figDesc><graphic coords="3,90.41,76.03,213.33,103.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Figure 3: The comparison between diffusion-based language models and autoregressive language models: diffusion LM iteratively denoises a sequence of Gaussian vectors into word vectors, while AR language model predicts the next word in a sequence of words based on the previous predictions.</figDesc><graphic coords="7,113.19,149.79,164.27,145.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>) and Diffusion Models in NLP. Token-level Controls of diffusion models include syntactic structure, parse trees, semantic content, parts-of-speech, etc. In terms of training complexity, diffusion models employ multiple rounds of diffusion steps T to generate the entire sequence. Each diffusion step involves optimizing the objective function to capture the denoising process. Specifically, Transformer models are utilized to model the denoising process within each diffusion step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Illustration for how to incorporate Transformers architecture with diffusion models in NLP.level of control enables precise modifications and interventions in the generated sequences, enhancing the interpretability and applicability of diffusion models in diverse downstream tasks.• Robustness to Input Corruption: Diffusion models exhibit enhanced robustness due to their denoising mechanism that facilitates the reconstruction of the original input. This process aids in mitigating errors and noise present in the input sequence. Consequently, diffusion models are capable of capturing a broader spectrum of input variations by learning a more adaptable distribution over the input data. In summary, diffusion models offer empirical advantages over AR models, encompassing parallel generation, text interpolation, and advanced tokenlevel controls. These characteristics underscore the potential of diffusion models in various text generation scenarios, emphasizing their efficiency, coherency, and flexibility. In addition to the advantages discussed in Table3, we also identify two significant disadvantages of diffusion models compared to AR models in terms of training complexity and interpretability.• Training Complexity: Diffusion models are more difficult to train than AR models due to their more complex architecture and optimiza-</figDesc><graphic coords="8,113.99,211.34,384.00,142.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Algorithms proposed to adapt the discrete data. Details of the proposed architectures are described in Section 3. Details of the algorithms are described in Section 5.</figDesc><graphic coords="11,92.66,66.65,426.70,197.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Challenges and future directions we conclude based on the surveyed papers.</figDesc><graphic coords="11,314.00,314.47,205.34,172.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of discrete and embedding diffusion models.</figDesc><table><row><cell>Model</cell><cell>Tasks</cell><cell>Schedule</cell><cell>Sampling</cell><cell></cell></row><row><cell></cell><cell cols="2">Discrete Diffusion Models</cell><cell></cell><cell></cell></row><row><cell>Multinomial Diffusion (Hoogeboom et al., 2021)</cell><cell>unconditional text generation, unsupervised spell-checking</cell><cell>Transition matrices</cell><cell>-</cell><cell></cell></row><row><cell>D3PM (Discrete Denoising Diffusion Probabilistic Models) (Austin et al., 2021b)</cell><cell>char-level text and image gen-eration</cell><cell>Uniform Transition Matrices</cell><cell>-</cell><cell></cell></row><row><cell>Zero-shot Diffusion (Nachmani and Dovrat, 2021)</cell><cell>machine translation</cell><cell>Partial Noising</cell><cell cols="2">Classifier-free conditional denoising</cell></row><row><cell>SUNDAE (Step-unrolled Denoising Au-toencoders) (Savinov et al., 2021)</cell><cell>machine translation and uncon-ditional text generation</cell><cell>Uniform Transition Matrices</cell><cell cols="2">Low-temperature sampling, Argmax-unrolled decoding, fewer token update</cell></row><row><cell>DiffusionBERT (He et al., 2022)</cell><cell>unconditional text generation</cell><cell>Spindle</cell><cell>x0-parameterization</cell><cell></cell></row><row><cell>SSD-LM (Semi-autoregressive Simplex-based Diffusion) (Han et al., 2022)</cell><cell>unconditional and controlled text generation</cell><cell>Logits generation</cell><cell cols="2">Greedy projection, Sam-pling, Multi-hot</cell></row><row><cell>Bit Diffusion (Generating Discrete Data using Diffusion Models with Self-Conditioning) (Chen et al., 2023b)</cell><cell>categorical image generation and image captioning</cell><cell>-</cell><cell cols="2">Self-Conditioning, Asym-metric Time Intervals</cell></row><row><cell>DiffusER (Discrete Diffusion via Edit-based Reconstruction) (Reid et al., 2023)</cell><cell>machine translation, summa-rization, and style transfer</cell><cell>Edit-based Corrup-tion</cell><cell cols="2">Beam Search, 2D Beam Search, Nucleus Sampling</cell></row><row><cell cols="2">Masked-Diffuse LM (Chen et al., 2023a) controllable text generation</cell><cell>Mask with Entropy and Reluency</cell><cell>Minimum Bayes Risk</cell><cell></cell></row><row><cell>RDMs (Reparameterized Discrete Diffu-sion Model) (Zheng et al., 2023)</cell><cell>machine translation</cell><cell>-</cell><cell cols="2">Adaptive Routing Strategy</cell></row><row><cell></cell><cell cols="2">Embedding Diffusion Models</cell><cell></cell><cell></cell></row><row><cell>Diffusion-LM (Li et al., 2022)</cell><cell>controllable text generation</cell><cell>Cosine</cell><cell cols="2">Rounding Step and MBR</cell></row><row><cell>DiffuSeq (Gong et al., 2022)</cell><cell>dialogue, question generation, simplification, paraphrasing</cell><cell>Partial Noising</cell><cell cols="2">Classifier-free Conditional Denoising, MBR</cell></row><row><cell>SED (Self-conditioned Embedding Dif-fusion) (Strudel et al., 2023)</cell><cell>conditional and unconditional text generation, text infilling</cell><cell>Cosine</cell><cell>Self-conditioning</cell><cell></cell></row><row><cell>CDCD (Continuous diffusion for cate-gorical data) (Dieleman et al., 2022)</cell><cell>prompt completion and infill-ing, machine translation</cell><cell>Partial Noising, Time warping</cell><cell>Self-conditioning, warping</cell><cell>Time</cell></row><row><cell>Difformer (Gao et al., 2022)</cell><cell>machine translation and ab-stractive text summarization</cell><cell>Noise Factor</cell><cell>2D parallel decoding</cell><cell></cell></row><row><cell>SeqDiffuSeq (Yuan et al., 2022)</cell><cell>dialogue, question generation, simplification, paraphrasing, translation</cell><cell>Adaptive noise sched-ule</cell><cell>Self-conditioning</cell><cell></cell></row><row><cell>DiffuSum (Zhang et al., 2023)</cell><cell>extractive text summarization</cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell>GENIE (Diffusion Language Model Pre-training Framework for Text Generation) (Lin et al., 2023)</cell><cell>text summarization, common sense generation</cell><cell>-</cell><cell cols="2">Continuous Paragraph De-noise</cell></row><row><cell>DiNoiSer (Diffused Conditional Se-quence Learning by Manipulating Noises) (Ye et al., 2023)</cell><cell>machine translation, text sim-plification, paraphrasing</cell><cell>Manipulated Noises</cell><cell cols="2">Self-conditioning, Condition-enhanced Denoiser, Beam Search, Minimum Bayes Risk</cell></row></table><note><p>involves independent decisions to either resample or retain values, with resampling performed from a uniform categorical distribution.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparative Analysis of Autoregressive (AR</figDesc><table><row><cell>• Text Interpolation: diffusion models demon-strate a superior capacity for text interpolation.</cell></row><row><cell>Leveraging the denoising process inherent in</cell></row><row><cell>their design, diffusion models can generate inter-</cell></row><row><cell>mediate sentences between two given sentences,</cell></row><row><cell>ensuring smooth transitions and coherent outputs.</cell></row><row><cell>This capability enhances the overall fluency and</cell></row><row><cell>cohesiveness of generated text.</cell></row><row><cell>• Token-level Controls: Diffusion models provide advanced Token-level Controls, facilitating fine-</cell></row><row><cell>grained manipulation of generated outputs. This</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This project is supported in part by <rs type="grantName">Sony Research Grant</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_4savPmM">
					<orgName type="grant-name">Sony Research Grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">2</ref>: This table summarizes the techniques each architecture uses or newly proposes for noise schedule and sampling, as well as the evaluation metrics that are applied. We also consider whether the architectures use the pre-trained models or not for further analysis. We use the following abbreviations for the sampling and evaluation metrics columns: PPL (Perplexity), MBR (Minimum Bayes Risk), bpc (bits per character), bpb (bits per raw byte), dist-1 (distinct unigram), div-4 (diverse 4-gram) </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Daniel Tarlow, and Rianne van den Berg. 2021a. Structured denoising diffusion models in discrete state-spaces</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Daniel Tarlow, and Rianne van den Berg. 2021b. Structured denoising diffusion models in discrete state-spaces</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Daniel Tarlow, and Rianne van den Berg. 2021c. Structured denoising diffusion models in discrete state-spaces</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<idno>ArXiv, abs/2107.03006</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of machine learning research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><surname>Gray</surname></persName>
		</author>
		<imprint>
			<pubPlace>Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</pubPlace>
		</imprint>
	</monogr>
	<note>Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Alex Smola, and Diyi Yang. 2023a. A cheaper and better diffusion language model with soft-masked noise</title>
		<author>
			<persName><forename type="first">Jiaao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Analog bits: Generating discrete data using diffusion models with self-conditioning</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Ruixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Diffusion models beat gans on image synthesis</title>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Sander Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Sartran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Roshannai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaroslav</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conor</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curtis</forename><surname>Durkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Hawthorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><surname>Adler</surname></persName>
		</author>
		<title level="m">Continuous diffusion for categorical data</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Difformer: Empowering diffusion models on the embedding space for text generation</title>
		<author>
			<persName><forename type="first">Zhujin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junliang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linli</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Diffuseq: Sequence to sequence text generation with diffusion models</title>
		<author>
			<persName><forename type="first">Shansan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangtao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Generative adversarial networks</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Ssd-lm: Semi-autoregressive simplex-based diffusion language model for text generation and modular control</title>
		<author>
			<persName><forename type="first">Xiaochuang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Diffusionbert: Improving generative masked language models with diffusion models</title>
		<author>
			<persName><forename type="first">Zhengfu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianxiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuanning</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Xuanjing Huang, and Xipeng Qiu</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Training compute-optimal large language models</title>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Sifre</surname></persName>
		</author>
		<idno>ArXiv, abs/2203.15556</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Argmax flows and multinomial diffusion: Learning categorical distributions</title>
		<author>
			<persName><forename type="first">Emiel</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didrik</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priyank</forename><surname>Jaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Forré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On density estimation with diffusion models</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Diederik P Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Autoencoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Glow: Generative flow with invertible 1x1 convolutions. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Dhariwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Denoising sequence-to-sequence pre-training for natural language generation</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>Bart</pubPlace>
		</imprint>
	</monogr>
	<note>translation, and comprehension</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Thickstun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Hashimoto</surname></persName>
		</author>
		<title level="m">Diffusionlm improves controllable text generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Text generation with diffusion language models: A pre-training approach with continuous paragraph denoise</title>
		<author>
			<persName><forename type="first">Zhenghao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Latent diffusion for language generation</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Lovelace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliot</forename><surname>Shekhtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Zero-shot translation using diffusion models</title>
		<author>
			<persName><forename type="first">Eliya</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaked</forename><surname>Dovrat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A systematic characterization of sampling algorithms for open-ended language generation</title>
		<author>
			<persName><forename type="first">Moin</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianxing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</title>
		<meeting>the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing<address><addrLine>Suzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="334" to="346" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theo</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Mauve: Measuring the gap between neural text and human text using divergence frontiers</title>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Pillutla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Thickstun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Harchaoui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pre-trained models for natural language processing: A survey</title>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianxiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yige</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Technological Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1872" to="1897" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>text transformer</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DiffusER: Diffusion via edit-based reconstruction</title>
		<author>
			<persName><forename type="first">Machel</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Josua Hellendoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning</title>
		<meeting>the 31st International Conference on Machine Learning<address><addrLine>Bejing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Highresolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Ommer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Erich Elsen, and Aaron van den Oord. 2021. Stepunrolled denoising autoencoders for text generation</title>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikolaj</forename><surname>Binkowski</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Niru Maheswaranathan, and Surya Ganguli. 2015a. Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Weiss</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Niru Maheswaranathan, and Surya Ganguli. 2015b. Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Self-conditioned embedding diffusion for text generation</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Sussman Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Leblond</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Generating text with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Dinoiser: Diffused conditional sequence learning by manipulating noises</title>
		<author>
			<persName><forename type="first">Jiasheng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaixiang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihua</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Seqdiffuseq: Text diffusion with encoder-decoder transformers</title>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Diffusum: Generation enhanced extractive summarization with diffusion</title>
		<author>
			<persName><forename type="first">Haopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Trading off diversity and quality in natural language generation</title>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Duckworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)</title>
		<meeting>the Workshop on Human Evaluation of NLP Systems (HumEval)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="25" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A reparameterized discrete diffusion model for text generation</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianbo</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
